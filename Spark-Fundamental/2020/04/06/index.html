<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=PingFang SC:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhangruochi.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Spark Fundamental">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark Fundamental">
<meta property="og:url" content="https://zhangruochi.com/Spark-Fundamental/2020/04/06/index.html">
<meta property="og:site_name" content="RUOCHI.AI">
<meta property="og:description" content="Spark Fundamental">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zhangruochi.com/Spark-Fundamental/2020/04/06/1.png">
<meta property="og:image" content="https://zhangruochi.com/Spark-Fundamental/2020/04/06/1.png">
<meta property="og:image" content="https://zhangruochi.com/Spark-Fundamental/2020/04/06/2.png">
<meta property="og:image" content="https://zhangruochi.com/Spark-Fundamental/2020/04/06/3.png">
<meta property="og:image" content="https://zhangruochi.com/Spark-Fundamental/2020/04/06/4.png">
<meta property="og:image" content="https://zhangruochi.com/Spark-Fundamental/2020/04/06/5.png">
<meta property="og:image" content="https://zhangruochi.com/Spark-Fundamental/2020/04/06/6.png">
<meta property="article:published_time" content="2020-04-06T14:12:46.000Z">
<meta property="article:modified_time" content="2022-01-18T07:41:08.973Z">
<meta property="article:author" content="Ruochi Zhang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhangruochi.com/Spark-Fundamental/2020/04/06/1.png">

<link rel="canonical" href="https://zhangruochi.com/Spark-Fundamental/2020/04/06/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Spark Fundamental | RUOCHI.AI</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RUOCHI.AI</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Spark-Fundamental/2020/04/06/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Spark Fundamental
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-06 22:12:46" itemprop="dateCreated datePublished" datetime="2020-04-06T22:12:46+08:00">2020-04-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-01-18 15:41:08" itemprop="dateModified" datetime="2022-01-18T15:41:08+08:00">2022-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Big-Data-Architecture/" itemprop="url" rel="index"><span itemprop="name">Big Data Architecture</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Big-Data-Architecture/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Spark-Fundamental/2020/04/06/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Spark-Fundamental/2020/04/06/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
            <div class="post-description">Spark Fundamental</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="basic-concepts">Basic concepts</h1>
<h2 id="work-with-the-sparkcontext-object">Work with the SparkContext object</h2>
<p>The Spark driver application uses the SparkContext object to allow a programming interface to interact with the driver application. The SparkContext object tells Spark how and where to access a cluster.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext, SparkConf</span><br><span class="line">conf = SparkConf().setAppName(appName).setMaster(master)</span><br><span class="line">sc = SparkContext(conf=conf)</span><br></pre></td></tr></table></figure>
<h2 id="work-with-resilient-distributed-datasets">Work with Resilient Distributed Datasets</h2>
<p>Spark uses an abstraction for working with data called a Resilient Distributed Dataset (RDD). An RDD is a collection of elements that can be operated on in parallel. RDDs are immutable, so you can't update the data in them. To update data in an RDD, you must create a new RDD. In Spark, all work is done by creating new RDDs, transforming existing RDDs, or using RDDs to compute results. When working with RDDs, the Spark driver application automatically distributes the work across the cluster. You can construct RDDs by parallelizing existing Python collections (lists), by manipulating RDDs, or by manipulating files in HDFS or any other storage system. You can run these types of methods on RDDs:</p>
<ul>
<li><strong>Actions</strong>: query the data and return values</li>
<li><strong>Transformations</strong>: manipulate data values and return pointers to new RDDs.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a Python collection of the numbers 1 - 10</span></span><br><span class="line">x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Put the collection into an RDD named x_nbr_rdd using the parallelize method</span></span><br><span class="line">x_nbr_rdd = sc.parallelize(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># View the first element in the RDD</span></span><br><span class="line"><span class="comment"># Each number in the collection is in a different element in the RDD. Because the first() method returned a value, it is an action.</span></span><br><span class="line">x_nbr_rdd.first()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now view the first five elements in the RDD</span></span><br><span class="line">x_nbr_rdd.take(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create another RDD</span></span><br><span class="line">y = [<span class="string">&quot;Hello Human&quot;</span>, <span class="string">&quot;My Name is Spark&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># y_str_rdd = sc.parallelize(y)</span></span><br><span class="line">y_str_rdd.take(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="manipulate-data-in-rdds">Manipulate data in RDDs</h2>
<p>Remember that to manipulate data, you use transformation functions. Here are some common Python transformation functions that you'll be using in this notebook: - <code>map(func)</code>: returns a new RDD with the results of running the specified function on each element - <code>filter(func)</code>: returns a new RDD with the elements for which the specified function returns true - <code>distinct([numTasks]))</code>: returns a new RDD that contains the distinct elements of the source RDD - <code>flatMap(func)</code>: returns a new RDD by first running the specified function on all elements, returning 0 or more results for each original element, and then flattening the results into individual elements You can also create functions that run a single expression and don't have a name with the Python lambda keyword. For example, this function returns the sum of its arguments: <code>lambda a , b : a + b</code>.</p>
<h3 id="update-numeric-values">Update numeric values</h3>
<p>Run the <code>map()</code> function with the lambda keyword to replace each element, X, in your first RDD (the one that has numeric values) with X+1. Because RDDs are <strong>immutable</strong>, you need to specify a new RDD name.</p>
<p><strong>Be careful</strong> with the collect method! It returns all elements of the RDD to the driver. Returning a large data set might be not be very useful. No-one wants to scroll through a million rows!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_nbr_rdd_2 = x_nbr_rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now look at the elements of the new RDD</span></span><br><span class="line">x_nbr_rdd_2.collect()</span><br></pre></td></tr></table></figure>
<h3 id="add-numbers-in-an-array">Add numbers in an array</h3>
<p>An array of values is a common data format where multiple values are contained in one element. You can manipulate the individual values if you split them up into separate elements. Create an array of numbers by including quotation marks around the whole set of numbers. If you omit the quotation marks, you get a collection of numbers instead of an array.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X = [<span class="string">&quot;1,2,3,4,5,6,7,8,9,10&quot;</span>]</span><br><span class="line"></span><br><span class="line">y_rd = sc.parallelize(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split the values at commas and add values in the positions 2 and 9 in the array. Keep in mind that an array starts with position 0. Use a backslash character, \, to break the line of code for clarity.</span></span><br><span class="line">Sum_rd = y_rd.<span class="built_in">map</span>(<span class="keyword">lambda</span> y: y.split(<span class="string">&quot;,&quot;</span>)).\</span><br><span class="line"><span class="built_in">map</span>(<span class="keyword">lambda</span> y: (<span class="built_in">int</span>(y[<span class="number">2</span>])+<span class="built_in">int</span>(y[<span class="number">9</span>])))</span><br><span class="line"></span><br><span class="line">Sum_rd.first()</span><br></pre></td></tr></table></figure>
<h3 id="split-and-count-text-strings">Split and count text strings</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Words = [<span class="string">&quot;Hello Human. I&#x27;m Spark and I love running analysis on data.&quot;</span>]</span><br><span class="line">words_rd = sc.parallelize(Words)</span><br><span class="line">words_rd.first()</span><br><span class="line"></span><br><span class="line">Words_rd2 = words_rd.<span class="built_in">map</span>(<span class="keyword">lambda</span> line: line.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">Words_rd2.first()</span><br><span class="line"></span><br><span class="line">Words_rd2.count()</span><br></pre></td></tr></table></figure>
<h3 id="count-words-with-a-pair-rdd">Count words with a pair RDD</h3>
<p>A common way to count the number of instances of words in an RDD is to create a pair RDD. A pair RDD converts each word into a key-value pair: the word is the key and the number 1 is the value. Because the values are all 1, when you add the values for a particular word, you get the number of instances of that word.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">z = [<span class="string">&quot;First,Line&quot;</span>, <span class="string">&quot;Second,Line&quot;</span>, <span class="string">&quot;and,Third,Line&quot;</span>]</span><br><span class="line">z_str_rdd = sc.parallelize(z)</span><br><span class="line">z_str_rdd.first()</span><br><span class="line"></span><br><span class="line">z_str_rdd_split_flatmap = z_str_rdd.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">z_str_rdd_split_flatmap.collect()</span><br><span class="line"></span><br><span class="line">countWords = z_str_rdd_split_flatmap.<span class="built_in">map</span>(<span class="keyword">lambda</span> word:(word,<span class="number">1</span>))</span><br><span class="line">countWords.collect()</span><br><span class="line"></span><br><span class="line"><span class="comment"># [(&#x27;First&#x27;, 1),</span></span><br><span class="line"><span class="comment">#  (&#x27;Line&#x27;, 1),</span></span><br><span class="line"><span class="comment">#  (&#x27;Second&#x27;, 1),</span></span><br><span class="line"><span class="comment">#  (&#x27;Line&#x27;, 1),</span></span><br><span class="line"><span class="comment">#  (&#x27;and&#x27;, 1),</span></span><br><span class="line"><span class="comment">#  (&#x27;Third&#x27;, 1),</span></span><br><span class="line"><span class="comment">#  (&#x27;Line&#x27;, 1)]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> add</span><br><span class="line">countWords2 = countWords.reduceByKey(add)</span><br><span class="line">countWords2.collect()</span><br><span class="line"></span><br><span class="line"><span class="comment"># [(&#x27;Second&#x27;, 1), (&#x27;Line&#x27;, 3), (&#x27;First&#x27;, 1), (&#x27;and&#x27;, 1), (&#x27;Third&#x27;, 1)]</span></span><br></pre></td></tr></table></figure>
<h3 id="filter-data">Filter data</h3>
<p>The filter command creates a new RDD from another RDD based on a filter criteria. The filter syntax is: <code>.filter(lambda line: "Filter Criteria Value" in line)</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">words_rd3 = z_str_rdd_split_flatmap.<span class="built_in">filter</span>(<span class="keyword">lambda</span> line: <span class="string">&quot;Second&quot;</span> <span class="keyword">in</span> line) </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;The count of words &quot;</span> + <span class="built_in">str</span>(words_rd3.first()))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Is: &quot;</span> + <span class="built_in">str</span>(words_rd3.count()))</span><br></pre></td></tr></table></figure>
<h1 id="querying-data">Querying data</h1>
<h2 id="enable-sql-processing">Enable SQL processing</h2>
<p>The preferred method to enable SQL processing with Spark 2.0 is to use the new SparkSession object, but you can also create a SQLContext object. Use the predefined Spark Context, sc, which contains the connection information for Spark, to create an SQLContext:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SQLContext</span><br><span class="line">sqlContext = SQLContext(sc)</span><br></pre></td></tr></table></figure>
<h2 id="create-a-dataframe">Create a DataFrame</h2>
<p>Instead of creating an RDD to read the file, you'll create a Spark DataFrame. Unlike an RDD, a DataFrame creates a <code>schema</code> around the data, which supplies the necessary structure for SQL queries. A self-describing format like JSON is ideal for DataFrames, but many other file types are supported, including text (CSV) and Parquet. Create a DataFrame: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">example1_df = sqlContext.read.json(<span class="string">&quot;world_bank.json.gz&quot;</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="create-a-table">Create a table</h2>
<p>SQL statements must be run against a table. Create a table that's a pointer to the DataFrame:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">example1_df.registerTempTable(<span class="string">&quot;world_bank&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="run-sql-queries">Run SQL queries</h2>
<p>You must define a new DataFrame for the results of the SQL query and put the SQL statement inside the sqlContext.sql() method. Run the following cell to select all columns from the table and print information about the resulting DataFrame and schema of the data:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">temp_df =  sqlContext.sql(<span class="string">&quot;select * from world_bank&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (<span class="built_in">type</span>(temp_df))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;*&quot;</span> * <span class="number">20</span>)</span><br><span class="line"><span class="built_in">print</span> (temp_df)</span><br></pre></td></tr></table></figure>
<h3 id="display-query-results-with-a-pandas-dataframe">Display query results with a pandas DataFrame</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">sqlContext.sql(<span class="string">&quot;select id, borrower from world_bank limit 2&quot;</span>).toPandas()</span><br></pre></td></tr></table></figure>
<h3 id="run-a-group-by-query">Run a group by query</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">select</span></span><br><span class="line"><span class="string">    regionname ,</span></span><br><span class="line"><span class="string">    count(*) as project_count</span></span><br><span class="line"><span class="string">from world_bank</span></span><br><span class="line"><span class="string">group by regionname </span></span><br><span class="line"><span class="string">order by count(*) desc</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">sqlContext.sql(query).toPandas()</span><br></pre></td></tr></table></figure>
<h3 id="run-a-subselect-query">Run a subselect query</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">select * from</span></span><br><span class="line"><span class="string">    (select</span></span><br><span class="line"><span class="string">        regionname ,</span></span><br><span class="line"><span class="string">        count(*) as project_count</span></span><br><span class="line"><span class="string">    from world_bank</span></span><br><span class="line"><span class="string">    group by regionname </span></span><br><span class="line"><span class="string">    order by count(*) desc) table_alias</span></span><br><span class="line"><span class="string">limit 2</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">sqlContext.sql(query).toPandas()</span><br></pre></td></tr></table></figure>
<h2 id="convert-rdds-to-dataframes">Convert RDDs to DataFrames</h2>
<p>If you want to run SQL queries on an existing RDD, you must convert the RDD to a DataFrame. The main difference between RDDs and DataFrames is whether the columns are named. You'll create an RDD and then convert it to a DataFrame in two different ways: - Apply a schema - Create rows with named columns</p>
<h3 id="create-a-simple-rdd">Create a simple RDD</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">data_e2 = []</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">6</span>):</span><br><span class="line">    random_int = <span class="built_in">int</span>(random.random() * <span class="number">10</span>)</span><br><span class="line">    data_e2.append([x, random_int, random_int^<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">rdd_example2 = sc.parallelize(data_e2)</span><br><span class="line"><span class="built_in">print</span> (rdd_example2.collect())</span><br><span class="line"></span><br><span class="line"><span class="comment"># [[1, 1, 3], [2, 3, 1], [3, 1, 3], [4, 8, 10], [5, 0, 2]]</span></span><br></pre></td></tr></table></figure>
<h3 id="apply-a-schema">Apply a schema</h3>
<p>You'll use the <code>StructField</code> method to create a schema object that's based on a string, apply the schema to the RDD to create a DataFrame, and then create a table to run SQL queries on. Define your schema columns as a string:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">schemaString = <span class="string">&quot;ID VAL1 VAL2&quot;</span></span><br></pre></td></tr></table></figure>
<p>Assign header information with the StructField method and create the schema with the <code>StructType</code> method:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fields = [StructField(field_name, StringType(), <span class="literal">True</span>) <span class="keyword">for</span> field_name <span class="keyword">in</span> schemaString.split()]</span><br><span class="line">schema = StructType(fields)</span><br></pre></td></tr></table></figure>
<p>Apply the schema to the RDD with the createDataFrame method</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">schemaExample = sqlContext.createDataFrame(rdd_example2, schema)</span><br></pre></td></tr></table></figure>
<p>Register the DataFrame as a table <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Register the DataFrame as a table</span></span><br><span class="line">schemaExample.registerTempTable(<span class="string">&quot;example2&quot;</span>)</span><br></pre></td></tr></table></figure></p>
<p>View the data</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> (schemaExample.collect())</span><br><span class="line"></span><br><span class="line"><span class="comment"># [Row(ID=&#x27;1&#x27;, VAL1=&#x27;1&#x27;, VAL2=&#x27;3&#x27;), Row(ID=&#x27;2&#x27;, VAL1=&#x27;3&#x27;, VAL2=&#x27;1&#x27;), Row(ID=&#x27;3&#x27;, VAL1=&#x27;1&#x27;, VAL2=&#x27;3&#x27;), Row(ID=&#x27;4&#x27;, VAL1=&#x27;8&#x27;, VAL2=&#x27;10&#x27;), Row(ID=&#x27;5&#x27;, VAL1=&#x27;0&#x27;, VAL2=&#x27;2&#x27;)]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># You can reference the columns names in DataFrames</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> schemaExample.take(<span class="number">2</span>):</span><br><span class="line">    <span class="built_in">print</span> (row.ID, row.VAL1, row.VAL2)</span><br></pre></td></tr></table></figure>
<p>Run a simple SQL query</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqlContext.sql(<span class="string">&quot;select * from example2&quot;</span>).toPandas()</span><br></pre></td></tr></table></figure>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="1.png" width = "20%" height="20%">
</center>
<h3 id="create-rows-with-named-columns">Create rows with named columns</h3>
<p>You'll create an RDD with named columns and then convert it to a DataFrame and a table. Create a new RDD and specify the names of the columns with the map method:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row</span><br><span class="line"></span><br><span class="line">rdd_example3 = rdd_example2.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: Row(<span class="built_in">id</span>=x[<span class="number">0</span>], val1=x[<span class="number">1</span>], val2=x[<span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (rdd_example3.collect()) </span><br><span class="line"></span><br><span class="line"><span class="comment"># [Row(id=1, val1=1, val2=3), Row(id=2, val1=3, val2=1), Row(id=3, val1=1, val2=3), Row(id=4, val1=8, val2=10), Row(id=5, val1=0, val2=2)]</span></span><br></pre></td></tr></table></figure>
<p>Convert rdd_example3 to a DataFrame and register an associated table</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_example3 = rdd_example3.toDF()</span><br><span class="line">df_example3.registerTempTable(<span class="string">&quot;example3&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>Run a simple SQL query</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqlContext.sql(<span class="string">&quot;select * from example3&quot;</span>).toPandas()</span><br></pre></td></tr></table></figure>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="1.png" width = "20%" height="20%">
</center>
<h3 id="join-tables">Join tables</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Join tables example2 and example3 on the ID column:</span></span><br><span class="line"></span><br><span class="line">query = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">select</span></span><br><span class="line"><span class="string">    *</span></span><br><span class="line"><span class="string">from</span></span><br><span class="line"><span class="string">    example2 e2</span></span><br><span class="line"><span class="string">inner join example3 e3 on</span></span><br><span class="line"><span class="string">    e2.ID = e3.id</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (sqlContext.sql(query).toPandas())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Alternatively, you can join DataFrames with a Python command instead of an SQL query:</span></span><br><span class="line"></span><br><span class="line">df_example4 = df_example3.join(schemaExample, schemaExample[<span class="string">&quot;ID&quot;</span>] == df_example3[<span class="string">&quot;id&quot;</span>] )</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> df_example4.take(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span> (row)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="create-sql-functions">Create SQL functions</h2>
<p>You can create functions that run in SQL queries. First, create a Python function and test it:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">simple_function</span>(<span class="params">v</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">int</span>(v * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#test the function</span></span><br><span class="line"><span class="built_in">print</span> (simple_function(<span class="number">3</span>))</span><br></pre></td></tr></table></figure>
<p>Next, register the function as an SQL function with the registerFunction method:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqlContext.registerFunction(<span class="string">&quot;simple_function&quot;</span>, simple_function)</span><br></pre></td></tr></table></figure>
<p>Now run the function in an SQL Statement:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">select</span></span><br><span class="line"><span class="string">    ID,</span></span><br><span class="line"><span class="string">    VAL1,</span></span><br><span class="line"><span class="string">    VAL2,</span></span><br><span class="line"><span class="string">    simple_function(VAL1) as s_VAL1,</span></span><br><span class="line"><span class="string">    simple_function(VAL2) as s_VAL2</span></span><br><span class="line"><span class="string">from</span></span><br><span class="line"><span class="string"> example2</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">sqlContext.sql(query).toPandas()</span><br></pre></td></tr></table></figure>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="2.png" width = "50%" height="50%">
</center>
<p>The values in the VAL1 and VAL2 columns look like strings (10 characters instead of a number multiplied by 10). That's because string is the default data type for columns in Spark DataFrames.</p>
<h2 id="convert-a-pandas-dataframe-to-a-spark-dataframe">Convert a pandas DataFrame to a Spark DataFrame</h2>
<p>Although pandas DataFrames display data in a friendlier format, Spark DataFrames can be faster and more scalable. You'll get a new data set, create a pandas DataFrame for it, and then convert the pandas DataFrame to a Spark DataFrame.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pandas_df = pd.read_csv(<span class="string">&quot;./GoSales_Tx.csv&quot;</span>)</span><br><span class="line">pandas_df.head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert the pandas DataFrame to a Spark DataFrame with the createDataFrame method. Remember using the createDataFrame method to convert an RDD to a Spark DataFrame</span></span><br><span class="line">spark_df = sqlContext.createDataFrame(pandas_df)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Register the Spark DataFrame as a table</span></span><br><span class="line">spark_df.registerTempTable(<span class="string">&quot;gosales_tx&quot;</span>)</span><br><span class="line"></span><br><span class="line">sqlContext.sql(<span class="string">&quot;select * from gosales_tx limit 10&quot;</span>).collect()</span><br></pre></td></tr></table></figure>
<h1 id="spark-machine-learning">Spark machine learning</h1>
<p>The Spark machine learning library makes practical machine learning scalable and easy. The library consists of common machine learning algorithms and utilities, including classification, regression, clustering, collaborative filtering (this notebook!), dimensionality reduction, lower-level optimization primitives, and higher-level pipeline APIs. The library has two packages: - spark.mllib contains the original API that handles data in RDDs. It's in maintenance mode, but fully supported. - spark.ml contains a newer API for constructing ML pipelines. It handles data in DataFrames. It's being actively enhanced.</p>
<h2 id="alternating-least-squares-algorithm">Alternating least squares algorithm</h2>
<p>The alternating least squares (ALS) algorithm provides collaborative filtering between customers and products to find products that the customers might like, based on their previous purchases or ratings. The ALS algorithm creates a matrix of all customers versus all products. Most cells in the matrix are empty, which means the customer hasn't bought that product. The ALS algorithm then fills in the probability of customers buying products that they haven't bought yet, based on similarities between customer purchases and similarities between products. The algorithm uses the least squares computation to minimize the estimation errors, and alternates between fixing the customer factors and solving for product factors and fixing the product factors and solving for customer factors. You don't, however, need to understand how the ALS algorithm works to use it! Spark machine learning algorithms have default values that work well in most cases.</p>
<h2 id="get-the-data">Get the data</h2>
<p>The data set contains the transactions of an online retailer of gift items for the period from 01/12/2010 to 09/12/2011. Many of the customers are wholesalers. You'll be using a slightly modified version of UCI's Online Retail Data Set. Here's a glimpse of the data:</p>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="3.png" width = "80%" height="80%">
</center>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm <span class="string">&#x27;OnlineRetail.csv.gz&#x27;</span> -f</span><br><span class="line">wget https://raw.githubusercontent.com/rosswlewis/RecommendationPoT/master/OnlineRetail.csv.gz</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">loadRetailData = sc.textFile(<span class="string">&quot;OnlineRetail.csv.gz&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> loadRetailData.take(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span> (row)</span><br><span class="line"></span><br><span class="line"><span class="comment"># InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,CustomerID,Country</span></span><br><span class="line"><span class="comment"># 536365,85123A,WHITE HANGING HEART T-LIGHT HOLDER,6,12/1/10 8:26,2.55,17850,United Kingdom</span></span><br><span class="line"><span class="comment"># 536365,71053,WHITE METAL LANTERN,6,12/1/10 8:26,3.39,17850,United Kingdom</span></span><br><span class="line"><span class="comment"># 536365,84406B,CREAM CUPID HEARTS COAT HANGER,8,12/1/10 8:26,2.75,17850,United Kingdom</span></span><br><span class="line"><span class="comment"># 536365,84029G,KNITTED UNION FLAG HOT WATER BOTTLE,6,12/1/10 8:26,3.39,17850,United Kingdom</span></span><br></pre></td></tr></table></figure>
<h2 id="prepare-and-shape-the-data">Prepare and shape the data</h2>
<p>It's been said that preparing and shaping data is 80% of a data scientist's job. Having the right data in the right format is critical for getting accurate results. To get the data ready, complete these tasks: - Format the data - Clean the data - Create a DataFrame - Remove unneeded columns</p>
<h3 id="format-the-data">Format the data</h3>
<p>Remove the header from the RDD and split the string in each row with a comma:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">header = loadRetailData.first()</span><br><span class="line">loadRetailData = loadRetailData.<span class="built_in">filter</span>(<span class="keyword">lambda</span> line: line != header).\</span><br><span class="line">                            <span class="built_in">map</span>(<span class="keyword">lambda</span> l: l.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> loadRetailData.take(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span> (row)</span><br><span class="line"></span><br><span class="line"><span class="comment"># [&#x27;536365&#x27;, &#x27;85123A&#x27;, &#x27;WHITE HANGING HEART T-LIGHT HOLDER&#x27;, &#x27;6&#x27;, &#x27;12/1/10 8:26&#x27;, &#x27;2.55&#x27;, &#x27;17850&#x27;, &#x27;United Kingdom&#x27;]</span></span><br><span class="line"><span class="comment"># [&#x27;536365&#x27;, &#x27;71053&#x27;, &#x27;WHITE METAL LANTERN&#x27;, &#x27;6&#x27;, &#x27;12/1/10 8:26&#x27;, &#x27;3.39&#x27;, &#x27;17850&#x27;, &#x27;United Kingdom&#x27;]</span></span><br><span class="line"><span class="comment"># [&#x27;536365&#x27;, &#x27;84406B&#x27;, &#x27;CREAM CUPID HEARTS COAT HANGER&#x27;, &#x27;8&#x27;, &#x27;12/1/10 8:26&#x27;, &#x27;2.75&#x27;, &#x27;17850&#x27;, &#x27;United Kingdom&#x27;]</span></span><br><span class="line"><span class="comment"># [&#x27;536365&#x27;, &#x27;84029G&#x27;, &#x27;KNITTED UNION FLAG HOT WATER BOTTLE&#x27;, &#x27;6&#x27;, &#x27;12/1/10 8:26&#x27;, &#x27;3.39&#x27;, &#x27;17850&#x27;, &#x27;United Kingdom&#x27;]</span></span><br><span class="line"><span class="comment"># [&#x27;536365&#x27;, &#x27;84029E&#x27;, &#x27;RED WOOLLY HOTTIE WHITE HEART.&#x27;, &#x27;6&#x27;, &#x27;12/1/10 8:26&#x27;, &#x27;3.39&#x27;, &#x27;17850&#x27;, &#x27;United Kingdom&#x27;]</span></span><br></pre></td></tr></table></figure>
<h3 id="clean-the-data">Clean the data</h3>
<p>Remove the rows that have incomplete data. Keep only the rows that meet the following criteria: - The purchase quantity is greater than 0 - The customer ID not equal to 0 - The stock code is not blank after you remove non-numeric characters</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">loadRetailData = loadRetailData.<span class="built_in">filter</span>(<span class="keyword">lambda</span> l: <span class="built_in">int</span>(l[<span class="number">3</span>]) &gt; <span class="number">0</span>\</span><br><span class="line">                                <span class="keyword">and</span> <span class="built_in">len</span>(re.sub(<span class="string">&quot;\D&quot;</span>, <span class="string">&quot;&quot;</span>, l[<span class="number">1</span>])) != <span class="number">0</span> \</span><br><span class="line">                                <span class="keyword">and</span> <span class="built_in">len</span>(l[<span class="number">6</span>]) != <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (loadRetailData.take(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># [[&#x27;536365&#x27;, &#x27;85123A&#x27;, &#x27;WHITE HANGING HEART T-LIGHT HOLDER&#x27;, &#x27;6&#x27;, &#x27;12/1/10 8:26&#x27;, &#x27;2.55&#x27;, &#x27;17850&#x27;, &#x27;United Kingdom&#x27;], [&#x27;536365&#x27;, &#x27;71053&#x27;, &#x27;WHITE METAL LANTERN&#x27;, &#x27;6&#x27;, &#x27;12/1/10 8:26&#x27;, &#x27;3.39&#x27;, &#x27;17850&#x27;, &#x27;United Kingdom&#x27;]]</span></span><br></pre></td></tr></table></figure>
<h3 id="create-a-dataframe-1">Create a DataFrame</h3>
<p>First, create an SQLContext and map each line to a row:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SQLContext, Row</span><br><span class="line">sqlContext = SQLContext(sc)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Convert each line to a Row.</span></span><br><span class="line">loadRetailData = loadRetailData.<span class="built_in">map</span>(<span class="keyword">lambda</span> l: Row(inv=<span class="built_in">int</span>(l[<span class="number">0</span>]),\</span><br><span class="line">                                    stockCode=<span class="built_in">int</span>(re.sub(<span class="string">&quot;\D&quot;</span>, <span class="string">&quot;&quot;</span>, l[<span class="number">1</span>])),\</span><br><span class="line">                                    description=l[<span class="number">2</span>],\</span><br><span class="line">                                    quant=<span class="built_in">int</span>(l[<span class="number">3</span>]),\</span><br><span class="line">                                    invDate=l[<span class="number">4</span>],\</span><br><span class="line">                                    price=<span class="built_in">float</span>(l[<span class="number">5</span>]),\</span><br><span class="line">                                    custId=<span class="built_in">int</span>(l[<span class="number">6</span>]),\</span><br><span class="line">                                    country=l[<span class="number">7</span>]))</span><br></pre></td></tr></table></figure>
<p>Create a DataFrame and show the inferred schema: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">retailDf = sqlContext.createDataFrame(loadRetailData)</span><br><span class="line"><span class="built_in">print</span> (retailDf.printSchema())</span><br><span class="line"></span><br><span class="line"><span class="comment"># root</span></span><br><span class="line"><span class="comment">#  |-- country: string (nullable = true)</span></span><br><span class="line"><span class="comment">#  |-- custId: long (nullable = true)</span></span><br><span class="line"><span class="comment">#  |-- description: string (nullable = true)</span></span><br><span class="line"><span class="comment">#  |-- inv: long (nullable = true)</span></span><br><span class="line"><span class="comment">#  |-- invDate: string (nullable = true)</span></span><br><span class="line"><span class="comment">#  |-- price: double (nullable = true)</span></span><br><span class="line"><span class="comment">#  |-- quant: long (nullable = true)</span></span><br><span class="line"><span class="comment">#  |-- stockCode: long (nullable = true)</span></span><br></pre></td></tr></table></figure></p>
<p>Register the DataFrame as a table so that you can run SQL queries on it and show the first two rows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">retailDf.registerTempTable(<span class="string">&quot;retailPurchases&quot;</span>)</span><br><span class="line">sqlContext.sql(<span class="string">&quot;SELECT * FROM retailPurchases limit 2&quot;</span>).toPandas()</span><br></pre></td></tr></table></figure>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="4.png" width = "80%" height="80%">
</center>
<h3 id="remove-unneeded-columns">Remove unneeded columns</h3>
<p>The only columns you need are custId, stockCode, and a new column, purch, which has a value of 1 to indicate that the customer purchased the product:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">SELECT </span></span><br><span class="line"><span class="string">    custId, stockCode, 1 as purch</span></span><br><span class="line"><span class="string">FROM </span></span><br><span class="line"><span class="string">    retailPurchases </span></span><br><span class="line"><span class="string">group </span></span><br><span class="line"><span class="string">    by custId, stockCode&quot;&quot;&quot;</span></span><br><span class="line">retailDf = sqlContext.sql(query)</span><br><span class="line">retailDf.registerTempTable(<span class="string">&quot;retailDf&quot;</span>)</span><br><span class="line"></span><br><span class="line">sqlContext.sql(<span class="string">&quot;select * from retailDf limit 10&quot;</span>).toPandas()</span><br></pre></td></tr></table></figure>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="5.png" width = "40%" height="40%">
</center>
<h2 id="split-the-data-into-three-sets">Split the data into three sets</h2>
<p>You'll split the data into three sets: - a testing data set (10% of the data) - a cross-validation data set (10% of the data) - a training data set (80% of the data)</p>
<p>Split the data randomly and create a DataFrame for each data set:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">testDf, cvDf, trainDf = retailDf.randomSplit([<span class="number">.1</span>,<span class="number">.1</span>,<span class="number">.8</span>],<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;trainDf count: &quot;</span>, trainDf.count(), <span class="string">&quot; example: &quot;</span>)</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> trainDf.take(<span class="number">2</span>): <span class="built_in">print</span> (row)</span><br><span class="line"><span class="built_in">print</span> ()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;cvDf count: &quot;</span>, cvDf.count(), <span class="string">&quot; example: &quot;</span>)</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> cvDf.take(<span class="number">2</span>): <span class="built_in">print</span> (row)</span><br><span class="line"><span class="built_in">print</span> ()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;testDf count: &quot;</span>, testDf.count(), <span class="string">&quot; example: &quot;</span>)</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> testDf.take(<span class="number">2</span>): <span class="built_in">print</span> (row)</span><br><span class="line"><span class="built_in">print</span> ()</span><br></pre></td></tr></table></figure>
<h2 id="build-recommendation-models">Build recommendation models</h2>
<p>Machine learning algorithms have standard parameters and hyperparameters. Standard parameters specify data and options. Hyperparameters control the performance of the algorithm. The ALS algorithm has these hyperparameters: - The rank hyperparameter represents the number of features. The default value of rank is 10. - The maxIter hyperparameter represents the number of iterations to run the least squares computation. The default value of maxIter is 10. Use the training DataFrame to train three models with the ALS algorithm with different values for the rank and maxIter hyperparameters. Assign the userCol, itemCol, and ratingCol parameters to the appropriate data columns. Set the implicitPrefs parameter to true so that the algorithm can predict latent factors.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALS</span><br><span class="line"></span><br><span class="line">als1 = ALS(rank=<span class="number">3</span>, maxIter=<span class="number">15</span>,userCol=<span class="string">&quot;custId&quot;</span>,itemCol=<span class="string">&quot;stockCode&quot;</span>,ratingCol=<span class="string">&quot;purch&quot;</span>,implicitPrefs=<span class="literal">True</span>)</span><br><span class="line">model1 = als1.fit(trainDf)</span><br><span class="line"></span><br><span class="line">als2 = ALS(rank=<span class="number">15</span>, maxIter=<span class="number">3</span>,userCol=<span class="string">&quot;custId&quot;</span>,itemCol=<span class="string">&quot;stockCode&quot;</span>,ratingCol=<span class="string">&quot;purch&quot;</span>,implicitPrefs=<span class="literal">True</span>)</span><br><span class="line">model2 = als2.fit(trainDf)</span><br><span class="line"></span><br><span class="line">als3 = ALS(rank=<span class="number">15</span>, maxIter=<span class="number">15</span>,userCol=<span class="string">&quot;custId&quot;</span>,itemCol=<span class="string">&quot;stockCode&quot;</span>,ratingCol=<span class="string">&quot;purch&quot;</span>,implicitPrefs=<span class="literal">True</span>)</span><br><span class="line">model3 = als3.fit(trainDf)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;The models are trained&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="test-the-models">Test the models</h2>
<p>First, test the three models on the cross-validation data set, and then on the testing data set. You'll know the model is accurate when the prediction values for products that the customers have already bought are close to 1.</p>
<h3 id="clean-the-cross-validation-data-set">Clean the cross validation data set</h3>
<p>Remove any of the customers or products in the cross-validation data set that are not in the training data set:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> UserDefinedFunction</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> BooleanType</span><br><span class="line">customers = <span class="built_in">set</span>(trainDf.rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> line: line.custId).collect())</span><br><span class="line">stock = <span class="built_in">set</span>(trainDf.rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> line: line.stockCode).collect())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (cvDf.count())</span><br><span class="line">cvDf = cvDf.rdd.<span class="built_in">filter</span>(<span class="keyword">lambda</span> line: line.stockCode <span class="keyword">in</span> stock <span class="keyword">and</span>\</span><br><span class="line">                                           line.custId <span class="keyword">in</span> customers).toDF()</span><br><span class="line"><span class="built_in">print</span> (cvDf.count())</span><br></pre></td></tr></table></figure>
<h3 id="run-the-models-on-the-cross-validation-data-set">Run the models on the cross-validation data set</h3>
<p>Run the model with the cross-validation DataFrame by using the transform function and print the first two rows of each set of predictions:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">predictions1 = model1.transform(cvDf)</span><br><span class="line">predictions2 = model2.transform(cvDf)</span><br><span class="line">predictions3 = model3.transform(cvDf)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (predictions1.take(<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span> (predictions2.take(<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span> (predictions3.take(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># [Row(custId=14606, stockCode=20735, purch=1, prediction=0.02294829487800598), Row(custId=16464, stockCode=20735, purch=1, prediction=0.00998256541788578)]</span></span><br><span class="line"><span class="comment"># [Row(custId=14606, stockCode=20735, purch=1, prediction=0.0441482812166214), Row(custId=16464, stockCode=20735, purch=1, prediction=0.004716672468930483)]</span></span><br><span class="line"><span class="comment"># [Row(custId=14606, stockCode=20735, purch=1, prediction=0.10467907041311264), Row(custId=16464, stockCode=20735, purch=1, prediction=0.0019032559357583523)]</span></span><br></pre></td></tr></table></figure>
<h3 id="calculate-the-accuracy-for-each-model">Calculate the accuracy for each model</h3>
<p>You'll use the mean squared error calculation to determine accuracy by comparing the prediction values for products to the actual purchase values. Remember that if a customer purchased a product, the value in the purch column is 1. The mean squared error calculation measures the average of the squares of the errors between what is estimated and the existing data. The lower the mean squared error value, the more accurate the model. For all predictions, subtract the prediction from the actual purchase value (1), square the result, and calculate the mean of all of the squared differences:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">meanSquaredError1 = predictions1.rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> line: (line.purch - line.prediction)**<span class="number">2</span>).mean()</span><br><span class="line">meanSquaredError2 = predictions2.rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> line: (line.purch - line.prediction)**<span class="number">2</span>).mean()</span><br><span class="line">meanSquaredError3 = predictions3.rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> line: (line.purch - line.prediction)**<span class="number">2</span>).mean()</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;Mean squared error = %.4f for our first model&#x27;</span> % meanSquaredError1)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;Mean squared error = %.4f for our second model&#x27;</span> % meanSquaredError2)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;Mean squared error = %.4f for our third model&#x27;</span> % meanSquaredError3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Mean squared error = 0.7393 for our first model</span></span><br><span class="line"><span class="comment"># Mean squared error = 0.7011 for our second model</span></span><br><span class="line"><span class="comment"># Mean squared error = 0.6683 for our third model</span></span><br></pre></td></tr></table></figure>
<p>The third model (model3) has the lowest mean squared error value, so it's the most accurate. Notice that of the three models, model3 has the highest values for the hyperparameters. At this point you might be tempted to run the model with even higher values for rank and maxIter. However, you might not get better results. Increasing the values of the hyperparameters increases the time for the model to run. Also, you don't want to overfit the model so that it exactly fits the original data. In that case, you wouldn't get any recommendations! For best results, keep the values of the hyperparameters close to the defaults.</p>
<h3 id="confirm-the-best-model">Confirm the best model</h3>
<p>Now run model3 on the testing data set to confirm that it's the best model. You want to make sure that the model is not over-matched to the cross-validation data. It's possible for a model to match one subset of the data well but not another. If the values of the mean squared error for the testing data set and the cross-validation data set are close, then you've confirmed that the model works for all the data. Clean the testing data set, run model3 on the testing data set, and calculate the mean squared error:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">filteredTestDf = testDf.rdd.<span class="built_in">filter</span>(<span class="keyword">lambda</span> line: line.stockCode <span class="keyword">in</span> stock <span class="keyword">and</span>\</span><br><span class="line">                                              line.custId <span class="keyword">in</span> customers).toDF()</span><br><span class="line">predictions4 = model3.transform(filteredTestDf)</span><br><span class="line">meanSquaredError4 = predictions4.rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> line: (line.purch - line.prediction)**<span class="number">2</span>).mean()</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;Mean squared error = %.4f for our best model&#x27;</span> % meanSquaredError4)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Mean squared error = 0.6693 for our best model</span></span><br><span class="line"><span class="comment"># That&#x27;s pretty close. The model works for all the data.</span></span><br></pre></td></tr></table></figure>
<h2 id="implement-the-model">Implement the model</h2>
<p>Use the best model to predict which products a specific customer might be interested in purchasing.</p>
<h3 id="create-a-dataframe-for-the-customer-and-all-products">Create a DataFrame for the customer and all products</h3>
<p>Create a DataFrame in which each row has the customer ID (15544) and a product ID</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> lit</span><br><span class="line"></span><br><span class="line">stock15544 = <span class="built_in">set</span>(trainDf.<span class="built_in">filter</span>(trainDf[<span class="string">&#x27;custId&#x27;</span>] == <span class="number">15544</span>).rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> line: line.stockCode).collect())</span><br><span class="line"></span><br><span class="line">userItems = trainDf.select(<span class="string">&quot;stockCode&quot;</span>).distinct().\</span><br><span class="line">            withColumn(<span class="string">&#x27;custId&#x27;</span>, lit(<span class="number">15544</span>)).\</span><br><span class="line">            rdd.<span class="built_in">filter</span>(<span class="keyword">lambda</span> line: line.stockCode <span class="keyword">not</span> <span class="keyword">in</span> stock15544).toDF()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> userItems.take(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span> (row.stockCode, row.custId)</span><br></pre></td></tr></table></figure>
<h3 id="rate-each-product">Rate each product</h3>
<p>Run the transform function to create a prediction value for each product:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">userItems = model3.transform(userItems)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> userItems.take(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span> (row.stockCode, row.custId, row.prediction)</span><br></pre></td></tr></table></figure>
<h3 id="find-the-top-recommendations">Find the top recommendations</h3>
<p>Print the top five product recommendations</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">userItems.registerTempTable(<span class="string">&quot;predictions&quot;</span>)</span><br><span class="line">query = <span class="string">&quot;select * from predictions order by prediction desc limit 5&quot;</span></span><br><span class="line"></span><br><span class="line">sqlContext.sql(query).toPandas()</span><br></pre></td></tr></table></figure>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="6.png" width = "40%" height="40%">
</center>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/Stock-Prices-Series-Problems/2020/04/05/" rel="prev" title="Stock Prices Series Problems">
      <i class="fa fa-chevron-left"></i> Stock Prices Series Problems
    </a></div>
      <div class="post-nav-item">
    <a href="/Machine-Learning-Pipeline/2020/04/13/" rel="next" title="Machine Learning Pipeline">
      Machine Learning Pipeline <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#basic-concepts"><span class="nav-number">1.</span> <span class="nav-text">Basic concepts</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#work-with-the-sparkcontext-object"><span class="nav-number">1.1.</span> <span class="nav-text">Work with the SparkContext object</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#work-with-resilient-distributed-datasets"><span class="nav-number">1.2.</span> <span class="nav-text">Work with Resilient Distributed Datasets</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#manipulate-data-in-rdds"><span class="nav-number">1.3.</span> <span class="nav-text">Manipulate data in RDDs</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#update-numeric-values"><span class="nav-number">1.3.1.</span> <span class="nav-text">Update numeric values</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#add-numbers-in-an-array"><span class="nav-number">1.3.2.</span> <span class="nav-text">Add numbers in an array</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#split-and-count-text-strings"><span class="nav-number">1.3.3.</span> <span class="nav-text">Split and count text strings</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#count-words-with-a-pair-rdd"><span class="nav-number">1.3.4.</span> <span class="nav-text">Count words with a pair RDD</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#filter-data"><span class="nav-number">1.3.5.</span> <span class="nav-text">Filter data</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#querying-data"><span class="nav-number">2.</span> <span class="nav-text">Querying data</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#enable-sql-processing"><span class="nav-number">2.1.</span> <span class="nav-text">Enable SQL processing</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#create-a-dataframe"><span class="nav-number">2.2.</span> <span class="nav-text">Create a DataFrame</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#create-a-table"><span class="nav-number">2.3.</span> <span class="nav-text">Create a table</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#run-sql-queries"><span class="nav-number">2.4.</span> <span class="nav-text">Run SQL queries</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#display-query-results-with-a-pandas-dataframe"><span class="nav-number">2.4.1.</span> <span class="nav-text">Display query results with a pandas DataFrame</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#run-a-group-by-query"><span class="nav-number">2.4.2.</span> <span class="nav-text">Run a group by query</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#run-a-subselect-query"><span class="nav-number">2.4.3.</span> <span class="nav-text">Run a subselect query</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#convert-rdds-to-dataframes"><span class="nav-number">2.5.</span> <span class="nav-text">Convert RDDs to DataFrames</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#create-a-simple-rdd"><span class="nav-number">2.5.1.</span> <span class="nav-text">Create a simple RDD</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#apply-a-schema"><span class="nav-number">2.5.2.</span> <span class="nav-text">Apply a schema</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#create-rows-with-named-columns"><span class="nav-number">2.5.3.</span> <span class="nav-text">Create rows with named columns</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#join-tables"><span class="nav-number">2.5.4.</span> <span class="nav-text">Join tables</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#create-sql-functions"><span class="nav-number">2.6.</span> <span class="nav-text">Create SQL functions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#convert-a-pandas-dataframe-to-a-spark-dataframe"><span class="nav-number">2.7.</span> <span class="nav-text">Convert a pandas DataFrame to a Spark DataFrame</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#spark-machine-learning"><span class="nav-number">3.</span> <span class="nav-text">Spark machine learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#alternating-least-squares-algorithm"><span class="nav-number">3.1.</span> <span class="nav-text">Alternating least squares algorithm</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#get-the-data"><span class="nav-number">3.2.</span> <span class="nav-text">Get the data</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#prepare-and-shape-the-data"><span class="nav-number">3.3.</span> <span class="nav-text">Prepare and shape the data</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#format-the-data"><span class="nav-number">3.3.1.</span> <span class="nav-text">Format the data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#clean-the-data"><span class="nav-number">3.3.2.</span> <span class="nav-text">Clean the data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#create-a-dataframe-1"><span class="nav-number">3.3.3.</span> <span class="nav-text">Create a DataFrame</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#remove-unneeded-columns"><span class="nav-number">3.3.4.</span> <span class="nav-text">Remove unneeded columns</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#split-the-data-into-three-sets"><span class="nav-number">3.4.</span> <span class="nav-text">Split the data into three sets</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#build-recommendation-models"><span class="nav-number">3.5.</span> <span class="nav-text">Build recommendation models</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#test-the-models"><span class="nav-number">3.6.</span> <span class="nav-text">Test the models</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#clean-the-cross-validation-data-set"><span class="nav-number">3.6.1.</span> <span class="nav-text">Clean the cross validation data set</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#run-the-models-on-the-cross-validation-data-set"><span class="nav-number">3.6.2.</span> <span class="nav-text">Run the models on the cross-validation data set</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#calculate-the-accuracy-for-each-model"><span class="nav-number">3.6.3.</span> <span class="nav-text">Calculate the accuracy for each model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#confirm-the-best-model"><span class="nav-number">3.6.4.</span> <span class="nav-text">Confirm the best model</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#implement-the-model"><span class="nav-number">3.7.</span> <span class="nav-text">Implement the model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#create-a-dataframe-for-the-customer-and-all-products"><span class="nav-number">3.7.1.</span> <span class="nav-text">Create a DataFrame for the customer and all products</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rate-each-product"><span class="nav-number">3.7.2.</span> <span class="nav-text">Rate each product</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#find-the-top-recommendations"><span class="nav-number">3.7.3.</span> <span class="nav-text">Find the top recommendations</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ruochi Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">211</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">42</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zhangruochi" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zhangruochi" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zrc720@gmail.com" title="E-Mail → mailto:zrc720@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.healthinformaticslab.org/" title="http:&#x2F;&#x2F;www.healthinformaticslab.org" rel="noopener" target="_blank">HILab</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.shihaizhou.com/" title="http:&#x2F;&#x2F;www.shihaizhou.com" rel="noopener" target="_blank">Rose</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/cherish_CX/" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;cherish_CX&#x2F;" rel="noopener" target="_blank">Chunxia</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ruochi Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'qW3MLcAgcX96sB6qbegeL7rP-gzGzoHsz',
      appKey     : 'GL6JvT9DgGxqYrY5Vj6bXVuv',
      placeholder: "Thank you for your reply",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'en' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>

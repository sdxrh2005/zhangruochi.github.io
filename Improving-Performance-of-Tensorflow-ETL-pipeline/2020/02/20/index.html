<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=PingFang SC:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhangruochi.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Improving Performance of Tensorflow ETL Pipeline">
<meta property="og:type" content="article">
<meta property="og:title" content="Improving Performance of Tensorflow ETL Pipeline">
<meta property="og:url" content="https://zhangruochi.com/Improving-Performance-of-Tensorflow-ETL-pipeline/2020/02/20/index.html">
<meta property="og:site_name" content="RUOCHI.AI">
<meta property="og:description" content="Improving Performance of Tensorflow ETL Pipeline">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-02-19T18:17:20.000Z">
<meta property="article:modified_time" content="2021-12-31T07:47:36.000Z">
<meta property="article:author" content="Ruochi Zhang">
<meta property="article:tag" content="Tensorflow">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://zhangruochi.com/Improving-Performance-of-Tensorflow-ETL-pipeline/2020/02/20/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Improving Performance of Tensorflow ETL Pipeline | RUOCHI.AI</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RUOCHI.AI</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Improving-Performance-of-Tensorflow-ETL-pipeline/2020/02/20/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Improving Performance of Tensorflow ETL Pipeline
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-20 02:17:20" itemprop="dateCreated datePublished" datetime="2020-02-20T02:17:20+08:00">2020-02-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-12-31 15:47:36" itemprop="dateModified" datetime="2021-12-31T15:47:36+08:00">2021-12-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI-Workflow/" itemprop="url" rel="index"><span itemprop="name">AI Workflow</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI-Workflow/ETL/" itemprop="url" rel="index"><span itemprop="name">ETL</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Improving-Performance-of-Tensorflow-ETL-pipeline/2020/02/20/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Improving-Performance-of-Tensorflow-ETL-pipeline/2020/02/20/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
            <div class="post-description">Improving Performance of Tensorflow ETL Pipeline</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="parallelization-with-tfds">Parallelization with TFDS</h1>
<p>In this week's exercise, we'll go back to the classic cats versus dogs example, but instead of just naively loading the data to train a model, you will be parallelizing various stages of the Extract, Transform and Load processes. In particular, you will be performing following tasks:</p>
<ol type="1">
<li>Parallelize the extraction of the stored TFRecords of the cats_vs_dogs dataset by using the interleave operation.</li>
<li>Parallelize the transformation during the preprocessing of the raw dataset by using the map operation.</li>
<li>Cache the processed dataset in memory by using the cache operation for faster retrieval.</li>
<li>Parallelize the loading of the cached dataset during the training cycle by using the prefetch operation.</li>
</ol>
<h2 id="setup">Setup</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow_datasets <span class="keyword">as</span> tfds</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> getcwd</span><br></pre></td></tr></table></figure>
<h2 id="create-and-compile-the-model">Create and Compile the Model</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span>():</span></span><br><span class="line">    input_layer = tf.keras.layers.Input(shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line">    base_model = tf.keras.applications.MobileNetV2(input_tensor=input_layer,</span><br><span class="line">                                                   weights=<span class="string">&#x27;imagenet&#x27;</span>,</span><br><span class="line">                                                   include_top=<span class="literal">False</span>)</span><br><span class="line">    base_model.trainable = <span class="literal">False</span></span><br><span class="line">    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)</span><br><span class="line">    x = tf.keras.layers.Dense(<span class="number">2</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)(x)</span><br><span class="line">    </span><br><span class="line">    model = tf.keras.models.Model(inputs=input_layer, outputs=x)</span><br><span class="line">    model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">                  loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,</span><br><span class="line">                  metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h2 id="naive-approach">Naive Approach</h2>
<p>Just for comparison, let's start by using the naive approach to Extract, Transform, and Load the data to train the model defined above. By naive approach we mean that we won't apply any of the new concepts of parallelization that we learned about in this module.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataset_name = <span class="string">&#x27;cats_vs_dogs&#x27;</span></span><br><span class="line">filePath = <span class="string">f&quot;<span class="subst">&#123;getcwd()&#125;</span>/../tmp2&quot;</span></span><br><span class="line">dataset, info = tfds.load(name=dataset_name, split=tfds.Split.TRAIN, with_info=<span class="literal">True</span>, data_dir=filePath)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(info.version)</span><br></pre></td></tr></table></figure>
<pre><code>2.0.1</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">features</span>):</span></span><br><span class="line">    image = features[<span class="string">&#x27;image&#x27;</span>]</span><br><span class="line">    image = tf.image.resize(image, (<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">    image = image / <span class="number">255.0</span></span><br><span class="line">    <span class="keyword">return</span> image, features[<span class="string">&#x27;label&#x27;</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = dataset.<span class="built_in">map</span>(preprocess).batch(<span class="number">32</span>)</span><br></pre></td></tr></table></figure>
<p>The next step will be to train the model using the following code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = create_model()</span><br><span class="line">model.fit(train_dataset, epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>Since we want to focus on the parallelization techniques, we won't go through the training process here, as this can take some time.</p>
<h1 id="parallelize-various-stages-of-the-etl-processes">Parallelize Various Stages of the ETL Processes</h1>
<p>The following exercises are about parallelizing various stages of Extract, Transform and Load processes. In particular, you will be tasked with performing following tasks:</p>
<ol type="1">
<li>Parallelize the extraction of the stored TFRecords of the cats_vs_dogs dataset by using the interleave operation.</li>
<li>Parallelize the transformation during the preprocessing of the raw dataset by using the map operation.</li>
<li>Cache the processed dataset in memory by using the cache operation for faster retrieval.</li>
<li>Parallelize the loading of the cached dataset during the training cycle by using the prefetch operation.</li>
</ol>
<p>We start by creating a dataset of strings corresponding to the <code>file_pattern</code> of the TFRecords of the cats_vs_dogs dataset.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">file_pattern = <span class="string">f&#x27;<span class="subst">&#123;getcwd()&#125;</span>/../tmp2/<span class="subst">&#123;dataset_name&#125;</span>/<span class="subst">&#123;info.version&#125;</span>/<span class="subst">&#123;dataset_name&#125;</span>-train.tfrecord*&#x27;</span></span><br><span class="line">files = tf.data.Dataset.list_files(file_pattern)</span><br></pre></td></tr></table></figure>
<p>Let's recall that the TFRecord format is a simple format for storing a sequence of binary records. This is very useful because by serializing the data and storing it in a set of files (100-200MB each) that can each be read linearly greatly increases the efficiency when reading the data.</p>
<p>Since we will use it later, we should also recall that a <code>tf.Example</code> message (or protobuf) is a flexible message type that represents a <code>&#123;"string": tf.train.Feature&#125;</code> mapping.</p>
<h2 id="parallelize-extraction">Parallelize Extraction</h2>
<p>In the cell below you will use the <a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#interleave">interleave</a> operation with certain <a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#args_38">arguments</a> to parallelize the extraction of the stored TFRecords of the cats_vs_dogs dataset.</p>
<p>Recall that <code>tf.data.experimental.AUTOTUNE</code> will delegate the decision about what level of parallelism to use to the <code>tf.data</code> runtime.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># EXERCISE: Parallelize the extraction of the stored TFRecords of</span></span><br><span class="line"><span class="comment"># the cats_vs_dogs dataset by using the interleave operation with</span></span><br><span class="line"><span class="comment"># cycle_length = 4 and the number of parallel calls set to tf.data.experimental.AUTOTUNE.</span></span><br><span class="line">train_dataset = files.interleave(tf.data.TFRecordDataset,</span><br><span class="line">                                cycle_length=<span class="number">4</span>,</span><br><span class="line">                                block_length=<span class="number">1</span>,</span><br><span class="line">                                num_parallel_calls=tf.data.experimental.AUTOTUNE)</span><br></pre></td></tr></table></figure>
<h2 id="parse-and-decode">Parse and Decode</h2>
<p>At this point the <code>train_dataset</code> contains serialized <code>tf.train.Example</code> messages. When iterated over, it returns these as scalar string tensors. The sample output for one record is given below:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: id=189, shape=(), dtype=string, numpy=b&#x27;\n\x8f\xc4\x01\n\x0e\n\x05label\x12\x05\x1a\x03\n\x01\x00\n,\n\x0eimage/filename\x12\x1a\n\x18\n\x16PetImages/Cat/4159.jpg\n\xcd\xc3\x01\n\x05image\x12...\xff\xd9&#x27;&gt;</span><br></pre></td></tr></table></figure>
<p>In order to be able to use these tensors to train our model, we must first parse them and decode them. We can parse and decode these string tensors by using a function. In the cell below you will create a <code>read_tfrecord</code> function that will read the serialized <code>tf.train.Example</code> messages and decode them. The function will also normalize and resize the images after they have been decoded.</p>
<p>In order to parse the <code>tf.train.Example</code> messages we need to create a <code>feature_description</code> dictionary. We need the <code>feature_description</code> dictionary because TFDS uses graph-execution and therefore, needs this description to build their shape and type signature. The basic structure of the <code>feature_description</code> dictionary looks like this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">feature_description = &#123;<span class="string">&#x27;feature&#x27;</span>: tf.io.FixedLenFeature([], tf.Dtype, default_value)&#125;</span><br></pre></td></tr></table></figure>
<p>The number of features in your <code>feature_description</code> dictionary will vary depending on your dataset. In our particular case, the features are <code>'image'</code> and <code>'label'</code> and can be seen in the sample output of the string tensor above. Therefore, our <code>feature_description</code> dictionary will look like this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">feature_description = &#123;</span><br><span class="line">    <span class="string">&#x27;image&#x27;</span>: tf.io.FixedLenFeature((), tf.string, <span class="string">&quot;&quot;</span>),</span><br><span class="line">    <span class="string">&#x27;label&#x27;</span>: tf.io.FixedLenFeature((), tf.int64, -<span class="number">1</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>where we have given the default values of <code>""</code> and <code>-1</code> to the <code>'image'</code> and <code>'label'</code> respectively.</p>
<p>The next step will be to parse the serialized <code>tf.train.Example</code> message using the <code>feature_description</code> dictionary given above. This can be done with the following code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">example = tf.io.parse_single_example(serialized_example, feature_description)</span><br></pre></td></tr></table></figure>
<p>Finally, we can decode the image by using:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image = tf.io.decode_jpeg(example[<span class="string">&#x27;image&#x27;</span>], channels=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>Use the code given above to complete the exercise below.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># EXERCISE: Fill in the missing code below.</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_tfrecord</span>(<span class="params">serialized_example</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create the feature description dictionary</span></span><br><span class="line">    feature_description = &#123;</span><br><span class="line">        <span class="string">&#x27;image&#x27;</span>: tf.io.FixedLenFeature((), tf.string, <span class="string">&quot;&quot;</span>),</span><br><span class="line">        <span class="string">&#x27;label&#x27;</span>: tf.io.FixedLenFeature((), tf.int64, -<span class="number">1</span>),</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># Parse the serialized_example and decode the image</span></span><br><span class="line">    example = tf.io.parse_single_example(serialized_example, feature_description)</span><br><span class="line">    image = tf.io.decode_jpeg(example[<span class="string">&#x27;image&#x27;</span>], channels=<span class="number">3</span>)</span><br><span class="line">    </span><br><span class="line">    image = tf.cast(image, tf.float32)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Normalize the pixels in the image</span></span><br><span class="line">    image = image / <span class="number">255.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Resize the image to (224, 224) using tf.image.resize</span></span><br><span class="line">    image = tf.image.resize(image, (<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> image, example[<span class="string">&#x27;label&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h2 id="parallelize-transformation">Parallelize Transformation</h2>
<p>You can now apply the <code>read_tfrecord</code> function to each item in the <code>train_dataset</code> by using the <code>map</code> method. You can parallelize the transformation of the <code>train_dataset</code> by using the <code>map</code> method with the <code>num_parallel_calls</code> set to the number of CPU cores.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># EXERCISE: Fill in the missing code below.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the number of CPU cores. </span></span><br><span class="line">cores = multiprocessing.cpu_count()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(cores)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Parallelize the transformation of the train_dataset by using</span></span><br><span class="line"><span class="comment"># the map operation with the number of parallel calls set to</span></span><br><span class="line"><span class="comment"># the number of CPU cores.</span></span><br><span class="line">train_dataset = train_dataset.<span class="built_in">map</span>(read_tfrecord, num_parallel_calls=cores)</span><br></pre></td></tr></table></figure>
<pre><code>8</code></pre>
<h2 id="cache-the-dataset">Cache the Dataset</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># EXERCISE: Cache the train_dataset in-memory.</span></span><br><span class="line">train_dataset = train_dataset.cache()</span><br></pre></td></tr></table></figure>
<h2 id="parallelize-loading">Parallelize Loading</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># EXERCISE: Fill in the missing code below.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Shuffle and batch the train_dataset. Use a buffer size of 1024</span></span><br><span class="line"><span class="comment"># for shuffling and a batch size 32 for batching. </span></span><br><span class="line">train_dataset = train_dataset.shuffle(buffer_size=<span class="number">1024</span>).batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Parallelize the loading by prefetching the train_dataset.</span></span><br><span class="line"><span class="comment"># Set the prefetching buffer size to tf.data.experimental.AUTOTUNE.</span></span><br><span class="line">train_dataset = train_dataset.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)</span><br></pre></td></tr></table></figure>
<p>The next step will be to train your model using the following code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = create_model()</span><br><span class="line">model.fit(train_dataset, epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>We won't go through the training process here as this can take some time. However, due to the parallelization of the various stages of the ETL processes, you should see a decrease in training time as compared to the naive approach depicted at beginning of the notebook. ```</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Tensorflow/" rel="tag"># Tensorflow</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/Use-Tensorflow-Lite-to-do-Inference-on-Raspberry-Pi/2020/02/17/" rel="prev" title="Use Tensorflow Lite to do Inference on Raspberry Pi">
      <i class="fa fa-chevron-left"></i> Use Tensorflow Lite to do Inference on Raspberry Pi
    </a></div>
      <div class="post-nav-item">
    <a href="/Programming-Language-Summary/2020/02/27/" rel="next" title="Programming Language: Summary">
      Programming Language: Summary <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#parallelization-with-tfds"><span class="nav-number">1.</span> <span class="nav-text">Parallelization with TFDS</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#setup"><span class="nav-number">1.1.</span> <span class="nav-text">Setup</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#create-and-compile-the-model"><span class="nav-number">1.2.</span> <span class="nav-text">Create and Compile the Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#naive-approach"><span class="nav-number">1.3.</span> <span class="nav-text">Naive Approach</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#parallelize-various-stages-of-the-etl-processes"><span class="nav-number">2.</span> <span class="nav-text">Parallelize Various Stages of the ETL Processes</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#parallelize-extraction"><span class="nav-number">2.1.</span> <span class="nav-text">Parallelize Extraction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#parse-and-decode"><span class="nav-number">2.2.</span> <span class="nav-text">Parse and Decode</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#parallelize-transformation"><span class="nav-number">2.3.</span> <span class="nav-text">Parallelize Transformation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cache-the-dataset"><span class="nav-number">2.4.</span> <span class="nav-text">Cache the Dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#parallelize-loading"><span class="nav-number">2.5.</span> <span class="nav-text">Parallelize Loading</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ruochi Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">218</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zhangruochi" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zhangruochi" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zrc720@gmail.com" title="E-Mail → mailto:zrc720@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.healthinformaticslab.org/" title="http:&#x2F;&#x2F;www.healthinformaticslab.org" rel="noopener" target="_blank">HILab</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.shihaizhou.com/" title="http:&#x2F;&#x2F;www.shihaizhou.com" rel="noopener" target="_blank">Rose</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/cherish_CX/" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;cherish_CX&#x2F;" rel="noopener" target="_blank">Chunxia</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ruochi Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'qW3MLcAgcX96sB6qbegeL7rP-gzGzoHsz',
      appKey     : 'GL6JvT9DgGxqYrY5Vj6bXVuv',
      placeholder: "Thank you for your reply",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'en' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=PingFang SC:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhangruochi.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="This is the assignment of coursera course Medical Diagnosis from deeplearning.ai  Chest X-Ray Medical Diagnosis with Deep Learning  Welcome to the first assignment of course 1 In this assignment! You">
<meta property="og:type" content="article">
<meta property="og:title" content="Chest X-Ray Medical Diagnosis with Deep Learning">
<meta property="og:url" content="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/index.html">
<meta property="og:site_name" content="RUOCHI.AI">
<meta property="og:description" content="This is the assignment of coursera course Medical Diagnosis from deeplearning.ai  Chest X-Ray Medical Diagnosis with Deep Learning  Welcome to the first assignment of course 1 In this assignment! You">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/output_1.png">
<meta property="og:image" content="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/output_28_1.png">
<meta property="og:image" content="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/output_31_0.png">
<meta property="og:image" content="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/output_42_0.png">
<meta property="og:image" content="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/output_46_0.png">
<meta property="og:image" content="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/output_62_0.png">
<meta property="og:image" content="https://journals.plos.org/plosmedicine/article/figure/image?size=large&id=10.1371/journal.pmed.1002686.t001">
<meta property="og:image" content="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/output_71_1.png">
<meta property="og:image" content="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/output_72_1.png">
<meta property="og:image" content="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/output_73_1.png">
<meta property="og:image" content="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/output_74_1.png">
<meta property="article:published_time" content="2020-04-15T13:11:55.000Z">
<meta property="article:modified_time" content="2020-04-16T01:49:43.000Z">
<meta property="article:author" content="Ruochi Zhang">
<meta property="article:tag" content="Medicine">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/output_1.png">

<link rel="canonical" href="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Chest X-Ray Medical Diagnosis with Deep Learning | RUOCHI.AI</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RUOCHI.AI</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Chest X-Ray Medical Diagnosis with Deep Learning
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-15 21:11:55" itemprop="dateCreated datePublished" datetime="2020-04-15T21:11:55+08:00">2020-04-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-16 09:49:43" itemprop="dateModified" datetime="2020-04-16T09:49:43+08:00">2020-04-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <ul>
<li>This is the assignment of coursera course <a target="_blank" rel="noopener" href="https://www.coursera.org/learn/ai-for-medical-diagnosis/">Medical Diagnosis</a> from deeplearning.ai</li>
</ul>
<h1 id="chest-x-ray-medical-diagnosis-with-deep-learning">Chest X-Ray Medical Diagnosis with Deep Learning</h1>
<p><img src="output_1.png" style="padding-top: 50px;width: 87%;left: 0px;margin-left: 0px;margin-right: 0px;"></p>
<p>Welcome to the first assignment of course 1</p>
<p>In this assignment! You will explore medical image diagnosis by building a state-of-the-art chest X-ray classifier using Keras.</p>
<p>The assignment will walk through some of the steps of building and evaluating this deep learning classifier model. In particular, you will: - Pre-process and prepare a real-world X-ray dataset - Use transfer learning to retrain a DenseNet model for X-ray image classification - Learn a technique to handle class imbalance - Measure diagnostic performance by computing the AUC (Area Under the Curve) for the ROC (Receiver Operating Characteristic) curve - Visualize model activity using GradCAMs</p>
<p>In completing this assignment you will learn about the following topics:</p>
<ul>
<li>Data preparation
<ul>
<li>Visualizing data</li>
<li>Preventing data leakage</li>
</ul></li>
<li>Model Development
<ul>
<li>Addressing class imbalance</li>
<li>Leveraging pre-trained models using transfer learning</li>
</ul></li>
<li>Evaluation
<ul>
<li>AUC and ROC curves</li>
</ul></li>
</ul>
<h2 id="outline">Outline</h2>
<p>Use these links to jump to specific sections of this assignment!</p>
<ul>
<li><a href="#1">1. Import Packages and Function</a></li>
<li><a href="#2">2. Load the Datasets</a>
<ul>
<li><a href="#2-1">2.1 Preventing Data Leakage</a>
<ul>
<li><a href="#Ex-1">Exercise 1 - Checking Data Leakage</a></li>
</ul></li>
<li><a href="#2-2">2.2 Preparing Images</a></li>
</ul></li>
<li><a href="#3">3. Model Development</a>
<ul>
<li><a href="#3-1">3.1 Addressing Class Imbalance</a>
<ul>
<li><a href="#Ex-2">Exercise 2 - Computing Class Frequencies</a></li>
<li><a href="#Ex-3">Exercise 3 - Weighted Loss</a></li>
</ul></li>
<li><a href="#3-3">3.3 DenseNet121</a></li>
</ul></li>
<li><a href="#4">4. Training [optional]</a>
<ul>
<li><a href="#4-1">4.1 Training on the Larger Dataset</a></li>
</ul></li>
<li><a href="#5">5. Prediction and Evaluation</a>
<ul>
<li><a href="#5-1">5.1 ROC Curve and AUROC</a></li>
<li><a href="#5-2">5.2 Visualizing Learning with GradCAM</a></li>
</ul></li>
</ul>
<p><a name='1'></a> ## 1. Import Packages and Functions¶</p>
<p>We'll make use of the following packages: - <code>numpy</code> and <code>pandas</code> is what we'll use to manipulate our data - <code>matplotlib.pyplot</code> and <code>seaborn</code> will be used to produce plots for visualization - <code>util</code> will provide the locally defined utility functions that have been provided for this assignment</p>
<p>We will also use several modules from the <code>keras</code> framework for building deep learning models.</p>
<p>Run the next cell to import all the necessary packages.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.applications.densenet <span class="keyword">import</span> DenseNet121</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, GlobalAveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> util</span><br></pre></td></tr></table></figure>
<p><a name='2'></a> ## 2 Load the Datasets</p>
<p>For this assignment, we will be using the <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.02315">ChestX-ray8 dataset</a> which contains 108,948 frontal-view X-ray images of 32,717 unique patients. - Each image in the data set contains multiple text-mined labels identifying 14 different pathological conditions. - These in turn can be used by physicians to diagnose 8 different diseases. - We will use this data to develop a single model that will provide binary classification predictions for each of the 14 labeled pathologies. - In other words it will predict 'positive' or 'negative' for each of the pathologies.</p>
<p>You can download the entire dataset for free <a target="_blank" rel="noopener" href="https://nihcc.app.box.com/v/ChestXray-NIHCC">here</a>. - We have provided a ~1000 image subset of the images for you. - These can be accessed in the folder path stored in the <code>IMAGE_DIR</code> variable.</p>
<p>The dataset includes a CSV file that provides the labels for each X-ray.</p>
<p>To make your job a bit easier, we have processed the labels for our small sample and generated three new files to get you started. These three files are:</p>
<ol type="1">
<li><code>nih/train-small.csv</code>: 875 images from our dataset to be used for training.</li>
<li><code>nih/valid-small.csv</code>: 109 images from our dataset to be used for validation.</li>
<li><code>nih/test.csv</code>: 420 images from our dataset to be used for testing.</li>
</ol>
<p>This dataset has been annotated by consensus among four different radiologists for 5 of our 14 pathologies: - <code>Consolidation</code> - <code>Edema</code> - <code>Effusion</code> - <code>Cardiomegaly</code> - <code>Atelectasis</code></p>
<h4 id="sidebar-on-meaning-of-class">Sidebar on meaning of 'class'</h4>
<p>It is worth noting that the word <strong>'class'</strong> is used in multiple ways is these discussions. - We sometimes refer to each of the 14 pathological conditions that are labeled in our dataset as a class. - But for each of those pathologies we are attempting to predict whether a certain condition is present (i.e. positive result) or absent (i.e. negative result). - These two possible labels of 'positive' or 'negative' (or the numerical equivalent of 1 or 0) are also typically referred to as classes. - Moreover, we also use the term in reference to software code 'classes' such as <code>ImageDataGenerator</code>.</p>
<p>As long as you are aware of all this though, it should not cause you any confusion as the term 'class' is usually clear from the context in which it is used.</p>
<h4 id="read-in-the-data">Read in the data</h4>
<p>Let's open these files using the <a target="_blank" rel="noopener" href="https://pandas.pydata.org/">pandas</a> library</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">train_df = pd.read_csv(<span class="string">&quot;nih/train-small.csv&quot;</span>)</span><br><span class="line">valid_df = pd.read_csv(<span class="string">&quot;nih/valid-small.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">test_df = pd.read_csv(<span class="string">&quot;nih/test.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Image
</th>
<th>
Atelectasis
</th>
<th>
Cardiomegaly
</th>
<th>
Consolidation
</th>
<th>
Edema
</th>
<th>
Effusion
</th>
<th>
Emphysema
</th>
<th>
Fibrosis
</th>
<th>
Hernia
</th>
<th>
Infiltration
</th>
<th>
Mass
</th>
<th>
Nodule
</th>
<th>
PatientId
</th>
<th>
Pleural_Thickening
</th>
<th>
Pneumonia
</th>
<th>
Pneumothorax
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
00027079_001.png
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
27079
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
00004477_001.png
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
4477
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
00018530_002.png
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
18530
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
3
</th>
<td>
00026928_001.png
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
26928
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
4
</th>
<td>
00016687_000.png
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
16687
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df.shape</span><br></pre></td></tr></table></figure>
<pre><code>(875, 16)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">labels = [<span class="string">&#x27;Cardiomegaly&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Emphysema&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Effusion&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Hernia&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Infiltration&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Mass&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Nodule&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Atelectasis&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;Pneumothorax&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;Pleural_Thickening&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Pneumonia&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Fibrosis&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Edema&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Consolidation&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p><a name='2-1'></a> ### 2.1 Preventing Data Leakage It is worth noting that our dataset contains multiple images for each patient. This could be the case, for example, when a patient has taken multiple X-ray images at different times during their hospital visits. In our data splitting, we have ensured that the split is done on the patient level so that there is no data "leakage" between the train, validation, and test datasets.</p>
<p><a name='Ex-1'></a> ### Exercise 1 - Checking Data Leakage In the cell below, write a function to check whether there is leakage between two datasets. We'll use this to make sure there are no patients in the test set that are also present in either the train or validation sets.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Make use of python's set.intersection() function.
</li>
<li>
In order to match the automatic grader's expectations, please start the line of code with <code>df1_patients_unique...[continue your code here]</code>
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_for_leakage</span>(<span class="params">df1, df2, patient_col</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Return True if there any patients are in both df1 and df2.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        df1 (dataframe): dataframe describing first dataset</span></span><br><span class="line"><span class="string">        df2 (dataframe): dataframe describing second dataset</span></span><br><span class="line"><span class="string">        patient_col (str): string name of column with patient IDs</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        leakage (bool): True if there is leakage, otherwise False</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    df1_patients_unique = <span class="built_in">set</span>(df1[patient_col].unique().tolist())</span><br><span class="line">    df2_patients_unique = <span class="built_in">set</span>(df2[patient_col].unique().tolist())</span><br><span class="line">    </span><br><span class="line">    patients_in_both_groups = df1_patients_unique.intersection(df2_patients_unique)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># leakage contains true if there is patient overlap, otherwise false.</span></span><br><span class="line">    leakage = <span class="built_in">len</span>(patients_in_both_groups) &gt;= <span class="number">1</span> <span class="comment"># boolean (true if there is at least 1 patient in both groups)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> leakage</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test case 1&quot;</span>)</span><br><span class="line">df1 = pd.DataFrame(&#123;<span class="string">&#x27;patient_id&#x27;</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]&#125;)</span><br><span class="line">df2 = pd.DataFrame(&#123;<span class="string">&#x27;patient_id&#x27;</span>: [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;df1&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;df2&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;leakage output: <span class="subst">&#123;check_for_leakage(df1, df2, <span class="string">&#x27;patient_id&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-------------------------------------&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test case 2&quot;</span>)</span><br><span class="line">df1 = pd.DataFrame(&#123;<span class="string">&#x27;patient_id&#x27;</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]&#125;)</span><br><span class="line">df2 = pd.DataFrame(&#123;<span class="string">&#x27;patient_id&#x27;</span>: [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;df1:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;df2:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;leakage output: <span class="subst">&#123;check_for_leakage(df1, df2, <span class="string">&#x27;patient_id&#x27;</span>)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>test case 1
df1
   patient_id
0           0
1           1
2           2
df2
   patient_id
0           2
1           3
2           4
leakage output: True
-------------------------------------
test case 2
df1:
   patient_id
0           0
1           1
2           2
df2:
   patient_id
0           3
1           4
2           5
leakage output: False</code></pre>
<h5 id="expected-output">Expected output</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">test case <span class="number">1</span></span><br><span class="line">df1</span><br><span class="line">   patient_id</span><br><span class="line"><span class="number">0</span>           <span class="number">0</span></span><br><span class="line"><span class="number">1</span>           <span class="number">1</span></span><br><span class="line"><span class="number">2</span>           <span class="number">2</span></span><br><span class="line">df2</span><br><span class="line">   patient_id</span><br><span class="line"><span class="number">0</span>           <span class="number">2</span></span><br><span class="line"><span class="number">1</span>           <span class="number">3</span></span><br><span class="line"><span class="number">2</span>           <span class="number">4</span></span><br><span class="line">leakage output: <span class="literal">True</span></span><br><span class="line">-------------------------------------</span><br><span class="line">test case <span class="number">2</span></span><br><span class="line">df1:</span><br><span class="line">   patient_id</span><br><span class="line"><span class="number">0</span>           <span class="number">0</span></span><br><span class="line"><span class="number">1</span>           <span class="number">1</span></span><br><span class="line"><span class="number">2</span>           <span class="number">2</span></span><br><span class="line">df2:</span><br><span class="line">   patient_id</span><br><span class="line"><span class="number">0</span>           <span class="number">3</span></span><br><span class="line"><span class="number">1</span>           <span class="number">4</span></span><br><span class="line"><span class="number">2</span>           <span class="number">5</span></span><br><span class="line">leakage output: <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>Run the next cell to check if there are patients in both train and test or in both valid and test.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;leakage between train and test: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(check_for_leakage(train_df, test_df, <span class="string">&#x27;PatientId&#x27;</span>)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;leakage between valid and test: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(check_for_leakage(valid_df, test_df, <span class="string">&#x27;PatientId&#x27;</span>)))</span><br></pre></td></tr></table></figure>
<pre><code>leakage between train and test: False
leakage between valid and test: False</code></pre>
<p>If we get <code>False</code> for both, then we're ready to start preparing the datasets for training. Remember to always check for data leakage!</p>
<p><a name='2-2'></a> ### 2.2 Preparing Images</p>
<p>With our dataset splits ready, we can now proceed with setting up our model to consume them. - For this we will use the off-the-shelf <a target="_blank" rel="noopener" href="https://keras.io/preprocessing/image/">ImageDataGenerator</a> class from the Keras framework, which allows us to build a "generator" for images specified in a dataframe. - This class also provides support for basic data augmentation such as random horizontal flipping of images. - We also use the generator to transform the values in each batch so that their mean is <span class="math inline">\(0\)</span> and their standard deviation is 1. - This will facilitate model training by standardizing the input distribution. - The generator also converts our single channel X-ray images (gray-scale) to a three-channel format by repeating the values in the image across all channels. - We will want this because the pre-trained model that we'll use requires three-channel inputs.</p>
<p>Since it is mainly a matter of reading and understanding Keras documentation, we have implemented the generator for you. There are a few things to note: 1. We normalize the mean and standard deviation of the data 3. We shuffle the input after each epoch. 4. We set the image size to be 320px by 320px</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_train_generator</span>(<span class="params">df, image_dir, x_col, y_cols, shuffle=<span class="literal">True</span>, batch_size=<span class="number">8</span>, seed=<span class="number">1</span>, target_w = <span class="number">320</span>, target_h = <span class="number">320</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Return generator for training set, normalizing using batch</span></span><br><span class="line"><span class="string">    statistics.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      train_df (dataframe): dataframe specifying training data.</span></span><br><span class="line"><span class="string">      image_dir (str): directory where image files are held.</span></span><br><span class="line"><span class="string">      x_col (str): name of column in df that holds filenames.</span></span><br><span class="line"><span class="string">      y_cols (list): list of strings that hold y labels for images.</span></span><br><span class="line"><span class="string">      sample_size (int): size of sample to use for normalization statistics.</span></span><br><span class="line"><span class="string">      batch_size (int): images per batch to be fed into model during training.</span></span><br><span class="line"><span class="string">      seed (int): random seed.</span></span><br><span class="line"><span class="string">      target_w (int): final width of input images.</span></span><br><span class="line"><span class="string">      target_h (int): final height of input images.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        train_generator (DataFrameIterator): iterator over training set</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>        </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;getting train generator...&quot;</span>) </span><br><span class="line">    <span class="comment"># normalize images</span></span><br><span class="line">    image_generator = ImageDataGenerator(</span><br><span class="line">        samplewise_center=<span class="literal">True</span>,</span><br><span class="line">        samplewise_std_normalization= <span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># flow from directory with specified batch size</span></span><br><span class="line">    <span class="comment"># and target image size</span></span><br><span class="line">    generator = image_generator.flow_from_dataframe(</span><br><span class="line">            dataframe=df,</span><br><span class="line">            directory=image_dir,</span><br><span class="line">            x_col=x_col,</span><br><span class="line">            y_col=y_cols,</span><br><span class="line">            class_mode=<span class="string">&quot;raw&quot;</span>,</span><br><span class="line">            batch_size=batch_size,</span><br><span class="line">            shuffle=shuffle,</span><br><span class="line">            seed=seed,</span><br><span class="line">            target_size=(target_w,target_h))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> generator</span><br></pre></td></tr></table></figure>
<h4 id="build-a-separate-generator-for-valid-and-test-sets">Build a separate generator for valid and test sets</h4>
<p>Now we need to build a new generator for validation and testing data.</p>
<p><strong>Why can't we use the same generator as for the training data?</strong></p>
<p>Look back at the generator we wrote for the training data. - It normalizes each image <strong>per batch</strong>, meaning that it uses batch statistics. - We should not do this with the test and validation data, since in a real life scenario we don't process incoming images a batch at a time (we process one image at a time). - Knowing the average per batch of test data would effectively give our model an advantage.<br />
- The model should not have any information about the test data.</p>
<p>What we need to do is normalize incoming test data using the statistics <strong>computed from the training set</strong>. * We implement this in the function below. * There is one technical note. Ideally, we would want to compute our sample mean and standard deviation using the entire training set. * However, since this is extremely large, that would be very time consuming. * In the interest of time, we'll take a random sample of the dataset and calcualte the sample mean and sample standard deviation.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_test_and_valid_generator</span>(<span class="params">valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=<span class="number">100</span>, batch_size=<span class="number">8</span>, seed=<span class="number">1</span>, target_w = <span class="number">320</span>, target_h = <span class="number">320</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Return generator for validation set and test test set using </span></span><br><span class="line"><span class="string">    normalization statistics from training set.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      valid_df (dataframe): dataframe specifying validation data.</span></span><br><span class="line"><span class="string">      test_df (dataframe): dataframe specifying test data.</span></span><br><span class="line"><span class="string">      train_df (dataframe): dataframe specifying training data.</span></span><br><span class="line"><span class="string">      image_dir (str): directory where image files are held.</span></span><br><span class="line"><span class="string">      x_col (str): name of column in df that holds filenames.</span></span><br><span class="line"><span class="string">      y_cols (list): list of strings that hold y labels for images.</span></span><br><span class="line"><span class="string">      sample_size (int): size of sample to use for normalization statistics.</span></span><br><span class="line"><span class="string">      batch_size (int): images per batch to be fed into model during training.</span></span><br><span class="line"><span class="string">      seed (int): random seed.</span></span><br><span class="line"><span class="string">      target_w (int): final width of input images.</span></span><br><span class="line"><span class="string">      target_h (int): final height of input images.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        test_generator (DataFrameIterator) and valid_generator: iterators over test set and validation set respectively</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;getting train and valid generators...&quot;</span>)</span><br><span class="line">    <span class="comment"># get generator to sample dataset</span></span><br><span class="line">    raw_train_generator = ImageDataGenerator().flow_from_dataframe(</span><br><span class="line">        dataframe=train_df, </span><br><span class="line">        directory=IMAGE_DIR, </span><br><span class="line">        x_col=<span class="string">&quot;Image&quot;</span>, </span><br><span class="line">        y_col=labels, </span><br><span class="line">        class_mode=<span class="string">&quot;raw&quot;</span>, </span><br><span class="line">        batch_size=sample_size, </span><br><span class="line">        shuffle=<span class="literal">True</span>, </span><br><span class="line">        target_size=(target_w, target_h))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># get data sample</span></span><br><span class="line">    batch = raw_train_generator.<span class="built_in">next</span>()</span><br><span class="line">    data_sample = batch[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># use sample to fit mean and std for test set generator</span></span><br><span class="line">    image_generator = ImageDataGenerator(</span><br><span class="line">        featurewise_center=<span class="literal">True</span>,</span><br><span class="line">        featurewise_std_normalization= <span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># fit generator to sample from training data</span></span><br><span class="line">    image_generator.fit(data_sample)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get test generator</span></span><br><span class="line">    valid_generator = image_generator.flow_from_dataframe(</span><br><span class="line">            dataframe=valid_df,</span><br><span class="line">            directory=image_dir,</span><br><span class="line">            x_col=x_col,</span><br><span class="line">            y_col=y_cols,</span><br><span class="line">            class_mode=<span class="string">&quot;raw&quot;</span>,</span><br><span class="line">            batch_size=batch_size,</span><br><span class="line">            shuffle=<span class="literal">False</span>,</span><br><span class="line">            seed=seed,</span><br><span class="line">            target_size=(target_w,target_h))</span><br><span class="line"></span><br><span class="line">    test_generator = image_generator.flow_from_dataframe(</span><br><span class="line">            dataframe=test_df,</span><br><span class="line">            directory=image_dir,</span><br><span class="line">            x_col=x_col,</span><br><span class="line">            y_col=y_cols,</span><br><span class="line">            class_mode=<span class="string">&quot;raw&quot;</span>,</span><br><span class="line">            batch_size=batch_size,</span><br><span class="line">            shuffle=<span class="literal">False</span>,</span><br><span class="line">            seed=seed,</span><br><span class="line">            target_size=(target_w,target_h))</span><br><span class="line">    <span class="keyword">return</span> valid_generator, test_generator</span><br></pre></td></tr></table></figure>
<p>With our generator function ready, let's make one generator for our training data and one each of our test and validation datasets.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">IMAGE_DIR = <span class="string">&quot;nih/images-small/&quot;</span></span><br><span class="line">train_generator = get_train_generator(train_df, IMAGE_DIR, <span class="string">&quot;Image&quot;</span>, labels)</span><br><span class="line">valid_generator, test_generator= get_test_and_valid_generator(valid_df, test_df, train_df, IMAGE_DIR, <span class="string">&quot;Image&quot;</span>, labels)</span><br></pre></td></tr></table></figure>
<pre><code>getting train generator...


/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 866 invalid image filename(s) in x_col=&quot;Image&quot;. These filename(s) will be ignored.
  .format(n_invalid, x_col)
/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 866 invalid image filename(s) in x_col=&quot;Image&quot;. These filename(s) will be ignored.
  .format(n_invalid, x_col)


Found 9 validated image filenames.
getting train and valid generators...
Found 9 validated image filenames.


/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 108 invalid image filename(s) in x_col=&quot;Image&quot;. These filename(s) will be ignored.
  .format(n_invalid, x_col)


Found 1 validated image filenames.
Found 420 validated image filenames.</code></pre>
<p>Let's peek into what the generator gives our model during training and validation. We can do this by calling the <code>__get_item__(index)</code> function:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x, y = train_generator.__getitem__(<span class="number">0</span>)</span><br><span class="line">plt.imshow(x[<span class="number">0</span>]);</span><br></pre></td></tr></table></figure>
<pre><code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).</code></pre>
<figure>
<img src="output_28_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p><a name='3'></a> ## 3 Model Development</p>
<p>Now we'll move on to model training and development. We have a few practical challenges to deal with before actually training a neural network, though. The first is class imbalance.</p>
<p><a name='3-1'></a> ### 3.1 Addressing Class Imbalance One of the challenges with working with medical diagnostic datasets is the large class imbalance present in such datasets. Let's plot the frequency of each of the labels in our dataset:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br><span class="line">plt.bar(x=labels, height=np.mean(train_generator.labels, axis=<span class="number">0</span>))</span><br><span class="line">plt.title(<span class="string">&quot;Frequency of Each Class&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_31_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>We can see from this plot that the prevalance of positive cases varies significantly across the different pathologies. (These trends mirror the ones in the full dataset as well.) * The <code>Hernia</code> pathology has the greatest imbalance with the proportion of positive training cases being about 0.2%. * But even the <code>Infiltration</code> pathology, which has the least amount of imbalance, has only 17.5% of the training cases labelled positive.</p>
<p>Ideally, we would train our model using an evenly balanced dataset so that the positive and negative training cases would contribute equally to the loss.</p>
<p>If we use a normal cross-entropy loss function with a highly unbalanced dataset, as we are seeing here, then the algorithm will be incentivized to prioritize the majority class (i.e negative in our case), since it contributes more to the loss.</p>
<h4 id="impact-of-class-imbalance-on-loss-function">Impact of class imbalance on loss function</h4>
<p>Let's take a closer look at this. Assume we would have used a normal cross-entropy loss for each pathology. We recall that the cross-entropy loss contribution from the <span class="math inline">\(i^{th}\)</span> training data case is:</p>
<p><span class="math display">\[\mathcal{L}_{cross-entropy}(x_i) = -(y_i \log(f(x_i)) + (1-y_i) \log(1-f(x_i))),\]</span></p>
<p>where <span class="math inline">\(x_i\)</span> and <span class="math inline">\(y_i\)</span> are the input features and the label, and <span class="math inline">\(f(x_i)\)</span> is the output of the model, i.e. the probability that it is positive.</p>
<p>Note that for any training case, either <span class="math inline">\(y_i=0\)</span> or else <span class="math inline">\((1-y_i)=0\)</span>, so only one of these terms contributes to the loss (the other term is multiplied by zero, and becomes zero).</p>
<p>We can rewrite the overall average cross-entropy loss over the entire training set <span class="math inline">\(\mathcal{D}\)</span> of size <span class="math inline">\(N\)</span> as follows:</p>
<p><span class="math display">\[\mathcal{L}_{cross-entropy}(\mathcal{D}) = - \frac{1}{N}\big( \sum_{\text{positive examples}} \log (f(x_i)) + \sum_{\text{negative examples}} \log(1-f(x_i)) \big).\]</span></p>
<p>Using this formulation, we can see that if there is a large imbalance with very few positive training cases, for example, then the loss will be dominated by the negative class. Summing the contribution over all the training cases for each class (i.e. pathological condition), we see that the contribution of each class (i.e. positive or negative) is:</p>
<p><span class="math display">\[freq_{p} = \frac{\text{number of positive examples}}{N} \]</span></p>
<p><span class="math display">\[\text{and}\]</span></p>
<p><span class="math display">\[freq_{n} = \frac{\text{number of negative examples}}{N}.\]</span></p>
<p><a name='Ex-2'></a> ### Exercise 2 - Computing Class Frequencies Complete the function below to calculate these frequences for each label in our dataset.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Use numpy.sum(a, axis=), and choose the axis (0 or 1)
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_class_freqs</span>(<span class="params">labels</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute positive and negative frequences for each class.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        labels (np.array): matrix of labels, size (num_examples, num_classes)</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        positive_frequencies (np.array): array of positive frequences for each</span></span><br><span class="line"><span class="string">                                         class, size (num_classes)</span></span><br><span class="line"><span class="string">        negative_frequencies (np.array): array of negative frequences for each</span></span><br><span class="line"><span class="string">                                         class, size (num_classes)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># total number of patients (rows)</span></span><br><span class="line">    N = labels.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    positive_frequencies = np.<span class="built_in">sum</span>(labels, axis=<span class="number">0</span>) / labels.shape[<span class="number">0</span>]</span><br><span class="line">    negative_frequencies = <span class="number">1</span> - positive_frequencies</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> positive_frequencies, negative_frequencies</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test</span></span><br><span class="line">labels_matrix = np.array(</span><br><span class="line">    [[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">     [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">     [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">     [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;labels:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(labels_matrix)</span><br><span class="line"></span><br><span class="line">test_pos_freqs, test_neg_freqs = compute_class_freqs(labels_matrix)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;pos freqs: <span class="subst">&#123;test_pos_freqs&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;neg freqs: <span class="subst">&#123;test_neg_freqs&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>labels:
[[1 0 0]
 [0 1 1]
 [1 0 1]
 [1 1 1]
 [1 0 1]]
pos freqs: [0.8 0.4 0.8]
neg freqs: [0.2 0.6 0.2]</code></pre>
<h5 id="expected-output-1">Expected output</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">labels:</span><br><span class="line">[[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]]</span><br><span class="line">pos freqs: [<span class="number">0.8</span> <span class="number">0.4</span> <span class="number">0.8</span>]</span><br><span class="line">neg freqs: [<span class="number">0.2</span> <span class="number">0.6</span> <span class="number">0.2</span>]</span><br></pre></td></tr></table></figure>
<p>Now we'll compute frequencies for our training data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">freq_pos, freq_neg = compute_class_freqs(train_generator.labels)</span><br><span class="line">freq_pos</span><br></pre></td></tr></table></figure>
<pre><code>array([0.        , 0.11111111, 0.22222222, 0.        , 0.22222222,
       0.11111111, 0.        , 0.11111111, 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        ])</code></pre>
<p>Let's visualize these two contribution ratios next to each other for each of the pathologies:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = pd.DataFrame(&#123;<span class="string">&quot;Class&quot;</span>: labels, <span class="string">&quot;Label&quot;</span>: <span class="string">&quot;Positive&quot;</span>, <span class="string">&quot;Value&quot;</span>: freq_pos&#125;)</span><br><span class="line">data = data.append([&#123;<span class="string">&quot;Class&quot;</span>: labels[l], <span class="string">&quot;Label&quot;</span>: <span class="string">&quot;Negative&quot;</span>, <span class="string">&quot;Value&quot;</span>: v&#125; <span class="keyword">for</span> l,v <span class="keyword">in</span> <span class="built_in">enumerate</span>(freq_neg)], ignore_index=<span class="literal">True</span>)</span><br><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br><span class="line">f = sns.barplot(x=<span class="string">&quot;Class&quot;</span>, y=<span class="string">&quot;Value&quot;</span>, hue=<span class="string">&quot;Label&quot;</span> ,data=data)</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_42_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>As we see in the above plot, the contributions of positive cases is significantly lower than that of the negative ones. However, we want the contributions to be equal. One way of doing this is by multiplying each example from each class by a class-specific weight factor, <span class="math inline">\(w_{pos}\)</span> and <span class="math inline">\(w_{neg}\)</span>, so that the overall contribution of each class is the same.</p>
<p>To have this, we want</p>
<p><span class="math display">\[w_{pos} \times freq_{p} = w_{neg} \times freq_{n},\]</span></p>
<p>which we can do simply by taking</p>
<p><span class="math display">\[w_{pos} = freq_{neg}\]</span> <span class="math display">\[w_{neg} = freq_{pos}\]</span></p>
<p>This way, we will be balancing the contribution of positive and negative labels.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pos_weights = freq_neg</span><br><span class="line">neg_weights = freq_pos</span><br><span class="line">pos_contribution = freq_pos * pos_weights </span><br><span class="line">neg_contribution = freq_neg * neg_weights</span><br></pre></td></tr></table></figure>
<p>Let's verify this by graphing the two contributions next to each other again:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = pd.DataFrame(&#123;<span class="string">&quot;Class&quot;</span>: labels, <span class="string">&quot;Label&quot;</span>: <span class="string">&quot;Positive&quot;</span>, <span class="string">&quot;Value&quot;</span>: pos_contribution&#125;)</span><br><span class="line">data = data.append([&#123;<span class="string">&quot;Class&quot;</span>: labels[l], <span class="string">&quot;Label&quot;</span>: <span class="string">&quot;Negative&quot;</span>, <span class="string">&quot;Value&quot;</span>: v&#125; </span><br><span class="line">                        <span class="keyword">for</span> l,v <span class="keyword">in</span> <span class="built_in">enumerate</span>(neg_contribution)], ignore_index=<span class="literal">True</span>)</span><br><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br><span class="line">sns.barplot(x=<span class="string">&quot;Class&quot;</span>, y=<span class="string">&quot;Value&quot;</span>, hue=<span class="string">&quot;Label&quot;</span> ,data=data);</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_46_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>As the above figure shows, by applying these weightings the positive and negative labels within each class would have the same aggregate contribution to the loss function. Now let's implement such a loss function.</p>
<p>After computing the weights, our final weighted loss for each training case will be</p>
<p><span class="math display">\[\mathcal{L}_{cross-entropy}^{w}(x) = - (w_{p} y \log(f(x)) + w_{n}(1-y) \log( 1 - f(x) ) ).\]</span></p>
<p><a name='Ex-3'></a> ### Exercise 3 - Weighted Loss Fill out the <code>weighted_loss</code> function below to return a loss function that calculates the weighted loss for each batch. Recall that for the multi-class loss, we add up the average loss for each individual class. Note that we also want to add a small value, <span class="math inline">\(\epsilon\)</span>, to the predicted values before taking their logs. This is simply to avoid a numerical error that would otherwise occur if the predicted value happens to be zero.</p>
<h5 id="note">Note</h5>
<p>Please use Keras functions to calculate the mean and the log.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/backend/mean">Keras.mean</a></li>
<li><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/backend/log">Keras.log</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_weighted_loss</span>(<span class="params">pos_weights, neg_weights, epsilon=<span class="number">1e-7</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Return weighted loss function given negative weights and positive weights.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      pos_weights (np.array): array of positive weights for each class, size (num_classes)</span></span><br><span class="line"><span class="string">      neg_weights (np.array): array of negative weights for each class, size (num_classes)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      weighted_loss (function): weighted loss function</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weighted_loss</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Return weighted loss value. </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            y_true (Tensor): Tensor of true labels, size is (num_examples, num_classes)</span></span><br><span class="line"><span class="string">            y_pred (Tensor): Tensor of predicted labels, size is (num_examples, num_classes)</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            loss (Tensor): overall scalar loss summed across all classes</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># initialize loss to zero</span></span><br><span class="line">        loss = <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(pos_weights)):</span><br><span class="line">            <span class="comment"># for each class, add average weighted loss for that class </span></span><br><span class="line">            loss += -(K.mean( pos_weights[i] * y_true[:,i] * K.log(y_pred[:,i] + epsilon) + \</span><br><span class="line">                                neg_weights[i] * (<span class="number">1</span> - y_true[:,i]) * K.log(<span class="number">1</span> - y_pred[:,i] + epsilon), axis = <span class="number">0</span>))</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line">    </span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> weighted_loss</span><br></pre></td></tr></table></figure>
<p>Now let's test our function with some simple cases.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test</span></span><br><span class="line">sess = K.get_session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test example:\n&quot;</span>)</span><br><span class="line">    y_true = K.constant(np.array(</span><br><span class="line">        [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line">    ))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;y_true:\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(y_true.<span class="built_in">eval</span>())</span><br><span class="line"></span><br><span class="line">    w_p = np.array([<span class="number">0.25</span>, <span class="number">0.25</span>, <span class="number">0.5</span>])</span><br><span class="line">    w_n = np.array([<span class="number">0.75</span>, <span class="number">0.75</span>, <span class="number">0.5</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nw_p:\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(w_p)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nw_n:\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(w_n)</span><br><span class="line"></span><br><span class="line">    y_pred_1 = K.constant(<span class="number">0.7</span>*np.ones(y_true.shape))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\ny_pred_1:\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(y_pred_1.<span class="built_in">eval</span>())</span><br><span class="line"></span><br><span class="line">    y_pred_2 = K.constant(<span class="number">0.3</span>*np.ones(y_true.shape))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\ny_pred_2:\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(y_pred_2.<span class="built_in">eval</span>())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># test with a large epsilon in order to catch errors</span></span><br><span class="line">    L = get_weighted_loss(w_p, w_n, epsilon=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nIf we weighted them correctly, we expect the two losses to be the same.&quot;</span>)</span><br><span class="line">    L1 = L(y_true, y_pred_1).<span class="built_in">eval</span>()</span><br><span class="line">    L2 = L(y_true, y_pred_2).<span class="built_in">eval</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\nL(y_pred_1)= <span class="subst">&#123;L1:<span class="number">.4</span>f&#125;</span>, L(y_pred_2)= <span class="subst">&#123;L2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Difference is L1 - L2 = <span class="subst">&#123;L1 - L2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test example:

y_true:

[[1. 1. 1.]
 [1. 1. 0.]
 [0. 1. 0.]
 [1. 0. 1.]]

w_p:

[0.25 0.25 0.5 ]

w_n:

[0.75 0.75 0.5 ]

y_pred_1:

[[0.7 0.7 0.7]
 [0.7 0.7 0.7]
 [0.7 0.7 0.7]
 [0.7 0.7 0.7]]

y_pred_2:

[[0.3 0.3 0.3]
 [0.3 0.3 0.3]
 [0.3 0.3 0.3]
 [0.3 0.3 0.3]]

If we weighted them correctly, we expect the two losses to be the same.

L(y_pred_1)= -0.4956, L(y_pred_2)= -0.4956
Difference is L1 - L2 = 0.0000</code></pre>
<h4 id="additional-check">Additional check</h4>
<p>If you implemented the function correctly, then if the epsilon for the <code>get_weighted_loss</code> is set to <code>1</code>, the weighted losses will be as follows: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L(y_pred_1)= -<span class="number">0.4956</span>, L(y_pred_2)= -<span class="number">0.4956</span></span><br></pre></td></tr></table></figure> If you are missing something in your implementation, you will see a different set of losses for L1 and L2 (even though L1 and L2 will be the same).</p>
<p><a name='3-3'></a> ### 3.3 DenseNet121</p>
<p>Next, we will use a pre-trained <a target="_blank" rel="noopener" href="https://www.kaggle.com/pytorch/densenet121">DenseNet121</a> model which we can load directly from Keras and then add two layers on top of it: 1. A <code>GlobalAveragePooling2D</code> layer to get the average of the last convolution layers from DenseNet121. 2. A <code>Dense</code> layer with <code>sigmoid</code> activation to get the prediction logits for each of our classes.</p>
<p>We can set our custom loss function for the model by specifying the <code>loss</code> parameter in the <code>compile()</code> function.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create the base pre-trained model</span></span><br><span class="line">base_model = DenseNet121(weights=<span class="string">&#x27;./nih/densenet.hdf5&#x27;</span>, include_top=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">x = base_model.output</span><br><span class="line"></span><br><span class="line"><span class="comment"># add a global spatial average pooling layer</span></span><br><span class="line">x = GlobalAveragePooling2D()(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># and a logistic layer</span></span><br><span class="line">predictions = Dense(<span class="built_in">len</span>(labels), activation=<span class="string">&quot;sigmoid&quot;</span>)(x)</span><br><span class="line"></span><br><span class="line">model = Model(inputs=base_model.<span class="built_in">input</span>, outputs=predictions)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=get_weighted_loss(pos_weights, neg_weights))</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.</code></pre>
<p><a name='4'></a> ## 4 Training [optional]</p>
<p>With our model ready for training, we will use the <code>model.fit()</code> function in Keras to train our model. - We are training on a small subset of the dataset (~1%).<br />
- So what we care about at this point is to make sure that the loss on the training set is decreasing.</p>
<p>Since training can take a considerable time, for pedagogical purposes we have chosen not to train the model here but rather to load a set of pre-trained weights in the next section. However, you can use the code shown below to practice training the model locally on your machine or in Colab.</p>
<p><strong>NOTE:</strong> Do not run the code below on the Coursera platform as it will exceed the platform's memory limitations.</p>
<p>Python Code for training the model:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit_generator(train_generator, </span><br><span class="line">                              validation_data=valid_generator,</span><br><span class="line">                              steps_per_epoch=<span class="number">100</span>, </span><br><span class="line">                              validation_steps=<span class="number">25</span>, </span><br><span class="line">                              epochs = <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.ylabel(<span class="string">&quot;loss&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Training Loss Curve&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><a name='4-1'></a> ### 4.1 Training on the Larger Dataset</p>
<p>Given that the original dataset is 40GB+ in size and the training process on the full dataset takes a few hours, we have trained the model on a GPU-equipped machine for you and provided the weights file from our model (with a batch size of 32 instead) to be used for the rest of this assignment.</p>
<p>The model architecture for our pre-trained model is exactly the same, but we used a few useful Keras "callbacks" for this training. Do spend time to read about these callbacks at your leisure as they will be very useful for managing long-running training sessions:</p>
<ol type="1">
<li>You can use <code>ModelCheckpoint</code> callback to monitor your model's <code>val_loss</code> metric and keep a snapshot of your model at the point.</li>
<li>You can use the <code>TensorBoard</code> to use the Tensorflow Tensorboard utility to monitor your runs in real-time.</li>
<li>You can use the <code>ReduceLROnPlateau</code> to slowly decay the learning rate for your model as it stops getting better on a metric such as <code>val_loss</code> to fine-tune the model in the final steps of training.</li>
<li>You can use the <code>EarlyStopping</code> callback to stop the training job when your model stops getting better in it's validation loss. You can set a <code>patience</code> value which is the number of epochs the model does not improve after which the training is terminated. This callback can also conveniently restore the weights for the best metric at the end of training to your model.</li>
</ol>
<p>You can read about these callbacks and other useful Keras callbacks <a target="_blank" rel="noopener" href="https://keras.io/callbacks/">here</a>.</p>
<p>Let's load our pre-trained weights into the model now:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_weights(<span class="string">&quot;./nih/pretrained_model.h5&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><a name='5'></a> ## 5 Prediction and Evaluation</p>
<p>Now that we have a model, let's evaluate it using our test set. We can conveniently use the <code>predict_generator</code> function to generate the predictions for the images in our test set.</p>
<p><strong>Note:</strong> The following cell can take about 4 minutes to run.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predicted_vals = model.predict_generator(test_generator, steps = <span class="built_in">len</span>(test_generator))</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.</code></pre>
<p><a name='5-1'></a> ### 5.1 ROC Curve and AUROC We'll cover topic of model evaluation in much more detail in later weeks, but for now we'll walk through computing a metric called the AUC (Area Under the Curve) from the ROC (<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">Receiver Operating Characteristic</a>) curve. This is also referred to as the AUROC value, but you will see all three terms in reference to the technique, and often used almost interchangeably.</p>
<p>For now, what you need to know in order to interpret the plot is that a curve that is more to the left and the top has more "area" under it, and indicates that the model is performing better.</p>
<p>We will use the <code>util.get_roc_curve()</code> function which has been provided for you in <code>util.py</code>. Look through this function and note the use of the <code>sklearn</code> library functions to generate the ROC curves and AUROC values for our model.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html">roc_curve</a></li>
<li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html">roc_auc_score</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">auc_rocs = util.get_roc_curve(labels, predicted_vals, test_generator)</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_62_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>You can compare the performance to the AUCs reported in the original ChexNeXt paper in the table below:</p>
<p>For reference, here's the AUC figure from the ChexNeXt paper which includes AUC values for their model as well as radiologists on this dataset:</p>
<p><img src="https://journals.plos.org/plosmedicine/article/figure/image?size=large&id=10.1371/journal.pmed.1002686.t001" width="80%"></p>
<p>This method does take advantage of a few other tricks such as self-training and ensembling as well, which can give a significant boost to the performance.</p>
<p>For details about the best performing methods and their performance on this dataset, we encourage you to read the following papers: - <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.05225">CheXNet</a> - <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1901.07031.pdf">CheXpert</a> - <a target="_blank" rel="noopener" href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002686">ChexNeXt</a></p>
<p><a name='5-2'></a> ### 5.2 Visualizing Learning with GradCAM</p>
<p>One of the challenges of using deep learning in medicine is that the complex architecture used for neural networks makes them much harder to interpret compared to traditional machine learning models (e.g. linear models).</p>
<p>One of the most common approaches aimed at increasing the interpretability of models for computer vision tasks is to use Class Activation Maps (CAM). - Class activation maps are useful for understanding where the model is "looking" when classifying an image.</p>
<p>In this section we will use a <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1610.02391">GradCAM's</a> technique to produce a heatmap highlighting the important regions in the image for predicting the pathological condition. - This is done by extracting the gradients of each predicted class, flowing into our model's final convolutional layer. Look at the <code>util.compute_gradcam</code> which has been provided for you in <code>util.py</code> to see how this is done with the Keras framework.</p>
<p>It is worth mentioning that GradCAM does not provide a full explanation of the reasoning for each classification probability. - However, it is still a useful tool for "debugging" our model and augmenting our prediction so that an expert could validate that a prediction is indeed due to the model focusing on the right regions of the image.</p>
<p>First we will load the small training set and setup to look at the 4 classes with the highest performing AUC measures.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&quot;nih/train-small.csv&quot;</span>)</span><br><span class="line">IMAGE_DIR = <span class="string">&quot;nih/images-small/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># only show the lables with top 4 AUC</span></span><br><span class="line">labels_to_show = np.take(labels, np.argsort(auc_rocs)[::-<span class="number">1</span>])[:<span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>Now let's look at a few specific images.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">util.compute_gradcam(model, <span class="string">&#x27;00008270_015.png&#x27;</span>, IMAGE_DIR, df, labels, labels_to_show)</span><br></pre></td></tr></table></figure>
<pre><code>Loading original image
Generating gradcam for class Cardiomegaly
Generating gradcam for class Mass
Generating gradcam for class Pneumothorax
Generating gradcam for class Edema</code></pre>
<figure>
<img src="output_71_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">util.compute_gradcam(model, <span class="string">&#x27;00011355_002.png&#x27;</span>, IMAGE_DIR, df, labels, labels_to_show)</span><br></pre></td></tr></table></figure>
<pre><code>Loading original image
Generating gradcam for class Cardiomegaly
Generating gradcam for class Mass
Generating gradcam for class Pneumothorax
Generating gradcam for class Edema</code></pre>
<figure>
<img src="output_72_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">util.compute_gradcam(model, <span class="string">&#x27;00029855_001.png&#x27;</span>, IMAGE_DIR, df, labels, labels_to_show)</span><br></pre></td></tr></table></figure>
<pre><code>Loading original image
Generating gradcam for class Cardiomegaly
Generating gradcam for class Mass
Generating gradcam for class Pneumothorax
Generating gradcam for class Edema</code></pre>
<figure>
<img src="output_73_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">util.compute_gradcam(model, <span class="string">&#x27;00005410_000.png&#x27;</span>, IMAGE_DIR, df, labels, labels_to_show)</span><br></pre></td></tr></table></figure>
<pre><code>Loading original image
Generating gradcam for class Cardiomegaly
Generating gradcam for class Mass
Generating gradcam for class Pneumothorax
Generating gradcam for class Edema</code></pre>
<figure>
<img src="output_74_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>Congratulations, you've completed the first assignment of course one! You've learned how to preprocess data, check for data leakage, train a pre-trained model, and evaluate using the AUC. Great work!</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Medicine/" rel="tag"># Medicine</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/Deploy-a-keras-model-on-IBM-cloud/2020/04/15/" rel="prev" title="Deploy a keras model on IBM cloud">
      <i class="fa fa-chevron-left"></i> Deploy a keras model on IBM cloud
    </a></div>
      <div class="post-nav-item">
    <a href="/Evaluation-of-Diagnostic-Models/2020/04/17/" rel="next" title="Evaluation of Diagnostic Models">
      Evaluation of Diagnostic Models <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#chest-x-ray-medical-diagnosis-with-deep-learning"><span class="nav-number">1.</span> <span class="nav-text">Chest X-Ray Medical Diagnosis with Deep Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#outline"><span class="nav-number">1.1.</span> <span class="nav-text">Outline</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#sidebar-on-meaning-of-class"><span class="nav-number">1.1.0.1.</span> <span class="nav-text">Sidebar on meaning of &#39;class&#39;</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#read-in-the-data"><span class="nav-number">1.1.0.2.</span> <span class="nav-text">Read in the data</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#expected-output"><span class="nav-number">1.1.0.2.1.</span> <span class="nav-text">Expected output</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#build-a-separate-generator-for-valid-and-test-sets"><span class="nav-number">1.1.0.3.</span> <span class="nav-text">Build a separate generator for valid and test sets</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#impact-of-class-imbalance-on-loss-function"><span class="nav-number">1.1.0.4.</span> <span class="nav-text">Impact of class imbalance on loss function</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#expected-output-1"><span class="nav-number">1.1.0.4.1.</span> <span class="nav-text">Expected output</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#note"><span class="nav-number">1.1.0.4.2.</span> <span class="nav-text">Note</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#additional-check"><span class="nav-number">1.1.0.5.</span> <span class="nav-text">Additional check</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ruochi Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">268</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zhangruochi" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zhangruochi" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zrc720@gmail.com" title="E-Mail → mailto:zrc720@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.healthinformaticslab.org/" title="http:&#x2F;&#x2F;www.healthinformaticslab.org" rel="noopener" target="_blank">HILab</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.shihaizhou.com/" title="http:&#x2F;&#x2F;www.shihaizhou.com" rel="noopener" target="_blank">Rose</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/cherish_CX/" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;cherish_CX&#x2F;" rel="noopener" target="_blank">Chunxia</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ruochi Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'qW3MLcAgcX96sB6qbegeL7rP-gzGzoHsz',
      appKey     : 'GL6JvT9DgGxqYrY5Vj6bXVuv',
      placeholder: "Thank you for your reply",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'en' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>

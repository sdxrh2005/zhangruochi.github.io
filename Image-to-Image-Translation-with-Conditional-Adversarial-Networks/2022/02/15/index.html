<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=PingFang SC:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhangruochi.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Image-to-Image Translation with Conditional Adversarial Networks  Category: Article Created: February 12, 2022 2:39 PM Status: Open URL: https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1611.07004.pdf Updated: February 15, 2022">
<meta property="og:type" content="article">
<meta property="og:title" content="Image-to-Image Translation with Conditional Adversarial Networks">
<meta property="og:url" content="https://zhangruochi.com/Image-to-Image-Translation-with-Conditional-Adversarial-Networks/2022/02/15/index.html">
<meta property="og:site_name" content="RUOCHI.AI">
<meta property="og:description" content="Image-to-Image Translation with Conditional Adversarial Networks  Category: Article Created: February 12, 2022 2:39 PM Status: Open URL: https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1611.07004.pdf Updated: February 15, 2022">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zhangruochi.com/Image-to-Image-Translation-with-Conditional-Adversarial-Networks/2022/02/15/Screen_Shot_2022-02-12_at_15.29.06.png">
<meta property="og:image" content="https://zhangruochi.com/Image-to-Image-Translation-with-Conditional-Adversarial-Networks/2022/02/15/Screen_Shot_2022-02-12_at_15.38.31.png">
<meta property="og:image" content="https://zhangruochi.com/Image-to-Image-Translation-with-Conditional-Adversarial-Networks/2022/02/15/Screen_Shot_2022-02-12_at_15.43.41.png">
<meta property="article:published_time" content="2022-02-15T10:09:48.000Z">
<meta property="article:modified_time" content="2022-02-15T10:33:56.808Z">
<meta property="article:author" content="Ruochi Zhang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhangruochi.com/Image-to-Image-Translation-with-Conditional-Adversarial-Networks/2022/02/15/Screen_Shot_2022-02-12_at_15.29.06.png">

<link rel="canonical" href="https://zhangruochi.com/Image-to-Image-Translation-with-Conditional-Adversarial-Networks/2022/02/15/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Image-to-Image Translation with Conditional Adversarial Networks | RUOCHI.AI</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RUOCHI.AI</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Image-to-Image-Translation-with-Conditional-Adversarial-Networks/2022/02/15/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Image-to-Image Translation with Conditional Adversarial Networks
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-02-15 18:09:48 / Modified: 18:33:56" itemprop="dateCreated datePublished" datetime="2022-02-15T18:09:48+08:00">2022-02-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-Note/" itemprop="url" rel="index"><span itemprop="name">Paper Note</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-Note/GANs/" itemprop="url" rel="index"><span itemprop="name">GANs</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Image-to-Image-Translation-with-Conditional-Adversarial-Networks/2022/02/15/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Image-to-Image-Translation-with-Conditional-Adversarial-Networks/2022/02/15/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="image-to-image-translation-with-conditional-adversarial-networks">Image-to-Image Translation with Conditional Adversarial Networks</h1>
<ul>
<li>Category: Article</li>
<li>Created: February 12, 2022 2:39 PM</li>
<li>Status: Open</li>
<li>URL: https://arxiv.org/pdf/1611.07004.pdf</li>
<li>Updated: February 15, 2022 5:15 PM</li>
</ul>
<h1 id="highlights">Highlights</h1>
<ol type="1">
<li><em>We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems.</em></li>
<li><em>As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.</em></li>
</ol>
<h1 id="intuition">Intuition</h1>
<ol type="1">
<li>If we take a naive approach and ask the CNN to minimize the Euclidean distance between predicted and ground truth pix- els, it will tend to produce blurry results.</li>
<li>It would be highly desirable if we could instead specify only a high-level goal, like “make the output indistinguishable from reality”, and then automatically learn a loss function appropriate for satisfying this goal.</li>
</ol>
<h1 id="methods">Methods</h1>
<p>Our generator we use a <strong>U-Ne</strong>t-based architecture, and for our discriminator we use a convolutional <strong>PatchGAN</strong> classifier, which only penalizes structure at the scale of image patches.</p>
<span id="more"></span>
<h2 id="loss-function">Loss function</h2>
<p>The objective of a conditional GAN can be expressed as</p>
<p><span class="math inline">\(\begin{aligned}\mathcal{L}_{c G A N}(G, D)=&amp; \mathbb{E}_{x, y}[\log D(x, y)]+\\&amp; \mathbb{E}_{x, z}[\log (1-D(x, G(x, z))]\end{aligned}\)</span></p>
<p>Previous approaches have found it beneficial to mix the GAN objective with a more traditional loss, such as L2 distance. The discriminator’s job remains unchanged, but the generator is tasked to not only fool the discriminator but also to be near the ground truth output in an L2 sense. We also explore this option, using L1 distance rather than L2 as L1 encourages less blurring:</p>
<p><span class="math display">\[
\mathcal{L}_{L 1}(G)=\mathbb{E}_{x, y, z}\left[\|y-G(x, z)\|_{1}\right]
\]</span></p>
<p><span class="math display">\[
G^{*}=\arg \min _{G} \max _{D} \mathcal{L}_{c G A N}(G, D)+\lambda \mathcal{L}_{L 1}(G)
\]</span></p>
<h2 id="generator">Generator</h2>
<p>To give the generator a means to circumvent the bottle- neck for information like this, we add skip connections, following the general shape of a <strong>U-Net</strong>.</p>
<figure>
<img src="Screen_Shot_2022-02-12_at_15.29.06.png" alt="Screen Shot 2022-02-12 at 15.29.06.png" /><figcaption aria-hidden="true">Screen Shot 2022-02-12 at 15.29.06.png</figcaption>
</figure>
<h2 id="discriminator-patchgan">D<strong>iscriminator (PatchGAN)</strong></h2>
<p>This motivates restricting the GAN discriminator to only model high-frequency structure, relying on an L1 term to force low-frequency correctness.</p>
<p>In order to model high-frequencies, it is sufficient to restrict our attention to the structure in local image patches. Therefore, we design a discriminator architecture – which we term a <em>Patch</em>GAN – that only penalizes structure at the scale of patches.</p>
<p>This discriminator tries to classify if each N × N patch in an image is real or fake. We run this discriminator convolution- ally across the image, averaging all responses to provide the ultimate output of D.</p>
<figure>
<img src="Screen_Shot_2022-02-12_at_15.38.31.png" alt="Screen Shot 2022-02-12 at 15.38.31.png" /><figcaption aria-hidden="true">Screen Shot 2022-02-12 at 15.38.31.png</figcaption>
</figure>
<h1 id="code">Code</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Discriminator Class</span></span><br><span class="line"><span class="string">    Structured like the contracting path of the U-Net, the discriminator will</span></span><br><span class="line"><span class="string">    output a matrix of values classifying corresponding portions of the image as real or fake. </span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        input_channels: the number of image input channels</span></span><br><span class="line"><span class="string">        hidden_channels: the initial number of discriminator convolutional filters</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_channels, hidden_channels=<span class="number">8</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        self.upfeature = FeatureMapBlock(input_channels, hidden_channels)</span><br><span class="line">        self.contract1 = ContractingBlock(hidden_channels, use_bn=<span class="literal">False</span>)</span><br><span class="line">        self.contract2 = ContractingBlock(hidden_channels * <span class="number">2</span>)</span><br><span class="line">        self.contract3 = ContractingBlock(hidden_channels * <span class="number">4</span>)</span><br><span class="line">        self.contract4 = ContractingBlock(hidden_channels * <span class="number">8</span>)</span><br><span class="line">        <span class="comment">#### START CODE HERE ####</span></span><br><span class="line">        self.final = nn.Conv2d(hidden_channels * <span class="number">16</span>, <span class="number">1</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="comment">#### END CODE HERE ####</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">        x = torch.cat([x, y], axis=<span class="number">1</span>)</span><br><span class="line">        x0 = self.upfeature(x)</span><br><span class="line">        x1 = self.contract1(x0)</span><br><span class="line">        x2 = self.contract2(x1)</span><br><span class="line">        x3 = self.contract3(x2)</span><br><span class="line">        x4 = self.contract4(x3)</span><br><span class="line">        xn = self.final(x4)</span><br><span class="line">        <span class="keyword">return</span> xn</span><br><span class="line"></span><br><span class="line"><span class="comment"># UNIT TEST</span></span><br><span class="line">test_discriminator = Discriminator(<span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">tuple</span>(test_discriminator(</span><br><span class="line">    torch.randn(<span class="number">1</span>, <span class="number">5</span>, <span class="number">256</span>, <span class="number">256</span>), </span><br><span class="line">    torch.randn(<span class="number">1</span>, <span class="number">5</span>, <span class="number">256</span>, <span class="number">256</span>)</span><br><span class="line">).shape) == (<span class="number">1</span>, <span class="number">1</span>, <span class="number">16</span>, <span class="number">16</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_gen_loss</span>(<span class="params">gen, disc, real, condition, adv_criterion, recon_criterion, lambda_recon</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Return the loss of the generator given inputs.</span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        gen: the generator; takes the condition and returns potential images</span></span><br><span class="line"><span class="string">        disc: the discriminator; takes images and the condition and</span></span><br><span class="line"><span class="string">          returns real/fake prediction matrices</span></span><br><span class="line"><span class="string">        real: the real images (e.g. maps) to be used to evaluate the reconstruction</span></span><br><span class="line"><span class="string">        condition: the source images (e.g. satellite imagery) which are used to produce the real images</span></span><br><span class="line"><span class="string">        adv_criterion: the adversarial loss function; takes the discriminator </span></span><br><span class="line"><span class="string">                  predictions and the true labels and returns a adversarial </span></span><br><span class="line"><span class="string">                  loss (which you aim to minimize)</span></span><br><span class="line"><span class="string">        recon_criterion: the reconstruction loss function; takes the generator </span></span><br><span class="line"><span class="string">                    outputs and the real images and returns a reconstructuion </span></span><br><span class="line"><span class="string">                    loss (which you aim to minimize)</span></span><br><span class="line"><span class="string">        lambda_recon: the degree to which the reconstruction loss should be weighted in the sum</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment">#### START CODE HERE ####</span></span><br><span class="line">    gen_img = gen(condition)</span><br><span class="line">    out = disc(gen_img, condition)</span><br><span class="line">    adv_loss = adv_criterion(out, torch.ones_like(out))</span><br><span class="line">    recon_loss = recon_criterion(gen_img, real)</span><br><span class="line">    gen_loss = adv_loss + lambda_recon * recon_loss</span><br><span class="line">    <span class="comment">#### END CODE HERE ####</span></span><br><span class="line">    <span class="keyword">return</span> gen_loss</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">adv_criterion = nn.BCEWithLogitsLoss() </span><br><span class="line">recon_criterion = nn.L1Loss() </span><br><span class="line">lambda_recon = <span class="number">200</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Update discriminator ###</span></span><br><span class="line">disc_fake_hat = disc(fake.detach(), condition) <span class="comment"># Detach generator</span></span><br><span class="line">disc_fake_loss = adv_criterion(disc_fake_hat, torch.zeros_like(disc_fake_hat))</span><br><span class="line">disc_real_hat = disc(real, condition)</span><br><span class="line">disc_real_loss = adv_criterion(disc_real_hat, torch.ones_like(disc_real_hat))</span><br><span class="line">disc_loss = (disc_fake_loss + disc_real_loss) / <span class="number">2</span></span><br><span class="line">disc_loss.backward(retain_graph=<span class="literal">True</span>) <span class="comment"># Update gradients</span></span><br><span class="line">disc_opt.step() <span class="comment"># Update optimizer</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Update generator ###</span></span><br><span class="line">gen_opt.zero_grad()</span><br><span class="line">gen_loss = get_gen_loss(gen, disc, real, condition, adv_criterion, recon_criterion, lambda_recon)</span><br></pre></td></tr></table></figure>
<h1 id="conclusion">Conclusion</h1>
<figure>
<img src="Screen_Shot_2022-02-12_at_15.43.41.png" alt="Screen Shot 2022-02-12 at 15.43.41.png" /><figcaption aria-hidden="true">Screen Shot 2022-02-12 at 15.43.41.png</figcaption>
</figure>
<p>The results in this paper suggest that conditional adversarial networks are a promising approach for many image- to-image translation tasks, especially those involving highly structured graphical outputs. These networks learn a loss adapted to the task and data at hand, which makes them applicable in a wide variety of settings.</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/Progressive-growing-of-GANs-for-improved-quality/2022/02/15/" rel="prev" title="Progressive growing of GANs for improved quality">
      <i class="fa fa-chevron-left"></i> Progressive growing of GANs for improved quality
    </a></div>
      <div class="post-nav-item">
    <a href="/InfoGAN-Interpretable-Representation-Learning-by-Information-Maximizing-Generative-Adversarial-Nets/2022/02/15/" rel="next" title="InfoGAN - Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets">
      InfoGAN - Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#image-to-image-translation-with-conditional-adversarial-networks"><span class="nav-number">1.</span> <span class="nav-text">Image-to-Image Translation with Conditional Adversarial Networks</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#highlights"><span class="nav-number">2.</span> <span class="nav-text">Highlights</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#intuition"><span class="nav-number">3.</span> <span class="nav-text">Intuition</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#methods"><span class="nav-number">4.</span> <span class="nav-text">Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#loss-function"><span class="nav-number">4.1.</span> <span class="nav-text">Loss function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#generator"><span class="nav-number">4.2.</span> <span class="nav-text">Generator</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#discriminator-patchgan"><span class="nav-number">4.3.</span> <span class="nav-text">Discriminator (PatchGAN)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#code"><span class="nav-number">5.</span> <span class="nav-text">Code</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#conclusion"><span class="nav-number">6.</span> <span class="nav-text">Conclusion</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ruochi Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">221</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zhangruochi" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zhangruochi" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zrc720@gmail.com" title="E-Mail → mailto:zrc720@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.healthinformaticslab.org/" title="http:&#x2F;&#x2F;www.healthinformaticslab.org" rel="noopener" target="_blank">HILab</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.shihaizhou.com/" title="http:&#x2F;&#x2F;www.shihaizhou.com" rel="noopener" target="_blank">Rose</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/cherish_CX/" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;cherish_CX&#x2F;" rel="noopener" target="_blank">Chunxia</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ruochi Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'qW3MLcAgcX96sB6qbegeL7rP-gzGzoHsz',
      appKey     : 'GL6JvT9DgGxqYrY5Vj6bXVuv',
      placeholder: "Thank you for your reply",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'en' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>

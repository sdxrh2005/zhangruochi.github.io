<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=PingFang SC:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhangruochi.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="RUOCHI.AI">
<meta property="og:url" content="https://zhangruochi.com/page/6/index.html">
<meta property="og:site_name" content="RUOCHI.AI">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Ruochi Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://zhangruochi.com/page/6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>RUOCHI.AI</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RUOCHI.AI</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Develop-a-blockchain-application-from-scratch-in-Python/2020/04/21/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Develop-a-blockchain-application-from-scratch-in-Python/2020/04/21/" class="post-title-link" itemprop="url">Develop a blockchain application from scratch in Python</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-21 00:37:03 / Modified: 14:02:15" itemprop="dateCreated datePublished" datetime="2020-04-21T00:37:03+08:00">2020-04-21</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Big-Data-Architecture/" itemprop="url" rel="index"><span itemprop="name">Big Data Architecture</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Big-Data-Architecture/Blockchain/" itemprop="url" rel="index"><span itemprop="name">Blockchain</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Develop-a-blockchain-application-from-scratch-in-Python/2020/04/21/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Develop-a-blockchain-application-from-scratch-in-Python/2020/04/21/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Blockchain is a way of storing digital data. The data can literally be anything. For Bitcoin, it’s the transactions (logs of transfers of Bitcoin from one account to another), but it can even be files; it doesn’t matter. The data is stored in the form of blocks, which are linked (or chained) together using cryptographic hashes — hence the name “blockchain.”</p>
<p>All of the magic lies in the way this data is stored and added to the blockchain. A blockchain is essentially a linked list that contains ordered data, with a few constraints such as:</p>
<ul>
<li>Blocks can’t be modified once added; in other words, it is append only.</li>
<li>There are specific rules for appending data to it.</li>
<li>Its architecture is distributed.</li>
</ul>
<p>Enforcing these constraints yields the following benefits:</p>
<ul>
<li>Immutability and durability of data</li>
<li>No single point of control or failure</li>
<li>A verifiable audit trail of the order in which data was added</li>
</ul>
<h3 id="store-transactions-into-blocks">Store transactions into blocks</h3>
<p>We’ll be storing data in our blockchain in a format that’s widely used: JSON. Here’s what a post stored in blockchain will look like:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123; </span><br><span class="line">  <span class="string">&quot;author&quot;</span>: <span class="string">&quot;some_author_name&quot;</span>, </span><br><span class="line">  <span class="string">&quot;content&quot;</span>: <span class="string">&quot;Some thoughts that author wants to share&quot;</span>, </span><br><span class="line">  <span class="string">&quot;timestamp&quot;</span>: <span class="string">&quot;The time at which the content was created&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The generic term “data” is often replaced on the internet by the term “transactions.” So, just to avoid confusion and maintain consistency, we’ll be using the term “transaction” to refer to data in our example application.</p>
<p>The transactions are packed into blocks. A block can contain one or many transactions. The blocks containing the transactions are generated frequently and added to the blockchain. Because there can be multiple blocks, each block should have a unique ID.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Block</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, index, transactions, timestamp</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Constructor for the `Block` class.</span></span><br><span class="line"><span class="string">        :param index: Unique ID of the block.</span></span><br><span class="line"><span class="string">        :param transactions: List of transactions.</span></span><br><span class="line"><span class="string">        :param timestamp: Time of generation of the block.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.index = index </span><br><span class="line">        self.transactions = transactions </span><br><span class="line">        self.timestamp = timestamp</span><br></pre></td></tr></table></figure>
<h3 id="add-digital-fingerprints-to-the-blocks">Add digital fingerprints to the blocks</h3>
<p>We’d like to prevent any kind of tampering in the data stored inside the block, and detection is the first step to that. To detect if the data in the block has been tampered with, you can use cryptographic hash functions.</p>
<p>A hash function is a function that takes data of any size and produces data of a fixed size from it (a hash), which is generally used to identify the input. The characteristics of an ideal hash function are:</p>
<ul>
<li>It should be easy to compute.</li>
<li>It should be deterministic, meaning the same data will always result in the same hash.</li>
<li>It should be uniformly random, meaning even a single bit change in the data should change the hash significantly.</li>
</ul>
<p>The consequence of this is:</p>
<ul>
<li>It is virtually impossible to guess the input data given the hash. (The only way is to try all possible input combinations.)</li>
<li>If you know both the input and the hash, you can simply pass the input through the hash function to verify the provided hash.</li>
</ul>
<p>This asymmetry of efforts that’s required to figure out the hash from an input (easy) vs. figuring out the input from a hash (almost impossible) is what blockchain leverages to obtain the desired characteristics.</p>
<p>We’ll store the hash of the block in a field inside our Block object, and it will act like a digital fingerprint (or signature) of data contained in it:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> sha256</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_hash</span>(<span class="params">block</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Returns the hash of the block instance by first converting it</span></span><br><span class="line"><span class="string">    into JSON string.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    block_string = json.dumps(self.__dict__, sort_keys=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sha256(block_string.encode()).hexdigest()</span><br></pre></td></tr></table></figure>
<p><strong>Note</strong>: In most cryptocurrencies, even the individual transactions in the block are hashed and then stored to form a hash tree (also known as a merkle tree). The root of the tree usually represents the hash of the block. It’s not a necessary requirement for the functioning of the blockchain, so we’re omitting it to keep things simple.</p>
<h3 id="chain-the-blocks">Chain the blocks</h3>
<p>Okay, we’ve now set up the blocks. The blockchain is supposed to be a collection of blocks. We can store all the blocks in the Python list (the equivalent of an array). But this is not sufficient, because what if someone intentionally replaces an old block with a new block in the collection? Creating a new block with altered transactions, computing the hash, and replacing it with any older block is no big deal in our current implementation.</p>
<p>We need a way to make sure that any change in the previous blocks invalidates the entire chain. The Bitcoin way to do this is to create dependency among consecutive blocks by chaining them with the hash of the block immediately previous to them. By chaining here, we mean to include the hash of the previous block in the current block in a new field called previous_hash.</p>
<p>Okay, if every block is linked to the previous block through the previous_hash field, what about the very first block? That block is called the genesis block and it can be generated either manually or through some unique logic. Let’s add the previous_hash field to the Block class and implement the initial structure of our Blockchain class.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> sha256</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Block</span>:</span></span><br><span class="line">    def__init__(self, index, transactions, timestamp, previous_hash):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Constructor for the `Block` class.</span></span><br><span class="line"><span class="string">        :param index:         Unique ID of the block.</span></span><br><span class="line"><span class="string">        :param transactions:  List of transactions.</span></span><br><span class="line"><span class="string">        :param timestamp:     Time of generation of the block.</span></span><br><span class="line"><span class="string">        :param previous_hash: Hash of the previous block in the chain which this block is part of.                                        </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.index = index</span><br><span class="line">        self.transactions = transactions</span><br><span class="line">        self.timestamp = timestamp</span><br><span class="line">        self.previous_hash = previous_hash <span class="comment"># Adding the previous hash field</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_hash</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Returns the hash of the block instance by first converting it</span></span><br><span class="line"><span class="string">        into JSON string.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        block_string = json.dumps(self.__dict__, sort_keys=<span class="literal">True</span>) <span class="comment"># The string equivalent also considers the previous_hash field now</span></span><br><span class="line">        <span class="keyword">return</span> sha256(block_string.encode()).hexdigest()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blockchain</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Constructor for the `Blockchain` class.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.chain = []</span><br><span class="line">        self.create_genesis_block()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">create_genesis_block</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        A function to generate genesis block and appends it to</span></span><br><span class="line"><span class="string">        the chain. The block has index 0, previous_hash as 0, and</span></span><br><span class="line"><span class="string">        a valid hash.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        genesis_block = Block(<span class="number">0</span>, [], time.time(), <span class="string">&quot;0&quot;</span>)</span><br><span class="line">        genesis_block.<span class="built_in">hash</span> = genesis_block.compute_hash()</span><br><span class="line">        self.chain.append(genesis_block)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">last_block</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        A quick pythonic way to retrieve the most recent block in the chain. Note that</span></span><br><span class="line"><span class="string">        the chain will always consist of at least one block (i.e., genesis block)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.chain[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>Now, if the content of any of the previous blocks changes: - The hash of that previous block would change. - This will lead to a mismatch with the previous_hash field in the next block. - Since the input data to compute the hash of any block also consists of the previous_hash field, the hash of the next block will also change.</p>
<p>Ultimately, the entire chain following the replaced block is invalidated, and the only way to fix it is to recompute the entire chain.</p>
<h3 id="implement-a-proof-of-work-algorithm">Implement a proof of work algorithm</h3>
<p>There is one problem, though. If we change the previous block, the hashes of all the blocks that follow can be re-computed quite easily to create a different valid blockchain. To prevent this, we can exploit the asymmetry in efforts of hash functions that we discussed earlier to make the task of calculating the hash difficult and random. Here’s how we do this: Instead of accepting any hash for the block, we add some constraint to it. Let’s add a constraint that our hash should start with “n leading zeroes” where n can be any positive integer.</p>
<p>We know that unless we change the data of the block, the hash is not going to change, and of course we don’t want to change existing data. So what do we do? Simple! We’ll add some dummy data that we can change. Let’s introduce a new field in our block called nonce. A nonce is a number that we can keep on changing until we get a hash that satisfies our constraint. The nonce satisfying the constraint serves as proof that some computation has been performed. This technique is a simplified version of the Hashcash algorithm used in Bitcoin. The number of zeroes specified in the constraint determines the difficulty of our proof of work algorithm (the greater the number of zeroes, the harder it is to figure out the nonce).</p>
<p>Also, due to the asymmetry, proof of work is difficult to compute but very easy to verify once you figure out the nonce (you just have to run the hash function again):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blockchain</span>:</span></span><br><span class="line">    <span class="comment"># difficulty of PoW algorithm</span></span><br><span class="line">    difficulty = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Previous code contd..</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">proof_of_work</span>(<span class="params">self, block</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Function that tries different values of the nonce to get a hash</span></span><br><span class="line"><span class="string">        that satisfies our difficulty criteria.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        block.nonce = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        computed_hash = block.compute_hash()</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> computed_hash.startswith(<span class="string">&#x27;0&#x27;</span> * Blockchain.difficulty):</span><br><span class="line">            block.nonce += <span class="number">1</span></span><br><span class="line">            computed_hash = block.compute_hash()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> computed_hash</span><br></pre></td></tr></table></figure>
<p>Notice that there is no specific logic to figuring out the nonce quickly; it’s just brute force. The only definite improvement that you can make is to use hardware chips that are specially designed to compute the hash function in a smaller number of CPU instructions.</p>
<h3 id="add-blocks-to-the-chain">Add blocks to the chain</h3>
<p>To add a block to the chain, we’ll first have to verify that:</p>
<ul>
<li>The data has not been tampered with (the proof of work provided is correct).</li>
<li>The order of transactions is preserved (the previous_hash field of the block to be added points to the hash of the latest block in our chain).</li>
</ul>
<p>Let’s see the code for adding blocks into the chain:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blockchain</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Previous code contd..</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_block</span>(<span class="params">self, block, proof</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        A function that adds the block to the chain after verification.</span></span><br><span class="line"><span class="string">        Verification includes:</span></span><br><span class="line"><span class="string">        * Checking if the proof is valid.</span></span><br><span class="line"><span class="string">        * The previous_hash referred in the block and the hash of a latest block</span></span><br><span class="line"><span class="string">          in the chain match.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        previous_hash = self.last_block.<span class="built_in">hash</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> previous_hash != block.previous_hash:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> Blockchain.is_valid_proof(block, proof):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        block.<span class="built_in">hash</span> = proof</span><br><span class="line">        self.chain.append(block)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_valid_proof</span>(<span class="params">self, block, block_hash</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Check if block_hash is valid hash of block and satisfies</span></span><br><span class="line"><span class="string">        the difficulty criteria.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> (block_hash.startswith(<span class="string">&#x27;0&#x27;</span> * Blockchain.difficulty) <span class="keyword">and</span></span><br><span class="line">                block_hash == block.compute_hash())</span><br></pre></td></tr></table></figure>
<h3 id="mining">Mining</h3>
<p>The transactions will be initially stored as a pool of unconfirmed transactions. The process of putting the unconfirmed transactions in a block and computing proof of work is known as the mining of blocks. Once the nonce satisfying our constraints is figured out, we can say that a block has been mined and it can be put into the blockchain.</p>
<p>In most of the cryptocurrencies (including Bitcoin), miners may be awarded some cryptocurrency as a reward for spending their computing power to compute a proof of work. Here’s what our mining function looks like:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blockchain</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.unconfirmed_transactions = [] <span class="comment"># data yet to get into blockchain</span></span><br><span class="line">        self.chain = []</span><br><span class="line">        self.create_genesis_block()</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Previous code contd...</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_new_transaction</span>(<span class="params">self, transaction</span>):</span></span><br><span class="line">        self.unconfirmed_transactions.append(transaction)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mine</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        This function serves as an interface to add the pending</span></span><br><span class="line"><span class="string">        transactions to the blockchain by adding them to the block</span></span><br><span class="line"><span class="string">        and figuring out proof of work.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.unconfirmed_transactions:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        last_block = self.last_block</span><br><span class="line"></span><br><span class="line">        new_block = Block(index=last_block.index + <span class="number">1</span>,</span><br><span class="line">                          transactions=self.unconfirmed_transactions,</span><br><span class="line">                          timestamp=time.time(),</span><br><span class="line">                          previous_hash=last_block.<span class="built_in">hash</span>)</span><br><span class="line"></span><br><span class="line">        proof = self.proof_of_work(new_block)</span><br><span class="line">        self.add_block(new_block, proof)</span><br><span class="line">        self.unconfirmed_transactions = []</span><br><span class="line">        <span class="keyword">return</span> new_block.index</span><br></pre></td></tr></table></figure>
<h3 id="combined-code">Combined Code</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> sha256</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Block</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, index, transactions, timestamp, previous_hash</span>):</span></span><br><span class="line">        self.index = index</span><br><span class="line">        self.transactions = transactions</span><br><span class="line">        self.timestamp = timestamp</span><br><span class="line">        self.previous_hash = previous_hash</span><br><span class="line">        self.nonce = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_hash</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        A function that return the hash of the block contents.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        block_string = json.dumps(self.__dict__, sort_keys=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> sha256(block_string.encode()).hexdigest()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blockchain</span>:</span></span><br><span class="line">    <span class="comment"># difficulty of our PoW algorithm</span></span><br><span class="line">    difficulty = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.unconfirmed_transactions = []</span><br><span class="line">        self.chain = []</span><br><span class="line">        self.create_genesis_block()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">create_genesis_block</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        A function to generate genesis block and appends it to</span></span><br><span class="line"><span class="string">        the chain. The block has index 0, previous_hash as 0, and</span></span><br><span class="line"><span class="string">        a valid hash.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        genesis_block = Block(<span class="number">0</span>, [], time.time(), <span class="string">&quot;0&quot;</span>)</span><br><span class="line">        genesis_block.<span class="built_in">hash</span> = genesis_block.compute_hash()</span><br><span class="line">        self.chain.append(genesis_block)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">last_block</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.chain[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_block</span>(<span class="params">self, block, proof</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        A function that adds the block to the chain after verification.</span></span><br><span class="line"><span class="string">        Verification includes:</span></span><br><span class="line"><span class="string">        * Checking if the proof is valid.</span></span><br><span class="line"><span class="string">        * The previous_hash referred in the block and the hash of latest block</span></span><br><span class="line"><span class="string">          in the chain match.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        previous_hash = self.last_block.<span class="built_in">hash</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> previous_hash != block.previous_hash:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.is_valid_proof(block, proof):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        block.<span class="built_in">hash</span> = proof</span><br><span class="line">        self.chain.append(block)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_valid_proof</span>(<span class="params">self, block, block_hash</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Check if block_hash is valid hash of block and satisfies</span></span><br><span class="line"><span class="string">        the difficulty criteria.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> (block_hash.startswith(<span class="string">&#x27;0&#x27;</span> * Blockchain.difficulty) <span class="keyword">and</span></span><br><span class="line">                block_hash == block.compute_hash())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">proof_of_work</span>(<span class="params">self, block</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Function that tries different values of nonce to get a hash</span></span><br><span class="line"><span class="string">        that satisfies our difficulty criteria.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        block.nonce = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        computed_hash = block.compute_hash()</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> computed_hash.startswith(<span class="string">&#x27;0&#x27;</span> * Blockchain.difficulty):</span><br><span class="line">            block.nonce += <span class="number">1</span></span><br><span class="line">            computed_hash = block.compute_hash()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> computed_hash</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_new_transaction</span>(<span class="params">self, transaction</span>):</span></span><br><span class="line">        self.unconfirmed_transactions.append(transaction)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mine</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        This function serves as an interface to add the pending</span></span><br><span class="line"><span class="string">        transactions to the blockchain by adding them to the block</span></span><br><span class="line"><span class="string">        and figuring out Proof Of Work.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.unconfirmed_transactions:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        new_block = Block(index=last_block.index + <span class="number">1</span>,</span><br><span class="line">                          transactions=self.unconfirmed_transactions,</span><br><span class="line">                          timestamp=time.time(),</span><br><span class="line">                          previous_hash=self.last_block.<span class="built_in">hash</span>)</span><br><span class="line"></span><br><span class="line">        proof = self.proof_of_work(new_block)</span><br><span class="line">        self.add_block(new_block, proof)</span><br><span class="line"></span><br><span class="line">        self.unconfirmed_transactions = []</span><br><span class="line">        <span class="keyword">return</span> new_block.index</span><br></pre></td></tr></table></figure>
<h3 id="create-interfaces">Create interfaces</h3>
<p>Okay, now it’s time to create interfaces for our blockchain node to interact with the application we’re going to build. We’ll be using a popular Python microframework called Flask to create a REST API that interacts with and invokes various operations in our blockchain node. If you’ve worked with any web framework before, the code below shouldn’t be difficult to follow along.</p>
<p>These REST endpoints can be used to play around with our blockchain by creating some transactions and then mining them.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, request</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize flask application</span></span><br><span class="line">app =  Flask(__name__)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize a blockchain object.</span></span><br><span class="line">blockchain = Blockchain()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### We need an endpoint for our application to submit a new transaction. This will be used by our application to add new data (posts) to the blockchain:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Flask&#x27;s way of declaring end-points</span></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/new_transaction&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">new_transaction</span>():</span></span><br><span class="line">    tx_data = request.get_json()</span><br><span class="line">    required_fields = [<span class="string">&quot;author&quot;</span>, <span class="string">&quot;content&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> field <span class="keyword">in</span> required_fields:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> tx_data.get(field):</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;Invalid transaction data&quot;</span>, <span class="number">404</span></span><br><span class="line"></span><br><span class="line">    tx_data[<span class="string">&quot;timestamp&quot;</span>] = time.time()</span><br><span class="line"></span><br><span class="line">    blockchain.add_new_transaction(tx_data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Success&quot;</span>, <span class="number">201</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### Here’s an endpoint to return the node’s copy of the chain. Our application will be using this endpoint to query all of the data to display:</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/chain&#x27;</span>, methods=[<span class="string">&#x27;GET&#x27;</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_chain</span>():</span></span><br><span class="line">    chain_data = []</span><br><span class="line">    <span class="keyword">for</span> block <span class="keyword">in</span> blockchain.chain:</span><br><span class="line">        chain_data.append(block.__dict__)</span><br><span class="line">    <span class="keyword">return</span> json.dumps(&#123;<span class="string">&quot;length&quot;</span>: <span class="built_in">len</span>(chain_data),</span><br><span class="line">                       <span class="string">&quot;chain&quot;</span>: chain_data&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Here’s an endpoint to request the node to mine the unconfirmed transactions (if any). We’ll be using it to initiate a command to mine from our application itself:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/mine&#x27;</span>, methods=[<span class="string">&#x27;GET&#x27;</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mine_unconfirmed_transactions</span>():</span></span><br><span class="line">    result = blockchain.mine()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> result:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;No transactions to mine&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Block #&#123;&#125; is mined.&quot;</span>.<span class="built_in">format</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/pending_tx&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_pending_tx</span>():</span></span><br><span class="line">    <span class="keyword">return</span> json.dumps(blockchain.unconfirmed_transactions)</span><br></pre></td></tr></table></figure>
<h3 id="establish-consensus-and-decentralization">Establish consensus and decentralization</h3>
<p>Up to this point, the blockchain that we’ve implemented is meant to run on a single computer. Even though we’re linking block with hashes and applying the proof of work constraint, we still can’t trust a single entity (in our case, a single machine). We need the data to be distributed, we need multiple nodes maintaining the blockchain. So, to transition from a single node to a peer-to-peer network, let’s first create a mechanism to let a new node become aware of other peers in the network:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Contains the host addresses of other participating members of the network</span></span><br><span class="line">peers = <span class="built_in">set</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Endpoint to add new peers to the network</span></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/register_node&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">register_new_peers</span>():</span></span><br><span class="line">    <span class="comment"># The host address to the peer node </span></span><br><span class="line">    node_address = request.get_json()[<span class="string">&quot;node_address&quot;</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> node_address:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Invalid data&quot;</span>, <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add the node to the peer list</span></span><br><span class="line">    peers.add(node_address)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Return the blockchain to the newly registered node so that it can sync</span></span><br><span class="line">    <span class="keyword">return</span> get_chain()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/register_with&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">register_with_existing_node</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Internally calls the `register_node` endpoint to</span></span><br><span class="line"><span class="string">    register current node with the remote node specified in the</span></span><br><span class="line"><span class="string">    request, and sync the blockchain as well with the remote node.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    node_address = request.get_json()[<span class="string">&quot;node_address&quot;</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> node_address:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Invalid data&quot;</span>, <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    data = &#123;<span class="string">&quot;node_address&quot;</span>: request.host_url&#125;</span><br><span class="line">    headers = &#123;<span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&quot;application/json&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Make a request to register with remote node and obtain information</span></span><br><span class="line">    response = requests.post(node_address + <span class="string">&quot;/register_node&quot;</span>,</span><br><span class="line">                             data=json.dumps(data), headers=headers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">        <span class="keyword">global</span> blockchain</span><br><span class="line">        <span class="keyword">global</span> peers</span><br><span class="line">        <span class="comment"># update chain and the peers</span></span><br><span class="line">        chain_dump = response.json()[<span class="string">&#x27;chain&#x27;</span>]</span><br><span class="line">        blockchain = create_chain_from_dump(chain_dump)</span><br><span class="line">        peers.update(response.json()[<span class="string">&#x27;peers&#x27;</span>])</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Registration successful&quot;</span>, <span class="number">200</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># if something goes wrong, pass it on to the API response</span></span><br><span class="line">        <span class="keyword">return</span> response.content, response.status_code</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_chain_from_dump</span>(<span class="params">chain_dump</span>):</span></span><br><span class="line">    blockchain = Blockchain()</span><br><span class="line">    <span class="keyword">for</span> idx, block_data <span class="keyword">in</span> <span class="built_in">enumerate</span>(chain_dump):</span><br><span class="line">        block = Block(block_data[<span class="string">&quot;index&quot;</span>],</span><br><span class="line">                      block_data[<span class="string">&quot;transactions&quot;</span>],</span><br><span class="line">                      block_data[<span class="string">&quot;timestamp&quot;</span>],</span><br><span class="line">                      block_data[<span class="string">&quot;previous_hash&quot;</span>])</span><br><span class="line">        proof = block_data[<span class="string">&#x27;hash&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> idx &gt; <span class="number">0</span>:</span><br><span class="line">            added = blockchain.add_block(block, proof)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> added:</span><br><span class="line">                <span class="keyword">raise</span> Exception(<span class="string">&quot;The chain dump is tampered!!&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># the block is a genesis block, no verification needed</span></span><br><span class="line">            blockchain.chain.append(block)</span><br><span class="line">    <span class="keyword">return</span> blockchain</span><br></pre></td></tr></table></figure>
<p>A new node participating in the network can invoke the register_with_existing_node method (via the /register_with endpoint) to register with existing nodes in the network. This will help with the following:</p>
<ul>
<li>Asking the remote node to add a new peer to its list of known peers.</li>
<li>Initializing the blockchain of the new node with that of the remote node.</li>
<li>Resyncing the blockchain with the network if the node goes off-grid.</li>
</ul>
<p>However, there’s a problem with multiple nodes. Due to intentional manipulation or unintentional reasons (like network latency), the copy of chains of a few nodes can differ. In that case, the nodes need to agree upon some version of the chain to maintain the integrity of the entire system. In other words, we need to achieve consensus.</p>
<p>A simple consensus algorithm could be to agree upon the longest valid chain when the chains of different participating nodes in the network appear to diverge. The rationale behind this approach is that the longest chain is a good estimate of the most amount of work done (remember proof of work is difficult to compute):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blockchain</span></span></span><br><span class="line"><span class="class">    &quot;&quot;&quot;</span></span><br><span class="line"><span class="class">    <span class="title">previous</span> <span class="title">code</span> <span class="title">continued</span>...</span></span><br><span class="line"><span class="class">    &quot;&quot;&quot;</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">check_chain_validity</span>(<span class="params">cls, chain</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        A helper method to check if the entire blockchain is valid.            </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        result = <span class="literal">True</span></span><br><span class="line">        previous_hash = <span class="string">&quot;0&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate through every block</span></span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> chain:</span><br><span class="line">            block_hash = block.<span class="built_in">hash</span></span><br><span class="line">            <span class="comment"># remove the hash field to recompute the hash again</span></span><br><span class="line">            <span class="comment"># using `compute_hash` method.</span></span><br><span class="line">            <span class="built_in">delattr</span>(block, <span class="string">&quot;hash&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> cls.is_valid_proof(block, block.<span class="built_in">hash</span>) <span class="keyword">or</span> \</span><br><span class="line">                    previous_hash != block.previous_hash:</span><br><span class="line">                result = <span class="literal">False</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            block.<span class="built_in">hash</span>, previous_hash = block_hash, block_hash</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">consensus</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Our simple consensus algorithm. If a longer valid chain is</span></span><br><span class="line"><span class="string">    found, our chain is replaced with it.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">global</span> blockchain</span><br><span class="line"></span><br><span class="line">    longest_chain = <span class="literal">None</span></span><br><span class="line">    current_len = <span class="built_in">len</span>(blockchain.chain)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> peers:</span><br><span class="line">        response = requests.get(<span class="string">&#x27;&#123;&#125;/chain&#x27;</span>.<span class="built_in">format</span>(node))</span><br><span class="line">        length = response.json()[<span class="string">&#x27;length&#x27;</span>]</span><br><span class="line">        chain = response.json()[<span class="string">&#x27;chain&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> length &gt; current_len <span class="keyword">and</span> blockchain.check_chain_validity(chain):</span><br><span class="line">              <span class="comment"># Longer valid chain found!</span></span><br><span class="line">            current_len = length</span><br><span class="line">            longest_chain = chain</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> longest_chain:</span><br><span class="line">        blockchain = longest_chain</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>Next, we need to develop a way for any node to announce to the network that it has mined a block so that everyone can update their blockchain and move on to mine other transactions. Other nodes can simply verify the proof of work and add the mined block to their respective chains (remember that verification is easy once the nonce is known):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># endpoint to add a block mined by someone else to</span></span><br><span class="line"><span class="comment"># the node&#x27;s chain. The node first verifies the block</span></span><br><span class="line"><span class="comment"># and then adds it to the chain.</span></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/add_block&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">verify_and_add_block</span>():</span></span><br><span class="line">    block_data = request.get_json()</span><br><span class="line">    block = Block(block_data[<span class="string">&quot;index&quot;</span>],</span><br><span class="line">                  block_data[<span class="string">&quot;transactions&quot;</span>],</span><br><span class="line">                  block_data[<span class="string">&quot;timestamp&quot;</span>],</span><br><span class="line">                  block_data[<span class="string">&quot;previous_hash&quot;</span>])</span><br><span class="line"></span><br><span class="line">    proof = block_data[<span class="string">&#x27;hash&#x27;</span>]</span><br><span class="line">    added = blockchain.add_block(block, proof)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> added:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;The block was discarded by the node&quot;</span>, <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Block added to the chain&quot;</span>, <span class="number">201</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">announce_new_block</span>(<span class="params">block</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A function to announce to the network once a block has been mined.</span></span><br><span class="line"><span class="string">    Other blocks can simply verify the proof of work and add it to their</span></span><br><span class="line"><span class="string">    respective chains.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> peer <span class="keyword">in</span> peers:</span><br><span class="line">        url = <span class="string">&quot;&#123;&#125;add_block&quot;</span>.<span class="built_in">format</span>(peer)</span><br><span class="line">        requests.post(url, data=json.dumps(block.__dict__, sort_keys=<span class="literal">True</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>The announce_new_block method should be called after every block is mined by the node so that peers can add it to their chains.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/mine&#x27;</span>, methods=[<span class="string">&#x27;GET&#x27;</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mine_unconfirmed_transactions</span>():</span></span><br><span class="line">    result = blockchain.mine()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> result:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;No transactions to mine&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Making sure we have the longest chain before announcing to the network</span></span><br><span class="line">        chain_length = <span class="built_in">len</span>(blockchain.chain)</span><br><span class="line">        consensus()</span><br><span class="line">        <span class="keyword">if</span> chain_length == <span class="built_in">len</span>(blockchain.chain):</span><br><span class="line">            <span class="comment"># announce the recently mined block to the network</span></span><br><span class="line">            announce_new_block(blockchain.last_block)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Block #&#123;&#125; is mined.&quot;</span>.<span class="built_in">format</span>(blockchain.last_block.index)</span><br></pre></td></tr></table></figure>
<h3 id="build-the-application">Build the application</h3>
<p>Now, it’s time to start working on the interface of our application. We’ve used Jinja2 templating to render the web pages and some CSS to make things look nice.</p>
<p>Our application needs to connect to a node in the blockchain network to fetch the data and also to submit new data. There can also be multiple nodes, as well.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> render_template, redirect, request</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> app <span class="keyword">import</span> app</span><br><span class="line"></span><br><span class="line"><span class="comment"># Node in the blockchain network that our application will communicate with</span></span><br><span class="line"><span class="comment"># to fetch and add data.</span></span><br><span class="line">CONNECTED_NODE_ADDRESS = <span class="string">&quot;http://127.0.0.1:8000&quot;</span></span><br><span class="line"></span><br><span class="line">posts = []</span><br></pre></td></tr></table></figure>
<p>The fetch_posts function gets the data from the node’s /chain endpoint, parses the data, and stores it locally.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetch_posts</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Function to fetch the chain from a blockchain node, parse the</span></span><br><span class="line"><span class="string">    data, and store it locally.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    get_chain_address = <span class="string">&quot;&#123;&#125;/chain&quot;</span>.<span class="built_in">format</span>(CONNECTED_NODE_ADDRESS)</span><br><span class="line">    response = requests.get(get_chain_address)</span><br><span class="line">    <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">        content = []</span><br><span class="line">        chain = json.loads(response.content)</span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> chain[<span class="string">&quot;chain&quot;</span>]:</span><br><span class="line">            <span class="keyword">for</span> tx <span class="keyword">in</span> block[<span class="string">&quot;transactions&quot;</span>]:</span><br><span class="line">                tx[<span class="string">&quot;index&quot;</span>] = block[<span class="string">&quot;index&quot;</span>]</span><br><span class="line">                tx[<span class="string">&quot;hash&quot;</span>] = block[<span class="string">&quot;previous_hash&quot;</span>]</span><br><span class="line">                content.append(tx)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">global</span> posts</span><br><span class="line">        posts = <span class="built_in">sorted</span>(content,</span><br><span class="line">                       key=<span class="keyword">lambda</span> k: k[<span class="string">&#x27;timestamp&#x27;</span>],</span><br><span class="line">                       reverse=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>The application has an HTML form to take user input and then makes a POST request to a connected node to add the transaction into the unconfirmed transactions pool. The transaction is then mined by the network, and then finally fetched once we refresh our web page:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/submit&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">submit_textarea</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Endpoint to create a new transaction via our application</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    post_content = request.form[<span class="string">&quot;content&quot;</span>]</span><br><span class="line">    author = request.form[<span class="string">&quot;author&quot;</span>]</span><br><span class="line"></span><br><span class="line">    post_object = &#123;</span><br><span class="line">        <span class="string">&#x27;author&#x27;</span>: author,</span><br><span class="line">        <span class="string">&#x27;content&#x27;</span>: post_content,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Submit a transaction</span></span><br><span class="line">    new_tx_address = <span class="string">&quot;&#123;&#125;/new_transaction&quot;</span>.<span class="built_in">format</span>(CONNECTED_NODE_ADDRESS)</span><br><span class="line"></span><br><span class="line">    requests.post(new_tx_address,</span><br><span class="line">                  json=post_object,</span><br><span class="line">                  headers=&#123;<span class="string">&#x27;Content-type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Return to the homepage</span></span><br><span class="line">    <span class="keyword">return</span> redirect(<span class="string">&#x27;/&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="reference">Reference</h1>
<ul>
<li>https://developer.ibm.com/tutorials/develop-a-blockchain-application-from-scratch-in-python/</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Cox-Proportional-Hazards-and-Random-Survival-Forests/2020/04/19/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Cox-Proportional-Hazards-and-Random-Survival-Forests/2020/04/19/" class="post-title-link" itemprop="url">Cox Proportional Hazards and Random Survival Forests</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-19 13:54:32" itemprop="dateCreated datePublished" datetime="2020-04-19T13:54:32+08:00">2020-04-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-20 01:54:52" itemprop="dateModified" datetime="2020-04-20T01:54:52+08:00">2020-04-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Cox-Proportional-Hazards-and-Random-Survival-Forests/2020/04/19/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Cox-Proportional-Hazards-and-Random-Survival-Forests/2020/04/19/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="cox-proportional-hazards-and-random-survival-forests">Cox Proportional Hazards and Random Survival Forests</h1>
<p>Welcome to the final assignment in Course 2! In this assignment you'll develop risk models using survival data and a combination of linear and non-linear techniques. We'll be using a dataset with survival data of patients with Primary Biliary Cirrhosis (pbc). PBC is a progressive disease of the liver caused by a buildup of bile within the liver (cholestasis) that results in damage to the small bile ducts that drain bile from the liver. Our goal will be to understand the effects of different factors on the survival times of the patients. Along the way you'll learn about the following topics:</p>
<ul>
<li>Cox Proportional Hazards
<ul>
<li>Data Preprocessing for Cox Models.</li>
</ul></li>
<li>Random Survival Forests
<ul>
<li>Permutation Methods for Interpretation.</li>
</ul></li>
</ul>
<h2 id="outline">Outline</h2>
<ul>
<li><a href="#1">1. Import Packages</a></li>
<li><a href="#2">2. Load the Dataset</a></li>
<li><a href="#3">3. Explore the Dataset</a></li>
<li><a href="#4">4. Cox Proportional Hazards</a>
<ul>
<li><a href="#Ex-1">Exercise 1</a></li>
</ul></li>
<li><a href="#5">5. Fitting and Interpreting a Cox Model</a></li>
<li><a href="#3">6. Hazard ratio</a>
<ul>
<li><a href="#Ex-2">Exercise 2</a></li>
</ul></li>
<li><a href="#7">7. Harrell's C-Index</a>
<ul>
<li><a href="#Ex-3">Exercise 3</a></li>
</ul></li>
<li><a href="#8">8. Random Survival Forests</a></li>
<li><a href="#9">9. Permutation Method for Interpretation</a></li>
</ul>
<p><a name='1'></a> ## 1. Import Packages</p>
<p>We'll first import all the packages that we need for this assignment.</p>
<ul>
<li><code>sklearn</code> is one of the most popular machine learning libraries.</li>
<li><code>numpy</code> is the fundamental package for scientific computing in python.</li>
<li><code>pandas</code> is what we'll use to manipulate our data.</li>
<li><code>matplotlib</code> is a plotting library.</li>
<li><code>lifelines</code> is an open-source survival analysis library.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lifelines <span class="keyword">import</span> CoxPHFitter</span><br><span class="line"><span class="keyword">from</span> lifelines.utils <span class="keyword">import</span> concordance_index <span class="keyword">as</span> cindex</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> util <span class="keyword">import</span> load_data</span><br></pre></td></tr></table></figure>
<p><a name='2'></a> ## 2. Load the Dataset</p>
<p>Run the next cell to load the data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = load_data()</span><br></pre></td></tr></table></figure>
<p><a name='3'></a> ## 3. Explore the Dataset</p>
<p>In the lecture videos <code>time</code> was in months, however in this assignment, <code>time</code> will be converted into years. Also notice that we have assigned a numeric value to <code>sex</code>, where <code>female = 0</code> and <code>male = 1</code>.</p>
<p>Next, familiarize yourself with the data and the shape of it.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(df.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># df.head() only outputs the top few rows</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<pre><code>(258, 19)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
time
</th>
<th>
status
</th>
<th>
trt
</th>
<th>
age
</th>
<th>
sex
</th>
<th>
ascites
</th>
<th>
hepato
</th>
<th>
spiders
</th>
<th>
edema
</th>
<th>
bili
</th>
<th>
chol
</th>
<th>
albumin
</th>
<th>
copper
</th>
<th>
alk.phos
</th>
<th>
ast
</th>
<th>
trig
</th>
<th>
platelet
</th>
<th>
protime
</th>
<th>
stage
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1.095890
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
58.765229
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
1.0
</td>
<td>
1.0
</td>
<td>
1.0
</td>
<td>
14.5
</td>
<td>
261.0
</td>
<td>
2.60
</td>
<td>
156.0
</td>
<td>
1718.0
</td>
<td>
137.95
</td>
<td>
172.0
</td>
<td>
190.0
</td>
<td>
12.2
</td>
<td>
4.0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
12.328767
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
56.446270
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
1.1
</td>
<td>
302.0
</td>
<td>
4.14
</td>
<td>
54.0
</td>
<td>
7394.8
</td>
<td>
113.52
</td>
<td>
88.0
</td>
<td>
221.0
</td>
<td>
10.6
</td>
<td>
3.0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2.772603
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
70.072553
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.5
</td>
<td>
1.4
</td>
<td>
176.0
</td>
<td>
3.48
</td>
<td>
210.0
</td>
<td>
516.0
</td>
<td>
96.10
</td>
<td>
55.0
</td>
<td>
151.0
</td>
<td>
12.0
</td>
<td>
4.0
</td>
</tr>
<tr>
<th>
3
</th>
<td>
5.273973
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
54.740589
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
1.0
</td>
<td>
0.5
</td>
<td>
1.8
</td>
<td>
244.0
</td>
<td>
2.54
</td>
<td>
64.0
</td>
<td>
6121.8
</td>
<td>
60.63
</td>
<td>
92.0
</td>
<td>
183.0
</td>
<td>
10.3
</td>
<td>
4.0
</td>
</tr>
<tr>
<th>
6
</th>
<td>
5.019178
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
55.534565
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
322.0
</td>
<td>
4.09
</td>
<td>
52.0
</td>
<td>
824.0
</td>
<td>
60.45
</td>
<td>
213.0
</td>
<td>
204.0
</td>
<td>
9.7
</td>
<td>
3.0
</td>
</tr>
</tbody>
</table>
</div>
<p>Take a minute to examine particular cases.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">20</span></span><br><span class="line">df.iloc[i, :]</span><br></pre></td></tr></table></figure>
<pre><code>time          11.175342
status         1.000000
trt            0.000000
age           44.520192
sex            1.000000
ascites        0.000000
hepato         1.000000
spiders        0.000000
edema          0.000000
bili           2.100000
chol         456.000000
albumin        4.000000
copper       124.000000
alk.phos    5719.000000
ast          221.880000
trig         230.000000
platelet      70.000000
protime        9.900000
stage          2.000000
Name: 23, dtype: float64</code></pre>
<p>Now, split your dataset into train, validation and test set using 60/20/20 split.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">df_dev, df_test = train_test_split(df, test_size = <span class="number">0.2</span>)</span><br><span class="line">df_train, df_val = train_test_split(df_dev, test_size = <span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Total number of patients:&quot;</span>, df.shape[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Total number of patients in training set:&quot;</span>, df_train.shape[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Total number of patients in validation set:&quot;</span>, df_val.shape[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Total number of patients in test set:&quot;</span>, df_test.shape[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>Total number of patients: 258
Total number of patients in training set: 154
Total number of patients in validation set: 52
Total number of patients in test set: 52</code></pre>
<p>Before proceeding to modeling, let's normalize the continuous covariates to make sure they're on the same scale. Again, we should normalize the test data using statistics from the train data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">continuous_columns = [<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;bili&#x27;</span>, <span class="string">&#x27;chol&#x27;</span>, <span class="string">&#x27;albumin&#x27;</span>, <span class="string">&#x27;copper&#x27;</span>, <span class="string">&#x27;alk.phos&#x27;</span>, <span class="string">&#x27;ast&#x27;</span>, <span class="string">&#x27;trig&#x27;</span>, <span class="string">&#x27;platelet&#x27;</span>, <span class="string">&#x27;protime&#x27;</span>]</span><br><span class="line">mean = df_train.loc[:, continuous_columns].mean()</span><br><span class="line">std = df_train.loc[:, continuous_columns].std()</span><br><span class="line">df_train.loc[:, continuous_columns] = (df_train.loc[:, continuous_columns] - mean) / std</span><br><span class="line">df_val.loc[:, continuous_columns] = (df_val.loc[:, continuous_columns] - mean) / std</span><br><span class="line">df_test.loc[:, continuous_columns] = (df_test.loc[:, continuous_columns] - mean) / std</span><br></pre></td></tr></table></figure>
<p>Let's check the summary statistics on our training dataset to make sure it's standardized.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_train.loc[:, continuous_columns].describe()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
age
</th>
<th>
bili
</th>
<th>
chol
</th>
<th>
albumin
</th>
<th>
copper
</th>
<th>
alk.phos
</th>
<th>
ast
</th>
<th>
trig
</th>
<th>
platelet
</th>
<th>
protime
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
count
</th>
<td>
1.540000e+02
</td>
<td>
1.540000e+02
</td>
<td>
1.540000e+02
</td>
<td>
1.540000e+02
</td>
<td>
1.540000e+02
</td>
<td>
1.540000e+02
</td>
<td>
1.540000e+02
</td>
<td>
1.540000e+02
</td>
<td>
1.540000e+02
</td>
<td>
1.540000e+02
</td>
</tr>
<tr>
<th>
mean
</th>
<td>
9.833404e-16
</td>
<td>
-3.258577e-16
</td>
<td>
1.153478e-16
</td>
<td>
1.153478e-16
</td>
<td>
5.767392e-18
</td>
<td>
1.326500e-16
</td>
<td>
-1.263059e-15
</td>
<td>
8.074349e-17
</td>
<td>
2.018587e-17
</td>
<td>
1.291896e-14
</td>
</tr>
<tr>
<th>
std
</th>
<td>
1.000000e+00
</td>
<td>
1.000000e+00
</td>
<td>
1.000000e+00
</td>
<td>
1.000000e+00
</td>
<td>
1.000000e+00
</td>
<td>
1.000000e+00
</td>
<td>
1.000000e+00
</td>
<td>
1.000000e+00
</td>
<td>
1.000000e+00
</td>
<td>
1.000000e+00
</td>
</tr>
<tr>
<th>
min
</th>
<td>
-2.304107e+00
</td>
<td>
-5.735172e-01
</td>
<td>
-1.115330e+00
</td>
<td>
-3.738104e+00
</td>
<td>
-9.856552e-01
</td>
<td>
-7.882167e-01
</td>
<td>
-1.489281e+00
</td>
<td>
-1.226674e+00
</td>
<td>
-2.058899e+00
</td>
<td>
-1.735556e+00
</td>
</tr>
<tr>
<th>
25%
</th>
<td>
-6.535035e-01
</td>
<td>
-4.895812e-01
</td>
<td>
-5.186963e-01
</td>
<td>
-5.697976e-01
</td>
<td>
-6.470611e-01
</td>
<td>
-5.186471e-01
</td>
<td>
-8.353982e-01
</td>
<td>
-6.884514e-01
</td>
<td>
-6.399831e-01
</td>
<td>
-7.382590e-01
</td>
</tr>
<tr>
<th>
50%
</th>
<td>
-6.443852e-03
</td>
<td>
-3.846612e-01
</td>
<td>
-2.576693e-01
</td>
<td>
5.663556e-02
</td>
<td>
-3.140636e-01
</td>
<td>
-3.416086e-01
</td>
<td>
-2.260984e-01
</td>
<td>
-2.495932e-01
</td>
<td>
-4.100373e-02
</td>
<td>
-1.398807e-01
</td>
</tr>
<tr>
<th>
75%
</th>
<td>
5.724289e-01
</td>
<td>
2.977275e-02
</td>
<td>
1.798617e-01
</td>
<td>
6.890921e-01
</td>
<td>
3.435366e-01
</td>
<td>
-4.620597e-03
</td>
<td>
6.061159e-01
</td>
<td>
3.755727e-01
</td>
<td>
6.617988e-01
</td>
<td>
3.587680e-01
</td>
</tr>
<tr>
<th>
max
</th>
<td>
2.654276e+00
</td>
<td>
5.239050e+00
</td>
<td>
6.243146e+00
</td>
<td>
2.140730e+00
</td>
<td>
5.495204e+00
</td>
<td>
4.869263e+00
</td>
<td>
3.058176e+00
</td>
<td>
5.165751e+00
</td>
<td>
3.190823e+00
</td>
<td>
4.447687e+00
</td>
</tr>
</tbody>
</table>
</div>
<p><a name='4'></a> ## 4. Cox Proportional Hazards</p>
<p>Our goal is to build a risk score using the survival data that we have. We'll begin by fitting a Cox Proportional Hazards model to your data.</p>
<p>Recall that the Cox Proportional Hazards model describes the hazard for an individual <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span> as</p>
<p><span class="math display">\[
\lambda(t, x) = \lambda_0(t)e^{\theta^T X_i}
\]</span></p>
<p>The <span class="math inline">\(\lambda_0\)</span> term is a baseline hazard and incorporates the risk over time, and the other term incorporates the risk due to the individual's covariates. After fitting the model, we can rank individuals using the person-dependent risk term <span class="math inline">\(e^{\theta^T X_i}\)</span>.</p>
<p>Categorical variables cannot be used in a regression model as they are. In order to use them, conversion to a series of variables is required.</p>
<p>Since our data has a mix of categorical (<code>stage</code>) and continuous (<code>wblc</code>) variables, before we proceed further we need to do some data engineering. To tackle the issue at hand we'll be using the <code>Dummy Coding</code> technique. In order to use Cox Proportional Hazards, we will have to turn the categorical data into one hot features so that we can fit our Cox model. Luckily, Pandas has a built-in function called <code>get_dummies</code> that will make it easier for us to implement our function. It turns categorical features into multiple binary features.</p>
<p><img src="1-hot-encode.png" style="padding-top: 5px;width: 60%;left: 0px;margin-left: 150px;margin-right: 0px;"></p>
<p><a name='Ex-1'></a> ### Exercise 1 In the cell below, implement the <code>to_one_hot(...)</code> function.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Remember to drop the first dummy for each each category to avoid convergence issues when fitting the proportional hazards model.
</li>
<li>
Check out the <a target="_blank" rel="noopener" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html" > get_dummies() </a> documentation.
</li>
<li>
Use <code>dtype=np.float64</code>.
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_one_hot</span>(<span class="params">dataframe, columns</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Convert columns in dataframe to one-hot encoding.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dataframe (dataframe): pandas dataframe containing covariates</span></span><br><span class="line"><span class="string">        columns (list of strings): list categorical column names to one hot encode</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        one_hot_df (dataframe): dataframe with categorical columns encoded</span></span><br><span class="line"><span class="string">                            as binary variables</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    one_hot_df = pd.get_dummies(dataframe,columns=columns, drop_first = <span class="literal">True</span>, dtype=np.float64)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> one_hot_df</span><br></pre></td></tr></table></figure>
<p>Now we'll use the function you coded to transform the training, validation, and test sets.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># List of categorical columns</span></span><br><span class="line">to_encode = [<span class="string">&#x27;edema&#x27;</span>, <span class="string">&#x27;stage&#x27;</span>]</span><br><span class="line"></span><br><span class="line">one_hot_train = to_one_hot(df_train, to_encode)</span><br><span class="line">one_hot_val = to_one_hot(df_val, to_encode)</span><br><span class="line">one_hot_test = to_one_hot(df_test, to_encode)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(one_hot_val.columns.tolist())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;There are <span class="subst">&#123;<span class="built_in">len</span>(one_hot_val.columns)&#125;</span> columns&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[&#39;time&#39;, &#39;status&#39;, &#39;trt&#39;, &#39;age&#39;, &#39;sex&#39;, &#39;ascites&#39;, &#39;hepato&#39;, &#39;spiders&#39;, &#39;bili&#39;, &#39;chol&#39;, &#39;albumin&#39;, &#39;copper&#39;, &#39;alk.phos&#39;, &#39;ast&#39;, &#39;trig&#39;, &#39;platelet&#39;, &#39;protime&#39;, &#39;edema_0.5&#39;, &#39;edema_1.0&#39;, &#39;stage_2.0&#39;, &#39;stage_3.0&#39;, &#39;stage_4.0&#39;]
There are 22 columns</code></pre>
<h4 id="expected-output">Expected output</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">&#x27;time&#x27;</span>, <span class="string">&#x27;status&#x27;</span>, <span class="string">&#x27;trt&#x27;</span>, <span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;ascites&#x27;</span>, <span class="string">&#x27;hepato&#x27;</span>, <span class="string">&#x27;spiders&#x27;</span>, <span class="string">&#x27;bili&#x27;</span>, <span class="string">&#x27;chol&#x27;</span>, <span class="string">&#x27;albumin&#x27;</span>, <span class="string">&#x27;copper&#x27;</span>, <span class="string">&#x27;alk.phos&#x27;</span>, <span class="string">&#x27;ast&#x27;</span>, <span class="string">&#x27;trig&#x27;</span>, <span class="string">&#x27;platelet&#x27;</span>, <span class="string">&#x27;protime&#x27;</span>, <span class="string">&#x27;edema_0.5&#x27;</span>, <span class="string">&#x27;edema_1.0&#x27;</span>, <span class="string">&#x27;stage_2.0&#x27;</span>, <span class="string">&#x27;stage_3.0&#x27;</span>, <span class="string">&#x27;stage_4.0&#x27;</span>]</span><br><span class="line">There are <span class="number">22</span> columns</span><br></pre></td></tr></table></figure>
<h3 id="look-for-new-features">Look for new features</h3>
<p>Now, let's take a peek at one of the transformed data sets. Do you notice any new features?</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(one_hot_train.shape)</span><br><span class="line">one_hot_train.head()</span><br></pre></td></tr></table></figure>
<pre><code>(154, 22)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
time
</th>
<th>
status
</th>
<th>
trt
</th>
<th>
age
</th>
<th>
sex
</th>
<th>
ascites
</th>
<th>
hepato
</th>
<th>
spiders
</th>
<th>
bili
</th>
<th>
chol
</th>
<th>
...
</th>
<th>
alk.phos
</th>
<th>
ast
</th>
<th>
trig
</th>
<th>
platelet
</th>
<th>
protime
</th>
<th>
edema_0.5
</th>
<th>
edema_1.0
</th>
<th>
stage_2.0
</th>
<th>
stage_3.0
</th>
<th>
stage_4.0
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
279
</th>
<td>
3.868493
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
-0.414654
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
-0.300725
</td>
<td>
-0.096081
</td>
<td>
...
</td>
<td>
0.167937
</td>
<td>
0.401418
</td>
<td>
0.330031
</td>
<td>
0.219885
</td>
<td>
-1.137178
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
0.0
</td>
</tr>
<tr>
<th>
137
</th>
<td>
3.553425
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
0.069681
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
0.895363
</td>
<td>
0.406085
</td>
<td>
...
</td>
<td>
0.101665
</td>
<td>
0.472367
</td>
<td>
1.621764
</td>
<td>
-0.120868
</td>
<td>
-0.239610
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
0.0
</td>
</tr>
<tr>
<th>
249
</th>
<td>
4.846575
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
-0.924494
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
-0.510565
</td>
<td>
-0.225352
</td>
<td>
...
</td>
<td>
0.245463
</td>
<td>
1.899020
</td>
<td>
-0.580807
</td>
<td>
0.422207
</td>
<td>
0.159309
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
266
</th>
<td>
0.490411
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
1.938314
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
1.0
</td>
<td>
1.0
</td>
<td>
0.748475
</td>
<td>
-0.608191
</td>
<td>
...
</td>
<td>
-0.650254
</td>
<td>
-0.288898
</td>
<td>
-0.481443
</td>
<td>
-0.727833
</td>
<td>
1.356065
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
12.328767
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.563645
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
1.0
</td>
<td>
-0.405645
</td>
<td>
-0.210436
</td>
<td>
...
</td>
<td>
2.173526
</td>
<td>
-0.144699
</td>
<td>
-0.531125
</td>
<td>
-0.450972
</td>
<td>
-0.139881
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
0.0
</td>
</tr>
</tbody>
</table>
<p>
5 rows × 22 columns
</p>
</div>
<p><a name='5'></a> ## 5. Fitting and Interpreting a Cox Model</p>
<p>Run the following cell to fit your Cox Proportional Hazards model using the <code>lifelines</code> package.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cph = CoxPHFitter()</span><br><span class="line">cph.fit(one_hot_train, duration_col = <span class="string">&#x27;time&#x27;</span>, event_col = <span class="string">&#x27;status&#x27;</span>, step_size=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;lifelines.CoxPHFitter: fitted with 154 total observations, 90 right-censored observations&gt;</code></pre>
<p>You can use <code>cph.print_summary()</code> to view the coefficients associated with each covariate as well as confidence intervals.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cph.print_summary()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<tbody>
<tr>
<th>
model
</th>
<td>
lifelines.CoxPHFitter
</td>
</tr>
<tr>
<th>
duration col
</th>
<td>
'time'
</td>
</tr>
<tr>
<th>
event col
</th>
<td>
'status'
</td>
</tr>
<tr>
<th>
number of observations
</th>
<td>
154
</td>
</tr>
<tr>
<th>
number of events observed
</th>
<td>
64
</td>
</tr>
<tr>
<th>
partial log-likelihood
</th>
<td>
-230.82
</td>
</tr>
<tr>
<th>
time fit was run
</th>
<td>
2020-04-19 16:30:56 UTC
</td>
</tr>
</tbody>
</table>
</div>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
coef
</th>
<th>
exp(coef)
</th>
<th>
se(coef)
</th>
<th>
coef lower 95%
</th>
<th>
coef upper 95%
</th>
<th>
exp(coef) lower 95%
</th>
<th>
exp(coef) upper 95%
</th>
<th>
z
</th>
<th>
p
</th>
<th>
-log2(p)
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
trt
</th>
<td>
-0.22
</td>
<td>
0.80
</td>
<td>
0.30
</td>
<td>
-0.82
</td>
<td>
0.37
</td>
<td>
0.44
</td>
<td>
1.45
</td>
<td>
-0.73
</td>
<td>
0.46
</td>
<td>
1.11
</td>
</tr>
<tr>
<th>
age
</th>
<td>
0.23
</td>
<td>
1.26
</td>
<td>
0.19
</td>
<td>
-0.13
</td>
<td>
0.60
</td>
<td>
0.88
</td>
<td>
1.82
</td>
<td>
1.26
</td>
<td>
0.21
</td>
<td>
2.27
</td>
</tr>
<tr>
<th>
sex
</th>
<td>
0.34
</td>
<td>
1.41
</td>
<td>
0.40
</td>
<td>
-0.45
</td>
<td>
1.14
</td>
<td>
0.64
</td>
<td>
3.11
</td>
<td>
0.84
</td>
<td>
0.40
</td>
<td>
1.33
</td>
</tr>
<tr>
<th>
ascites
</th>
<td>
-0.10
</td>
<td>
0.91
</td>
<td>
0.56
</td>
<td>
-1.20
</td>
<td>
1.01
</td>
<td>
0.30
</td>
<td>
2.75
</td>
<td>
-0.17
</td>
<td>
0.86
</td>
<td>
0.21
</td>
</tr>
<tr>
<th>
hepato
</th>
<td>
0.31
</td>
<td>
1.36
</td>
<td>
0.38
</td>
<td>
-0.44
</td>
<td>
1.06
</td>
<td>
0.64
</td>
<td>
2.89
</td>
<td>
0.81
</td>
<td>
0.42
</td>
<td>
1.26
</td>
</tr>
<tr>
<th>
spiders
</th>
<td>
-0.18
</td>
<td>
0.83
</td>
<td>
0.38
</td>
<td>
-0.94
</td>
<td>
0.57
</td>
<td>
0.39
</td>
<td>
1.77
</td>
<td>
-0.47
</td>
<td>
0.64
</td>
<td>
0.66
</td>
</tr>
<tr>
<th>
bili
</th>
<td>
0.05
</td>
<td>
1.05
</td>
<td>
0.18
</td>
<td>
-0.29
</td>
<td>
0.39
</td>
<td>
0.75
</td>
<td>
1.48
</td>
<td>
0.29
</td>
<td>
0.77
</td>
<td>
0.37
</td>
</tr>
<tr>
<th>
chol
</th>
<td>
0.19
</td>
<td>
1.20
</td>
<td>
0.15
</td>
<td>
-0.10
</td>
<td>
0.47
</td>
<td>
0.91
</td>
<td>
1.60
</td>
<td>
1.28
</td>
<td>
0.20
</td>
<td>
2.33
</td>
</tr>
<tr>
<th>
albumin
</th>
<td>
-0.40
</td>
<td>
0.67
</td>
<td>
0.18
</td>
<td>
-0.75
</td>
<td>
-0.06
</td>
<td>
0.47
</td>
<td>
0.94
</td>
<td>
-2.28
</td>
<td>
0.02
</td>
<td>
5.46
</td>
</tr>
<tr>
<th>
copper
</th>
<td>
0.30
</td>
<td>
1.35
</td>
<td>
0.16
</td>
<td>
-0.01
</td>
<td>
0.61
</td>
<td>
0.99
</td>
<td>
1.84
</td>
<td>
1.91
</td>
<td>
0.06
</td>
<td>
4.14
</td>
</tr>
<tr>
<th>
alk.phos
</th>
<td>
-0.22
</td>
<td>
0.80
</td>
<td>
0.14
</td>
<td>
-0.49
</td>
<td>
0.05
</td>
<td>
0.61
</td>
<td>
1.05
</td>
<td>
-1.62
</td>
<td>
0.11
</td>
<td>
3.24
</td>
</tr>
<tr>
<th>
ast
</th>
<td>
0.21
</td>
<td>
1.24
</td>
<td>
0.16
</td>
<td>
-0.10
</td>
<td>
0.53
</td>
<td>
0.91
</td>
<td>
1.69
</td>
<td>
1.34
</td>
<td>
0.18
</td>
<td>
2.48
</td>
</tr>
<tr>
<th>
trig
</th>
<td>
0.20
</td>
<td>
1.23
</td>
<td>
0.16
</td>
<td>
-0.11
</td>
<td>
0.52
</td>
<td>
0.89
</td>
<td>
1.68
</td>
<td>
1.27
</td>
<td>
0.21
</td>
<td>
2.28
</td>
</tr>
<tr>
<th>
platelet
</th>
<td>
0.14
</td>
<td>
1.15
</td>
<td>
0.15
</td>
<td>
-0.16
</td>
<td>
0.43
</td>
<td>
0.86
</td>
<td>
1.54
</td>
<td>
0.92
</td>
<td>
0.36
</td>
<td>
1.48
</td>
</tr>
<tr>
<th>
protime
</th>
<td>
0.36
</td>
<td>
1.43
</td>
<td>
0.17
</td>
<td>
0.03
</td>
<td>
0.69
</td>
<td>
1.03
</td>
<td>
1.99
</td>
<td>
2.15
</td>
<td>
0.03
</td>
<td>
4.97
</td>
</tr>
<tr>
<th>
edema_0.5
</th>
<td>
1.24
</td>
<td>
3.47
</td>
<td>
0.46
</td>
<td>
0.35
</td>
<td>
2.14
</td>
<td>
1.42
</td>
<td>
8.50
</td>
<td>
2.72
</td>
<td>
0.01
</td>
<td>
7.28
</td>
</tr>
<tr>
<th>
edema_1.0
</th>
<td>
2.02
</td>
<td>
7.51
</td>
<td>
0.60
</td>
<td>
0.84
</td>
<td>
3.20
</td>
<td>
2.31
</td>
<td>
24.43
</td>
<td>
3.35
</td>
<td>
&lt;0.005
</td>
<td>
10.28
</td>
</tr>
<tr>
<th>
stage_2.0
</th>
<td>
1.21
</td>
<td>
3.35
</td>
<td>
1.08
</td>
<td>
-0.92
</td>
<td>
3.33
</td>
<td>
0.40
</td>
<td>
28.06
</td>
<td>
1.11
</td>
<td>
0.27
</td>
<td>
1.91
</td>
</tr>
<tr>
<th>
stage_3.0
</th>
<td>
1.18
</td>
<td>
3.27
</td>
<td>
1.09
</td>
<td>
-0.96
</td>
<td>
3.33
</td>
<td>
0.38
</td>
<td>
27.86
</td>
<td>
1.08
</td>
<td>
0.28
</td>
<td>
1.84
</td>
</tr>
<tr>
<th>
stage_4.0
</th>
<td>
1.41
</td>
<td>
4.10
</td>
<td>
1.15
</td>
<td>
-0.85
</td>
<td>
3.67
</td>
<td>
0.43
</td>
<td>
39.43
</td>
<td>
1.22
</td>
<td>
0.22
</td>
<td>
2.18
</td>
</tr>
</tbody>
</table>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<tbody>
<tr>
<th>
Concordance
</th>
<td>
0.83
</td>
</tr>
<tr>
<th>
Log-likelihood ratio test
</th>
<td>
97.63 on 20 df, -log2(p)=38.13
</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Question:</strong></p>
<ul>
<li>According to the model, was treatment <code>trt</code> beneficial?</li>
<li>What was its associated hazard ratio?
<ul>
<li>Note that the hazard ratio is how much an incremental increase in the feature variable changes the hazard.</li>
</ul></li>
</ul>
<details>
<summary>
<font size="3" color="darkgreen"><b>Check your answer!</b></font>
</summary>
<p>
<ul>
<ul>
<li>
You should see that the treatment (trt) was beneficial because it has a negative impact on the hazard (the coefficient is negative, and exp(coef) is less than 1).
</li>
<li>
The associated hazard ratio is ~0.8, because this is the exp(coef) of treatment.
</li>
</ul>
</p>
<p>We can compare the predicted survival curves for treatment variables. Run the next cell to plot survival curves using the <code>plot_covariate_groups()</code> function. - The y-axis is th survival rate - The x-axis is time</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cph.plot_covariate_groups(<span class="string">&#x27;trt&#x27;</span>, values=[<span class="number">0</span>, <span class="number">1</span>]);</span><br></pre></td></tr></table></figure>
<p>Notice how the group without treatment has a lower survival rate at all times (the x-axis is time) compared to the treatment group.</p>
<p><a name='6'></a> ## 6. Hazard Ratio</p>
<p>Recall from the lecture videos that the Hazard Ratio between two patients was the likelihood of one patient (e.g smoker) being more at risk than the other (e.g non-smoker). <span class="math display">\[
\frac{\lambda_{smoker}(t)}{\lambda_{nonsmoker}(t)} = e^{\theta (X_{smoker} - X_{nonsmoker})^T}
\]</span></p>
<p>Where</p>
<p><span class="math display">\[
\lambda_{smoker}(t) = \lambda_0(t)e^{\theta X_{smoker}^T}
\]</span> and <span class="math display">\[
\lambda_{nonsmoker}(t) = \lambda_0(t)e^{\theta X_{nonsmoker}^T} \\
\]</span></p>
<p><a name='Ex-2'></a> ### Exercise 2 In the cell below, write a function to compute the hazard ratio between two individuals given the model's coefficients.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
use numpy.dot
</li>
<li>
use nump.exp
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hazard_ratio</span>(<span class="params">case_1, case_2, cox_params</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Return the hazard ratio of case_1 : case_2 using</span></span><br><span class="line"><span class="string">    the coefficients of the cox model.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        case_1 (np.array): (1 x d) array of covariates</span></span><br><span class="line"><span class="string">        case_2 (np.array): (1 x d) array of covariates</span></span><br><span class="line"><span class="string">        model (np.array): (1 x d) array of cox model coefficients</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        hazard_ratio (float): hazard ratio of case_1 : case_2</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    hr = np.exp(np.dot(cox_params,(case_1 - case_2).T))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> hr</span><br></pre></td></tr></table></figure>
<p>Now, evaluate it on the following pair of indivduals: <code>i = 1</code> and <code>j = 5</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">1</span></span><br><span class="line">case_1 = one_hot_train.iloc[i, :].drop([<span class="string">&#x27;time&#x27;</span>, <span class="string">&#x27;status&#x27;</span>])</span><br><span class="line"></span><br><span class="line">j = <span class="number">5</span></span><br><span class="line">case_2 = one_hot_train.iloc[j, :].drop([<span class="string">&#x27;time&#x27;</span>, <span class="string">&#x27;status&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(hazard_ratio(case_1.values, case_2.values, cph.params_.values))</span><br></pre></td></tr></table></figure>
<pre><code>15.029017732492221</code></pre>
<h4 id="expected-output-1">Expected Output:</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">15.029017732492221</span></span><br></pre></td></tr></table></figure>
<p><strong>Question:</strong></p>
<p>Is <code>case_1</code> or <code>case_2</code> at greater risk?</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Check your answer!</b></font>
</summary>
<p>
<ul>
<ul>
<li>
You should see that <code>case_1</code> is at higher risk.
</li>
<li>
The hazard ratio of case 1 / case 2 is greater than 1, so case 1 had a higher hazard relative to case 2
</li>
</ul>
</p>
<p>Inspect different pairs, and see if you can figure out which patient is more at risk.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">4</span></span><br><span class="line">case_a = one_hot_train.iloc[i, :].drop([<span class="string">&#x27;time&#x27;</span>, <span class="string">&#x27;status&#x27;</span>])</span><br><span class="line"></span><br><span class="line">j = <span class="number">7</span></span><br><span class="line">case_b = one_hot_train.iloc[j, :].drop([<span class="string">&#x27;time&#x27;</span>, <span class="string">&#x27;status&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Case A\n\n&quot;</span>, case_a, <span class="string">&quot;\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Case B\n\n&quot;</span>, case_b, <span class="string">&quot;\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Hazard Ratio:&quot;</span>, hazard_ratio(case_a.values, case_b.values, cph.params_.values))</span><br></pre></td></tr></table></figure>
<pre><code>Case A

 trt          0.000000
age          0.563645
sex          0.000000
ascites      0.000000
hepato       1.000000
spiders      1.000000
bili        -0.405645
chol        -0.210436
albumin      1.514297
copper      -0.481961
alk.phos     2.173526
ast         -0.144699
trig        -0.531125
platelet    -0.450972
protime     -0.139881
edema_0.5    0.000000
edema_1.0    0.000000
stage_2.0    0.000000
stage_3.0    1.000000
stage_4.0    0.000000
Name: 1, dtype: float64 

Case B

 trt          0.000000
age          0.463447
sex          0.000000
ascites      0.000000
hepato       1.000000
spiders      0.000000
bili        -0.489581
chol        -0.309875
albumin     -1.232371
copper      -0.504348
alk.phos     2.870427
ast         -0.936261
trig        -0.150229
platelet     3.190823
protime     -0.139881
edema_0.5    0.000000
edema_1.0    0.000000
stage_2.0    0.000000
stage_3.0    0.000000
stage_4.0    1.000000
Name: 38, dtype: float64 

Hazard Ratio: 0.1780450006997129</code></pre>
<details>
<summary>
<font size="3" color="darkgreen"><b>Check your answer!</b></font>
</summary>
<p>
<ul>
<ul>
<li>
You should see that <code>case_2</code> is at higher risk.
</li>
<li>
The hazard ratio of case 1 / case 2 is less than 1, so case 2 had a higher hazard relative to case 1
</li>
</ul>
</p>
<p><a name='7'></a> ## 7. Harrell's C-index</p>
<p>To evaluate how good our model is performing, we will write our own version of the C-index. Similar to the week 1 case, C-index in the survival context is the probability that, given a randomly selected pair of individuals, the one who died sooner has a higher risk score.</p>
<p>However, we need to take into account censoring. Imagine a pair of patients, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>.</p>
<h4 id="scenario-1">Scenario 1</h4>
<ul>
<li>A was censored at time <span class="math inline">\(t_A\)</span></li>
<li>B died at <span class="math inline">\(t_B\)</span></li>
<li><span class="math inline">\(t_A &lt; t_B\)</span>.</li>
</ul>
<p>Because of censoring, we can't say whether <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span> should have a higher risk score.</p>
<h4 id="scenario-2">Scenario 2</h4>
<p>Now imagine that <span class="math inline">\(t_A &gt; t_B\)</span>.</p>
<ul>
<li>A was censored at time <span class="math inline">\(t_A\)</span></li>
<li>B died at <span class="math inline">\(t_B\)</span></li>
<li><span class="math inline">\(t_A &gt; t_B\)</span></li>
</ul>
<p>Now we can definitively say that <span class="math inline">\(B\)</span> should have a higher risk score than <span class="math inline">\(A\)</span>, since we know for a fact that <span class="math inline">\(A\)</span> lived longer.</p>
<p>Therefore, when we compute our C-index - We should only consider pairs where at most one person is censored - If they are censored, then their censored time should occur <em>after</em> the other person's time of death.</p>
<p>The metric we get if we use this rule is called <strong>Harrel's C-index</strong>.</p>
<p>Note that in this case, being censored at time <span class="math inline">\(t\)</span> means that the true death time was some time AFTER time <span class="math inline">\(t\)</span> and not at <span class="math inline">\(t\)</span>. - Therefore if <span class="math inline">\(t_A = t_B\)</span> and A was censored: - Then <span class="math inline">\(A\)</span> actually lived longer than <span class="math inline">\(B\)</span>. - This will effect how you deal with ties in the exercise below!</p>
<p><a name='Ex-3'></a> ### Exercise 3 Fill in the function below to compute Harrel's C-index.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
If you get a division by zero error, consider checking how you count when a pair is permissible (in the case where one patient is censored and the other is not censored).
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">harrell_c</span>(<span class="params">y_true, scores, event</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Compute Harrel C-index given true event/censoring times,</span></span><br><span class="line"><span class="string">    model output, and event indicators.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        y_true (array): array of true event times</span></span><br><span class="line"><span class="string">        scores (array): model risk scores</span></span><br><span class="line"><span class="string">        event (array): indicator, 1 if event occurred at that index, 0 for censorship</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        result (float): C-index metric</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    n = <span class="built_in">len</span>(y_true)</span><br><span class="line">    <span class="keyword">assert</span> (<span class="built_in">len</span>(scores) == n <span class="keyword">and</span> <span class="built_in">len</span>(event) == n)</span><br><span class="line">    </span><br><span class="line">    concordant = <span class="number">0.0</span></span><br><span class="line">    permissible = <span class="number">0.0</span></span><br><span class="line">    ties = <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    result = <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; and &#x27;pass&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># use double for loop to go through cases</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="comment"># set lower bound on j to avoid double counting</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, n):</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># check if at most one is censored</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> (event[i] == <span class="number">0</span> <span class="keyword">and</span> event[j] == <span class="number">0</span>):</span><br><span class="line"></span><br><span class="line">                <span class="comment"># check if neither are censored</span></span><br><span class="line">                <span class="keyword">if</span> event[i] == <span class="number">1</span> <span class="keyword">and</span> event[j] == <span class="number">1</span>:</span><br><span class="line">                    permissible += <span class="number">1</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># check if scores are tied</span></span><br><span class="line">                    <span class="keyword">if</span> y_true[i] == y_true[j]:</span><br><span class="line">                        ties += <span class="number">1</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># check for concordant</span></span><br><span class="line">                    <span class="keyword">elif</span> y_true[i] &gt; y_true[j] <span class="keyword">and</span> scores[i] &lt; scores[j]:</span><br><span class="line">                        concordant += <span class="number">1</span></span><br><span class="line">                    <span class="keyword">elif</span> y_true[i] &lt; y_true[j] <span class="keyword">and</span> scores[i] &gt; scores[j]:</span><br><span class="line">                        concordant += <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># check if one is censored</span></span><br><span class="line">                <span class="keyword">elif</span> event[i] == <span class="number">0</span> <span class="keyword">or</span> event[j] == <span class="number">0</span>:</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># get censored index</span></span><br><span class="line">                    censored = j</span><br><span class="line">                    uncensored = i</span><br><span class="line">                    </span><br><span class="line">                    <span class="keyword">if</span> event[i] == <span class="number">0</span>:</span><br><span class="line">                        censored = i</span><br><span class="line">                        uncensored = j</span><br><span class="line">                        </span><br><span class="line">                    <span class="comment"># check if permissible</span></span><br><span class="line">                    <span class="comment"># Note: in this case, we are assuming that censored at a time</span></span><br><span class="line">                    <span class="comment"># means that you did NOT die at that time. That is, if you</span></span><br><span class="line">                    <span class="comment"># live until time 30 and have event = 0, then you lived THROUGH</span></span><br><span class="line">                    <span class="comment"># time 30.</span></span><br><span class="line">                    <span class="keyword">if</span> y_true[censored] &gt;= y_true[uncensored]:</span><br><span class="line">                        permissible += <span class="number">1</span></span><br><span class="line">                        </span><br><span class="line">                        <span class="comment"># check if scores are tied</span></span><br><span class="line">                        <span class="keyword">if</span> scores[i] == scores[j]:</span><br><span class="line">                            <span class="comment"># update ties </span></span><br><span class="line">                            ties += <span class="number">1</span></span><br><span class="line">                            </span><br><span class="line">                        <span class="comment"># check if scores are concordant </span></span><br><span class="line">                        <span class="keyword">if</span> y_true[censored] &gt;= y_true[uncensored] <span class="keyword">and</span> scores[censored] &lt; scores[uncensored]:</span><br><span class="line">                            concordant += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># set result to c-index computed from number of concordant pairs,</span></span><br><span class="line">    <span class="comment"># number of ties, and number of permissible pairs (REPLACE 0 with your code) </span></span><br><span class="line">    result = (concordant + <span class="number">0.5</span> * ties) / permissible</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result   </span><br></pre></td></tr></table></figure>
<p>You can test your function on the following test cases:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">y_true = [<span class="number">30</span>, <span class="number">12</span>, <span class="number">84</span>, <span class="number">9</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Case 1</span></span><br><span class="line">event = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line">scores = [<span class="number">0.5</span>, <span class="number">0.9</span>, <span class="number">0.1</span>, <span class="number">1.0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Case 1&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Expected: 1.0, Output: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(harrell_c(y_true, scores, event)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Case 2</span></span><br><span class="line">scores = [<span class="number">0.9</span>, <span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">0.1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nCase 2&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Expected: 0.0, Output: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(harrell_c(y_true, scores, event)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Case 3</span></span><br><span class="line">event = [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line">scores = [<span class="number">0.5</span>, <span class="number">0.9</span>, <span class="number">0.1</span>, <span class="number">1.0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nCase 3&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Expected: 1.0, Output: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(harrell_c(y_true, scores, event)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Case 4</span></span><br><span class="line">y_true = [<span class="number">30</span>, <span class="number">30</span>, <span class="number">20</span>, <span class="number">20</span>]</span><br><span class="line">event = [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">scores = [<span class="number">10</span>, <span class="number">5</span>, <span class="number">15</span>, <span class="number">20</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nCase 4&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Expected: 0.75, Output: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(harrell_c(y_true, scores, event)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Case 5</span></span><br><span class="line">y_true = <span class="built_in">list</span>(<span class="built_in">reversed</span>([<span class="number">30</span>, <span class="number">30</span>, <span class="number">30</span>, <span class="number">20</span>, <span class="number">20</span>]))</span><br><span class="line">event = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">scores = <span class="built_in">list</span>(<span class="built_in">reversed</span>([<span class="number">15</span>, <span class="number">10</span>, <span class="number">5</span>, <span class="number">15</span>, <span class="number">20</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nCase 5&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Expected: 0.583, Output: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(harrell_c(y_true, scores, event)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Case 6</span></span><br><span class="line">y_true = [<span class="number">10</span>,<span class="number">10</span>]</span><br><span class="line">event = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">scores = [<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nCase 6&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Expected: 1.0 , Output:<span class="subst">&#123;harrell_c(y_true, scores, event):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Case 1
Expected: 1.0, Output: 1.0

Case 2
Expected: 0.0, Output: 0.0

Case 3
Expected: 1.0, Output: 1.0

Case 4
Expected: 0.75, Output: 0.75

Case 5
Expected: 0.583, Output: 0.5833333333333334

Case 6
Expected: 1.0 , Output:1.0000</code></pre>
<p>Now use the Harrell's C-index function to evaluate the cox model on our data sets.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train</span></span><br><span class="line">scores = cph.predict_partial_hazard(one_hot_train)</span><br><span class="line">cox_train_scores = harrell_c(one_hot_train[<span class="string">&#x27;time&#x27;</span>].values, scores.values, one_hot_train[<span class="string">&#x27;status&#x27;</span>].values)</span><br><span class="line"><span class="comment"># Validation</span></span><br><span class="line">scores = cph.predict_partial_hazard(one_hot_val)</span><br><span class="line">cox_val_scores = harrell_c(one_hot_val[<span class="string">&#x27;time&#x27;</span>].values, scores.values, one_hot_val[<span class="string">&#x27;status&#x27;</span>].values)</span><br><span class="line"><span class="comment"># Test</span></span><br><span class="line">scores = cph.predict_partial_hazard(one_hot_test)</span><br><span class="line">cox_test_scores = harrell_c(one_hot_test[<span class="string">&#x27;time&#x27;</span>].values, scores.values, one_hot_test[<span class="string">&#x27;status&#x27;</span>].values)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Train:&quot;</span>, cox_train_scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Val:&quot;</span>, cox_val_scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test:&quot;</span>, cox_test_scores)</span><br></pre></td></tr></table></figure>
<pre><code>Train: 0.8265139116202946
Val: 0.8544776119402985
Test: 0.8478543563068921</code></pre>
<p>What do these values tell us ?</p>
<p><a name='8'></a> ## 8. Random Survival Forests</p>
<p>This performed well, but you have a hunch you can squeeze out better performance by using a machine learning approach. You decide to use a Random Survival Forest. To do this, you can use the <code>RandomForestSRC</code> package in R. To call R function from Python, we'll use the <code>r2py</code> package. Run the following cell to import the necessary requirements.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">%load_ext rpy2.ipython</span><br><span class="line">%R require(ggplot2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> rpy2.robjects.packages <span class="keyword">import</span> importr</span><br><span class="line"><span class="comment"># import R&#x27;s &quot;base&quot; package</span></span><br><span class="line">base = importr(<span class="string">&#x27;base&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># import R&#x27;s &quot;utils&quot; package</span></span><br><span class="line">utils = importr(<span class="string">&#x27;utils&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># import rpy2&#x27;s package module</span></span><br><span class="line"><span class="keyword">import</span> rpy2.robjects.packages <span class="keyword">as</span> rpackages</span><br><span class="line"></span><br><span class="line">forest = rpackages.importr(<span class="string">&#x27;randomForestSRC&#x27;</span>, lib_loc=<span class="string">&#x27;R&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> rpy2 <span class="keyword">import</span> robjects <span class="keyword">as</span> ro</span><br><span class="line">R = ro.r</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> rpy2.robjects <span class="keyword">import</span> pandas2ri</span><br><span class="line">pandas2ri.activate()</span><br></pre></td></tr></table></figure>
<pre><code>R[write to console]: Loading required package: ggplot2</code></pre>
<p>Instead of encoding our categories as binary features, we can use the original dataframe since trees deal well with raw categorical data (can you think why this might be?).</p>
<p>Run the code cell below to build your forest.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = forest.rfsrc(ro.Formula(<span class="string">&#x27;Surv(time, status) ~ .&#x27;</span>), data=df_train, ntree=<span class="number">300</span>, nodedepth=<span class="number">5</span>, seed=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure>
<pre><code>                         Sample size: 154
                    Number of deaths: 64
                     Number of trees: 300
           Forest terminal node size: 15
       Average no. of terminal nodes: 6.54
No. of variables tried at each split: 5
              Total no. of variables: 17
       Resampling used to grow trees: swor
    Resample size used to grow trees: 97
                            Analysis: RSF
                              Family: surv
                      Splitting rule: logrank *random*
       Number of random split points: 10
                          Error rate: 19.07%</code></pre>
<p>Finally, let's evaluate on our validation and test sets, and compare it with our Cox model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">result = R.predict(model, newdata=df_val)</span><br><span class="line">scores = np.array(result.rx(<span class="string">&#x27;predicted&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Cox Model Validation Score:&quot;</span>, cox_val_scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Survival Forest Validation Score:&quot;</span>, harrell_c(df_val[<span class="string">&#x27;time&#x27;</span>].values, scores, df_val[<span class="string">&#x27;status&#x27;</span>].values))</span><br></pre></td></tr></table></figure>
<pre><code>Cox Model Validation Score: 0.8544776119402985
Survival Forest Validation Score: 0.8296019900497512</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">result = R.predict(model, newdata=df_test)</span><br><span class="line">scores = np.array(result.rx(<span class="string">&#x27;predicted&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Cox Model Test Score:&quot;</span>, cox_test_scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Survival Forest Validation Score:&quot;</span>, harrell_c(df_test[<span class="string">&#x27;time&#x27;</span>].values, scores, df_test[<span class="string">&#x27;status&#x27;</span>].values))</span><br></pre></td></tr></table></figure>
<pre><code>Cox Model Test Score: 0.8478543563068921
Survival Forest Validation Score: 0.8621586475942783</code></pre>
<p>Your random forest model should be outperforming the Cox model slightly. Let's dig deeper to see how they differ.</p>
<p><a name='9'></a> ## 9. Permutation Method for Interpretation</p>
<p>We'll dig a bit deeper into interpretation methods for forests a bit later, but for now just know that random surival forests come with their own built in variable importance feature. The method is referred to as VIMP, and for the purpose of this section you should just know that higher absolute value of the VIMP means that the variable generally has a larger effect on the model outcome.</p>
<p>Run the next cell to compute and plot VIMP for the random survival forest.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vimps = np.array(forest.vimp(model).rx(<span class="string">&#x27;importance&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">y = np.arange(<span class="built_in">len</span>(vimps))</span><br><span class="line">plt.barh(y, np.<span class="built_in">abs</span>(vimps))</span><br><span class="line">plt.yticks(y, df_train.drop([<span class="string">&#x27;time&#x27;</span>, <span class="string">&#x27;status&#x27;</span>], axis=<span class="number">1</span>).columns)</span><br><span class="line">plt.title(<span class="string">&quot;VIMP (absolute value)&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_67_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<h3 id="question">Question:</h3>
<p>How does the variable importance compare to that of the Cox model? Which variable is important in both models? Which variable is important in the random survival forest but not in the Cox model? You should see that <code>edema</code> is important in both the random survival forest and the Cox model. You should also see that <code>bili</code> is important in the random survival forest but not the Cox model .</p>
<h1 id="congratulations">Congratulations!</h1>
<p>You've finished the last assignment in course 2! Take a minute to look back at the analysis you've done over the last four assignments. You've done a great job!</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Survival-Estimates-that-Vary-with-Time/2020/04/18/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Survival-Estimates-that-Vary-with-Time/2020/04/18/" class="post-title-link" itemprop="url">Survival Estimates that Vary with Time</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-18 23:54:54" itemprop="dateCreated datePublished" datetime="2020-04-18T23:54:54+08:00">2020-04-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-19 23:09:46" itemprop="dateModified" datetime="2020-04-19T23:09:46+08:00">2020-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Survival-Estimates-that-Vary-with-Time/2020/04/18/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Survival-Estimates-that-Vary-with-Time/2020/04/18/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="survival-estimates-that-vary-with-time">Survival Estimates that Vary with Time</h1>
<p>Welcome to the third assignment of Course 2. In this assignment, we'll use Python to build some of the statistical models we learned this past week to analyze surivival estimates for a dataset of lymphoma patients. We'll also evaluate these models and interpret their outputs. Along the way, you will be learning about the following:</p>
<ul>
<li>Censored Data</li>
<li>Kaplan-Meier Estimates</li>
<li>Subgroup Analysis</li>
</ul>
<h2 id="outline">Outline</h2>
<ul>
<li><a href="#1">1. Import Packages</a></li>
<li><a href="#2">2. Load the Dataset</a></li>
<li><a href="#">3. Censored Data</a>
<ul>
<li><a href="#Ex-1">Exercise 1</a></li>
</ul></li>
<li><a href="#4">4. Survival Estimates</a>
<ul>
<li><a href="#Ex-2">Exercise 2</a></li>
<li><a href="#Ex-3">Exercise 3</a></li>
</ul></li>
<li><a href="#5">5. Subgroup Analysis</a>
<ul>
<li><a href="#5-1">5.1 Bonus: Log Rank Test</a></li>
</ul></li>
</ul>
<p><a name='1'></a> ## 1. Import Packages</p>
<p>We'll first import all the packages that we need for this assignment.</p>
<ul>
<li><code>lifelines</code> is an open-source library for data analysis.</li>
<li><code>numpy</code> is the fundamental package for scientific computing in python.</li>
<li><code>pandas</code> is what we'll use to manipulate our data.</li>
<li><code>matplotlib</code> is a plotting library.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lifelines</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> util <span class="keyword">import</span> load_data</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lifelines <span class="keyword">import</span> KaplanMeierFitter <span class="keyword">as</span> KM</span><br><span class="line"><span class="keyword">from</span> lifelines.statistics <span class="keyword">import</span> logrank_test</span><br></pre></td></tr></table></figure>
<p><a name='2'></a> ## 2. Load the Dataset</p>
<p>Run the next cell to load the lymphoma data set.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = load_data()</span><br></pre></td></tr></table></figure>
<p>As always, you first look over your data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data shape: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(data.shape))</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>
<pre><code>data shape: (80, 3)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Stage_group
</th>
<th>
Time
</th>
<th>
Event
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
6
</td>
<td>
1
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
19
</td>
<td>
1
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1
</td>
<td>
32
</td>
<td>
1
</td>
</tr>
<tr>
<th>
3
</th>
<td>
1
</td>
<td>
42
</td>
<td>
1
</td>
</tr>
<tr>
<th>
4
</th>
<td>
1
</td>
<td>
42
</td>
<td>
1
</td>
</tr>
</tbody>
</table>
</div>
<p>The column <code>Time</code> states how long the patient lived before they died or were censored.</p>
<p>The column <code>Event</code> says whether a death was observed or not. <code>Event</code> is 1 if the event is observed (i.e. the patient died) and 0 if data was censored.</p>
<p>Censorship here means that the observation has ended without any observed event. For example, let a patient be in a hospital for 100 days at most. If a patient dies after only 44 days, their event will be recorded as <code>Time = 44</code> and <code>Event = 1</code>. If a patient walks out after 100 days and dies 3 days later (103 days total), this event is not observed in our process and the corresponding row has <code>Time = 100</code> and <code>Event = 0</code>. If a patient survives for 25 years after being admitted, their data for are still <code>Time = 100</code> and <code>Event = 0</code>.</p>
<p><a name='3'></a> ## 3. Censored Data</p>
<p>We can plot a histogram of the survival times to see in general how long cases survived before censorship or events.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data.Time.hist();</span><br><span class="line">plt.xlabel(<span class="string">&quot;Observation time before death or censorship (days)&quot;</span>);</span><br><span class="line">plt.ylabel(<span class="string">&quot;Frequency (number of patients)&quot;</span>);</span><br><span class="line"><span class="comment"># Note that the semicolon at the end of the plotting line</span></span><br><span class="line"><span class="comment"># silences unnecessary textual output - try removing it</span></span><br><span class="line"><span class="comment"># to observe its effect</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="output_11_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">&quot;Event&quot;</span>].unique()</span><br></pre></td></tr></table></figure>
<pre><code>array([1, 0])</code></pre>
<p><a name='Ex-1'></a> ### Exercise 1</p>
<p>In the next cell, write a function to compute the fraction (<span class="math inline">\(\in [0, 1]\)</span>) of observations which were censored.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Summing up the <code>'Event'</code> column will give you the number of observations where censorship has NOT occurred.
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">frac_censored</span>(<span class="params">df</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Return percent of observations which were censored.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        df (dataframe): dataframe which contains column &#x27;Event&#x27; which is </span></span><br><span class="line"><span class="string">                        1 if an event occurred (death)</span></span><br><span class="line"><span class="string">                        0 if the event did not occur (censored)</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        frac_censored (float): fraction of cases which were censored. </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    result = <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    result = <span class="number">1</span>- df[<span class="string">&#x27;Event&#x27;</span>].<span class="built_in">sum</span>(axis = <span class="number">0</span>) / df.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(frac_censored(data))</span><br></pre></td></tr></table></figure>
<pre><code>0.32499999999999996</code></pre>
<h4 id="expected-output">Expected Output:</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.325</span></span><br></pre></td></tr></table></figure>
<p>Run the next cell to see the distributions of survival times for censored and uncensored examples.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">df_censored = data[data.Event == <span class="number">0</span>]</span><br><span class="line">df_uncensored = data[data.Event == <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">df_censored.Time.hist()</span><br><span class="line">plt.title(<span class="string">&quot;Censored&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Time (days)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Frequency&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">df_uncensored.Time.hist()</span><br><span class="line">plt.title(<span class="string">&quot;Uncensored&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Time (days)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Frequency&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_19_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_19_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p><a name='4'></a> ## 4. Survival Estimates</p>
<p>We'll now try to estimate the survival function:</p>
<p><span class="math display">\[
S(t) = P(T &gt; t)
\]</span></p>
<p>To illustrate the strengths of Kaplan Meier, we'll start with a naive estimator of the above survival function. To estimate this quantity, we'll divide the number of people who we know lived past time <span class="math inline">\(t\)</span> by the number of people who were not censored before <span class="math inline">\(t\)</span>.</p>
<p>Formally, let <span class="math inline">\(i\)</span> = 1, ..., <span class="math inline">\(n\)</span> be the cases, and let <span class="math inline">\(t_i\)</span> be the time when <span class="math inline">\(i\)</span> was censored or an event happened. Let <span class="math inline">\(e_i= 1\)</span> if an event was observed for <span class="math inline">\(i\)</span> and 0 otherwise. Then let <span class="math inline">\(X_t = \{i : T_i &gt; t\}\)</span>, and let <span class="math inline">\(M_t = \{i : e_i = 1 \text{ or } T_i &gt; t\}\)</span>. The estimator you will compute will be:</p>
<p><span class="math display">\[
\hat{S}(t) = \frac{|X_t|}{|M_t|}
\]</span></p>
<p><a name='Ex-2'></a> ### Exercise 2 Write a function to compute this estimate for arbitrary <span class="math inline">\(t\)</span> in the cell below.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">naive_estimator</span>(<span class="params">t, df</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Return naive estimate for S(t), the probability</span></span><br><span class="line"><span class="string">    of surviving past time t. Given by number</span></span><br><span class="line"><span class="string">    of cases who survived past time t divided by the</span></span><br><span class="line"><span class="string">    number of cases who weren&#x27;t censored before time t.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        t (int): query time</span></span><br><span class="line"><span class="string">        df (dataframe): survival data. Has a Time column,</span></span><br><span class="line"><span class="string">                        which says how long until that case</span></span><br><span class="line"><span class="string">                        experienced an event or was censored,</span></span><br><span class="line"><span class="string">                        and an Event column, which is 1 if an event</span></span><br><span class="line"><span class="string">                        was observed and 0 otherwise.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        S_t (float): estimator for survival function evaluated at t.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    S_t = <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    S_t = df[df[<span class="string">&#x27;Time&#x27;</span>] &gt; t].shape[<span class="number">0</span>] / df[ (df[<span class="string">&#x27;Event&#x27;</span>] == <span class="number">1</span>) | (df[<span class="string">&#x27;Time&#x27;</span>] &gt; t) ].shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> S_t</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Cases&quot;</span>)</span><br><span class="line"></span><br><span class="line">sample_df = pd.DataFrame(columns = [<span class="string">&quot;Time&quot;</span>, <span class="string">&quot;Event&quot;</span>])</span><br><span class="line">sample_df.Time = [<span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>]</span><br><span class="line">sample_df.Event = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sample dataframe for testing code:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(sample_df)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Case 1: S(3)&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Output: &#123;&#125;, Expected: &#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(naive_estimator(<span class="number">3</span>, sample_df), <span class="number">1.0</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Case 2: S(12)&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Output: &#123;&#125;, Expected: &#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(naive_estimator(<span class="number">12</span>, sample_df), <span class="number">0.5</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Case 3: S(20)&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Output: &#123;&#125;, Expected: &#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(naive_estimator(<span class="number">20</span>, sample_df), <span class="number">0.0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test case 4</span></span><br><span class="line">sample_df = pd.DataFrame(&#123;<span class="string">&#x27;Time&#x27;</span>: [<span class="number">5</span>,<span class="number">5</span>,<span class="number">10</span>],</span><br><span class="line">                          <span class="string">&#x27;Event&#x27;</span>: [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>]</span><br><span class="line">                         &#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test case 4: S(5)&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Output: <span class="subst">&#123;naive_estimator(<span class="number">5</span>, sample_df)&#125;</span>, Expected: 0.5&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Cases
Sample dataframe for testing code:
   Time  Event
0     5      0
1    10      1
2    15      0


Test Case 1: S(3)
Output: 1.0, Expected: 1.0

Test Case 2: S(12)
Output: 0.5, Expected: 0.5

Test Case 3: S(20)
Output: 0.0, Expected: 0.0

Test case 4: S(5)
Output: 0.5, Expected: 0.5</code></pre>
<p>In the next cell, we will plot the naive estimator using the real data up to the maximum time in the dataset.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">max_time = data.Time.<span class="built_in">max</span>()</span><br><span class="line">x = <span class="built_in">range</span>(<span class="number">0</span>, max_time+<span class="number">1</span>)</span><br><span class="line">y = np.zeros(<span class="built_in">len</span>(x))</span><br><span class="line"><span class="keyword">for</span> i, t <span class="keyword">in</span> <span class="built_in">enumerate</span>(x):</span><br><span class="line">    y[i] = naive_estimator(t, data)</span><br><span class="line">    </span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.title(<span class="string">&quot;Naive Survival Estimate&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Time&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Estimated cumulative survival rate&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_25_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p><a name='Ex-3'></a> ### Exercise 3</p>
<p>Next let's compare this with the Kaplan Meier estimate. In the cell below, write a function that computes the Kaplan Meier estimate of <span class="math inline">\(S(t)\)</span> at every distinct time in the dataset.</p>
<p>Recall the Kaplan-Meier estimate:</p>
<p><span class="math display">\[
S(t) = \prod_{t_i \leq t} (1 - \frac{d_i}{n_i})
\]</span></p>
<p>where <span class="math inline">\(t_i\)</span> are the events observed in the dataset and <span class="math inline">\(d_i\)</span> is the number of deaths at time <span class="math inline">\(t_i\)</span> and <span class="math inline">\(n_i\)</span> is the number of people who we know have survived up to time <span class="math inline">\(t_i\)</span>.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Try sorting by Time.
</li>
<li>
Use <a target="_blank" rel="noopener" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html">pandas.Series.unique<a>
</li>
<li>
If you get a division by zero error, please double-check how you calculated <code>n_t</code>
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">HomemadeKM</span>(<span class="params">df</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Return KM estimate evaluated at every distinct</span></span><br><span class="line"><span class="string">    time (event or censored) recorded in the dataset.</span></span><br><span class="line"><span class="string">    Event times and probabilities should begin with</span></span><br><span class="line"><span class="string">    time 0 and probability 1.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Example:</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    input: </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">         Time  Censor</span></span><br><span class="line"><span class="string">    0     5       0</span></span><br><span class="line"><span class="string">    1    10       1</span></span><br><span class="line"><span class="string">    2    15       0</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    correct output: </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    event_times: [0, 5, 10, 15]</span></span><br><span class="line"><span class="string">    S: [1.0, 1.0, 0.5, 0.5]</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        df (dataframe): dataframe which has columns for Time</span></span><br><span class="line"><span class="string">                          and Event, defined as usual.</span></span><br><span class="line"><span class="string">                          </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        event_times (list of ints): array of unique event times</span></span><br><span class="line"><span class="string">                                      (begins with 0).</span></span><br><span class="line"><span class="string">        S (list of floats): array of survival probabilites, so that</span></span><br><span class="line"><span class="string">                            S[i] = P(T &gt; event_times[i]). This </span></span><br><span class="line"><span class="string">                            begins with 1.0 (since no one dies at time</span></span><br><span class="line"><span class="string">                            0).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># individuals are considered to have survival probability 1</span></span><br><span class="line">    <span class="comment"># at time 0</span></span><br><span class="line">    event_times = [<span class="number">0</span>]</span><br><span class="line">    p = <span class="number">1.0</span></span><br><span class="line">    S = [p]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># get collection of unique observed event times</span></span><br><span class="line">    observed_event_times = df[<span class="string">&#x27;Time&#x27;</span>].unique().tolist()</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># sort event times</span></span><br><span class="line">    observed_event_times = <span class="built_in">sorted</span>(observed_event_times)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># iterate through event times</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> observed_event_times:</span><br><span class="line">  </span><br><span class="line">        <span class="comment"># compute n_t, number of people who survive to time t</span></span><br><span class="line">        n_t = df[df[<span class="string">&#x27;Time&#x27;</span>] &gt;= t].shape[<span class="number">0</span>]</span><br><span class="line">  </span><br><span class="line">        <span class="comment"># compute d_t, number of people who die at time t</span></span><br><span class="line">        d_t = df[(df[<span class="string">&#x27;Time&#x27;</span>] == t) &amp; (df[<span class="string">&#x27;Event&#x27;</span>] == <span class="number">1</span>)].shape[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># update p</span></span><br><span class="line">        p = p * ( <span class="number">1</span> - d_t / n_t)</span><br><span class="line">  </span><br><span class="line">        <span class="comment"># update S and event_times (ADD code below)</span></span><br><span class="line">        <span class="comment"># hint: use append</span></span><br><span class="line">        S.append(p)</span><br><span class="line">        event_times.append(t)</span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> event_times, S</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;TEST CASES:\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Case 1\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test DataFrame:&quot;</span>)</span><br><span class="line">sample_df = pd.DataFrame(columns = [<span class="string">&quot;Time&quot;</span>, <span class="string">&quot;Event&quot;</span>])</span><br><span class="line">sample_df.Time = [<span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>]</span><br><span class="line">sample_df.Event = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(sample_df.head())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nOutput:&quot;</span>)</span><br><span class="line">x, y = HomemadeKM(sample_df)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Event times: &#123;&#125;, Survival Probabilities: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(x, y))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nExpected:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Event times: [0, 5, 10, 15], Survival Probabilities: [1.0, 1.0, 0.5, 0.5]&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nTest Case 2\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test DataFrame:&quot;</span>)</span><br><span class="line"></span><br><span class="line">sample_df = pd.DataFrame(columns = [<span class="string">&quot;Time&quot;</span>, <span class="string">&quot;Event&quot;</span>])</span><br><span class="line">sample_df.loc[:, <span class="string">&quot;Time&quot;</span>] = [<span class="number">2</span>, <span class="number">15</span>, <span class="number">12</span>, <span class="number">10</span>, <span class="number">20</span>]</span><br><span class="line">sample_df.loc[:, <span class="string">&quot;Event&quot;</span>] = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(sample_df.head())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nOutput:&quot;</span>)</span><br><span class="line">x, y = HomemadeKM(sample_df)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Event times: &#123;&#125;, Survival Probabilities: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(x, y))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nExpected:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Event times: [0, 2, 10, 12, 15, 20], Survival Probabilities: [1.0, 1.0, 0.75, 0.5, 0.5, 0.0]&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>TEST CASES:

Test Case 1

Test DataFrame:
   Time  Event
0     5      0
1    10      1
2    15      0

Output:
Event times: [0, 5, 10, 15], Survival Probabilities: [1.0, 1.0, 0.5, 0.5]

Expected:
Event times: [0, 5, 10, 15], Survival Probabilities: [1.0, 1.0, 0.5, 0.5]

Test Case 2

Test DataFrame:
   Time  Event
0     2      0
1    15      0
2    12      1
3    10      1
4    20      1

Output:
Event times: [0, 2, 10, 12, 15, 20], Survival Probabilities: [1.0, 1.0, 0.75, 0.5, 0.5, 0.0]

Expected:
Event times: [0, 2, 10, 12, 15, 20], Survival Probabilities: [1.0, 1.0, 0.75, 0.5, 0.5, 0.0]</code></pre>
<p>Now let's plot the two against each other on the data to see the difference.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">max_time = data.Time.<span class="built_in">max</span>()</span><br><span class="line">x = <span class="built_in">range</span>(<span class="number">0</span>, max_time+<span class="number">1</span>)</span><br><span class="line">y = np.zeros(<span class="built_in">len</span>(x))</span><br><span class="line"><span class="keyword">for</span> i, t <span class="keyword">in</span> <span class="built_in">enumerate</span>(x):</span><br><span class="line">    y[i] = naive_estimator(t, data)</span><br><span class="line">    </span><br><span class="line">plt.plot(x, y, label=<span class="string">&quot;Naive&quot;</span>)</span><br><span class="line"></span><br><span class="line">x, y = HomemadeKM(data)</span><br><span class="line">plt.step(x, y, label=<span class="string">&quot;Kaplan-Meier&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Time&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Survival probability estimate&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_31_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<h3 id="question">Question</h3>
<p>What differences do you observe between the naive estimator and Kaplan-Meier estimator? Do any of our earlier explorations of the dataset help to explain these differences?</p>
<p><a name='5'></a> ## 5. Subgroup Analysis</p>
<p>We see that along with Time and Censor, we have a column called <code>Stage_group</code>. - A value of 1 in this column denotes a patient with stage III cancer - A value of 2 denotes stage IV.</p>
<p>We want to compare the survival functions of these two groups.</p>
<p>This time we'll use the <code>KaplanMeierFitter</code> class from <code>lifelines</code>. Run the next cell to fit and plot the Kaplan Meier curves for each group.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">S1 = data[data.Stage_group == <span class="number">1</span>]</span><br><span class="line">km1 = KM()</span><br><span class="line">km1.fit(S1.loc[:, <span class="string">&#x27;Time&#x27;</span>], event_observed = S1.loc[:, <span class="string">&#x27;Event&#x27;</span>], label = <span class="string">&#x27;Stage III&#x27;</span>)</span><br><span class="line"></span><br><span class="line">S2 = data[data.Stage_group == <span class="number">2</span>]</span><br><span class="line">km2 = KM()</span><br><span class="line">km2.fit(S2.loc[:, <span class="string">&quot;Time&quot;</span>], event_observed = S2.loc[:, <span class="string">&#x27;Event&#x27;</span>], label = <span class="string">&#x27;Stage IV&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax = km1.plot(ci_show=<span class="literal">False</span>)</span><br><span class="line">km2.plot(ax = ax, ci_show=<span class="literal">False</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;time&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Survival probability estimate&#x27;</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;two_km_curves&#x27;</span>, dpi=<span class="number">300</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_34_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>Let's compare the survival functions at 90, 180, 270, and 360 days</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">survivals = pd.DataFrame([<span class="number">90</span>, <span class="number">180</span>, <span class="number">270</span>, <span class="number">360</span>], columns = [<span class="string">&#x27;time&#x27;</span>])</span><br><span class="line">survivals.loc[:, <span class="string">&#x27;Group 1&#x27;</span>] = km1.survival_function_at_times(survivals[<span class="string">&#x27;time&#x27;</span>]).values</span><br><span class="line">survivals.loc[:, <span class="string">&#x27;Group 2&#x27;</span>] = km2.survival_function_at_times(survivals[<span class="string">&#x27;time&#x27;</span>]).values</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">survivals</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
time
</th>
<th>
Group 1
</th>
<th>
Group 2
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
90
</td>
<td>
0.736842
</td>
<td>
0.424529
</td>
</tr>
<tr>
<th>
1
</th>
<td>
180
</td>
<td>
0.680162
</td>
<td>
0.254066
</td>
</tr>
<tr>
<th>
2
</th>
<td>
270
</td>
<td>
0.524696
</td>
<td>
0.195436
</td>
</tr>
<tr>
<th>
3
</th>
<td>
360
</td>
<td>
0.524696
</td>
<td>
0.195436
</td>
</tr>
</tbody>
</table>
</div>
<p>This makes clear the difference in survival between the Stage III and IV cancer groups in the dataset.</p>
<p><a name='5-1'></a> ## 5.1 Bonus: Log-Rank Test</p>
<p>To say whether there is a statistical difference between the survival curves we can run the log-rank test. This test tells us the probability that we could observe this data if the two curves were the same. The derivation of the log-rank test is somewhat complicated, but luckily <code>lifelines</code> has a simple function to compute it.</p>
<p>Run the next cell to compute a p-value using <code>lifelines.statistics.logrank_test</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logrank_p_value</span>(<span class="params">group_1_data, group_2_data</span>):</span></span><br><span class="line">    result = logrank_test(group_1_data.Time, group_2_data.Time,</span><br><span class="line">                          group_1_data.Event, group_2_data.Event)</span><br><span class="line">    <span class="keyword">return</span> result.p_value</span><br><span class="line"></span><br><span class="line">logrank_p_value(S1, S2)</span><br></pre></td></tr></table></figure>
<pre><code>0.009588929834755544</code></pre>
<p>If everything is correct, you should see a p value of less than <code>0.05</code>, which indicates that the difference in the curves is indeed statistically significant.</p>
<h1 id="congratulations">Congratulations!</h1>
<p>You've completed the third assignment of Course 2. You've learned about the Kaplan Meier estimator, a fundamental non-parametric estimator in survival analysis. Next week we'll learn how to take into account patient covariates in our survival estimates!</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Risk-Models-Using-Tree-based-Models/2020/04/18/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Risk-Models-Using-Tree-based-Models/2020/04/18/" class="post-title-link" itemprop="url">Risk Models Using Tree-based Models</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-18 23:53:23" itemprop="dateCreated datePublished" datetime="2020-04-18T23:53:23+08:00">2020-04-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-12-31 13:48:37" itemprop="dateModified" datetime="2021-12-31T13:48:37+08:00">2021-12-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Risk-Models-Using-Tree-based-Models/2020/04/18/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Risk-Models-Using-Tree-based-Models/2020/04/18/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="risk-models-using-tree-based-models">Risk Models Using Tree-based Models</h1>
<p>Welcome to the second assignment of Course 2!</p>
<h2 id="outline">Outline</h2>
<ul>
<li><a href="#risk-models-using-tree-based-models">Risk Models Using Tree-based Models</a>
<ul>
<li><a href="#outline">Outline</a></li>
<li><a href="#1-import-packages">1. Import Packages</a></li>
<li><a href="#2-load-the-dataset">2. Load the Dataset</a></li>
<li><a href="#3-explore-the-dataset">3. Explore the Dataset</a></li>
<li><a href="#4-dealing-with-missing-data">4. Dealing with Missing Data</a>
<ul>
<li><a href="#exercise-1">Exercise 1</a></li>
</ul></li>
<li><a href="#5-decision-trees">5. Decision Trees</a>
<ul>
<li><a href="#exercise-2">Exercise 2</a></li>
</ul></li>
<li><a href="#6-random-forests">6. Random Forests</a>
<ul>
<li><a href="#exercise-3">Exercise 3</a></li>
</ul></li>
<li><a href="#7-imputation">7. Imputation</a></li>
<li><a href="#8-error-analysis">8. Error Analysis</a>
<ul>
<li><a href="#exercise-4">Exercise 4</a>
<ul>
<li><a href="#test-your-work">Test Your Work</a></li>
<li><a href="#expected-output">Expected Output</a></li>
</ul></li>
</ul></li>
<li><a href="#9-imputation-approaches">9. Imputation Approaches</a>
<ul>
<li><a href="#exercise-5">Exercise 5</a>
<ul>
<li><a href="#target-performance">Target performance</a></li>
<li><a href="#expected-output-1">Expected output</a></li>
</ul></li>
<li><a href="#exercise-6">Exercise 6</a>
<ul>
<li><a href="#target-performance-1">Target performance</a></li>
<li><a href="#expected-output-2">Expected Output</a></li>
</ul></li>
</ul></li>
<li><a href="#10-comparison">10. Comparison</a></li>
<li><a href="#11-explanations-shap">11. Explanations: SHAP</a></li>
</ul></li>
<li><a href="#congratulations">Congratulations!</a></li>
</ul>
<p>In this assignment, you'll gain experience with tree based models by predicting the 10-year risk of death of individuals from the NHANES I epidemiology dataset (for a detailed description of this dataset you can check the <a target="_blank" rel="noopener" href="https://wwwn.cdc.gov/nchs/nhanes/nhefs/default.aspx/">CDC Website</a>). This is a challenging task and a great test bed for the machine learning methods we learned this week.</p>
<p>As you go through the assignment, you'll learn about:</p>
<ul>
<li>Dealing with Missing Data
<ul>
<li>Complete Case Analysis.</li>
<li>Imputation</li>
</ul></li>
<li>Decision Trees
<ul>
<li>Evaluation.</li>
<li>Regularization.</li>
</ul></li>
<li>Random Forests
<ul>
<li>Hyperparameter Tuning.</li>
</ul></li>
</ul>
<p><a name='1'></a> ## 1. Import Packages</p>
<p>We'll first import all the common packages that we need for this assignment.</p>
<ul>
<li><code>shap</code> is a library that explains predictions made by machine learning models.</li>
<li><code>sklearn</code> is one of the most popular machine learning libraries.</li>
<li><code>itertools</code> allows us to conveniently manipulate iterable objects such as lists.</li>
<li><code>pydotplus</code> is used together with <code>IPython.display.Image</code> to visualize graph structures such as decision trees.</li>
<li><code>numpy</code> is a fundamental package for scientific computing in Python.</li>
<li><code>pandas</code> is what we'll use to manipulate our data.</li>
<li><code>seaborn</code> is a plotting library which has some convenient functions for visualizing missing data.</li>
<li><code>matplotlib</code> is a plotting library.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> shap</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">import</span> pydotplus</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image </span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> export_graphviz</span><br><span class="line"><span class="keyword">from</span> sklearn.externals.six <span class="keyword">import</span> StringIO</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.experimental <span class="keyword">import</span> enable_iterative_imputer</span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> IterativeImputer, SimpleImputer</span><br><span class="line"></span><br><span class="line"><span class="comment"># We&#x27;ll also import some helper functions that will be useful later on.</span></span><br><span class="line"><span class="keyword">from</span> util <span class="keyword">import</span> load_data, cindex</span><br></pre></td></tr></table></figure>
<p><a name='2'></a> ## 2. Load the Dataset</p>
<p>Run the next cell to load in the NHANES I epidemiology dataset. This dataset contains various features of hospital patients as well as their outcomes, i.e. whether or not they died within 10 years.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_dev, X_test, y_dev, y_test = load_data(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>The dataset has been split into a development set (or dev set), which we will use to develop our risk models, and a test set, which we will use to test our models.</p>
<p>We further split the dev set into a training and validation set, respectively to train and tune our models, using a 75/25 split (note that we set a random state to make this split repeatable).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=<span class="number">0.25</span>, random_state=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p><a name='3'></a> ## 3. Explore the Dataset</p>
<p>The first step is to familiarize yourself with the data. Run the next cell to get the size of your training set and look at a small sample.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X_train shape: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(X_train.shape))</span><br><span class="line">X_train.head()</span><br></pre></td></tr></table></figure>
<pre><code>X_train shape: (5147, 18)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Age
</th>
<th>
Diastolic BP
</th>
<th>
Poverty index
</th>
<th>
Race
</th>
<th>
Red blood cells
</th>
<th>
Sedimentation rate
</th>
<th>
Serum Albumin
</th>
<th>
Serum Cholesterol
</th>
<th>
Serum Iron
</th>
<th>
Serum Magnesium
</th>
<th>
Serum Protein
</th>
<th>
Sex
</th>
<th>
Systolic BP
</th>
<th>
TIBC
</th>
<th>
TS
</th>
<th>
White blood cells
</th>
<th>
BMI
</th>
<th>
Pulse pressure
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1599
</th>
<td>
43.0
</td>
<td>
84.0
</td>
<td>
637.0
</td>
<td>
1.0
</td>
<td>
49.3
</td>
<td>
10.0
</td>
<td>
5.0
</td>
<td>
253.0
</td>
<td>
134.0
</td>
<td>
1.59
</td>
<td>
7.7
</td>
<td>
1.0
</td>
<td>
NaN
</td>
<td>
490.0
</td>
<td>
27.3
</td>
<td>
9.1
</td>
<td>
25.803007
</td>
<td>
34.0
</td>
</tr>
<tr>
<th>
2794
</th>
<td>
72.0
</td>
<td>
96.0
</td>
<td>
154.0
</td>
<td>
2.0
</td>
<td>
43.4
</td>
<td>
23.0
</td>
<td>
4.3
</td>
<td>
265.0
</td>
<td>
106.0
</td>
<td>
1.66
</td>
<td>
6.8
</td>
<td>
2.0
</td>
<td>
208.0
</td>
<td>
301.0
</td>
<td>
35.2
</td>
<td>
6.0
</td>
<td>
33.394319
</td>
<td>
112.0
</td>
</tr>
<tr>
<th>
1182
</th>
<td>
54.0
</td>
<td>
78.0
</td>
<td>
205.0
</td>
<td>
1.0
</td>
<td>
43.8
</td>
<td>
12.0
</td>
<td>
4.2
</td>
<td>
206.0
</td>
<td>
180.0
</td>
<td>
1.67
</td>
<td>
6.6
</td>
<td>
2.0
</td>
<td>
NaN
</td>
<td>
363.0
</td>
<td>
49.6
</td>
<td>
5.9
</td>
<td>
20.278410
</td>
<td>
34.0
</td>
</tr>
<tr>
<th>
6915
</th>
<td>
59.0
</td>
<td>
90.0
</td>
<td>
417.0
</td>
<td>
1.0
</td>
<td>
43.4
</td>
<td>
9.0
</td>
<td>
4.5
</td>
<td>
327.0
</td>
<td>
114.0
</td>
<td>
1.65
</td>
<td>
7.6
</td>
<td>
2.0
</td>
<td>
NaN
</td>
<td>
347.0
</td>
<td>
32.9
</td>
<td>
6.1
</td>
<td>
32.917744
</td>
<td>
78.0
</td>
</tr>
<tr>
<th>
500
</th>
<td>
34.0
</td>
<td>
80.0
</td>
<td>
385.0
</td>
<td>
1.0
</td>
<td>
77.7
</td>
<td>
9.0
</td>
<td>
4.1
</td>
<td>
197.0
</td>
<td>
64.0
</td>
<td>
1.74
</td>
<td>
7.3
</td>
<td>
2.0
</td>
<td>
NaN
</td>
<td>
376.0
</td>
<td>
17.0
</td>
<td>
8.2
</td>
<td>
30.743489
</td>
<td>
30.0
</td>
</tr>
</tbody>
</table>
</div>
<p>Our targets <code>y</code> will be whether or not the target died within 10 years. Run the next cell to see the target data series.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_train.head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<pre><code>1599    False
2794     True
1182    False
6915    False
500     False
1188     True
9739    False
3266    False
6681    False
8822    False
5856     True
3415    False
9366    False
7975    False
1397    False
6809    False
9461    False
9374    False
1170     True
158     False
Name: time, dtype: bool</code></pre>
<p>Use the next cell to examine individual cases and familiarize yourself with the features.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">10</span></span><br><span class="line"><span class="built_in">print</span>(X_train.iloc[i,:])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nDied within 10 years? &#123;&#125;&quot;</span>.<span class="built_in">format</span>(y_train.loc[y_train.index[i]]))</span><br></pre></td></tr></table></figure>
<pre><code>Age                    67.000000
Diastolic BP           94.000000
Poverty index         114.000000
Race                    1.000000
Red blood cells        43.800000
Sedimentation rate     12.000000
Serum Albumin           3.700000
Serum Cholesterol     178.000000
Serum Iron             73.000000
Serum Magnesium         1.850000
Serum Protein           7.000000
Sex                     1.000000
Systolic BP           140.000000
TIBC                  311.000000
TS                     23.500000
White blood cells       4.300000
BMI                    17.481227
Pulse pressure         46.000000
Name: 5856, dtype: float64

Died within 10 years? True</code></pre>
<p><a name='4'></a> ## 4. Dealing with Missing Data</p>
<p>Looking at our data in <code>X_train</code>, we see that some of the data is missing: some values in the output of the previous cell are marked as <code>NaN</code> ("not a number").</p>
<p>Missing data is a common occurrence in data analysis, that can be due to a variety of reasons, such as measuring instrument malfunction, respondents not willing or not able to supply information, and errors in the data collection process.</p>
<p>Let's examine the missing data pattern. <code>seaborn</code> is an alternative to <code>matplotlib</code> that has some convenient plotting functions for data analysis. We can use its <code>heatmap</code> function to easily visualize the missing data pattern.</p>
<p>Run the cell below to plot the missing data:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sns.heatmap(X_train.isnull(), cbar=<span class="literal">False</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Training&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">sns.heatmap(X_val.isnull(), cbar=<span class="literal">False</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Validation&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_17_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_17_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>For each feature, represented as a column, values that are present are shown in black, and missing values are set in a light color.</p>
<p>From this plot, we can see that many values are missing for systolic blood pressure (<code>Systolic BP</code>).</p>
<p><a name='Ex-1'></a> ### Exercise 1</p>
<p>In the cell below, write a function to compute the fraction of cases with missing data. This will help us decide how we handle this missing data in the future.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
The <code>pandas.DataFrame.isnull()</code> method is helpful in this case.
</li>
<li>
Use the <code>pandas.DataFrame.any()</code> method and set the <code>axis</code> parameter.
</li>
<li>
Divide the total number of rows with missing data by the total number of rows. Remember that in Python, <code>True</code> values are equal to 1.
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fraction_rows_missing</span>(<span class="params">df</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Return percent of rows with any missing</span></span><br><span class="line"><span class="string">    data in the dataframe. </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">        df (dataframe): a pandas dataframe with potentially missing data</span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">        frac_missing (float): fraction of rows with missing data</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE &#x27;Pass&#x27; with your &#x27;return&#x27; code) ###</span></span><br><span class="line">    <span class="keyword">return</span> df.isnull().<span class="built_in">any</span>(axis = <span class="number">1</span>).<span class="built_in">sum</span>() / df.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br></pre></td></tr></table></figure>
<p>Test your function by running the cell below.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df_test = pd.DataFrame(&#123;<span class="string">&#x27;a&#x27;</span>:[<span class="literal">None</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="literal">None</span>], <span class="string">&#x27;b&#x27;</span>:[<span class="number">1</span>, <span class="literal">None</span>, <span class="number">0</span>, <span class="number">1</span>]&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Example dataframe:\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nComputed fraction missing: &#123;&#125;, expected: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(fraction_rows_missing(df_test), <span class="number">0.75</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fraction of rows missing from X_train: <span class="subst">&#123;fraction_rows_missing(X_train):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fraction of rows missing from X_val: <span class="subst">&#123;fraction_rows_missing(X_val):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fraction of rows missing from X_test: <span class="subst">&#123;fraction_rows_missing(X_test):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Example dataframe:

     a    b
0  NaN  1.0
1  1.0  NaN
2  1.0  0.0
3  NaN  1.0

Computed fraction missing: 0.75, expected: 0.75
Fraction of rows missing from X_train: 0.699
Fraction of rows missing from X_val: 0.704
Fraction of rows missing from X_test: 0.000</code></pre>
<p>We see that our train and validation sets have missing values, but luckily our test set has complete cases.</p>
<p>As a first pass, we will begin with a <strong>complete case analysis</strong>, dropping all of the rows with any missing data. Run the following cell to drop these rows from our train and validation sets.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_train_dropped = X_train.dropna(axis=<span class="string">&#x27;rows&#x27;</span>)</span><br><span class="line">y_train_dropped = y_train.loc[X_train_dropped.index]</span><br><span class="line">X_val_dropped = X_val.dropna(axis=<span class="string">&#x27;rows&#x27;</span>)</span><br><span class="line">y_val_dropped = y_val.loc[X_val_dropped.index]</span><br></pre></td></tr></table></figure>
<p><a name='5'></a> ## 5. Decision Trees</p>
<p>Having just learned about decision trees, you choose to use a decision tree classifier. Use scikit-learn to build a decision tree for the hospital dataset using the train set.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dt = DecisionTreeClassifier(max_depth=<span class="literal">None</span>, random_state=<span class="number">10</span>)</span><br><span class="line">dt.fit(X_train_dropped, y_train_dropped)</span><br></pre></td></tr></table></figure>
<p>DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort='deprecated', random_state=10, splitter='best')</p>
<p>Next we will evaluate our model. We'll use C-Index for evaluation.</p>
<blockquote>
<p>Remember from lesson 4 of week 1 that the C-Index evaluates the ability of a model to differentiate between different classes, by quantifying how often, when considering all pairs of patients (A, B), the model says that patient A has a higher risk score than patient B when, in the observed data, patient A actually died and patient B actually lived. In our case, our model is a binary classifier, where each risk score is either 1 (the model predicts that the patient will die) or 0 (the patient will live).</p>
<p>More formally, defining <em>permissible pairs</em> of patients as pairs where the outcomes are different, <em>concordant pairs</em> as permissible pairs where the patient that died had a higher risk score (i.e. our model predicted 1 for the patient that died and 0 for the one that lived), and <em>ties</em> as permissible pairs where the risk scores were equal (i.e. our model predicted 1 for both patients or 0 for both patients), the C-Index is equal to:</p>
</blockquote>
<p>Run the next cell to compute the C-Index on the train and validation set (we've given you an implementation this time). <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y_train_preds = dt.predict_proba(X_train_dropped)[:, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Train C-Index: <span class="subst">&#123;cindex(y_train_dropped.values, y_train_preds)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y_val_preds = dt.predict_proba(X_val_dropped)[:, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Val C-Index: <span class="subst">&#123;cindex(y_val_dropped.values, y_val_preds)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure></p>
<pre><code>Train C-Index: 1.0
Val C-Index: 0.5629321808510638</code></pre>
<p>Unfortunately your tree seems to be overfitting: it fits the training data so closely that it doesn't generalize well to other samples such as those from the validation set.</p>
<blockquote>
<p>The training C-index comes out to 1.0 because, when initializing <code>DecisionTreeClasifier</code>, we have left <code>max_depth</code> and <code>min_samples_split</code> unspecified. The resulting decision tree will therefore keep splitting as far as it can, which pretty much guarantees a pure fit to the training data.</p>
</blockquote>
<p>To handle this, you can change some of the hyperparameters of our tree.</p>
<p><a name='Ex-2'></a> ### Exercise 2</p>
<p>Try and find a set of hyperparameters that improves the generalization to the validation set and recompute the C-index. If you do it right, you should get C-index above 0.6 for the validation set.</p>
<p>You can refer to the documentation for the sklearn <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html">DecisionTreeClassifier</a>.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Try limiting the depth of the tree (<code>'max_depth'</code>).
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Experiment with different hyperparameters for the DecisionTreeClassifier</span></span><br><span class="line"><span class="comment"># until you get a c-index above 0.6 for the validation set</span></span><br><span class="line">dt_hyperparams = &#123;</span><br><span class="line">    <span class="comment"># set your own hyperparameters below, such as &#x27;min_samples_split&#x27;: 1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="string">&quot;max_depth&quot;</span>: <span class="number">3</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Run the next cell to fit and evaluate the regularized tree.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line">dt_reg = DecisionTreeClassifier(**dt_hyperparams, random_state=<span class="number">10</span>)</span><br><span class="line">dt_reg.fit(X_train_dropped, y_train_dropped)</span><br><span class="line"></span><br><span class="line">y_train_preds = dt_reg.predict_proba(X_train_dropped)[:, <span class="number">1</span>]</span><br><span class="line">y_val_preds = dt_reg.predict_proba(X_val_dropped)[:, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Train C-Index: <span class="subst">&#123;cindex(y_train_dropped.values, y_train_preds)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Val C-Index (expected &gt; 0.6): <span class="subst">&#123;cindex(y_val_dropped.values, y_val_preds)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Train C-Index: 0.688738755448391
Val C-Index (expected &gt; 0.6): 0.6302692819148936</code></pre>
<p>If you used a low <code>max_depth</code> you can print the entire tree. This allows for easy interpretability. Run the next cell to print the tree splits.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dot_data = StringIO()</span><br><span class="line">export_graphviz(dt_reg, feature_names=X_train_dropped.columns, out_file=dot_data,  </span><br><span class="line">                filled=<span class="literal">True</span>, rounded=<span class="literal">True</span>, proportion=<span class="literal">True</span>, special_characters=<span class="literal">True</span>,</span><br><span class="line">                impurity=<span class="literal">False</span>, class_names=[<span class="string">&#x27;neg&#x27;</span>, <span class="string">&#x27;pos&#x27;</span>], precision=<span class="number">2</span>)</span><br><span class="line">graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  </span><br><span class="line">Image(graph.create_png())</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img src="output_38_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<blockquote>
<p><strong>Overfitting, underfitting, and the bias-variance tradeoff</strong></p>
<p>If you tested several values of <code>max_depth</code>, you may have seen that a value of <code>3</code> gives training and validation C-Indices of about <code>0.689</code> and <code>0.630</code>, and that a <code>max_depth</code> of <code>2</code> gives better agreement with values of about <code>0.653</code> and <code>0.607</code>. In the latter case, we have further reduced overfitting, at the cost of a minor loss in predictive performance.</p>
<p>Contrast this with a <code>max_depth</code> value of <code>1</code>, which results in C-Indices of about <code>0.597</code> for the training set and <code>0.598</code> for the validation set: we have eliminated overfitting but with a much stronger degradation of predictive performance.</p>
<p>Lower predictive performance on the training and validation sets is indicative of the model <em>underfitting</em> the data: it neither learns enough from the training data nor is able to generalize to unseen data (the validation data in our case).</p>
<p>Finding a model that minimizes and acceptably balances underfitting and overfitting (e.g. selecting the model with a <code>max_depth</code> of <code>2</code> over the other values) is a common problem in machine learning that is known as the <em>bias-variance tradeoff</em>.</p>
</blockquote>
<p><a name='6'></a> ## 6. Random Forests</p>
<p>No matter how you choose hyperparameters, a single decision tree is prone to overfitting. To solve this problem, you can try <strong>random forests</strong>, which combine predictions from many different trees to create a robust classifier.</p>
<p>As before, we will use scikit-learn to build a random forest for the data. We will use the default hyperparameters.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rf = RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">10</span>)</span><br><span class="line">rf.fit(X_train_dropped, y_train_dropped)</span><br></pre></td></tr></table></figure>
<pre><code>RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion=&#39;gini&#39;, max_depth=None, max_features=&#39;auto&#39;,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=None, oob_score=False, random_state=10, verbose=0,
                       warm_start=False)</code></pre>
<p>Now compute and report the C-Index for the random forest on the training and validation set.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">y_train_rf_preds = rf.predict_proba(X_train_dropped)[:, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Train C-Index: <span class="subst">&#123;cindex(y_train_dropped.values, y_train_rf_preds)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">y_val_rf_preds = rf.predict_proba(X_val_dropped)[:, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Val C-Index: <span class="subst">&#123;cindex(y_val_dropped.values, y_val_rf_preds)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Train C-Index: 1.0
Val C-Index: 0.6660488696808511</code></pre>
<p>Training a random forest with the default hyperparameters results in a model that has better predictive performance than individual decision trees as in the previous section, but this model is overfitting.</p>
<p>We therefore need to tune (or optimize) the hyperparameters, to find a model that both has good predictive performance and minimizes overfitting.</p>
<p>The hyperparameters we choose to adjust will be:</p>
<ul>
<li><code>n_estimators</code>: the number of trees used in the forest.</li>
<li><code>max_depth</code>: the maximum depth of each tree.</li>
<li><code>min_samples_leaf</code>: the minimum number (if <code>int</code>) or proportion (if <code>float</code>) of samples in a leaf.</li>
</ul>
<p>The approach we implement to tune the hyperparameters is known as a grid search:</p>
<ul>
<li><p>We define a set of possible values for each of the target hyperparameters.</p></li>
<li><p>A model is trained and evaluated for every possible combination of hyperparameters.</p></li>
<li><p>The best performing set of hyperparameters is returned.</p></li>
</ul>
<p>The cell below implements a hyperparameter grid search, using the C-Index to evaluate each tested model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">holdout_grid_search</span>(<span class="params">clf, X_train_hp, y_train_hp, X_val_hp, y_val_hp, hyperparams, fixed_hyperparams=&#123;&#125;</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Conduct hyperparameter grid search on hold out validation set. Use holdout validation.</span></span><br><span class="line"><span class="string">    Hyperparameters are input as a dictionary mapping each hyperparameter name to the</span></span><br><span class="line"><span class="string">    range of values they should iterate over. Use the cindex function as your evaluation</span></span><br><span class="line"><span class="string">    function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">        clf: sklearn classifier</span></span><br><span class="line"><span class="string">        X_train_hp (dataframe): dataframe for training set input variables</span></span><br><span class="line"><span class="string">        y_train_hp (dataframe): dataframe for training set targets</span></span><br><span class="line"><span class="string">        X_val_hp (dataframe): dataframe for validation set input variables</span></span><br><span class="line"><span class="string">        y_val_hp (dataframe): dataframe for validation set targets</span></span><br><span class="line"><span class="string">        hyperparams (dict): hyperparameter dictionary mapping hyperparameter</span></span><br><span class="line"><span class="string">                            names to range of values for grid search</span></span><br><span class="line"><span class="string">        fixed_hyperparams (dict): dictionary of fixed hyperparameters that</span></span><br><span class="line"><span class="string">                                  are not included in the grid search</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">        best_estimator (sklearn classifier): fitted sklearn classifier with best performance on</span></span><br><span class="line"><span class="string">                                             validation set</span></span><br><span class="line"><span class="string">        best_hyperparams (dict): hyperparameter dictionary mapping hyperparameter</span></span><br><span class="line"><span class="string">                                 names to values in best_estimator</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    best_estimator = <span class="literal">None</span></span><br><span class="line">    best_hyperparams = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># hold best running score</span></span><br><span class="line">    best_score = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># get list of param values</span></span><br><span class="line">    lists = hyperparams.values()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># get all param combinations</span></span><br><span class="line">    param_combinations = <span class="built_in">list</span>(itertools.product(*lists))</span><br><span class="line">    total_param_combinations = <span class="built_in">len</span>(param_combinations)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># iterate through param combinations</span></span><br><span class="line">    <span class="keyword">for</span> i, params <span class="keyword">in</span> <span class="built_in">enumerate</span>(param_combinations, <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># fill param dict with params</span></span><br><span class="line">        param_dict = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> param_index, param_name <span class="keyword">in</span> <span class="built_in">enumerate</span>(hyperparams):</span><br><span class="line">            param_dict[param_name] = params[param_index]</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># create estimator with specified params</span></span><br><span class="line">        estimator = clf(**param_dict, **fixed_hyperparams)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># fit estimator</span></span><br><span class="line">        estimator.fit(X_train_hp, y_train_hp)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># get predictions on validation set</span></span><br><span class="line">        preds = estimator.predict_proba(X_val_hp)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># compute cindex for predictions</span></span><br><span class="line">        estimator_score = cindex(y_val_hp, preds[:,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;[<span class="subst">&#123;i&#125;</span>/<span class="subst">&#123;total_param_combinations&#125;</span>] <span class="subst">&#123;param_dict&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Val C-Index: <span class="subst">&#123;estimator_score&#125;</span>\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if new high score, update high score, best estimator</span></span><br><span class="line">        <span class="comment"># and best params </span></span><br><span class="line">        <span class="keyword">if</span> estimator_score &gt;= best_score:</span><br><span class="line">                best_score = estimator_score</span><br><span class="line">                best_estimator = estimator</span><br><span class="line">                best_hyperparams = param_dict</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add fixed hyperparamters to best combination of variable hyperparameters</span></span><br><span class="line">    best_hyperparams.update(fixed_hyperparams)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> best_estimator, best_hyperparams</span><br></pre></td></tr></table></figure>
<p><a name='Ex-3'></a> ### Exercise 3</p>
<p>In the cell below, define the values you want to run the hyperparameter grid search on, and run the cell to find the best-performing set of hyperparameters.</p>
<p>Your objective is to get a C-Index above <code>0.6</code> on both the train and validation set.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
n_estimators: try values greater than 100
</li>
<li>
max_depth: try values in the range 1 to 100
</li>
<li>
min_samples_leaf: try float values below .5 and/or int values greater than 2
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_forest_grid_search</span>(<span class="params">X_train_dropped, y_train_dropped, X_val_dropped, y_val_dropped</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define ranges for the chosen random forest hyperparameters </span></span><br><span class="line">    hyperparams = &#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">### START CODE HERE (REPLACE array values with your code) ###</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># how many trees should be in the forest (int)</span></span><br><span class="line">        <span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">50</span>, <span class="number">200</span>, <span class="number">200</span>],</span><br><span class="line"></span><br><span class="line">        <span class="comment"># the maximum depth of trees in the forest (int)</span></span><br><span class="line">        </span><br><span class="line">        <span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>],</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># the minimum number of samples in a leaf as a fraction</span></span><br><span class="line">        <span class="comment"># of the total number of samples in the training set</span></span><br><span class="line">        <span class="comment"># Can be int (in which case that is the minimum number)</span></span><br><span class="line">        <span class="comment"># or float (in which case the minimum is that fraction of the</span></span><br><span class="line">        <span class="comment"># number of training set samples)</span></span><br><span class="line">        <span class="string">&#x27;min_samples_leaf&#x27;</span>: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line"></span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    fixed_hyperparams = &#123;</span><br><span class="line">        <span class="string">&#x27;random_state&#x27;</span>: <span class="number">10</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    rf = RandomForestClassifier</span><br><span class="line"></span><br><span class="line">    best_rf, best_hyperparams = holdout_grid_search(rf, X_train_dropped, y_train_dropped,</span><br><span class="line">                                                    X_val_dropped, y_val_dropped, hyperparams,</span><br><span class="line">                                                    fixed_hyperparams)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Best hyperparameters:\n<span class="subst">&#123;best_hyperparams&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    y_train_best = best_rf.predict_proba(X_train_dropped)[:, <span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Train C-Index: <span class="subst">&#123;cindex(y_train_dropped, y_train_best)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    y_val_best = best_rf.predict_proba(X_val_dropped)[:, <span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Val C-Index: <span class="subst">&#123;cindex(y_val_dropped, y_val_best)&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># add fixed hyperparamters to best combination of variable hyperparameters</span></span><br><span class="line">    best_hyperparams.update(fixed_hyperparams)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> best_rf, best_hyperparams</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_rf, best_hyperparams = random_forest_grid_search(X_train_dropped, y_train_dropped, X_val_dropped, y_val_dropped)</span><br></pre></td></tr></table></figure>
<pre><code>[1/27] &#123;&#39;n_estimators&#39;: 50, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.6724567819148937

[2/27] &#123;&#39;n_estimators&#39;: 50, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.6722240691489362

[3/27] &#123;&#39;n_estimators&#39;: 50, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.6725066489361702

[4/27] &#123;&#39;n_estimators&#39;: 50, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.6637965425531915

[5/27] &#123;&#39;n_estimators&#39;: 50, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.6655585106382979

[6/27] &#123;&#39;n_estimators&#39;: 50, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.659624335106383

[7/27] &#123;&#39;n_estimators&#39;: 50, &#39;max_depth&#39;: 10, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.6611535904255319

[8/27] &#123;&#39;n_estimators&#39;: 50, &#39;max_depth&#39;: 10, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.6647273936170213

[9/27] &#123;&#39;n_estimators&#39;: 50, &#39;max_depth&#39;: 10, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.6605884308510638

[10/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.6811502659574468

[11/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.6815159574468085

[12/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.6809175531914894

[13/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.6765458776595744

[14/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.6750831117021276

[15/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.6745844414893617

[16/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 10, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.668467420212766

[17/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 10, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.6737699468085107

[18/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 10, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.667436835106383

[19/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.6811502659574468

[20/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.6815159574468085

[21/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.6809175531914894

[22/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.6765458776595744

[23/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.6750831117021276

[24/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.6745844414893617

[25/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 10, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.668467420212766

[26/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 10, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.6737699468085107

[27/27] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 10, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.667436835106383

Best hyperparameters:
&#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 2, &#39;random_state&#39;: 10&#125;
Train C-Index: 0.7798145228600575
Val C-Index: 0.6815159574468085</code></pre>
<p>Finally, evaluate the model on the test set. This is a crucial step, as trying out many combinations of hyperparameters and evaluating them on the validation set could result in a model that ends up overfitting the validation set. We therefore need to check if the model performs well on unseen data, which is the role of the test set, which we have held out until now.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line">y_test_best = best_rf.predict_proba(X_test)[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Test C-Index: <span class="subst">&#123;cindex(y_test.values, y_test_best)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test C-Index: 0.7013860174676174</code></pre>
<p>Your C-Index on the test set should be greater than <code>0.6</code>.</p>
<p><a name='7'></a> ## 7. Imputation</p>
<p>You've now built and optimized a random forest model on our data. However, there was still a drop in test C-Index. This might be because you threw away more than half of the data of our data because of missing values for systolic blood pressure. Instead, we can try filling in, or imputing, these values.</p>
<p>First, let's explore to see if our data is missing at random or not. Let's plot histograms of the dropped rows against each of the covariates (aside from systolic blood pressure) to see if there is a trend. Compare these to the histograms of the feature in the entire dataset. Try to see if one of the covariates has a signficantly different distribution in the two subsets.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dropped_rows = X_train[X_train.isnull().<span class="built_in">any</span>(axis=<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">columns_except_Systolic_BP = [col <span class="keyword">for</span> col <span class="keyword">in</span> X_train.columns <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&#x27;Systolic BP&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> columns_except_Systolic_BP:</span><br><span class="line">    sns.distplot(X_train.loc[:, col], norm_hist=<span class="literal">True</span>, kde=<span class="literal">False</span>, label=<span class="string">&#x27;full data&#x27;</span>)</span><br><span class="line">    sns.distplot(dropped_rows.loc[:, col], norm_hist=<span class="literal">True</span>, kde=<span class="literal">False</span>, label=<span class="string">&#x27;without missing data&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_54_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_2.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_3.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_4.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_5.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_6.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_7.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_8.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_9.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_10.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_11.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_12.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_13.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_14.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_15.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_54_16.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>Most of the covariates are distributed similarly whether or not we have discarded rows with missing data. In other words missingness of the data is independent of these covariates.</p>
<p>If this had been true across <em>all</em> covariates, then the data would have been said to be <strong>missing completely at random (MCAR)</strong>.</p>
<p>But when considering the age covariate, we see that much more data tends to be missing for patients over 65. The reason could be that blood pressure was measured less frequently for old people to avoid placing additional burden on them.</p>
<p>As missingness is related to one or more covariates, the missing data is said to be <strong>missing at random (MAR)</strong>.</p>
<p>Based on the information we have, there is however no reason to believe that the <em>values</em> of the missing data — or specifically the values of the missing systolic blood pressures — are related to the age of the patients. If this was the case, then this data would be said to be <strong>missing not at random (MNAR)</strong>.</p>
<p><a name='8'></a> ## 8. Error Analysis</p>
<p><a name='Ex-4'></a> ### Exercise 4 Using the information from the plots above, try to find a subgroup of the test data on which the model performs poorly. You should be able to easily find a subgroup of at least 250 cases on which the model has a C-Index of less than 0.69.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Define a mask using a feature and a threshold, e.g. patients with a BMI below 20: <code>mask = X_test['BMI'] &lt; 20 </code>.
</li>
<li>
Try to find a subgroup for which the model had little data.
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bad_subset</span>(<span class="params">forest, X_test, y_test</span>):</span></span><br><span class="line">    <span class="comment"># define mask to select large subset with poor performance</span></span><br><span class="line">    <span class="comment"># currently mask defines the entire set</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE the code after &#x27;mask =&#x27; with your code) ###</span></span><br><span class="line">    mask = X_test[<span class="string">&#x27;Age&#x27;</span>] &gt; <span class="number">67</span></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    X_subgroup = X_test[mask]</span><br><span class="line">    y_subgroup = y_test[mask]</span><br><span class="line">    subgroup_size = <span class="built_in">len</span>(X_subgroup)</span><br><span class="line"></span><br><span class="line">    y_subgroup_preds = forest.predict_proba(X_subgroup)[:, <span class="number">1</span>]</span><br><span class="line">    performance = cindex(y_subgroup.values, y_subgroup_preds)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> performance, subgroup_size</span><br></pre></td></tr></table></figure>
<h4 id="test-your-work">Test Your Work</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">performance, subgroup_size = bad_subset(best_rf, X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Subgroup size should greater than 250, performance should be less than 0.69 &quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Subgroup size: <span class="subst">&#123;subgroup_size&#125;</span>, C-Index: <span class="subst">&#123;performance&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Subgroup size should greater than 250, performance should be less than 0.69 
Subgroup size: 320, C-Index: 0.670638197475522</code></pre>
<h4 id="expected-output">Expected Output</h4>
<p>Note, your actual output will vary depending on the hyper-parameters that you chose and the mask that you chose. - Make sure that the c-index is less than 0.69 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Subgroup size: <span class="number">586</span>, C-Index: <span class="number">0.6275</span></span><br></pre></td></tr></table></figure></p>
<p><strong>Bonus</strong>: - See if you can get a c-index as low as 0.53 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Subgroup size: 251, C-Index: 0.5331</span><br></pre></td></tr></table></figure></p>
<p><a name='9'></a> ## 9. Imputation Approaches</p>
<p>Seeing that our data is not missing completely at random, we can handle the missing values by replacing them with substituted values based on the other values that we have. This is known as imputation.</p>
<p>The first imputation strategy that we will use is <strong>mean substitution</strong>: we will replace the missing values for each feature with the mean of the available values. In the next cell, use the <code>SimpleImputer</code> from <code>sklearn</code> to use mean imputation for the missing values.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Impute values using the mean</span></span><br><span class="line">imputer = SimpleImputer(strategy=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">imputer.fit(X_train)</span><br><span class="line">X_train_mean_imputed = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)</span><br><span class="line">X_val_mean_imputed = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns)</span><br></pre></td></tr></table></figure>
<p><a name='Ex-5'></a> ### Exercise 5 Now perform a hyperparameter grid search to find the best-performing random forest model, and report results on the test set.</p>
<p>Define the parameter ranges for the hyperparameter search in the next cell, and run the cell.</p>
<h4 id="target-performance">Target performance</h4>
<p>Make your test c-index at least 0.74 or higher</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
n_estimators: try values greater than 100
</li>
<li>
max_depth: try values in the range 1 to 100
</li>
<li>
min_samples_leaf: try float values below .5 and/or int values greater than 2
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define ranges for the random forest hyperparameter search </span></span><br><span class="line">hyperparams = &#123;</span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE array values with your code) ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># how many trees should be in the forest (int)</span></span><br><span class="line">    <span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">200</span>,<span class="number">500</span>],</span><br><span class="line"></span><br><span class="line">    <span class="comment"># the maximum depth of trees in the forest (int)</span></span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">3</span>,<span class="number">5</span>],</span><br><span class="line"></span><br><span class="line">    <span class="comment"># the minimum number of samples in a leaf as a fraction</span></span><br><span class="line">    <span class="comment"># of the total number of samples in the training set</span></span><br><span class="line">    <span class="comment"># Can be int (in which case that is the minimum number)</span></span><br><span class="line">    <span class="comment"># or float (in which case the minimum is that fraction of the</span></span><br><span class="line">    <span class="comment"># number of training set samples)</span></span><br><span class="line">    <span class="string">&#x27;min_samples_leaf&#x27;</span>: [<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line">rf = RandomForestClassifier</span><br><span class="line"></span><br><span class="line">rf_mean_imputed, best_hyperparams_mean_imputed = holdout_grid_search(rf, X_train_mean_imputed, y_train,</span><br><span class="line">                                                                     X_val_mean_imputed, y_val,</span><br><span class="line">                                                                     hyperparams, &#123;<span class="string">&#x27;random_state&#x27;</span>: <span class="number">10</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Performance for best hyperparameters:&quot;</span>)</span><br><span class="line"></span><br><span class="line">y_train_best = rf_mean_imputed.predict_proba(X_train_mean_imputed)[:, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;- Train C-Index: <span class="subst">&#123;cindex(y_train, y_train_best):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">y_val_best = rf_mean_imputed.predict_proba(X_val_mean_imputed)[:, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;- Val C-Index: <span class="subst">&#123;cindex(y_val, y_val_best):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">y_test_imp = rf_mean_imputed.predict_proba(X_test)[:, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;- Test C-Index: <span class="subst">&#123;cindex(y_test, y_test_imp):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[1/8] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.7395345453913784

[2/8] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.7397907669057344

[3/8] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.7491450235484942

[4/8] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.7481646505507676

[5/8] &#123;&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.740106701061148

[6/8] &#123;&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.7403585798379725

[7/8] &#123;&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.7496932941618408

[8/8] &#123;&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.7494088448535303

Performance for best hyperparameters:
- Train C-Index: 0.8137
- Val C-Index: 0.7497
- Test C-Index: 0.7819</code></pre>
<h4 id="expected-output-1">Expected output</h4>
<p>Note, your actual c-index values will vary depending on the hyper-parameters that you choose.<br />
- Try to get a good Test c-index, similar these numbers below:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Performance <span class="keyword">for</span> best hyperparameters:</span><br><span class="line">- Train C-Index: <span class="number">0.8109</span></span><br><span class="line">- Val C-Index: <span class="number">0.7495</span></span><br><span class="line">- Test C-Index: <span class="number">0.7805</span></span><br></pre></td></tr></table></figure>
<p>Next, we will apply another imputation strategy, known as <strong>multivariate feature imputation</strong>, using scikit-learn's <code>IterativeImputer</code> class (see the <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/impute.html#iterative-imputer">documentation</a>).</p>
<p>With this strategy, for each feature that is missing values, a regression model is trained to predict observed values based on all of the other features, and the missing values are inferred using this model. As a single iteration across all features may not be enough to impute all missing values, several iterations may be performed, hence the name of the class <code>IterativeImputer</code>.</p>
<p>In the next cell, use <code>IterativeImputer</code> to perform multivariate feature imputation.</p>
<blockquote>
<p>Note that the first time the cell is run, <code>imputer.fit(X_train)</code> may fail with the message <code>LinAlgError: SVD did not converge</code>: simply re-run the cell.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Impute using regression on other covariates</span></span><br><span class="line">imputer = IterativeImputer(random_state=<span class="number">0</span>, sample_posterior=<span class="literal">False</span>, max_iter=<span class="number">1</span>, min_value=<span class="number">0</span>)</span><br><span class="line">imputer.fit(X_train)</span><br><span class="line">X_train_imputed = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)</span><br><span class="line">X_val_imputed = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns)</span><br></pre></td></tr></table></figure>
<p><a name='Ex-6'></a> ### Exercise 6</p>
<p>Perform a hyperparameter grid search to find the best-performing random forest model, and report results on the test set. Define the parameter ranges for the hyperparameter search in the next cell, and run the cell.</p>
<h4 id="target-performance-1">Target performance</h4>
<p>Try to get a text c-index of at least 0.74 or higher.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
n_estimators: try values greater than 100
</li>
<li>
max_depth: try values in the range 1 to 100
</li>
<li>
min_samples_leaf: try float values below .5 and/or int values greater than 2
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define ranges for the random forest hyperparameter search </span></span><br><span class="line">hyperparams = &#123;</span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE array values with your code) ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># how many trees should be in the forest (int)</span></span><br><span class="line">    <span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">200</span>,<span class="number">500</span>],</span><br><span class="line"></span><br><span class="line">    <span class="comment"># the maximum depth of trees in the forest (int)</span></span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>],</span><br><span class="line"></span><br><span class="line">    <span class="comment"># the minimum number of samples in a leaf as a fraction</span></span><br><span class="line">    <span class="comment"># of the total number of samples in the training set</span></span><br><span class="line">    <span class="comment"># Can be int (in which case that is the minimum number)</span></span><br><span class="line">    <span class="comment"># or float (in which case the minimum is that fraction of the</span></span><br><span class="line">    <span class="comment"># number of training set samples)</span></span><br><span class="line">    <span class="string">&#x27;min_samples_leaf&#x27;</span>: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line">rf = RandomForestClassifier</span><br><span class="line"></span><br><span class="line">rf_imputed, best_hyperparams_imputed = holdout_grid_search(rf, X_train_imputed, y_train,</span><br><span class="line">                                                           X_val_imputed, y_val,</span><br><span class="line">                                                           hyperparams, &#123;<span class="string">&#x27;random_state&#x27;</span>: <span class="number">10</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Performance for best hyperparameters:&quot;</span>)</span><br><span class="line"></span><br><span class="line">y_train_best = rf_imputed.predict_proba(X_train_imputed)[:, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;- Train C-Index: <span class="subst">&#123;cindex(y_train, y_train_best):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">y_val_best = rf_imputed.predict_proba(X_val_imputed)[:, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;- Val C-Index: <span class="subst">&#123;cindex(y_val, y_val_best):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">y_test_imp = rf_imputed.predict_proba(X_test)[:, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;- Test C-Index: <span class="subst">&#123;cindex(y_test, y_test_imp):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[1/18] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.7354751714838482

[2/18] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.7357596207921587

[3/18] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.7356792801478268

[4/18] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.745511237919047

[5/18] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.7446752609442414

[6/18] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.7453787844243376

[7/18] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 7, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.7486206379915707

[8/18] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 7, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.7506139545185099

[9/18] &#123;&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 7, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.749875689138162

[10/18] &#123;&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.73679102095588

[11/18] &#123;&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.737142782695928

[12/18] &#123;&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.737118897639505

[13/18] &#123;&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.7460540801104792

[14/18] &#123;&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.7457783162772317

[15/18] &#123;&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 5, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.746544809451534

[16/18] &#123;&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 7, &#39;min_samples_leaf&#39;: 1&#125;
Val C-Index: 0.7486162952540393

[17/18] &#123;&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 7, &#39;min_samples_leaf&#39;: 2&#125;
Val C-Index: 0.7508050349698939

[18/18] &#123;&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 7, &#39;min_samples_leaf&#39;: 3&#125;
Val C-Index: 0.7501840235028955

Performance for best hyperparameters:
- Train C-Index: 0.8774
- Val C-Index: 0.7508
- Test C-Index: 0.7834</code></pre>
<h4 id="expected-output-2">Expected Output</h4>
<p>Note, your actual output will vary depending on the hyper-parameters that you chose and the mask that you chose. <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Performance <span class="keyword">for</span> best hyperparameters:</span><br><span class="line">- Train C-Index: <span class="number">0.8131</span></span><br><span class="line">- Val C-Index: <span class="number">0.7454</span></span><br><span class="line">- Test C-Index: <span class="number">0.7797</span></span><br></pre></td></tr></table></figure></p>
<p><a name='10'></a> ## 10. Comparison</p>
<p>For good measure, retest on the subgroup from before to see if your new models do better.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">performance, subgroup_size = bad_subset(best_rf, X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;C-Index (no imputation): <span class="subst">&#123;performance&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">performance, subgroup_size = bad_subset(rf_mean_imputed, X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;C-Index (mean imputation): <span class="subst">&#123;performance&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">performance, subgroup_size = bad_subset(rf_imputed, X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;C-Index (multivariate feature imputation): <span class="subst">&#123;performance&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>C-Index (no imputation): 0.670638197475522
C-Index (mean imputation): 0.6847548267862058
C-Index (multivariate feature imputation): 0.6926978884039164</code></pre>
<p>We should see that avoiding complete case analysis (i.e. analysis only on observations for which there is no missing data) allows our model to generalize a bit better. Remember to examine your missing cases to judge whether they are missing at random or not!</p>
<p><a name='11'></a> ## 11. Explanations: SHAP</p>
<p>Using a random forest has improved results, but we've lost some of the natural interpretability of trees. In this section we'll try to explain the predictions using slightly more sophisticated techniques.</p>
<p>You choose to apply <strong>SHAP (SHapley Additive exPlanations) </strong>, a cutting edge method that explains predictions made by black-box machine learning models (i.e. models which are too complex to be understandable by humans as is).</p>
<blockquote>
<p>Given a prediction made by a machine learning model, SHAP values explain the prediction by quantifying the additive importance of each feature to the prediction. SHAP values have their roots in cooperative game theory, where Shapley values are used to quantify the contribution of each player to the game.</p>
<p>Although it is computationally expensive to compute SHAP values for general black-box models, in the case of trees and forests there exists a fast polynomial-time algorithm. For more details, see the <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1802.03888.pdf">TreeShap paper</a>.</p>
</blockquote>
<p>We'll use the <a target="_blank" rel="noopener" href="https://github.com/slundberg/shap">shap library</a> to do this for our random forest model. Run the next cell to output the most at risk individuals in the test set according to our model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_test_risk = X_test.copy(deep=<span class="literal">True</span>)</span><br><span class="line">X_test_risk.loc[:, <span class="string">&#x27;risk&#x27;</span>] = rf_imputed.predict_proba(X_test_risk)[:, <span class="number">1</span>]</span><br><span class="line">X_test_risk = X_test_risk.sort_values(by=<span class="string">&#x27;risk&#x27;</span>, ascending=<span class="literal">False</span>)</span><br><span class="line">X_test_risk.head()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Age
</th>
<th>
Diastolic BP
</th>
<th>
Poverty index
</th>
<th>
Race
</th>
<th>
Red blood cells
</th>
<th>
Sedimentation rate
</th>
<th>
Serum Albumin
</th>
<th>
Serum Cholesterol
</th>
<th>
Serum Iron
</th>
<th>
Serum Magnesium
</th>
<th>
Serum Protein
</th>
<th>
Sex
</th>
<th>
Systolic BP
</th>
<th>
TIBC
</th>
<th>
TS
</th>
<th>
White blood cells
</th>
<th>
BMI
</th>
<th>
Pulse pressure
</th>
<th>
risk
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
5493
</th>
<td>
67.0
</td>
<td>
80.0
</td>
<td>
30.0
</td>
<td>
1.0
</td>
<td>
77.7
</td>
<td>
59.0
</td>
<td>
3.4
</td>
<td>
231.0
</td>
<td>
36.0
</td>
<td>
1.40
</td>
<td>
6.3
</td>
<td>
1.0
</td>
<td>
170.0
</td>
<td>
202.0
</td>
<td>
17.8
</td>
<td>
8.4
</td>
<td>
17.029470
</td>
<td>
90.0
</td>
<td>
0.689064
</td>
</tr>
<tr>
<th>
6337
</th>
<td>
69.0
</td>
<td>
80.0
</td>
<td>
233.0
</td>
<td>
1.0
</td>
<td>
77.7
</td>
<td>
48.0
</td>
<td>
4.2
</td>
<td>
159.0
</td>
<td>
87.0
</td>
<td>
1.81
</td>
<td>
6.9
</td>
<td>
1.0
</td>
<td>
146.0
</td>
<td>
291.0
</td>
<td>
29.9
</td>
<td>
15.2
</td>
<td>
17.931276
</td>
<td>
66.0
</td>
<td>
0.639300
</td>
</tr>
<tr>
<th>
2044
</th>
<td>
74.0
</td>
<td>
80.0
</td>
<td>
83.0
</td>
<td>
1.0
</td>
<td>
47.6
</td>
<td>
19.0
</td>
<td>
4.2
</td>
<td>
205.0
</td>
<td>
72.0
</td>
<td>
1.71
</td>
<td>
6.9
</td>
<td>
1.0
</td>
<td>
180.0
</td>
<td>
310.0
</td>
<td>
23.2
</td>
<td>
10.8
</td>
<td>
20.900101
</td>
<td>
100.0
</td>
<td>
0.582532
</td>
</tr>
<tr>
<th>
1017
</th>
<td>
65.0
</td>
<td>
98.0
</td>
<td>
16.0
</td>
<td>
1.0
</td>
<td>
49.4
</td>
<td>
30.0
</td>
<td>
3.4
</td>
<td>
124.0
</td>
<td>
129.0
</td>
<td>
1.59
</td>
<td>
7.7
</td>
<td>
1.0
</td>
<td>
184.0
</td>
<td>
293.0
</td>
<td>
44.0
</td>
<td>
5.9
</td>
<td>
30.858853
</td>
<td>
86.0
</td>
<td>
0.573548
</td>
</tr>
<tr>
<th>
6609
</th>
<td>
72.0
</td>
<td>
90.0
</td>
<td>
75.0
</td>
<td>
1.0
</td>
<td>
29.3
</td>
<td>
59.0
</td>
<td>
3.9
</td>
<td>
216.0
</td>
<td>
64.0
</td>
<td>
1.63
</td>
<td>
7.4
</td>
<td>
2.0
</td>
<td>
182.0
</td>
<td>
322.0
</td>
<td>
19.9
</td>
<td>
9.3
</td>
<td>
22.281793
</td>
<td>
92.0
</td>
<td>
0.565259
</td>
</tr>
</tbody>
</table>
</div>
<p>We can use SHAP values to try and understand the model output on specific individuals using force plots. Run the cell below to see a force plot on the riskiest individual.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">explainer = shap.TreeExplainer(rf_imputed)</span><br><span class="line">i = <span class="number">0</span></span><br><span class="line">shap_value = explainer.shap_values(X_test.loc[X_test_risk.index[i], :])[<span class="number">1</span>]</span><br><span class="line">shap.force_plot(explainer.expected_value[<span class="number">1</span>], shap_value, feature_names=X_test.columns, matplotlib=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_83_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>How to read this chart: - The red sections on the left are features which push the model towards the final prediction in the positive direction (i.e. a higher Age increases the predicted risk). - The blue sections on the right are features that push the model towards the final prediction in the negative direction (if an increase in a feature leads to a lower risk, it will be shown in blue). - Note that the exact output of your chart will differ depending on the hyper-parameters that you choose for your model.</p>
<p>We can also use SHAP values to understand the model output in aggregate. Run the next cell to initialize the SHAP values (this may take a few minutes).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shap_values = shap.TreeExplainer(rf_imputed).shap_values(X_test)[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>Run the next cell to see a summary plot of the SHAP values for each feature on each of the test examples. The colors indicate the value of the feature.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shap.summary_plot(shap_values, X_test)</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_87_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>Clearly we see that being a woman (<code>sex = 2.0</code>, as opposed to men for which <code>sex = 1.0</code>) has a negative SHAP value, meaning that it reduces the risk of dying within 10 years. High age and high systolic blood pressure have positive SHAP values, and are therefore related to increased mortality.</p>
<p>You can see how features interact using dependence plots. These plot the SHAP value for a given feature for each data point, and color the points in using the value for another feature. This lets us begin to explain the variation in SHAP value for a single value of the main feature.</p>
<p>Run the next cell to see the interaction between Age and Sex.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shap.dependence_plot(<span class="string">&#x27;Age&#x27;</span>, shap_values, X_test, interaction_index=<span class="string">&#x27;Sex&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_89_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>We see that while Age &gt; 50 is generally bad (positive SHAP value), being a woman generally reduces the impact of age. This makes sense since we know that women generally live longer than men.</p>
<p>Let's now look at poverty index and age.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shap.dependence_plot(<span class="string">&#x27;Poverty index&#x27;</span>, shap_values, X_test, interaction_index=<span class="string">&#x27;Age&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_91_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>We see that the impact of poverty index drops off quickly, and for higher income individuals age begins to explain much of variation in the impact of poverty index.</p>
<p>Try some other pairs and see what other interesting relationships you can find!</p>
<h1 id="congratulations">Congratulations!</h1>
<p>You have completed the second assignment in Course 2. Along the way you've learned to fit decision trees, random forests, and deal with missing data. Now you're ready to move on to week 3!</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/" class="post-title-link" itemprop="url">Build and Evaluate a Linear Risk model</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-18 23:50:08" itemprop="dateCreated datePublished" datetime="2020-04-18T23:50:08+08:00">2020-04-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-19 23:09:57" itemprop="dateModified" datetime="2020-04-19T23:09:57+08:00">2020-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="build-and-evaluate-a-linear-risk-model">Build and Evaluate a Linear Risk model</h1>
<p>Welcome to the first assignment in Course 2!</p>
<h2 id="outline">Outline</h2>
<ul>
<li><a href="#1">1. Import Packages</a></li>
<li><a href="#2">2. Load Data</a></li>
<li><a href="#3">3. Explore the Dataset</a></li>
<li><a href="#4">4. Mean-Normalize the Data</a>
<ul>
<li><a href="#Ex-1">Exercise 1</a></li>
</ul></li>
<li><a href="#Ex-2">5. Build the Model</a>
<ul>
<li><a href="#Ex-2">Exercise 2</a></li>
</ul></li>
<li><a href="#6">6. Evaluate the Model Using the C-Index</a>
<ul>
<li><a href="#Ex-3">Exercise 3</a></li>
</ul></li>
<li><a href="#7">7. Evaluate the Model on the Test Set</a></li>
<li><a href="#8">8. Improve the Model</a>
<ul>
<li><a href="#Ex-4">Exercise 4</a></li>
</ul></li>
<li><a href="#9">9. Evalute the Improved Model</a></li>
</ul>
<h2 id="overview-of-the-assignment">Overview of the Assignment</h2>
<p>In this assignment, you'll build a risk score model for retinopathy in diabetes patients using logistic regression.</p>
<p>As we develop the model, we will learn about the following topics:</p>
<ul>
<li>Data preprocessing
<ul>
<li>Log transformations</li>
<li>Standardization</li>
</ul></li>
<li>Basic Risk Models
<ul>
<li>Logistic Regression</li>
<li>C-index</li>
<li>Interactions Terms</li>
</ul></li>
</ul>
<h3 id="diabetic-retinopathy">Diabetic Retinopathy</h3>
<p>Retinopathy is an eye condition that causes changes to the blood vessels in the part of the eye called the retina. This often leads to vision changes or blindness. Diabetic patients are known to be at high risk for retinopathy.</p>
<h3 id="logistic-regression">Logistic Regression</h3>
<p>Logistic regression is an appropriate analysis to use for predicting the probability of a binary outcome. In our case, this would be the probability of having or not having diabetic retinopathy. Logistic Regression is one of the most commonly used algorithms for binary classification. It is used to find the best fitting model to describe the relationship between a set of features (also referred to as input, independent, predictor, or explanatory variables) and a binary outcome label (also referred to as an output, dependent, or response variable). Logistic regression has the property that the output prediction is always in the range <span class="math inline">\([0,1]\)</span>. Sometimes this output is used to represent a probability from 0%-100%, but for straight binary classification, the output is converted to either <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span> depending on whether it is below or above a certain threshold, usually <span class="math inline">\(0.5\)</span>.</p>
<p>It may be confusing that the term regression appears in the name even though logistic regression is actually a classification algorithm, but that's just a name it was given for historical reasons.</p>
<p><a name='1'></a> ## 1. Import Packages</p>
<p>We'll first import all the packages that we need for this assignment.</p>
<ul>
<li><code>numpy</code> is the fundamental package for scientific computing in python.</li>
<li><code>pandas</code> is what we'll use to manipulate our data.</li>
<li><code>matplotlib</code> is a plotting library.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<p><a name='2'></a> ## 2. Load Data</p>
<p>First we will load in the dataset that we will use for training and testing our model.</p>
<ul>
<li>Run the next cell to load the data using a function imported from our local utils module.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> load_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># This function creates randomly generated data</span></span><br><span class="line"><span class="comment"># X, y = load_data(6000)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># For stability, load data from files that were generated using the load_data</span></span><br><span class="line">X = pd.read_csv(<span class="string">&#x27;X_data.csv&#x27;</span>,index_col=<span class="number">0</span>)</span><br><span class="line">y_df = pd.read_csv(<span class="string">&#x27;y_data.csv&#x27;</span>,index_col=<span class="number">0</span>)</span><br><span class="line">y = y_df[<span class="string">&#x27;y&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p><code>X</code> and <code>y</code> are Pandas DataFrames that hold the data for 6,000 diabetic patients.</p>
<p><a name='3'></a> ## 3. Explore the Dataset</p>
<p>The features (<code>X</code>) include the following fields: * Age: (years) * Systolic_BP: Systolic blood pressure (mmHg) * Diastolic_BP: Diastolic blood pressure (mmHg) * Cholesterol: (mg/DL)</p>
<p>We can use the <code>head()</code> method to display the first few records of each.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.head()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Age
</th>
<th>
Systolic_BP
</th>
<th>
Diastolic_BP
</th>
<th>
Cholesterol
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
77.196340
</td>
<td>
85.288742
</td>
<td>
80.021878
</td>
<td>
79.957109
</td>
</tr>
<tr>
<th>
1
</th>
<td>
63.529850
</td>
<td>
99.379736
</td>
<td>
84.852361
</td>
<td>
110.382411
</td>
</tr>
<tr>
<th>
2
</th>
<td>
69.003986
</td>
<td>
111.349455
</td>
<td>
109.850616
</td>
<td>
100.828246
</td>
</tr>
<tr>
<th>
3
</th>
<td>
82.638210
</td>
<td>
95.056128
</td>
<td>
79.666851
</td>
<td>
87.066303
</td>
</tr>
<tr>
<th>
4
</th>
<td>
78.346286
</td>
<td>
109.154591
</td>
<td>
90.713220
</td>
<td>
92.511770
</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.shape</span><br></pre></td></tr></table></figure>
<pre><code>(6000, 4)</code></pre>
<p>The target (<code>y</code>) is an indicator of whether or not the patient developed retinopathy.</p>
<ul>
<li>y = 1 : patient has retinopathy.</li>
<li>y = 0 : patient does not have retinopathy.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y.head()</span><br></pre></td></tr></table></figure>
<pre><code>0    1.0
1    1.0
2    1.0
3    1.0
4    1.0
Name: y, dtype: float64</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y.shape</span><br></pre></td></tr></table></figure>
<pre><code>(6000,)</code></pre>
<p>Before we build a model, let's take a closer look at the distribution of our training data. To do this, we will split the data into train and test sets using a 75/25 split.</p>
<p>For this, we can use the built in function provided by sklearn library. See the documentation for <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">sklearn.model_selection.train_test_split</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=<span class="number">0.75</span>, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>Plot the histograms of each column of <code>X_train</code> below:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> X.columns:</span><br><span class="line">    X_train_raw.loc[:, col].hist()</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_18_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_18_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_18_2.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_18_3.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>As we can see, the distributions have a generally bell shaped distribution, but with slight rightward skew.</p>
<p>Many statistical models assume that the data is normally distributed, forming a symmetric Gaussian bell shape (with no skew) more like the example below.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line">data = np.random.normal(<span class="number">50</span>,<span class="number">12</span>, <span class="number">5000</span>)</span><br><span class="line">fitting_params = norm.fit(data)</span><br><span class="line">norm_dist_fitted = norm(*fitting_params)</span><br><span class="line">t = np.linspace(<span class="number">0</span>,<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">plt.hist(data, bins=<span class="number">60</span>, density=<span class="literal">True</span>)</span><br><span class="line">plt.plot(t, norm_dist_fitted.pdf(t))</span><br><span class="line">plt.title(<span class="string">&#x27;Example of Normally Distributed Data&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_20_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>We can transform our data to be closer to a normal distribution by removing the skew. One way to remove the skew is by applying the log function to the data.</p>
<p>Let's plot the log of the feature variables to see that it produces the desired effect.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> X_train_raw.columns:</span><br><span class="line">    np.log(X_train_raw.loc[:, col]).hist()</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_22_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_22_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_22_2.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_22_3.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>We can see that the data is more symmetric after taking the log.</p>
<p><a name='4'></a> ## 4. Mean-Normalize the Data</p>
<p>Let's now transform our data so that the distributions are closer to standard normal distributions.</p>
<p>First we will remove some of the skew from the distribution by using the log transformation. Then we will "standardize" the distribution so that it has a mean of zero and standard deviation of 1. Recall that a standard normal distribution has mean of zero and standard deviation of 1.</p>
<p><a name='Ex-1'></a> ### Exercise 1 * Write a function that first removes some of the skew in the data, and then standardizes the distribution so that for each data point <span class="math inline">\(x\)</span>, <span class="math display">\[\overline{x} = \frac{x - mean(x)}{std(x)}\]</span> * Keep in mind that we want to pretend that the test data is "unseen" data. * This implies that it is unavailable to us for the purpose of preparing our data, and so we do not want to consider it when evaluating the mean and standard deviation that we use in the above equation. Instead we want to calculate these values using the training data alone, but then use them for standardizing both the training and the test data. * For a further discussion on the topic, see this article <a target="_blank" rel="noopener" href="https://sebastianraschka.com/faq/docs/scale-training-test.html">"Why do we need to re-use training parameters to transform test data"</a>.</p>
<h4 id="note">Note</h4>
<ul>
<li>For the sample standard deviation, please calculate the unbiased estimator: <span class="math display">\[s = \sqrt{\frac{\sum_{i=1}^n(x_{i} - \bar{x})^2}{n-1}}\]</span></li>
<li>In other words, if you numpy, set the degrees of freedom <code>ddof</code> to 1.</li>
<li>For pandas, the default <code>ddof</code> is already set to 1.</li>
</ul>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
When working with Pandas DataFrames, you can use the aggregation functions <code>mean</code> and <code>std</code> functions. Note that in order to apply an aggregation function separately for each row or each column, you'll set the axis parameter to either <code>0</code> or <code>1</code>. One produces the aggregation along columns and the other along rows, but it is easy to get them confused. So experiment with each option below to see which one you should use to get an average for each column in the dataframe. <code> avg = df.mean(axis=0) avg = df.mean(axis=1) </code>
</li>
<br></br>
<li>
Remember to use <b>training</b> data statistics when standardizing both the training and the test data.
</li>
</ul>
</p>
</details>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_standard_normal</span>(<span class="params">df_train, df_test</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    In order to make the data closer to a normal distribution, take log</span></span><br><span class="line"><span class="string">    transforms to reduce the skew.</span></span><br><span class="line"><span class="string">    Then standardize the distribution with a mean of zero and standard deviation of 1. </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      df_train (dataframe): unnormalized training data.</span></span><br><span class="line"><span class="string">      df_test (dataframe): unnormalized test data.</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      df_train_normalized (dateframe): normalized training data.</span></span><br><span class="line"><span class="string">      df_test_normalized (dataframe): normalized test data.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###  </span></span><br><span class="line">    <span class="comment"># Remove skew by applying the log function to the train set, and to the test set</span></span><br><span class="line">    df_train_unskewed = np.log(df_train)</span><br><span class="line">    df_test_unskewed = np.log(df_test)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#calculate the mean and standard deviation of the training set</span></span><br><span class="line">    mean = df_train_unskewed.mean(axis = <span class="number">0</span>)</span><br><span class="line">    stdev = df_train_unskewed.std(axis = <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># standardize the training set</span></span><br><span class="line">    df_train_standardized = (df_train_unskewed - mean)/ stdev</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># standardize the test set (see instructions and hints above)</span></span><br><span class="line">    df_test_standardized = (df_test_unskewed - mean) / stdev</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> df_train_standardized, df_test_standardized</span><br></pre></td></tr></table></figure>
<h4 id="test-your-work">Test Your Work</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test</span></span><br><span class="line">tmp_train = pd.DataFrame(&#123;<span class="string">&#x27;field1&#x27;</span>: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">10</span>], <span class="string">&#x27;field2&#x27;</span>: [<span class="number">4</span>,<span class="number">5</span>,<span class="number">11</span>]&#125;)</span><br><span class="line">tmp_test = pd.DataFrame(&#123;<span class="string">&#x27;field1&#x27;</span>: [<span class="number">1</span>,<span class="number">3</span>,<span class="number">10</span>], <span class="string">&#x27;field2&#x27;</span>: [<span class="number">4</span>,<span class="number">6</span>,<span class="number">11</span>]&#125;)</span><br><span class="line">tmp_train_transformed, tmp_test_transformed = make_standard_normal(tmp_train,tmp_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Training set transformed field1 has mean <span class="subst">&#123;tmp_train_transformed[<span class="string">&#x27;field1&#x27;</span>].mean(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span> and standard deviation <span class="subst">&#123;tmp_train_transformed[<span class="string">&#x27;field1&#x27;</span>].std(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span> &quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Test set transformed, field1 has mean <span class="subst">&#123;tmp_test_transformed[<span class="string">&#x27;field1&#x27;</span>].mean(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span> and standard deviation <span class="subst">&#123;tmp_test_transformed[<span class="string">&#x27;field1&#x27;</span>].std(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Skew of training set field1 before transformation: <span class="subst">&#123;tmp_train[<span class="string">&#x27;field1&#x27;</span>].skew(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Skew of training set field1 after transformation: <span class="subst">&#123;tmp_train_transformed[<span class="string">&#x27;field1&#x27;</span>].skew(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Skew of test set field1 before transformation: <span class="subst">&#123;tmp_test[<span class="string">&#x27;field1&#x27;</span>].skew(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Skew of test set field1 after transformation: <span class="subst">&#123;tmp_test_transformed[<span class="string">&#x27;field1&#x27;</span>].skew(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Training set transformed field1 has mean -0.0000 and standard deviation 1.0000 
Test set transformed, field1 has mean 0.1144 and standard deviation 0.9749
Skew of training set field1 before transformation: 1.6523
Skew of training set field1 after transformation: 1.0857
Skew of test set field1 before transformation: 1.3896
Skew of test set field1 after transformation: 0.1371</code></pre>
<h4 id="expected-output">Expected Output:</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Training set transformed field1 has mean <span class="number">-0.0000</span> <span class="keyword">and</span> standard deviation <span class="number">1.0000</span> </span><br><span class="line">Test set transformed, field1 has mean <span class="number">0.1144</span> <span class="keyword">and</span> standard deviation <span class="number">0.9749</span></span><br><span class="line">Skew of training set field1 before transformation: <span class="number">1.6523</span></span><br><span class="line">Skew of training set field1 after transformation: <span class="number">1.0857</span></span><br><span class="line">Skew of test set field1 before transformation: <span class="number">1.3896</span></span><br><span class="line">Skew of test set field1 after transformation: <span class="number">0.1371</span></span><br></pre></td></tr></table></figure>
<h4 id="transform-training-and-test-data">Transform training and test data</h4>
<p>Use the function that you just implemented to make the data distribution closer to a standard normal distribution.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test = make_standard_normal(X_train_raw, X_test_raw)</span><br></pre></td></tr></table></figure>
<p>After transforming the training and test sets, we'll expect the training set to be centered at zero with a standard deviation of <span class="math inline">\(1\)</span>.</p>
<p>We will avoid observing the test set during model training in order to avoid biasing the model training process, but let's have a look at the distributions of the transformed training data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> X_train.columns:</span><br><span class="line">    X_train[col].hist()</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_35_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_35_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_35_2.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_35_3.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p><a name='5'></a> ## 5. Build the Model</p>
<p>Now we are ready to build the risk model by training logistic regression with our data.</p>
<p><a name='Ex-2'></a> ### Exercise 2</p>
<ul>
<li>Implement the <code>lr_model</code> function to build a model using logistic regression with the <code>LogisticRegression</code> class from <code>sklearn</code>.</li>
<li>See the documentation for <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit">sklearn.linear_model.LogisticRegression</a>.</li>
</ul>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
You can leave all the parameters to their default values when constructing an instance of the <code>sklearn.linear_model.LogisticRegression</code> class. If you get a warning message regarding the <code>solver</code> parameter, however, you may want to specify that particular one explicitly with <code>solver='lbfgs'</code>.
</li>
<br></br>
</ul>
</p>
</details>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lr_model</span>(<span class="params">X_train, y_train</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    <span class="comment"># import the LogisticRegression class</span></span><br><span class="line">    <span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># create the model object</span></span><br><span class="line">    model = LogisticRegression(solver=<span class="string">&#x27;lbfgs&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># fit the model to the training data</span></span><br><span class="line">    model.fit(X_train, y_train)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="comment">#return the fitted model</span></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h4 id="test-your-work-1">Test Your Work</h4>
<p>Note: the <code>predict</code> method returns the model prediction <em>after</em> converting it from a value in the <span class="math inline">\([0,1]\)</span> range to a <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span> depending on whether it is below or above <span class="math inline">\(0.5\)</span>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test</span></span><br><span class="line">tmp_model = lr_model(X_train[<span class="number">0</span>:<span class="number">3</span>], y_train[<span class="number">0</span>:<span class="number">3</span>] )</span><br><span class="line"><span class="built_in">print</span>(tmp_model.predict(X_train[<span class="number">4</span>:<span class="number">5</span>]))</span><br><span class="line"><span class="built_in">print</span>(tmp_model.predict(X_train[<span class="number">5</span>:<span class="number">6</span>]))</span><br></pre></td></tr></table></figure>
<pre><code>[1.]
[1.]</code></pre>
<h4 id="expected-output-1">Expected Output:</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1.</span>]</span><br><span class="line">[<span class="number">0.</span>]</span><br></pre></td></tr></table></figure>
<p>Now that we've tested our model, we can go ahead and build it. Note that the <code>lr_model</code> function also fits the model to the training data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_X = lr_model(X_train, y_train)</span><br></pre></td></tr></table></figure>
<p><a name='6'></a> ## 6. Evaluate the Model Using the C-index</p>
<p>Now that we have a model, we need to evaluate it. We'll do this using the c-index. * The c-index measures the discriminatory power of a risk score. * Intuitively, a higher c-index indicates that the model's prediction is in agreement with the actual outcomes of a pair of patients. * The formula for the c-index is</p>
<p><span class="math display">\[ \mbox{cindex} = \frac{\mbox{concordant} + 0.5 \times \mbox{ties}}{\mbox{permissible}} \]</span></p>
<ul>
<li>A permissible pair is a pair of patients who have different outcomes.</li>
<li>A concordant pair is a permissible pair in which the patient with the higher risk score also has the worse outcome.</li>
<li>A tie is a permissible pair where the patients have the same risk score.</li>
</ul>
<p><a name='Ex-3'></a> ### Exercise 3</p>
<ul>
<li>Implement the <code>cindex</code> function to compute c-index.</li>
<li><code>y_true</code> is the array of actual patient outcomes, 0 if the patient does not eventually get the disease, and 1 if the patient eventually gets the disease.</li>
<li><code>scores</code> is the risk score of each patient. These provide relative measures of risk, so they can be any real numbers. By convention, they are always non-negative.</li>
<li>Here is an example of input data and how to interpret it: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_true = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">scores = [<span class="number">0.45</span>, <span class="number">1.25</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>There are two patients. Index 0 of each array is associated with patient 0. Index 1 is associated with patient 1.</li>
<li>Patient 0 does not have the disease in the future (<code>y_true</code> is 0), and based on past information, has a risk score of 0.45.</li>
<li>Patient 1 has the disease at some point in the future (<code>y_true</code> is 1), and based on past information, has a risk score of 1.25.</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cindex</span>(<span class="params">y_true, scores</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">    y_true (np.array): a 1-D array of true binary outcomes (values of zero or one)</span></span><br><span class="line"><span class="string">        0: patient does not get the disease</span></span><br><span class="line"><span class="string">        1: patient does get the disease</span></span><br><span class="line"><span class="string">    scores (np.array): a 1-D array of corresponding risk scores output by the model</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">    c_index (float): (concordant pairs + 0.5*ties) / number of permissible pairs</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    n = <span class="built_in">len</span>(y_true)</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(scores) == n</span><br><span class="line"></span><br><span class="line">    concordant = <span class="number">0</span></span><br><span class="line">    permissible = <span class="number">0</span></span><br><span class="line">    ties = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    <span class="comment"># use two nested for loops to go through all unique pairs of patients</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, n): <span class="comment">#choose the range of j so that j&gt;i</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Check if the pair is permissible (the patient outcomes are different)</span></span><br><span class="line">            <span class="keyword">if</span> y_true[i] != y_true[j]:</span><br><span class="line">                <span class="comment"># Count the pair if it&#x27;s permissible</span></span><br><span class="line">                permissible += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># For permissible pairs, check if they are concordant or are ties</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># check for ties in the score</span></span><br><span class="line">                <span class="keyword">if</span> scores[i] == scores[j]:</span><br><span class="line">                    <span class="comment"># count the tie</span></span><br><span class="line">                    ties += <span class="number">1</span></span><br><span class="line">                    <span class="comment"># if it&#x27;s a tie, we don&#x27;t need to check patient outcomes, continue to the top of the for loop.</span></span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># case 1: patient i doesn&#x27;t get the disease, patient j does</span></span><br><span class="line">                <span class="keyword">if</span> y_true[i] == <span class="number">0</span> <span class="keyword">and</span> y_true[j] == <span class="number">1</span>:</span><br><span class="line">                    <span class="comment"># Check if patient i has a lower risk score than patient j</span></span><br><span class="line">                    <span class="keyword">if</span> scores[i] &lt; scores[j]:</span><br><span class="line">                        <span class="comment"># count the concordant pair</span></span><br><span class="line">                        concordant += <span class="number">1</span></span><br><span class="line">                    <span class="comment"># Otherwise if patient i has a higher risk score, it&#x27;s not a concordant pair.</span></span><br><span class="line">                    <span class="comment"># Already checked for ties earlier</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># case 2: patient i gets the disease, patient j does not</span></span><br><span class="line">                <span class="keyword">if</span> y_true[i] == <span class="number">1</span> <span class="keyword">and</span> y_true[j] == <span class="number">0</span>:</span><br><span class="line">                    <span class="comment"># Check if patient i has a higher risk score than patient j</span></span><br><span class="line">                    <span class="keyword">if</span> scores[i] &gt; scores[j]:</span><br><span class="line">                        <span class="comment">#count the concordant pair</span></span><br><span class="line">                        concordant += <span class="number">1</span></span><br><span class="line">                    <span class="comment"># Otherwise if patient i has a lower risk score, it&#x27;s not a concordant pair.</span></span><br><span class="line">                    <span class="comment"># We already checked for ties earlier</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculate the c-index using the count of permissible pairs, concordant pairs, and tied pairs.</span></span><br><span class="line">    c_index = (concordant + <span class="number">0.5</span> * ties) / permissible</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> c_index</span><br></pre></td></tr></table></figure>
<h4 id="test-your-work-2">Test Your Work</h4>
<p>You can use the following test cases to make sure your implementation is correct.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test</span></span><br><span class="line">y_true = np.array([<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Case 1</span></span><br><span class="line">scores = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Case 1 Output: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(cindex(y_true, scores)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Case 2</span></span><br><span class="line">scores = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Case 2 Output: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(cindex(y_true, scores)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Case 3</span></span><br><span class="line">scores = np.array([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.0</span>, <span class="number">1.0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Case 3 Output: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(cindex(y_true, scores)))</span><br><span class="line">cindex(y_true, scores)</span><br></pre></td></tr></table></figure>
<pre><code>Case 1 Output: 0.0
Case 2 Output: 1.0
Case 3 Output: 0.875





0.875</code></pre>
<h4 id="expected-output-2">Expected Output:</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Case <span class="number">1</span> Output: <span class="number">0.0</span></span><br><span class="line">Case <span class="number">2</span> Output: <span class="number">1.0</span></span><br><span class="line">Case <span class="number">3</span> Output: <span class="number">0.875</span></span><br></pre></td></tr></table></figure>
<h4 id="note-1">Note</h4>
<p>Please check your implementation of the for loops. - There is way to make a mistake on the for loops that cannot be caught with unit tests. - Bonus: Can you think of what this error could be, and why it can't be caught by unit tests?</p>
<p><a name='7'></a> ## 7. Evaluate the Model on the Test Set</p>
<p>Now, you can evaluate your trained model on the test set.</p>
<p>To get the predicted probabilities, we use the <code>predict_proba</code> method. This method will return the result from the model <em>before</em> it is converted to a binary 0 or 1. For each input case, it returns an array of two values which represent the probabilities for both the negative case (patient does not get the disease) and positive case (patient the gets the disease).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scores = model_X.predict_proba(X_test)[:, <span class="number">1</span>]</span><br><span class="line">c_index_X_test = cindex(y_test.values, scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;c-index on test set is <span class="subst">&#123;c_index_X_test:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>c-index on test set is 0.8182</code></pre>
<h4 id="expected-output-3">Expected output:</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c-index on test set is <span class="number">0.8336</span></span><br></pre></td></tr></table></figure>
<p>Let's plot the coefficients to see which variables (patient features) are having the most effect. You can access the model coefficients by using <code>model.coef_</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">coeffs = pd.DataFrame(data = model_X.coef_, columns = X_train.columns)</span><br><span class="line">coeffs.T.plot.bar(legend=<span class="literal">None</span>);</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_56_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<h3 id="question">Question:</h3>
<blockquote>
<p><strong>Which three variables have the largest impact on the model's predictions?</strong></p>
</blockquote>
<p><a name='8'></a> ## 8. Improve the Model</p>
<p>You can try to improve your model by including interaction terms. * An interaction term is the product of two variables. * For example, if we have data <span class="math display">\[ x = [x_1, x_2]\]</span> * We could add the product so that: <span class="math display">\[ \hat{x} = [x_1, x_2, x_1*x_2]\]</span></p>
<p><a name='Ex-4'></a> ### Exercise 4</p>
<p>Write code below to add all interactions between every pair of variables to the training and test datasets.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_interactions</span>(<span class="params">X</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Add interaction terms between columns to dataframe.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">    X (dataframe): Original data</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    X_int (dataframe): Original data with interaction terms appended. </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    features = X.columns</span><br><span class="line">    m = <span class="built_in">len</span>(features)</span><br><span class="line">    X_int = X.copy(deep=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    <span class="comment"># &#x27;i&#x27; loops through all features in the original dataframe X</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m-<span class="number">1</span>):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># get the name of feature &#x27;i&#x27;</span></span><br><span class="line">        feature_i_name = features[i]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># get the data for feature &#x27;i&#x27;</span></span><br><span class="line">        feature_i_data = X[feature_i_name]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># choose the index of column &#x27;j&#x27; to be greater than column i</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, m):</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># get the name of feature &#x27;j&#x27;</span></span><br><span class="line">            feature_j_name = features[j]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># get the data for feature j&#x27;</span></span><br><span class="line">            feature_j_data = X[feature_j_name]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># create the name of the interaction feature by combining both names</span></span><br><span class="line">            <span class="comment"># example: &quot;apple&quot; and &quot;orange&quot; are combined to be &quot;apple_x_orange&quot;</span></span><br><span class="line">            feature_i_j_name = feature_i_name + <span class="string">&quot;_x_&quot;</span> + feature_j_name</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Multiply the data for feature &#x27;i&#x27; and feature &#x27;j&#x27;</span></span><br><span class="line">            <span class="comment"># store the result as a column in dataframe X_int</span></span><br><span class="line">            X_int[feature_i_j_name] = feature_i_data * feature_j_data</span><br><span class="line">        </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X_int</span><br></pre></td></tr></table></figure>
<h4 id="test-your-work-3">Test Your Work</h4>
<p>Run the cell below to check your implementation.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original Data&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(X_train.loc[:, [<span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Systolic_BP&#x27;</span>]].head())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Data w/ Interactions&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(add_interactions(X_train.loc[:, [<span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Systolic_BP&#x27;</span>]].head()))</span><br></pre></td></tr></table></figure>
<pre><code>Original Data
           Age  Systolic_BP
1824 -0.912451    -0.068019
253  -0.302039     1.719538
1114  2.576274     0.155962
3220  1.163621    -2.033931
2108 -0.446238    -0.054554
Data w/ Interactions
           Age  Systolic_BP  Age_x_Systolic_BP
1824 -0.912451    -0.068019           0.062064
253  -0.302039     1.719538          -0.519367
1114  2.576274     0.155962           0.401800
3220  1.163621    -2.033931          -2.366725
2108 -0.446238    -0.054554           0.024344</code></pre>
<h4 id="expected-output-4">Expected Output:</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Original Data</span><br><span class="line">           Age  Systolic_BP</span><br><span class="line"><span class="number">2472</span> <span class="number">-2.340711</span>     <span class="number">0.077089</span></span><br><span class="line"><span class="number">4496</span>  <span class="number">0.009916</span>    <span class="number">-1.324053</span></span><br><span class="line"><span class="number">2243</span>  <span class="number">0.927302</span>    <span class="number">-0.424337</span></span><br><span class="line"><span class="number">4311</span> <span class="number">-0.087282</span>     <span class="number">0.399865</span></span><br><span class="line"><span class="number">843</span>   <span class="number">2.204586</span>     <span class="number">0.025521</span></span><br><span class="line">Data w/ Interactions</span><br><span class="line">           Age  Systolic_BP  Age_x_Systolic_BP</span><br><span class="line"><span class="number">2472</span> <span class="number">-2.340711</span>     <span class="number">0.077089</span>          <span class="number">-0.180444</span></span><br><span class="line"><span class="number">4496</span>  <span class="number">0.009916</span>    <span class="number">-1.324053</span>          <span class="number">-0.013129</span></span><br><span class="line"><span class="number">2243</span>  <span class="number">0.927302</span>    <span class="number">-0.424337</span>          <span class="number">-0.393489</span></span><br><span class="line"><span class="number">4311</span> <span class="number">-0.087282</span>     <span class="number">0.399865</span>          <span class="number">-0.034901</span></span><br><span class="line"><span class="number">843</span>   <span class="number">2.204586</span>     <span class="number">0.025521</span>           <span class="number">0.056264</span></span><br></pre></td></tr></table></figure>
<p>Once you have correctly implemented <code>add_interactions</code>, use it to make transformed version of <code>X_train</code> and <code>X_test</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train_int = add_interactions(X_train)</span><br><span class="line">X_test_int = add_interactions(X_test)</span><br></pre></td></tr></table></figure>
<p><a name='9'></a> ## 9. Evaluate the Improved Model</p>
<p>Now we can train the new and improved version of the model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_X_int = lr_model(X_train_int, y_train)</span><br></pre></td></tr></table></figure>
<p>Let's evaluate our new model on the test set.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scores_X = model_X.predict_proba(X_test)[:, <span class="number">1</span>]</span><br><span class="line">c_index_X_int_test = cindex(y_test.values, scores_X)</span><br><span class="line"></span><br><span class="line">scores_X_int = model_X_int.predict_proba(X_test_int)[:, <span class="number">1</span>]</span><br><span class="line">c_index_X_int_test = cindex(y_test.values, scores_X_int)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;c-index on test set without interactions is <span class="subst">&#123;c_index_X_test:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;c-index on test set with interactions is <span class="subst">&#123;c_index_X_int_test:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>c-index on test set without interactions is 0.8182
c-index on test set with interactions is 0.8281</code></pre>
<p>You should see that the model with interaction terms performs a bit better than the model without interactions.</p>
<p>Now let's take another look at the model coefficients to try and see which variables made a difference. Plot the coefficients and report which features seem to be the most important.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int_coeffs = pd.DataFrame(data = model_X_int.coef_, columns = X_train_int.columns)</span><br><span class="line">int_coeffs.T.plot.bar();</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_71_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<h3 id="questions">Questions:</h3>
<blockquote>
<p><strong>Which variables are most important to the model?</strong><br> <strong>Have the relevant variables changed?</strong><br> <strong>What does it mean when the coefficients are positive or negative?</strong><br></p>
</blockquote>
<p>You may notice that Age, Systolic_BP, and Cholesterol have a positive coefficient. This means that a higher value in these three features leads to a higher prediction probability for the disease. You also may notice that the interaction of Age x Cholesterol has a negative coefficient. This means that a higher value for the Age x Cholesterol product reduces the prediction probability for the disease.</p>
<p>To understand the effect of interaction terms, let's compare the output of the model we've trained on sample cases with and without the interaction. Run the cell below to choose an index and look at the features corresponding to that case in the training set.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">index = index = <span class="number">3432</span></span><br><span class="line">case = X_train_int.iloc[index, :]</span><br><span class="line"><span class="built_in">print</span>(case)</span><br></pre></td></tr></table></figure>
<pre><code>Age                           2.502061
Systolic_BP                   1.713547
Diastolic_BP                  0.268265
Cholesterol                   2.146349
Age_x_Systolic_BP             4.287400
Age_x_Diastolic_BP            0.671216
Age_x_Cholesterol             5.370296
Systolic_BP_x_Diastolic_BP    0.459685
Systolic_BP_x_Cholesterol     3.677871
Diastolic_BP_x_Cholesterol    0.575791
Name: 5970, dtype: float64</code></pre>
<p>We can see that they have above average Age and Cholesterol. We can now see what our original model would have output by zero-ing out the value for Cholesterol and Age.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">new_case = case.copy(deep=<span class="literal">True</span>)</span><br><span class="line">new_case.loc[<span class="string">&quot;Age_x_Cholesterol&quot;</span>] = <span class="number">0</span></span><br><span class="line">new_case</span><br></pre></td></tr></table></figure>
<pre><code>Age                           2.502061
Systolic_BP                   1.713547
Diastolic_BP                  0.268265
Cholesterol                   2.146349
Age_x_Systolic_BP             4.287400
Age_x_Diastolic_BP            0.671216
Age_x_Cholesterol             0.000000
Systolic_BP_x_Diastolic_BP    0.459685
Systolic_BP_x_Cholesterol     3.677871
Diastolic_BP_x_Cholesterol    0.575791
Name: 5970, dtype: float64</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Output with interaction: \t<span class="subst">&#123;model_X_int.predict_proba([case.values])[:, <span class="number">1</span>][<span class="number">0</span>]:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Output without interaction: \t<span class="subst">&#123;model_X_int.predict_proba([new_case.values])[:, <span class="number">1</span>][<span class="number">0</span>]:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Output with interaction:    0.9448
Output without interaction:     0.9965</code></pre>
<h4 id="expected-output-5">Expected output</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Output with interaction: <span class="number">0.9448</span></span><br><span class="line">Output without interaction: <span class="number">0.9965</span></span><br></pre></td></tr></table></figure>
<p>We see that the model is less confident in its prediction with the interaction term than without (the prediction value is lower when including the interaction term). With the interaction term, the model has adjusted for the fact that the effect of high cholesterol becomes less important for older patients compared to younger patients.</p>
<h1 id="congratulations">Congratulations!</h1>
<p>You have finished the first assignment of Course 2.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/" class="post-title-link" itemprop="url">Brain Tumor Auto-Segmentation for Magnetic Resonance Imaging (MRI)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-17 23:10:42" itemprop="dateCreated datePublished" datetime="2020-04-17T23:10:42+08:00">2020-04-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-19 23:10:02" itemprop="dateModified" datetime="2020-04-19T23:10:02+08:00">2020-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><img src="https://miro.medium.com/max/2652/1*eTkBMyqdg9JodNcG_O4-Kw.jpeg" width="100%"></p>
<p><a target="_blank" rel="noopener" href="https://medium.com/stanford-ai-for-healthcare/its-a-no-brainer-deep-learning-for-brain-mr-images-f60116397472">Image Source</a></p>
<h1 id="brain-tumor-auto-segmentation-for-magnetic-resonance-imaging-mri">Brain Tumor Auto-Segmentation for Magnetic Resonance Imaging (MRI)</h1>
<p>Welcome to the final part of the "Artificial Intelligence for Medicine" course 1!</p>
<p>You will learn how to build a neural network to automatically segment tumor regions in brain, using <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Magnetic_resonance_imaging">MRI (Magnetic Resonance Imaging</a>) scans.</p>
<p>The MRI scan is one of the most common image modalities that we encounter in the radiology field.<br />
Other data modalities include: - <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/CT_scan">Computer Tomography (CT)</a>, - <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Ultrasound">Ultrasound</a> - <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/X-ray">X-Rays</a>.</p>
<p>In this assignment we will be focusing on MRIs but many of our learnings applies to other mentioned modalities as well. We'll walk you through some of the steps of training a deep learning model for segmentation.</p>
<p><strong>You will learn:</strong></p>
<ul>
<li>What is in an MR image</li>
<li>Standard data preparation techniques for MRI datasets</li>
<li>Metrics and loss functions for segmentation</li>
<li>Visualizing and evaluating segmentation models</li>
</ul>
<h2 id="outline">Outline</h2>
<p>Use these links to jump to particular sections of this assignment!</p>
<ul>
<li><a href="#1">1. Dataset</a>
<ul>
<li><a href="#1-1">1.1 What is an MRI?</a></li>
<li><a href="#1-2">1.2 MRI Data Processing</a></li>
<li><a href="#1-3">1.3 Exploring the Dataset</a></li>
<li><a href="#1-4">1.4 Data Preprocessing</a>
<ul>
<li><a href="#1-4-1">1.4.1 Sub-volume Sampling</a></li>
<li><a href="#1-4-2">1.4.2 Standardization</a></li>
</ul></li>
</ul></li>
<li><a href="#2">2. Model: 3D U-Net</a></li>
<li><a href="#3">3. Metrics</a>
<ul>
<li><a href="#3-1">3.1 Dice Coefficient</a></li>
<li><a href="#3-2">3.2 Soft Dice Loss</a></li>
</ul></li>
<li><a href="#4">4. Training</a></li>
<li><a href="#5">5. Evaluation</a>
<ul>
<li><a href="#5-1">5.1 Overall Performance</a></li>
<li><a href="#5-2">5.2 Patch-level Predictions</a></li>
<li><a href="#5-3">5.3 Running on Entire Scans</a></li>
</ul></li>
</ul>
<h2 id="packages">Packages</h2>
<p>In this assignment, we'll make use of the following packages:</p>
<ul>
<li><code>keras</code> is a framework for building deep learning models.</li>
<li><code>keras.backend</code> allows us to perform math operations on tensors.</li>
<li><code>nibabel</code> will let us extract the images and labels from the files in our dataset.</li>
<li><code>numpy</code> is a library for mathematical and scientific operations.</li>
<li><code>pandas</code> is what we'll use to manipulate our data.</li>
</ul>
<h2 id="import-packages">Import Packages</h2>
<p>Run the next cell to import all the necessary packages, dependencies and custom util functions.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> nibabel <span class="keyword">as</span> nib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> backend <span class="keyword">as</span> K </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> util</span><br></pre></td></tr></table></figure>
<pre><code>Using TensorFlow backend.</code></pre>
<p><a name="1"></a> # 1 Dataset <a name="1-1"></a> ## 1.1 What is an MRI?</p>
<p>Magnetic resonance imaging (MRI) is an advanced imaging technique that is used to observe a variety of diseases and parts of the body.</p>
<p>As we will see later, neural networks can analyze these images individually (as a radiologist would) or combine them into a single 3D volume to make predictions.</p>
<p>At a high level, MRI works by measuring the radio waves emitting by atoms subjected to a magnetic field.</p>
<p><img src="https://miro.medium.com/max/1740/1*yC1Bt3IOzNv8Pp7t1v7F1Q.png"></p>
<p>In this assignment, we'll build a multi-class segmentation model. We'll identify 3 different abnormalities in each image: edemas, non-enhancing tumors, and enhancing tumors.</p>
<p><a name="1-2"></a></p>
<h2 id="mri-data-processing">1.2 MRI Data Processing</h2>
<p>We often encounter MR images in the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/DICOM">DICOM format</a>. - The DICOM format is the output format for most commercial MRI scanners. This type of data can be processed using the <a target="_blank" rel="noopener" href="https://pydicom.github.io/pydicom/stable/getting_started.html">pydicom</a> Python library.</p>
<p>In this assignment, we will be using the data from the <a target="_blank" rel="noopener" href="https://decathlon-10.grand-challenge.org">Decathlon 10 Challenge</a>. This data has been mostly pre-processed for the competition participants, however in real practice, MRI data needs to be significantly pre-preprocessed before we can use it to train our models.</p>
<p><a name="1-3"></a> ## 1.3 Exploring the Dataset</p>
<p>Our dataset is stored in the <a target="_blank" rel="noopener" href="https://nifti.nimh.nih.gov/nifti-1/">NifTI-1 format</a> and we will be using the <a target="_blank" rel="noopener" href="https://github.com/nipy/nibabel">NiBabel library</a> to interact with the files. Each training sample is composed of two separate files:</p>
<p>The first file is an image file containing a 4D array of MR image in the shape of (240, 240, 155, 4). - The first 3 dimensions are the X, Y, and Z values for each point in the 3D volume, which is commonly called a voxel. - The 4th dimension is the values for 4 different sequences - 0: FLAIR: "Fluid Attenuated Inversion Recovery" (FLAIR) - 1: T1w: "T1-weighted" - 2: t1gd: "T1-weighted with gadolinium contrast enhancement" (T1-Gd) - 3: T2w: "T2-weighted"</p>
<p>The second file in each training example is a label file containing a 3D array with the shape of (240, 240, 155).<br />
- The integer values in this array indicate the "label" for each voxel in the corresponding image files: - 0: background - 1: edema - 2: non-enhancing tumor - 3: enhancing tumor</p>
<p>We have access to a total of 484 training images which we will be splitting into a training (80%) and validation (20%) dataset.</p>
<p>Let's begin by looking at one single case and visualizing the data! You have access to 10 different cases via this notebook and we strongly encourage you to explore the data further on your own.</p>
<p>We'll use the <a target="_blank" rel="noopener" href="https://nipy.org/nibabel/nibabel_images.html">NiBabel library</a> to load the image and label for a case. The function is shown below to give you a sense of how it works.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set home directory and data directory</span></span><br><span class="line">HOME_DIR = <span class="string">&quot;./BraTS-Data/&quot;</span></span><br><span class="line">DATA_DIR = HOME_DIR</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_case</span>(<span class="params">image_nifty_file, label_nifty_file</span>):</span></span><br><span class="line">    <span class="comment"># load the image and label file, get the image content and return a numpy array for each</span></span><br><span class="line">    image = np.array(nib.load(image_nifty_file).get_fdata())</span><br><span class="line">    label = np.array(nib.load(label_nifty_file).get_fdata())</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> image, label</span><br></pre></td></tr></table></figure>
<p>We'll now visualize an example. For this, we use a pre-defined function we have written in the <code>util.py</code> file that uses <code>matplotlib</code> to generate a summary of the image.</p>
<p>The colors correspond to each class. - Red is edema - Green is a non-enhancing tumor - Blue is an enhancing tumor.</p>
<p>Do feel free to look at this function at your own time to understand how this is achieved.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">image, label = load_case(DATA_DIR + <span class="string">&quot;imagesTr/BRATS_003.nii.gz&quot;</span>, DATA_DIR + <span class="string">&quot;labelsTr/BRATS_003.nii.gz&quot;</span>)</span><br><span class="line">image = util.get_labeled_image(image, label)</span><br><span class="line"></span><br><span class="line">util.plot_image_grid(image)</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_10_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>We've also written a utility function which generates a GIF that shows what it looks like to iterate over each axis.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image, label = load_case(DATA_DIR + <span class="string">&quot;imagesTr/BRATS_003.nii.gz&quot;</span>, DATA_DIR + <span class="string">&quot;labelsTr/BRATS_003.nii.gz&quot;</span>)</span><br><span class="line">util.visualize_data_gif(util.get_labeled_image(image, label))</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_12_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p><strong>Reminder:</strong> You can explore more images in the <code>imagesTr</code> directory by changing the image name file.</p>
<p><a name="1-4"></a> ## 1.4 Data Preprocessing using patches</p>
<p>While our dataset is provided to us post-registration and in the NIfTI format, we still have to do some minor pre-processing before feeding the data to our model.</p>
<h5 id="generate-sub-volumes">Generate sub-volumes</h5>
<p>We are going to first generate "patches" of our data which you can think of as sub-volumes of the whole MR images. - The reason that we are generating patches is because a network that can process the entire volume at once will simply not fit inside our current environment's memory/GPU. - Therefore we will be using this common technique to generate spatially consistent sub-volumes of our data, which can be fed into our network. - Specifically, we will be generating randomly sampled sub-volumes of shape [160, 160, 16] from our images. - Furthermore, given that a large portion of the MRI volumes are just brain tissue or black background without any tumors, we want to make sure that we pick patches that at least include some amount of tumor data. - Therefore, we are only going to pick patches that have at most 95% non-tumor regions (so at least 5% tumor). - We do this by filtering the volumes based on the values present in the background labels.</p>
<h5 id="standardization-mean-0-stdev-1">Standardization (mean 0, stdev 1)</h5>
<p>Lastly, given that the values in MR images cover a very wide range, we will standardize the values to have a mean of zero and standard deviation of 1. - This is a common technique in deep image processing since standardization makes it much easier for the network to learn.</p>
<p>Let's walk through these steps in the following exercises.</p>
<p><a name="1-4-1"></a> ### 1.4.1 Sub-volume Sampling Fill in the function below takes in: - a 4D image (shape: [240, 240, 155, 4]) - its 3D label (shape: [240, 240, 155]) arrays,</p>
<p>The function returns: - A randomly generated sub-volume of size [160, 160, 16] - Its corresponding label in a 1-hot format which has the shape [3, 160, 160, 160]</p>
<p>Additionally: 1. Make sure that at most 95% of the returned patch is non-tumor regions. 2. Given that our network expects the channels for our images to appear as the first dimension (instead of the last one in our current setting) reorder the dimensions of the image to have the channels appear as the first dimension. 3. Reorder the dimensions of the label array to have the first dimension as the classes (instead of the last one in our current setting) 4. Reduce the labels array dimension to only include the non-background classes (total of 3 instead of 4)</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Check the lecture notebook for a similar example in 1 dimension
</li>
<li>
To check the ratio of background to the whole sub-volume, the numerator is the number of background labels in the sub-volume. The last dimension of the label array at index 0 contains the labels to identify whether the voxel is a background (value of 1) or not a a background (value of 0).
</li>
<li>
For the denominator of the background ratio, this is the volume of the output (see <code>output_x</code>, <code>output_y</code>, <code>output_z</code> in the function parameters).
</li>
<li>
<a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical">keras.utils.to_categorical(y, num_classes=)</a>
</li>
<li>
<a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.moveaxis.html" > np.moveaxis </a> can help you re-arrange the dimensions of the arrays
</li>
<li>
<a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.randint.html">np.random.randint</a> for random sampling
</li>
<li>
When taking a subset of the label <code>'y'</code> that excludes the background class, remember which dimension contains the <code>'num_classes'</code> channel after re-ordering the axes.
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_sub_volume</span>(<span class="params">image, label, </span></span></span><br><span class="line"><span class="params"><span class="function">                   orig_x = <span class="number">240</span>, orig_y = <span class="number">240</span>, orig_z = <span class="number">155</span>, </span></span></span><br><span class="line"><span class="params"><span class="function">                   output_x = <span class="number">160</span>, output_y = <span class="number">160</span>, output_z = <span class="number">16</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                   num_classes = <span class="number">4</span>, max_tries = <span class="number">1000</span>, </span></span></span><br><span class="line"><span class="params"><span class="function">                   background_threshold=<span class="number">0.95</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Extract random sub-volume from original images.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        image (np.array): original image, </span></span><br><span class="line"><span class="string">            of shape (orig_x, orig_y, orig_z, num_channels)</span></span><br><span class="line"><span class="string">        label (np.array): original label. </span></span><br><span class="line"><span class="string">            labels coded using discrete values rather than</span></span><br><span class="line"><span class="string">            a separate dimension, </span></span><br><span class="line"><span class="string">            so this is of shape (orig_x, orig_y, orig_z)</span></span><br><span class="line"><span class="string">        orig_x (int): x_dim of input image</span></span><br><span class="line"><span class="string">        orig_y (int): y_dim of input image</span></span><br><span class="line"><span class="string">        orig_z (int): z_dim of input image</span></span><br><span class="line"><span class="string">        output_x (int): desired x_dim of output</span></span><br><span class="line"><span class="string">        output_y (int): desired y_dim of output</span></span><br><span class="line"><span class="string">        output_z (int): desired z_dim of output</span></span><br><span class="line"><span class="string">        num_classes (int): number of class labels</span></span><br><span class="line"><span class="string">        max_tries (int): maximum trials to do when sampling</span></span><br><span class="line"><span class="string">        background_threshold (float): limit on the fraction </span></span><br><span class="line"><span class="string">            of the sample which can be the background</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    returns:</span></span><br><span class="line"><span class="string">        X (np.array): sample of original image of dimension </span></span><br><span class="line"><span class="string">            (num_channels, output_x, output_y, output_z)</span></span><br><span class="line"><span class="string">        y (np.array): labels which correspond to X, of dimension </span></span><br><span class="line"><span class="string">            (num_classes, output_x, output_y, output_z)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Initialize features and labels with `None`</span></span><br><span class="line">    X = <span class="literal">None</span></span><br><span class="line">    y = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    tries = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> tries &lt; max_tries:</span><br><span class="line">        <span class="comment"># randomly sample sub-volume by sampling the corner voxel</span></span><br><span class="line">        <span class="comment"># hint: make sure to leave enough room for the output dimensions!</span></span><br><span class="line">        start_x = np.random.randint(orig_x - output_x + <span class="number">1</span> )</span><br><span class="line">        start_y = np.random.randint(orig_y - output_y + <span class="number">1</span> )</span><br><span class="line">        start_z = np.random.randint(orig_z - output_z + <span class="number">1</span> )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># extract relevant area of label</span></span><br><span class="line">        y = label[start_x: start_x + output_x,</span><br><span class="line">                  start_y: start_y + output_y,</span><br><span class="line">                  start_z: start_z + output_z]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># One-hot encode the categories.</span></span><br><span class="line">        <span class="comment"># This adds a 4th dimension, &#x27;num_classes&#x27;</span></span><br><span class="line">        <span class="comment"># (output_x, output_y, output_z, num_classes)</span></span><br><span class="line">        y = keras.utils.to_categorical(y, num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute the background ratio</span></span><br><span class="line">        bgrd_ratio = y[:,:,:, <span class="number">0</span>].<span class="built_in">sum</span>() / (output_x * output_y * output_z)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># increment tries counter</span></span><br><span class="line">        tries += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># if background ratio is below the desired threshold,</span></span><br><span class="line">        <span class="comment"># use that sub-volume.</span></span><br><span class="line">        <span class="comment"># otherwise continue the loop and try another random sub-volume</span></span><br><span class="line">        <span class="keyword">if</span> bgrd_ratio &lt; background_threshold:</span><br><span class="line"></span><br><span class="line">            <span class="comment"># make copy of the sub-volume</span></span><br><span class="line">            X = np.copy(image[start_x: start_x + output_x,</span><br><span class="line">                              start_y: start_y + output_y,</span><br><span class="line">                              start_z: start_z + output_z, :])</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># change dimension of X</span></span><br><span class="line">            <span class="comment"># from (x_dim, y_dim, z_dim, num_channels)</span></span><br><span class="line">            <span class="comment"># to (num_channels, x_dim, y_dim, z_dim)</span></span><br><span class="line">            X = np.moveaxis(X, -<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># change dimension of y</span></span><br><span class="line">            <span class="comment"># from (x_dim, y_dim, z_dim, num_classes)</span></span><br><span class="line">            <span class="comment"># to (num_classes, x_dim, y_dim, z_dim)</span></span><br><span class="line">            y = np.moveaxis(y, -<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment">### END CODE HERE ###</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># take a subset of y that excludes the background class</span></span><br><span class="line">            <span class="comment"># in the &#x27;num_classes&#x27; dimension</span></span><br><span class="line">            y = y[<span class="number">1</span>:, :, :, :]</span><br><span class="line">    </span><br><span class="line">            <span class="keyword">return</span> X, y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># if we&#x27;ve tried max_tries number of samples</span></span><br><span class="line">    <span class="comment"># Give up in order to avoid looping forever.</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Tried <span class="subst">&#123;tries&#125;</span> times to find a sub-volume. Giving up...&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="test-case">Test Case:</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">image = np.zeros((<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">label = np.zeros((<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">            image[i, j, k, <span class="number">0</span>] = i*j*k</span><br><span class="line">            label[i, j, k] = k</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;image:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;z = <span class="subst">&#123;k&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(image[:, :, k, <span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;z = <span class="subst">&#123;k&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[:, :, k])</span><br></pre></td></tr></table></figure>
<pre><code>image:
z = 0
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]]
z = 1
[[0. 0. 0. 0.]
 [0. 1. 2. 3.]
 [0. 2. 4. 6.]
 [0. 3. 6. 9.]]
z = 2
[[ 0.  0.  0.  0.]
 [ 0.  2.  4.  6.]
 [ 0.  4.  8. 12.]
 [ 0.  6. 12. 18.]]


label:
z = 0
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]]
z = 1
[[1. 1. 1. 1.]
 [1. 1. 1. 1.]
 [1. 1. 1. 1.]
 [1. 1. 1. 1.]]
z = 2
[[2. 2. 2. 2.]
 [2. 2. 2. 2.]
 [2. 2. 2. 2.]
 [2. 2. 2. 2.]]</code></pre>
<h4 id="test-extracting-2-2-2-sub-volume">Test: Extracting (2, 2, 2) sub-volume</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sample_image, sample_label = get_sub_volume(image, </span><br><span class="line">                                            label,</span><br><span class="line">                                            orig_x=<span class="number">4</span>, </span><br><span class="line">                                            orig_y=<span class="number">4</span>, </span><br><span class="line">                                            orig_z=<span class="number">3</span>,</span><br><span class="line">                                            output_x=<span class="number">2</span>, </span><br><span class="line">                                            output_y=<span class="number">2</span>, </span><br><span class="line">                                            output_z=<span class="number">2</span>,</span><br><span class="line">                                            num_classes = <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sampled Image:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;z = &quot;</span> + <span class="built_in">str</span>(k))</span><br><span class="line">    <span class="built_in">print</span>(sample_image[<span class="number">0</span>, :, :, k])</span><br></pre></td></tr></table></figure>
<pre><code>Sampled Image:
z = 0
[[0. 2.]
 [0. 3.]]
z = 1
[[0. 4.]
 [0. 6.]]</code></pre>
<h4 id="expected-output">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Sampled Image:</span><br><span class="line">z = <span class="number">0</span></span><br><span class="line">[[<span class="number">0.</span> <span class="number">2.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">3.</span>]]</span><br><span class="line">z = <span class="number">1</span></span><br><span class="line">[[<span class="number">0.</span> <span class="number">4.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">6.</span>]]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sampled Label:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = &quot;</span> + <span class="built_in">str</span>(c))</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;z = &quot;</span> + <span class="built_in">str</span>(k))</span><br><span class="line">        <span class="built_in">print</span>(sample_label[c, :, :, k])</span><br></pre></td></tr></table></figure>
<pre><code>Sampled Label:
class = 0
z = 0
[[1. 1.]
 [1. 1.]]
z = 1
[[0. 0.]
 [0. 0.]]
class = 1
z = 0
[[0. 0.]
 [0. 0.]]
z = 1
[[1. 1.]
 [1. 1.]]</code></pre>
<h4 id="expected-output-1">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Sampled Label:</span><br><span class="line"><span class="class"><span class="keyword">class</span> = 0</span></span><br><span class="line"><span class="class"><span class="title">z</span> = 0</span></span><br><span class="line"><span class="class">[[1. 1.]</span></span><br><span class="line"><span class="class"> [1. 1.]]</span></span><br><span class="line"><span class="class"><span class="title">z</span> = 1</span></span><br><span class="line"><span class="class">[[0. 0.]</span></span><br><span class="line"><span class="class"> [0. 0.]]</span></span><br><span class="line"><span class="class"><span class="title">class</span> = 1</span></span><br><span class="line"><span class="class"><span class="title">z</span> = 0</span></span><br><span class="line"><span class="class">[[0. 0.]</span></span><br><span class="line"><span class="class"> [0. 0.]]</span></span><br><span class="line"><span class="class"><span class="title">z</span> = 1</span></span><br><span class="line"><span class="class">[[1. 1.]</span></span><br><span class="line"><span class="class"> [1. 1.]]</span></span><br></pre></td></tr></table></figure>
<p>You can run the following cell to look at a candidate patch and ensure that the function works correctly. We'll look at the enhancing tumor part of the label.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">image, label = load_case(DATA_DIR + <span class="string">&quot;imagesTr/BRATS_001.nii.gz&quot;</span>, DATA_DIR + <span class="string">&quot;labelsTr/BRATS_001.nii.gz&quot;</span>)</span><br><span class="line">X, y = get_sub_volume(image, label)</span><br><span class="line"><span class="comment"># enhancing tumor is channel 2 in the class label</span></span><br><span class="line"><span class="comment"># you can change indexer for y to look at different classes</span></span><br><span class="line">util.visualize_patch(X[<span class="number">0</span>, :, :, :], y[<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_26_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p><a name="1-4-2"></a> ### 1.4.2 Standardization</p>
<p>Next, fill in the following function that given a patch (sub-volume), standardizes the values across each channel and each Z plane to have a mean of zero and standard deviation of 1.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Check that the standard deviation is not zero before dividing by it.
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">standardize</span>(<span class="params">image</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Standardize mean and standard deviation </span></span><br><span class="line"><span class="string">        of each channel and z_dimension.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        image (np.array): input image, </span></span><br><span class="line"><span class="string">            shape (num_channels, dim_x, dim_y, dim_z)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        standardized_image (np.array): standardized version of input image</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize to array of zeros, with same shape as the image</span></span><br><span class="line">    standardized_image = np.empty(image.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># iterate over channels</span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(image.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="comment"># iterate over the `z` dimension</span></span><br><span class="line">        <span class="keyword">for</span> z <span class="keyword">in</span> <span class="built_in">range</span>(image.shape[<span class="number">3</span>]):</span><br><span class="line">            <span class="comment"># get a slice of the image </span></span><br><span class="line">            <span class="comment"># at channel c and z-th dimension `z`</span></span><br><span class="line">            image_slice = image[c,:,:,z]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># subtract the mean from image_slice</span></span><br><span class="line">            centered = image_slice - image_slice.mean()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> image_slice.std() != <span class="number">0</span>:</span><br><span class="line">                centered_scaled = image_slice / image_slice.std()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                centered_scaled = centered</span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">            <span class="comment"># update  the slice of standardized image</span></span><br><span class="line">            <span class="comment"># with the scaled centered and scaled image</span></span><br><span class="line">            standardized_image[c, :, :, z] = centered_scaled</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> standardized_image</span><br></pre></td></tr></table></figure>
<p>And to sanity check, let's look at the output of our function:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X_norm = standardize(X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;standard deviation for a slice should be 1.0&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;stddv for X_norm[0, :, :, 0]: <span class="subst">&#123;X_norm[<span class="number">0</span>,:,:,<span class="number">0</span>].std():<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>standard deviation for a slice should be 1.0
stddv for X_norm[0, :, :, 0]: 1.00</code></pre>
<p>Let's visualize our patch again just to make sure (it won't look different since the <code>imshow</code> function we use to visualize automatically normalizes the pixels when displaying in black and white).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">util.visualize_patch(X_norm[<span class="number">0</span>, :, :, :], y[<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_33_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p><a name="2"></a> # 2 Model: 3D U-Net Now let's build our model. In this assignment we will be building a <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.06650">3D U-net</a>. - This architecture will take advantage of the volumetric shape of MR images and is one of the best performing models for this task. - Feel free to familiarize yourself with the architecture by reading <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.06650">this paper</a>.</p>
<p><img src="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png" width="50%"></p>
<p><a name="3"></a> # 3 Metrics</p>
<p><a name="3-1"></a> ## 3.1 Dice Similarity Coefficient</p>
<p>Aside from the architecture, one of the most important elements of any deep learning method is the choice of our loss function.</p>
<p>A natural choice that you may be familiar with is the cross-entropy loss function. - However, this loss function is not ideal for segmentation tasks due to heavy class imbalance (there are typically not many positive regions).</p>
<p>A much more common loss for segmentation tasks is the Dice similarity coefficient, which is a measure of how well two contours overlap. - The Dice index ranges from 0 (complete mismatch) - To 1 (perfect match).</p>
<p>In general, for two sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, the Dice similarity coefficient is defined as: <span class="math display">\[\text{DSC}(A, B) = \frac{2 \times |A \cap B|}{|A| + |B|}.\]</span></p>
<p>Here we can interpret <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> as sets of voxels, <span class="math inline">\(A\)</span> being the predicted tumor region and <span class="math inline">\(B\)</span> being the ground truth.</p>
<p>Our model will map each voxel to 0 or 1 - 0 means it is a background voxel - 1 means it is part of the segmented region.</p>
<p>In the dice coefficient, the variables in the formula are: - <span class="math inline">\(x\)</span> : the input image - <span class="math inline">\(f(x)\)</span> : the model output (prediction) - <span class="math inline">\(y\)</span> : the label (actual ground truth)</p>
<p>The dice coefficient "DSC" is:</p>
<p><span class="math display">\[\text{DSC}(f, x, y) = \frac{2 \times \sum_{i, j} f(x)_{ij} \times y_{ij} + \epsilon}{\sum_{i,j} f(x)_{ij} + \sum_{i, j} y_{ij} + \epsilon}\]</span></p>
<ul>
<li><span class="math inline">\(\epsilon\)</span> is a small number that is added to avoid division by zero</li>
</ul>
<p><img src="https://www.researchgate.net/publication/328671987/figure/fig4/AS:688210103529478@1541093483784/Calculation-of-the-Dice-similarity-coefficient-The-deformed-contour-of-the-liver-from.ppm" width="30%"></p>
<p><a target="_blank" rel="noopener" href="https://www.researchgate.net/figure/Calculation-of-the-Dice-similarity-coefficient-The-deformed-contour-of-the-liver-from_fig4_328671987">Image Source</a></p>
<p>Implement the dice coefficient for a single output class below.</p>
<ul>
<li>Please use the <a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/backend/sum">Keras.sum(x,axis=)</a> function to compute the numerator and denominator of the dice coefficient.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">single_class_dice_coefficient</span>(<span class="params">y_true, y_pred, axis=(<span class="params"><span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span></span>), </span></span></span><br><span class="line"><span class="params"><span class="function">                                  epsilon=<span class="number">0.00001</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute dice coefficient for single class.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        y_true (Tensorflow tensor): tensor of ground truth values for single class.</span></span><br><span class="line"><span class="string">                                    shape: (x_dim, y_dim, z_dim)</span></span><br><span class="line"><span class="string">        y_pred (Tensorflow tensor): tensor of predictions for single class.</span></span><br><span class="line"><span class="string">                                    shape: (x_dim, y_dim, z_dim)</span></span><br><span class="line"><span class="string">        axis (tuple): spatial axes to sum over when computing numerator and</span></span><br><span class="line"><span class="string">                      denominator of dice coefficient.</span></span><br><span class="line"><span class="string">                      Hint: pass this as the &#x27;axis&#x27; argument to the K.sum function.</span></span><br><span class="line"><span class="string">        epsilon (float): small constant added to numerator and denominator to</span></span><br><span class="line"><span class="string">                        avoid divide by 0 errors.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        dice_coefficient (float): computed value of dice coefficient.     </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    dice_numerator = K.<span class="built_in">sum</span>(<span class="number">2</span> * y_true * y_pred, axis= axis) + epsilon</span><br><span class="line">    dice_denominator = K.<span class="built_in">sum</span>(y_true,axis= axis) + K.<span class="built_in">sum</span>(y_pred, axis = axis) + epsilon</span><br><span class="line">    dice_coefficient = dice_numerator / dice_denominator </span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dice_coefficient</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TEST CASES</span></span><br><span class="line">sess = K.get_session()</span><br><span class="line"><span class="comment">#sess = tf.compat.v1.Session()</span></span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    pred = np.expand_dims(np.eye(<span class="number">2</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #1&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[:, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[:, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># choosing a large epsilon to help check for implementation errors</span></span><br><span class="line">    dc = single_class_dice_coefficient(pred, label,epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;dice coefficient: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #2&quot;</span>)</span><br><span class="line">    pred = np.expand_dims(np.eye(<span class="number">2</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]]), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[:, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[:, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># choosing a large epsilon to help check for implementation errors</span></span><br><span class="line">    dc = single_class_dice_coefficient(pred, label,epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;dice_coefficient: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #1
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 0.]]
dice coefficient: 0.6000


Test Case #2
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 1.]]
dice_coefficient: 0.8333</code></pre>
<h5 id="expected-output-2">Expected output</h5>
<p>If you get a different result, please check that you implemented the equation completely. <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#1</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span>]]</span><br><span class="line">dice coefficient: <span class="number">0.6000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Test Case <span class="comment">#2</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">dice_coefficient: <span class="number">0.8333</span></span><br></pre></td></tr></table></figure></p>
<h3 id="dice-coefficient-for-multiple-classes">Dice Coefficient for Multiple classes</h3>
<p>Now that we have the single class case, we can think about how to approach the multi class context. - Remember that for this task, we want segmentations for each of the 3 classes of abnormality (edema, enhancing tumor, non-enhancing tumor). - This will give us 3 different dice coefficients (one for each abnormality class). - To combine these, we can just take the average. We can write that the overall dice coefficient is:</p>
<p><span class="math display">\[DC(f, x, y) = \frac{1}{3} \left ( DC_{1}(f, x, y) + DC_{2}(f, x, y) + DC_{3}(f, x, y) \right )\]</span></p>
<ul>
<li><span class="math inline">\(DC_{1}\)</span>, <span class="math inline">\(DC_{2}\)</span> and <span class="math inline">\(DC_{3}\)</span> are edema, enhancing tumor, and non-enhancing tumor dice coefficients.</li>
</ul>
<p>For any number of classes, the equation becomes:<br />
<span class="math display">\[DC(f, x, y) = \frac{1}{N} \sum_{c=1}^{C} \left ( DC_{c}(f, x, y) \right )\]</span></p>
<p>In this case, with three categories, <span class="math inline">\(C = 3\)</span></p>
<p>Implement the mean dice coefficient below. This should not be very different from your singe-class implementation.</p>
<p>Please use the <a target="_blank" rel="noopener" href="https://keras.io/backend/#mean">K.mean</a> function to take the average of the three classes.<br />
- Apply the mean to the ratio that you calculate in the last line of code that you'll implement.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dice_coefficient</span>(<span class="params">y_true, y_pred, axis=(<span class="params"><span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span></span>), </span></span></span><br><span class="line"><span class="params"><span class="function">                     epsilon=<span class="number">0.00001</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute mean dice coefficient over all abnormality classes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        y_true (Tensorflow tensor): tensor of ground truth values for all classes.</span></span><br><span class="line"><span class="string">                                    shape: (num_classes, x_dim, y_dim, z_dim)</span></span><br><span class="line"><span class="string">        y_pred (Tensorflow tensor): tensor of predictions for all classes.</span></span><br><span class="line"><span class="string">                                    shape: (num_classes, x_dim, y_dim, z_dim)</span></span><br><span class="line"><span class="string">        axis (tuple): spatial axes to sum over when computing numerator and</span></span><br><span class="line"><span class="string">                      denominator of dice coefficient.</span></span><br><span class="line"><span class="string">                      Hint: pass this as the &#x27;axis&#x27; argument to the K.sum</span></span><br><span class="line"><span class="string">                            and K.mean functions.</span></span><br><span class="line"><span class="string">        epsilon (float): small constant add to numerator and denominator to</span></span><br><span class="line"><span class="string">                        avoid divide by 0 errors.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        dice_coefficient (float): computed value of dice coefficient.     </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    dice_numerator = K.<span class="built_in">sum</span>(<span class="number">2</span> * y_true * y_pred, axis= axis) + epsilon</span><br><span class="line">    dice_denominator = K.<span class="built_in">sum</span>(y_true,axis= axis) + K.<span class="built_in">sum</span>(y_pred, axis = axis) + epsilon</span><br><span class="line">    dice_coefficient = K.mean(dice_numerator / dice_denominator,axis = <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dice_coefficient</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TEST CASES</span></span><br><span class="line">sess = K.get_session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #1&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    dc = dice_coefficient(pred, label,epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;dice coefficient: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #2&quot;</span>)</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    dc = dice_coefficient(pred, label,epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;dice coefficient: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #3&quot;</span>)</span><br><span class="line">    pred = np.zeros((<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">    pred[<span class="number">0</span>, :, :, :] = np.expand_dims(np.eye(<span class="number">2</span>), -<span class="number">1</span>)</span><br><span class="line">    pred[<span class="number">1</span>, :, :, :] = np.expand_dims(np.eye(<span class="number">2</span>), -<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    label = np.zeros((<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">    label[<span class="number">0</span>, :, :, :] = np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), -<span class="number">1</span>)</span><br><span class="line">    label[<span class="number">1</span>, :, :, :] = np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]]), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 0&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 1&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">1</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 0&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 1&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">1</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    dc = dice_coefficient(pred, label,epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;dice coefficient: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #1
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 0.]]
dice coefficient: 0.6000


Test Case #2
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 1.]]
dice coefficient: 0.8333


Test Case #3
pred:
class = 0
[[1. 0.]
 [0. 1.]]
class = 1
[[1. 0.]
 [0. 1.]]
label:
class = 0
[[1. 1.]
 [0. 0.]]
class = 1
[[1. 1.]
 [0. 1.]]
dice coefficient: 0.7167</code></pre>
<h4 id="expected-output-3">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#1</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span>]]</span><br><span class="line">dice coefficient: <span class="number">0.6000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Test Case <span class="comment">#2</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">dice coefficient: <span class="number">0.8333</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Test Case <span class="comment">#3</span></span><br><span class="line">pred:</span><br><span class="line"><span class="class"><span class="keyword">class</span> = 0</span></span><br><span class="line"><span class="class">[[1. 0.]</span></span><br><span class="line"><span class="class"> [0. 1.]]</span></span><br><span class="line"><span class="class"><span class="title">class</span> = 1</span></span><br><span class="line"><span class="class">[[1. 0.]</span></span><br><span class="line"><span class="class"> [0. 1.]]</span></span><br><span class="line"><span class="class"><span class="title">label</span>:</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> = 0</span></span><br><span class="line"><span class="class">[[1. 1.]</span></span><br><span class="line"><span class="class"> [0. 0.]]</span></span><br><span class="line"><span class="class"><span class="title">class</span> = 1</span></span><br><span class="line"><span class="class">[[1. 1.]</span></span><br><span class="line"><span class="class"> [0. 1.]]</span></span><br><span class="line"><span class="class"><span class="title">dice</span> <span class="title">coefficient</span>:</span> <span class="number">0.7167</span></span><br></pre></td></tr></table></figure>
<p><a name="3-2"></a> ## 3.2 Soft Dice Loss</p>
<p>While the Dice Coefficient makes intuitive sense, it is not the best for training. - This is because it takes in discrete values (zeros and ones). - The model outputs <em>probabilities</em> that each pixel is, say, a tumor or not, and we want to be able to backpropagate through those outputs.</p>
<p>Therefore, we need an analogue of the Dice loss which takes real valued input. This is where the <strong>Soft Dice loss</strong> comes in. The formula is:</p>
<p><span class="math display">\[\mathcal{L}_{Dice}(p, q) = 1 - \frac{2\times\sum_{i, j} p_{ij}q_{ij} + \epsilon}{\left(\sum_{i, j} p_{ij}^2 \right) + \left(\sum_{i, j} q_{ij}^2 \right) + \epsilon}\]</span></p>
<ul>
<li><span class="math inline">\(p\)</span> is our predictions</li>
<li><span class="math inline">\(q\)</span> is the ground truth</li>
<li>In practice each <span class="math inline">\(q_i\)</span> will either be 0 or 1.</li>
<li><span class="math inline">\(\epsilon\)</span> is a small number that is added to avoid division by zero</li>
</ul>
<p>The soft Dice loss ranges between - 0: perfectly matching the ground truth distribution <span class="math inline">\(q\)</span> - 1: complete mismatch with the ground truth.</p>
<p>You can also check that if <span class="math inline">\(p_i\)</span> and <span class="math inline">\(q_i\)</span> are each 0 or 1, then the soft Dice loss is just one minus the dice coefficient.</p>
<h3 id="multi-class-soft-dice-loss">Multi-Class Soft Dice Loss</h3>
<p>We've explained the single class case for simplicity, but the multi-class generalization is exactly the same as that of the dice coefficient. - Since you've already implemented the multi-class dice coefficient, we'll have you jump directly to the multi-class soft dice loss.</p>
<p>For any number of categories of diseases, the expression becomes:</p>
<p><span class="math display">\[\mathcal{L}_{Dice}(p, q) = 1 - \frac{1}{N} \sum_{c=1}^{C} \frac{2\times\sum_{i, j} p_{cij}q_{cij} + \epsilon}{\left(\sum_{i, j} p_{cij}^2 \right) + \left(\sum_{i, j} q_{cij}^2 \right) + \epsilon}\]</span></p>
<p>Please implement the soft dice loss below!</p>
<p>As before, you will use K.mean() - Apply the average the mean to ratio that you'll calculate in the last line of code that you'll implement.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">soft_dice_loss</span>(<span class="params">y_true, y_pred, axis=(<span class="params"><span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span></span>), </span></span></span><br><span class="line"><span class="params"><span class="function">                   epsilon=<span class="number">0.00001</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute mean soft dice loss over all abnormality classes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        y_true (Tensorflow tensor): tensor of ground truth values for all classes.</span></span><br><span class="line"><span class="string">                                    shape: (num_classes, x_dim, y_dim, z_dim)</span></span><br><span class="line"><span class="string">        y_pred (Tensorflow tensor): tensor of soft predictions for all classes.</span></span><br><span class="line"><span class="string">                                    shape: (num_classes, x_dim, y_dim, z_dim)</span></span><br><span class="line"><span class="string">        axis (tuple): spatial axes to sum over when computing numerator and</span></span><br><span class="line"><span class="string">                      denominator in formula for dice loss.</span></span><br><span class="line"><span class="string">                      Hint: pass this as the &#x27;axis&#x27; argument to the K.sum</span></span><br><span class="line"><span class="string">                            and K.mean functions.</span></span><br><span class="line"><span class="string">        epsilon (float): small constant added to numerator and denominator to</span></span><br><span class="line"><span class="string">                        avoid divide by 0 errors.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        dice_loss (float): computed value of dice loss.     </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line"></span><br><span class="line">    dice_numerator = <span class="number">2</span> * K.<span class="built_in">sum</span>(y_true * y_pred, axis=axis) + epsilon</span><br><span class="line">    dice_denominator = K.<span class="built_in">sum</span>(K.square(y_true), axis = axis) + K.<span class="built_in">sum</span>(K.square(y_pred), axis = axis) + epsilon</span><br><span class="line">    dice_loss = <span class="number">1</span> - K.mean(dice_numerator / dice_denominator, axis = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dice_loss</span><br></pre></td></tr></table></figure>
<h4 id="test-case-1">Test Case 1</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TEST CASES</span></span><br><span class="line">sess = K.get_session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #1&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    dc = soft_dice_loss(pred, label, epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;soft dice loss:<span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #1
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 0.]]
soft dice loss:0.4000</code></pre>
<h4 id="expected-output-4">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#1</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span>]]</span><br><span class="line">soft dice loss:<span class="number">0.4000</span></span><br></pre></td></tr></table></figure>
<h4 id="test-case-2">Test Case 2</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">sess = K.get_session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #2&quot;</span>)</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(<span class="number">0.5</span>*np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    dc = soft_dice_loss(pred, label, epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;soft dice loss: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #2
pred:
[[0.5 0. ]
 [0.  0.5]]
label:
[[1. 1.]
 [0. 0.]]
soft dice loss: 0.4286</code></pre>
<h4 id="expected-output-5">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#2</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">0.5</span> <span class="number">0.</span> ]</span><br><span class="line"> [<span class="number">0.</span>  <span class="number">0.5</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span>]]</span><br><span class="line">soft dice loss: <span class="number">0.4286</span></span><br></pre></td></tr></table></figure>
<h4 id="test-case-3">Test Case 3</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sess = K.get_session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #3&quot;</span>)</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    dc = soft_dice_loss(pred, label, epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;soft dice loss: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #3
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 1.]]
soft dice loss: 0.1667</code></pre>
<h4 id="expected-output-6">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#3</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">soft dice loss: <span class="number">0.1667</span></span><br></pre></td></tr></table></figure>
<h4 id="test-case-4">Test Case 4</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">sess = K.get_session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #4&quot;</span>)</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    pred[<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>] = <span class="number">0.8</span></span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    dc = soft_dice_loss(pred, label, epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;soft dice loss: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #4
pred:
[[1.  0.8]
 [0.  1. ]]
label:
[[1. 1.]
 [0. 1.]]
soft dice loss: 0.0060</code></pre>
<h4 id="expected-output-7">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#4</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span>  <span class="number">0.8</span>]</span><br><span class="line"> [<span class="number">0.</span>  <span class="number">1.</span> ]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">soft dice loss: <span class="number">0.0060</span></span><br></pre></td></tr></table></figure>
<h4 id="test-case-5">Test Case 5</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">sess = K.get_session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #5&quot;</span>)</span><br><span class="line">    pred = np.zeros((<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">    pred[<span class="number">0</span>, :, :, :] = np.expand_dims(<span class="number">0.5</span>*np.eye(<span class="number">2</span>), -<span class="number">1</span>)</span><br><span class="line">    pred[<span class="number">1</span>, :, :, :] = np.expand_dims(np.eye(<span class="number">2</span>), -<span class="number">1</span>)</span><br><span class="line">    pred[<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>] = <span class="number">0.8</span></span><br><span class="line"></span><br><span class="line">    label = np.zeros((<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">    label[<span class="number">0</span>, :, :, :] = np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), -<span class="number">1</span>)</span><br><span class="line">    label[<span class="number">1</span>, :, :, :] = np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]]), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 0&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 1&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">1</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 0&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 1&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">1</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    dc = soft_dice_loss(pred, label, epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;soft dice loss: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #5
pred:
class = 0
[[0.5 0. ]
 [0.  0.5]]
class = 1
[[1.  0.8]
 [0.  1. ]]
label:
class = 0
[[1. 1.]
 [0. 0.]]
class = 1
[[1. 1.]
 [0. 1.]]
soft dice loss: 0.2173</code></pre>
<h4 id="expected-output-8">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#5</span></span><br><span class="line">pred:</span><br><span class="line"><span class="class"><span class="keyword">class</span> = 0</span></span><br><span class="line"><span class="class">[[0.5 0. ]</span></span><br><span class="line"><span class="class"> [0.  0.5]]</span></span><br><span class="line"><span class="class"><span class="title">class</span> = 1</span></span><br><span class="line"><span class="class">[[1.  0.8]</span></span><br><span class="line"><span class="class"> [0.  1. ]]</span></span><br><span class="line"><span class="class"><span class="title">label</span>:</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> = 0</span></span><br><span class="line"><span class="class">[[1. 1.]</span></span><br><span class="line"><span class="class"> [0. 0.]]</span></span><br><span class="line"><span class="class"><span class="title">class</span> = 1</span></span><br><span class="line"><span class="class">[[1. 1.]</span></span><br><span class="line"><span class="class"> [0. 1.]]</span></span><br><span class="line"><span class="class"><span class="title">soft</span> <span class="title">dice</span> <span class="title">loss</span>:</span> <span class="number">0.2173</span></span><br></pre></td></tr></table></figure>
<h4 id="test-case-6">Test Case 6</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test case 6</span></span><br><span class="line">pred = np.array([</span><br><span class="line">                    [</span><br><span class="line">                        [ </span><br><span class="line">                            [<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">                        ],</span><br><span class="line">                        [</span><br><span class="line">                            [<span class="number">1.0</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]</span><br><span class="line">                        ]</span><br><span class="line">                    ],</span><br><span class="line">                    [</span><br><span class="line">                        [ </span><br><span class="line">                            [<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">                        ],</span><br><span class="line">                        [</span><br><span class="line">                            [<span class="number">1.0</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]</span><br><span class="line">                        ]</span><br><span class="line">                    ],</span><br><span class="line">                  ])</span><br><span class="line">label = np.array([</span><br><span class="line">                    [</span><br><span class="line">                        [ </span><br><span class="line">                            [<span class="number">1.0</span>, <span class="number">0.0</span>], [<span class="number">1.0</span>, <span class="number">0.0</span>]</span><br><span class="line">                        ],</span><br><span class="line">                        [</span><br><span class="line">                            [<span class="number">1.0</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">                        ]</span><br><span class="line">                    ],</span><br><span class="line">                    [</span><br><span class="line">                        [ </span><br><span class="line">                            [<span class="number">0.0</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">                        ],</span><br><span class="line">                        [</span><br><span class="line">                            [<span class="number">1.0</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">                        ]</span><br><span class="line">                    ]</span><br><span class="line">                  ])</span><br><span class="line"></span><br><span class="line">sess = K.get_session()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test case #6&quot;</span>)</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    dc = soft_dice_loss(pred, label, epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;soft dice loss&quot;</span>,dc.<span class="built_in">eval</span>())</span><br></pre></td></tr></table></figure>
<pre><code>Test case #6
soft dice loss 0.4375</code></pre>
<h4 id="expected-output-9">Expected Output</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Test case <span class="comment">#6</span></span><br><span class="line">soft dice loss: <span class="number">0.4375</span></span><br></pre></td></tr></table></figure>
<p>Note, if you don't have a scalar, and have an array with more than one value, please check your implementation!</p>
<p><a name="4"></a> # 4 Create and Train the model</p>
<p>Once you've finished implementing the soft dice loss, we can create the model!</p>
<p>We'll use the <code>unet_model_3d</code> function in <code>utils</code> which we implemented for you. - This creates the model architecture and compiles the model with the specified loss functions and metrics. - Check out function <code>util.unet_model_3d(loss_function)</code> in the <code>util.py</code> file.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = util.unet_model_3d(loss_function=soft_dice_loss, metrics=[dice_coefficient])</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.</code></pre>
<p><a name="4-1"></a> ## 4.1 Training on a Large Dataset</p>
<p>In order to facilitate the training on the large dataset: - We have pre-processed the entire dataset into patches and stored the patches in the <a target="_blank" rel="noopener" href="http://docs.h5py.org/en/stable/"><code>h5py</code></a> format. - We also wrote a custom Keras <a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code>Sequence</code></a> class which can be used as a <code>Generator</code> for the keras model to train on large datasets. - Feel free to look at the <code>VolumeDataGenerator</code> class in <code>util.py</code> to learn about how such a generator can be coded.</p>
<p>Note: <a target="_blank" rel="noopener" href="https://www.geeksforgeeks.org/keras-fit-and-keras-fit_generator/">Here</a> you can check the difference between <code>fit</code> and <code>fit_generator</code> functions.</p>
<p>To get a flavor of the training on the larger dataset, you can run the following cell to train the model on a small subset of the dataset (85 patches). You should see the loss going down and the dice coefficient going up.</p>
<p>Running <code>model.fit()</code> on the Coursera workspace may cause the kernel to die. - Soon, we will load a pre-trained version of this model, so that you don't need to train the model on this workspace.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run this on your local machine only</span></span><br><span class="line"><span class="comment"># May cause the kernel to die if running in the Coursera platform</span></span><br><span class="line"></span><br><span class="line">base_dir = HOME_DIR + <span class="string">&quot;processed/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(base_dir + <span class="string">&quot;config.json&quot;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    config = json.load(json_file)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get generators for training and validation sets</span></span><br><span class="line">train_generator = util.VolumeDataGenerator(config[<span class="string">&quot;train&quot;</span>], base_dir + <span class="string">&quot;train/&quot;</span>, batch_size=<span class="number">3</span>, dim=(<span class="number">160</span>, <span class="number">160</span>, <span class="number">16</span>), verbose=<span class="number">0</span>)</span><br><span class="line">valid_generator = util.VolumeDataGenerator(config[<span class="string">&quot;valid&quot;</span>], base_dir + <span class="string">&quot;valid/&quot;</span>, batch_size=<span class="number">3</span>, dim=(<span class="number">160</span>, <span class="number">160</span>, <span class="number">16</span>), verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">steps_per_epoch = <span class="number">20</span></span><br><span class="line">n_epochs=<span class="number">10</span></span><br><span class="line">validation_steps = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">model.fit_generator(generator=train_generator,</span><br><span class="line">        steps_per_epoch=steps_per_epoch,</span><br><span class="line">        epochs=n_epochs,</span><br><span class="line">        use_multiprocessing=<span class="literal">True</span>,</span><br><span class="line">        validation_data=valid_generator,</span><br><span class="line">        validation_steps=validation_steps)</span><br><span class="line"></span><br><span class="line"><span class="comment"># run this cell if you to save the weights of your trained model in cell section 4.1</span></span><br><span class="line"><span class="comment">#model.save_weights(base_dir + &#x27;my_model_pretrained.hdf5&#x27;)</span></span><br></pre></td></tr></table></figure>
<p><a name="4-2"></a> ## 4.2 Loading a Pre-Trained Model As in assignment 1, instead of having the model train for longer, we'll give you access to a pretrained version. We'll use this to extract predictions and measure performance.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># run this cell if you didn&#x27;t run the training cell in section 4.1</span></span><br><span class="line">base_dir = HOME_DIR + <span class="string">&quot;processed/&quot;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(base_dir + <span class="string">&quot;config.json&quot;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    config = json.load(json_file)</span><br><span class="line"><span class="comment"># Get generators for training and validation sets</span></span><br><span class="line">train_generator = util.VolumeDataGenerator(config[<span class="string">&quot;train&quot;</span>], base_dir + <span class="string">&quot;train/&quot;</span>, batch_size=<span class="number">3</span>, dim=(<span class="number">160</span>, <span class="number">160</span>, <span class="number">16</span>), verbose=<span class="number">0</span>)</span><br><span class="line">valid_generator = util.VolumeDataGenerator(config[<span class="string">&quot;valid&quot;</span>], base_dir + <span class="string">&quot;valid/&quot;</span>, batch_size=<span class="number">3</span>, dim=(<span class="number">160</span>, <span class="number">160</span>, <span class="number">16</span>), verbose=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_weights(HOME_DIR + <span class="string">&quot;model_pretrained.hdf5&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;model_1&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4, 160, 160,  0                                            
__________________________________________________________________________________________________
conv3d_1 (Conv3D)               (None, 32, 160, 160, 3488        input_1[0][0]                    
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 160, 160, 0           conv3d_1[0][0]                   
__________________________________________________________________________________________________
conv3d_2 (Conv3D)               (None, 64, 160, 160, 55360       activation_1[0][0]               
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 160, 160, 0           conv3d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling3d_1 (MaxPooling3D)  (None, 64, 80, 80, 8 0           activation_2[0][0]               
__________________________________________________________________________________________________
conv3d_3 (Conv3D)               (None, 64, 80, 80, 8 110656      max_pooling3d_1[0][0]            
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 64, 80, 80, 8 0           conv3d_3[0][0]                   
__________________________________________________________________________________________________
conv3d_4 (Conv3D)               (None, 128, 80, 80,  221312      activation_3[0][0]               
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 128, 80, 80,  0           conv3d_4[0][0]                   
__________________________________________________________________________________________________
max_pooling3d_2 (MaxPooling3D)  (None, 128, 40, 40,  0           activation_4[0][0]               
__________________________________________________________________________________________________
conv3d_5 (Conv3D)               (None, 128, 40, 40,  442496      max_pooling3d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 128, 40, 40,  0           conv3d_5[0][0]                   
__________________________________________________________________________________________________
conv3d_6 (Conv3D)               (None, 256, 40, 40,  884992      activation_5[0][0]               
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 256, 40, 40,  0           conv3d_6[0][0]                   
__________________________________________________________________________________________________
max_pooling3d_3 (MaxPooling3D)  (None, 256, 20, 20,  0           activation_6[0][0]               
__________________________________________________________________________________________________
conv3d_7 (Conv3D)               (None, 256, 20, 20,  1769728     max_pooling3d_3[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 256, 20, 20,  0           conv3d_7[0][0]                   
__________________________________________________________________________________________________
conv3d_8 (Conv3D)               (None, 512, 20, 20,  3539456     activation_7[0][0]               
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512, 20, 20,  0           conv3d_8[0][0]                   
__________________________________________________________________________________________________
up_sampling3d_1 (UpSampling3D)  (None, 512, 40, 40,  0           activation_8[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 768, 40, 40,  0           up_sampling3d_1[0][0]            
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
conv3d_9 (Conv3D)               (None, 256, 40, 40,  5308672     concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 256, 40, 40,  0           conv3d_9[0][0]                   
__________________________________________________________________________________________________
conv3d_10 (Conv3D)              (None, 256, 40, 40,  1769728     activation_9[0][0]               
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 256, 40, 40,  0           conv3d_10[0][0]                  
__________________________________________________________________________________________________
up_sampling3d_2 (UpSampling3D)  (None, 256, 80, 80,  0           activation_10[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 384, 80, 80,  0           up_sampling3d_2[0][0]            
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv3d_11 (Conv3D)              (None, 128, 80, 80,  1327232     concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 80, 80,  0           conv3d_11[0][0]                  
__________________________________________________________________________________________________
conv3d_12 (Conv3D)              (None, 128, 80, 80,  442496      activation_11[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 128, 80, 80,  0           conv3d_12[0][0]                  
__________________________________________________________________________________________________
up_sampling3d_3 (UpSampling3D)  (None, 128, 160, 160 0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 192, 160, 160 0           up_sampling3d_3[0][0]            
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv3d_13 (Conv3D)              (None, 64, 160, 160, 331840      concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 64, 160, 160, 0           conv3d_13[0][0]                  
__________________________________________________________________________________________________
conv3d_14 (Conv3D)              (None, 64, 160, 160, 110656      activation_13[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 64, 160, 160, 0           conv3d_14[0][0]                  
__________________________________________________________________________________________________
conv3d_15 (Conv3D)              (None, 3, 160, 160,  195         activation_14[0][0]              
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 3, 160, 160,  0           conv3d_15[0][0]                  
==================================================================================================
Total params: 16,318,307
Trainable params: 16,318,307
Non-trainable params: 0
__________________________________________________________________________________________________</code></pre>
<p><a name="5"></a> # 5 Evaluation</p>
<p>Now that we have a trained model, we'll learn to extract its predictions and evaluate its performance on scans from our validation set.</p>
<p><a name="5-1"></a> ## 5.1 Overall Performance</p>
<p>First let's measure the overall performance on the validation set. - We can do this by calling the keras <a target="_blank" rel="noopener" href="https://keras.io/models/model/#evaluate_generator">evaluate_generator</a> function and passing in the validation generator, created in section 4.1.</p>
<h4 id="using-the-validation-set-for-testing">Using the validation set for testing</h4>
<ul>
<li>Note: since we didn't do cross validation tuning on the final model, it's okay to use the validation set.</li>
<li>For real life implementations, however, you would want to do cross validation as usual to choose hyperparamters and then use a hold out test set to assess performance</li>
</ul>
<p>Python Code for measuring the overall performance on the validation set:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val_loss, val_dice = model.evaluate_generator(valid_generator)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;validation soft dice loss: <span class="subst">&#123;val_loss:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;validation dice coefficient: <span class="subst">&#123;val_dice:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="expected-output-10">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">validation soft dice loss: <span class="number">0.4742</span></span><br><span class="line">validation dice coefficient: <span class="number">0.5152</span></span><br></pre></td></tr></table></figure>
<p><strong>NOTE:</strong> Do not run the code shown above on the Coursera platform as it will exceed the platform's memory limitations. However, you can run the code shown above locally on your machine or in Colab to practice measuring the overall performance on the validation set.</p>
<p>Like we mentioned above, due to memory limitiations on the Coursera platform we won't be runing the above code, however, you should take note of the <strong>expected output</strong> below it. We should note that due to the randomness in choosing sub-volumes, the values for soft dice loss and dice coefficient will be different each time that you run it.</p>
<p><a name="5-2"></a> ## 5.2 Patch-level predictions</p>
<p>When applying the model, we'll want to look at segmentations for individual scans (entire scans, not just the sub-volumes) - This will be a bit complicated because of our sub-volume approach. - First let's keep things simple and extract model predictions for sub-volumes. - We can use the sub-volume which we extracted at the beginning of the assignment.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">util.visualize_patch(X_norm[<span class="number">0</span>, :, :, :], y[<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_76_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<h4 id="add-a-batch-dimension">Add a 'batch' dimension</h4>
<p>We can extract predictions by calling <code>model.predict</code> on the patch. - We'll add an <code>images_per_batch</code> dimension, since the <code>predict</code> method is written to take in batches. - The dimensions of the input should be <code>(images_per_batch, num_channels, x_dim, y_dim, z_dim)</code>. - Use <a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.expand_dims.html">numpy.expand_dims</a> to add a new dimension as the zero-th dimension by setting axis=0</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_norm_with_batch_dimension = np.expand_dims(X_norm, axis=<span class="number">0</span>)</span><br><span class="line">patch_pred = model.predict(X_norm_with_batch_dimension)</span><br></pre></td></tr></table></figure>
<h4 id="convert-prediction-from-probability-into-a-category">Convert prediction from probability into a category</h4>
<p>Currently, each element of <code>patch_pred</code> is a number between 0.0 and 1.0. - Each number is the model's confidence that a voxel is part of a given class. - You will convert these to discrete 0 and 1 integers by using a threshold. - We'll use a threshold of 0.5. - In real applications, you would tune this to achieve your required level of sensitivity or specificity.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set threshold.</span></span><br><span class="line">threshold = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># use threshold to get hard predictions</span></span><br><span class="line">patch_pred[patch_pred &gt; threshold] = <span class="number">1.0</span></span><br><span class="line">patch_pred[patch_pred &lt;= threshold] = <span class="number">0.0</span></span><br></pre></td></tr></table></figure>
<p>Now let's visualize the original patch and ground truth alongside our thresholded predictions.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Patch and ground truth&quot;</span>)</span><br><span class="line">util.visualize_patch(X_norm[<span class="number">0</span>, :, :, :], y[<span class="number">2</span>])</span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Patch and prediction&quot;</span>)</span><br><span class="line">util.visualize_patch(X_norm[<span class="number">0</span>, :, :, :], patch_pred[<span class="number">0</span>, <span class="number">2</span>, :, :, :])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>Patch and ground truth</code></pre>
<figure>
<img src="output_82_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<pre><code>Patch and prediction</code></pre>
<figure>
<img src="output_82_3.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<h4 id="sensitivity-and-specificity">Sensitivity and Specificity</h4>
<p>The model is covering some of the relevant areas, but it's definitely not perfect. - To quantify its performance, we can use per-pixel sensitivity and specificity.</p>
<p>Recall that in terms of the true positives, true negatives, false positives, and false negatives,</p>
<p><span class="math display">\[\text{sensitivity} = \frac{\text{true positives}}{\text{true positives} + \text{false negatives}}\]</span></p>
<p><span class="math display">\[\text{specificity} = \frac{\text{true negatives}}{\text{true negatives} + \text{false positives}}\]</span></p>
<p>Below let's write a function to compute the sensitivity and specificity per output class.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Recall that a true positive occurs when the class prediction is equal to 1, and the class label is also equal to 1
</li>
<li>
Use <a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html" > numpy.sum() </a>
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_class_sens_spec</span>(<span class="params">pred, label, class_num</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute sensitivity and specificity for a particular example</span></span><br><span class="line"><span class="string">    for a given class.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pred (np.array): binary arrary of predictions, shape is</span></span><br><span class="line"><span class="string">                         (num classes, height, width, depth).</span></span><br><span class="line"><span class="string">        label (np.array): binary array of labels, shape is</span></span><br><span class="line"><span class="string">                          (num classes, height, width, depth).</span></span><br><span class="line"><span class="string">        class_num (int): number between 0 - (num_classes -1) which says</span></span><br><span class="line"><span class="string">                         which prediction class to compute statistics</span></span><br><span class="line"><span class="string">                         for.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        sensitivity (float): precision for given class_num.</span></span><br><span class="line"><span class="string">        specificity (float): recall for given class_num</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># extract sub-array for specified class</span></span><br><span class="line">    class_pred = pred[class_num]</span><br><span class="line">    class_label = label[class_num]</span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># true positives</span></span><br><span class="line">    tp = np.<span class="built_in">sum</span>((class_label == <span class="number">1</span>) &amp; (class_pred == <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># true negatives</span></span><br><span class="line">    tn = np.<span class="built_in">sum</span>((class_label == <span class="number">0</span>) &amp; (class_pred == <span class="number">0</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#false positives</span></span><br><span class="line">    fp = np.<span class="built_in">sum</span>((class_label == <span class="number">0</span>) &amp; (class_pred == <span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># false negatives</span></span><br><span class="line">    fn = np.<span class="built_in">sum</span>((class_label == <span class="number">1</span>) &amp; (class_pred == <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute sensitivity and specificity</span></span><br><span class="line">    sensitivity = tp / (tp + fn)</span><br><span class="line">    specificity = tn / (tn + fp)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sensitivity, specificity</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TEST CASES</span></span><br><span class="line">pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Case #1&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">sensitivity, specificity = compute_class_sens_spec(pred, label, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;sensitivity: <span class="subst">&#123;sensitivity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;specificity: <span class="subst">&#123;specificity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #1
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 0.]]
sensitivity: 0.5000
specificity: 0.5000</code></pre>
<h4 id="expected-output-11">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#1</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span>]]</span><br><span class="line">sensitivity: <span class="number">0.5000</span></span><br><span class="line">specificity: <span class="number">0.5000</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Case #2&quot;</span>)</span><br><span class="line"></span><br><span class="line">pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">sensitivity, specificity = compute_class_sens_spec(pred, label, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;sensitivity: <span class="subst">&#123;sensitivity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;specificity: <span class="subst">&#123;specificity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #2
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 1.]]
sensitivity: 0.6667
specificity: 1.0000</code></pre>
<h4 id="expected-output-12">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#2</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">sensitivity: <span class="number">0.6667</span></span><br><span class="line">specificity: <span class="number">1.0000</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Note: we must explicity import &#x27;display&#x27; in order for the autograder to compile the submitted code</span></span><br><span class="line"><span class="comment"># Even though we could use this function without importing it, keep this import in order to allow the grader to work</span></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Case #3&quot;</span>)</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>: [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">                   <span class="string">&#x27;preds_test&#x27;</span>: [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                   <span class="string">&#x27;category&#x27;</span>: [<span class="string">&#x27;TP&#x27;</span>,<span class="string">&#x27;TP&#x27;</span>,<span class="string">&#x27;TN&#x27;</span>,<span class="string">&#x27;TN&#x27;</span>,<span class="string">&#x27;TN&#x27;</span>,<span class="string">&#x27;FP&#x27;</span>,<span class="string">&#x27;FP&#x27;</span>,<span class="string">&#x27;FP&#x27;</span>,<span class="string">&#x27;FP&#x27;</span>,<span class="string">&#x27;FN&#x27;</span>,<span class="string">&#x27;FN&#x27;</span>,<span class="string">&#x27;FN&#x27;</span>,<span class="string">&#x27;FN&#x27;</span>,<span class="string">&#x27;FN&#x27;</span>]</span><br><span class="line">                  &#125;)</span><br><span class="line"></span><br><span class="line">display(df)</span><br><span class="line">pred = np.array( [df[<span class="string">&#x27;preds_test&#x27;</span>]])</span><br><span class="line">label = np.array( [df[<span class="string">&#x27;y_test&#x27;</span>]])</span><br><span class="line"></span><br><span class="line">sensitivity, specificity = compute_class_sens_spec(pred, label, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;sensitivity: <span class="subst">&#123;sensitivity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;specificity: <span class="subst">&#123;specificity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #3</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
y_test
</th>
<th>
preds_test
</th>
<th>
category
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
1
</td>
<td>
TP
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
1
</td>
<td>
TP
</td>
</tr>
<tr>
<th>
2
</th>
<td>
0
</td>
<td>
0
</td>
<td>
TN
</td>
</tr>
<tr>
<th>
3
</th>
<td>
0
</td>
<td>
0
</td>
<td>
TN
</td>
</tr>
<tr>
<th>
4
</th>
<td>
0
</td>
<td>
0
</td>
<td>
TN
</td>
</tr>
<tr>
<th>
5
</th>
<td>
0
</td>
<td>
1
</td>
<td>
FP
</td>
</tr>
<tr>
<th>
6
</th>
<td>
0
</td>
<td>
1
</td>
<td>
FP
</td>
</tr>
<tr>
<th>
7
</th>
<td>
0
</td>
<td>
1
</td>
<td>
FP
</td>
</tr>
<tr>
<th>
8
</th>
<td>
0
</td>
<td>
1
</td>
<td>
FP
</td>
</tr>
<tr>
<th>
9
</th>
<td>
1
</td>
<td>
0
</td>
<td>
FN
</td>
</tr>
<tr>
<th>
10
</th>
<td>
1
</td>
<td>
0
</td>
<td>
FN
</td>
</tr>
<tr>
<th>
11
</th>
<td>
1
</td>
<td>
0
</td>
<td>
FN
</td>
</tr>
<tr>
<th>
12
</th>
<td>
1
</td>
<td>
0
</td>
<td>
FN
</td>
</tr>
<tr>
<th>
13
</th>
<td>
1
</td>
<td>
0
</td>
<td>
FN
</td>
</tr>
</tbody>
</table>
</div>
<pre><code>sensitivity: 0.2857
specificity: 0.4286</code></pre>
<h4 id="expected-output-13">Expected Output</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Test case <span class="comment">#3</span></span><br><span class="line">...</span><br><span class="line">sensitivity: <span class="number">0.2857</span></span><br><span class="line">specificity: <span class="number">0.4286</span></span><br></pre></td></tr></table></figure>
<h4 id="sensitivity-and-specificity-for-the-patch-prediction">Sensitivity and Specificity for the patch prediction</h4>
<p>Next let's compute the sensitivity and specificity on that patch for expanding tumors.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sensitivity, specificity = compute_class_sens_spec(patch_pred[<span class="number">0</span>], y, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Sensitivity: <span class="subst">&#123;sensitivity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Specificity: <span class="subst">&#123;specificity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Sensitivity: 0.8049
Specificity: 0.9924</code></pre>
<h4 id="expected-output-14">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Sensitivity: <span class="number">0.7891</span></span><br><span class="line">Specificity: <span class="number">0.9960</span></span><br></pre></td></tr></table></figure>
<p>We can also display the sensitivity and specificity for each class.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_sens_spec_df</span>(<span class="params">pred, label</span>):</span></span><br><span class="line">    patch_metrics = pd.DataFrame(</span><br><span class="line">        columns = [<span class="string">&#x27;Edema&#x27;</span>, </span><br><span class="line">                   <span class="string">&#x27;Non-Enhancing Tumor&#x27;</span>, </span><br><span class="line">                   <span class="string">&#x27;Enhancing Tumor&#x27;</span>], </span><br><span class="line">        index = [<span class="string">&#x27;Sensitivity&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;Specificity&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i, class_name <span class="keyword">in</span> <span class="built_in">enumerate</span>(patch_metrics.columns):</span><br><span class="line">        sens, spec = compute_class_sens_spec(pred, label, i)</span><br><span class="line">        patch_metrics.loc[<span class="string">&#x27;Sensitivity&#x27;</span>, class_name] = <span class="built_in">round</span>(sens,<span class="number">4</span>)</span><br><span class="line">        patch_metrics.loc[<span class="string">&#x27;Specificity&#x27;</span>, class_name] = <span class="built_in">round</span>(spec,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> patch_metrics</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = get_sens_spec_df(patch_pred[<span class="number">0</span>], y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure>
<pre><code>              Edema Non-Enhancing Tumor Enhancing Tumor
Sensitivity  0.8746              0.9419          0.8049
Specificity    0.97              0.9957          0.9924</code></pre>
<h4 id="expected-output-15">Expected output</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">              Edema Non-Enhancing Tumor Enhancing Tumor</span><br><span class="line">Sensitivity  <span class="number">0.9085</span>              <span class="number">0.9505</span>          <span class="number">0.7891</span></span><br><span class="line">Specificity  <span class="number">0.9848</span>              <span class="number">0.9961</span>           <span class="number">0.996</span></span><br></pre></td></tr></table></figure>
<p><a name="5-3"></a> ## 5.3 Running on entire scans As of now, our model just runs on patches, but what we really want to see is our model's result on a whole MRI scan.</p>
<ul>
<li>To do this, generate patches for the scan.</li>
<li>Then we run the model on the patches.</li>
<li>Then combine the results together to get a fully labeled MR image.</li>
</ul>
<p>The output of our model will be a 4D array with 3 probability values for each voxel in our data. - We then can use a threshold (which you can find by a calibration process) to decide whether or not to report a label for each voxel.</p>
<p>We have written a function that stitches the patches together: <code>predict_and_viz(image, label, model, threshold)</code> - Inputs: an image, label and model. - Ouputs: the model prediction over the whole image, and a visual of the ground truth and prediction.</p>
<p>Run the following cell to see this function in action!</p>
<h4 id="note-the-prediction-takes-some-time">Note: the prediction takes some time!</h4>
<ul>
<li>The first prediction will take about 7 to 8 minutes to run.</li>
<li>You can skip running this first prediction to save time.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># uncomment this code to run it</span></span><br><span class="line"><span class="comment"># image, label = load_case(DATA_DIR + &quot;imagesTr/BRATS_001.nii.gz&quot;, DATA_DIR + &quot;labelsTr/BRATS_001.nii.gz&quot;)</span></span><br><span class="line"><span class="comment"># pred = util.predict_and_viz(image, label, model, .5, loc=(130, 130, 77))                </span></span><br></pre></td></tr></table></figure>
<p>Here's a second prediction. - Takes about 7 to 8 minutes to run</p>
<p>Please run this second prediction so that we can check the predictions.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.getsizeof(image) / <span class="number">1000</span>  / <span class="number">1000</span></span><br></pre></td></tr></table></figure>
<pre><code>285696144</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image, label = load_case(DATA_DIR + <span class="string">&quot;imagesTr/BRATS_003.nii.gz&quot;</span>, DATA_DIR + <span class="string">&quot;labelsTr/BRATS_003.nii.gz&quot;</span>)</span><br><span class="line">pred = util.predict_and_viz(image, label, model, <span class="number">.5</span>, loc=(<span class="number">130</span>, <span class="number">130</span>, <span class="number">77</span>))                </span><br></pre></td></tr></table></figure>
<figure>
<img src="output_103_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<h4 id="check-how-well-the-predictions-do">Check how well the predictions do</h4>
<p>We can see some of the discrepancies between the model and the ground truth visually. - We can also use the functions we wrote previously to compute sensitivity and specificity for each class over the whole scan. - First we need to format the label and prediction to match our functions expect.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">whole_scan_label = keras.utils.to_categorical(label, num_classes = <span class="number">4</span>)</span><br><span class="line">whole_scan_pred = pred</span><br><span class="line"></span><br><span class="line"><span class="comment"># move axis to match shape expected in functions</span></span><br><span class="line">whole_scan_label = np.moveaxis(whole_scan_label, <span class="number">3</span> ,<span class="number">0</span>)[<span class="number">1</span>:<span class="number">4</span>]</span><br><span class="line">whole_scan_pred = np.moveaxis(whole_scan_pred, <span class="number">3</span>, <span class="number">0</span>)[<span class="number">1</span>:<span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>Now we can compute sensitivity and specificity for each class just like before.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">whole_scan_df = get_sens_spec_df(whole_scan_pred, whole_scan_label)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(whole_scan_df)</span><br></pre></td></tr></table></figure>
<pre><code>              Edema Non-Enhancing Tumor Enhancing Tumor
Sensitivity   0.902              0.2617          0.8496
Specificity  0.9894              0.9998          0.9982</code></pre>
<h1 id="thats-all-for-now">That's all for now!</h1>
<p>Congratulations on finishing this challenging assignment! You now know all the basics for building a neural auto-segmentation model for MRI images. We hope that you end up using these skills on interesting and challenging problems that you face in the real world.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/TensorFlow-js-Converter/2020/04/17/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/TensorFlow-js-Converter/2020/04/17/" class="post-title-link" itemprop="url">TensorFlow.js Converter</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-17 23:05:16" itemprop="dateCreated datePublished" datetime="2020-04-17T23:05:16+08:00">2020-04-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-18 11:07:31" itemprop="dateModified" datetime="2020-04-18T11:07:31+08:00">2020-04-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI-Workflow/" itemprop="url" rel="index"><span itemprop="name">AI Workflow</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI-Workflow/Deployment/" itemprop="url" rel="index"><span itemprop="name">Deployment</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/TensorFlow-js-Converter/2020/04/17/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/TensorFlow-js-Converter/2020/04/17/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="converting-a-keras-model-to-json-format">Converting a Keras Model to JSON Format</h1>
<p>In the previous lesson you saw how to use a CNN to make your recognition of the handwriting digits more efficient. In this lesson you'll take that to the next level, recognizing real images of Cats and Dogs in order to classify an incoming image as one or the other. In particular the handwriting recognition made your life a little easier by having all the images be the same size and shape, and they were all monochrome color. Real-world images aren't like that -- they're in different shapes, aspect ratios etc, and they're usually in color!</p>
<p>So, as part of the task you need to process your data -- not least resizing it to be uniform in shape.</p>
<p>You'll follow these steps:</p>
<ol type="1">
<li>Explore the Example Data of Cats and Dogs.</li>
<li>Build and Train a Neural Network to recognize the difference between the two.</li>
<li>Evaluate the Training and Validation accuracy.</li>
<li>Save the trained model as a Keras HDF5 file.</li>
<li>Use the tensorflow.js converter to convert the saved Keras model into JSON format.</li>
</ol>
<h1 id="import-resources">Import Resources</h1>
<p>In order to use the tensorflow.js converter we need to install <code>tensorflowjs</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%load_ext autoreload</span><br><span class="line">%autoreload <span class="number">2</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\u2022 Using TensorFlow Version:&#x27;</span>, tf.__version__)</span><br></pre></td></tr></table></figure>
<pre><code>• Using TensorFlow Version: 2.1.0</code></pre>
<h2 id="explore-the-example-data">Explore the Example Data</h2>
<p>Let's start by downloading our example data, a .zip of 2,000 JPG pictures of cats and dogs, and extracting it locally in <code>/tmp</code>.</p>
<p><strong>NOTE:</strong> The 2,000 images used in this exercise are excerpted from the <a target="_blank" rel="noopener" href="https://www.kaggle.com/c/dogs-vs-cats/data">"Dogs vs. Cats" dataset</a> available on Kaggle, which contains 25,000 images. Here, we use a subset of the full dataset to decrease training time for educational purposes.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!wget --no-check-certificate \</span><br><span class="line">  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.<span class="built_in">zip</span> \</span><br><span class="line">  -O /tmp/cats_and_dogs_filtered.<span class="built_in">zip</span></span><br></pre></td></tr></table></figure>
<pre><code>Warning: Failed to set locale category LC_NUMERIC to en_CN.
Warning: Failed to set locale category LC_TIME to en_CN.
Warning: Failed to set locale category LC_COLLATE to en_CN.
Warning: Failed to set locale category LC_MONETARY to en_CN.
Warning: Failed to set locale category LC_MESSAGES to en_CN.
--2020-02-14 21:04:38--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip
Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.12.240
Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.12.240|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 68606236 (65M) [application/zip]
Saving to: ‘/tmp/cats_and_dogs_filtered.zip’

/tmp/cats_and_dogs_ 100%[===================&gt;]  65.43M  26.3MB/s    in 2.5s    

2020-02-14 21:04:40 (26.3 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]</code></pre>
<p>The following python code will use the OS library to use Operating System libraries, giving you access to the file system, and the zipfile library allowing you to unzip the data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"></span><br><span class="line">local_zip = <span class="string">&#x27;/tmp/cats_and_dogs_filtered.zip&#x27;</span></span><br><span class="line"></span><br><span class="line">zip_ref = zipfile.ZipFile(local_zip, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">zip_ref.extractall(<span class="string">&#x27;/tmp&#x27;</span>)</span><br><span class="line">zip_ref.close()</span><br></pre></td></tr></table></figure>
<p>The contents of the .zip are extracted to the base directory <code>/tmp/cats_and_dogs_filtered</code>, which contains <code>train</code> and <code>validation</code> subdirectories for the training and validation datasets (see the <a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/crash-course/validation/check-your-intuition">Machine Learning Crash Course</a> for a refresher on training, validation, and test sets), which in turn each contain <code>cats</code> and <code>dogs</code> subdirectories.</p>
<p>In short: The training set is the data that is used to tell the neural network model that 'this is what a cat looks like', 'this is what a dog looks like' etc. The validation data set is images of cats and dogs that the neural network will not see as part of the training, so you can test how well or how badly it does in evaluating if an image contains a cat or a dog.</p>
<p>One thing to pay attention to in this sample: We do not explicitly label the images as cats or dogs. If you remember with the handwriting example earlier, we had labelled 'this is a 1', 'this is a 7' etc. Later you'll see something called an ImageGenerator being used -- and this is coded to read images from subdirectories, and automatically label them from the name of that subdirectory. So, for example, you will have a 'training' directory containing a 'cats' directory and a 'dogs' one. ImageGenerator will label the images appropriately for you, reducing a coding step.</p>
<p>Let's define each of these directories:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">base_dir = <span class="string">&#x27;/tmp/cats_and_dogs_filtered&#x27;</span></span><br><span class="line"></span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">validation_dir = os.path.join(base_dir, <span class="string">&#x27;validation&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Directory with our training cat/dog pictures</span></span><br><span class="line">train_cats_dir = os.path.join(train_dir, <span class="string">&#x27;cats&#x27;</span>)</span><br><span class="line">train_dogs_dir = os.path.join(train_dir, <span class="string">&#x27;dogs&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Directory with our validation cat/dog pictures</span></span><br><span class="line">validation_cats_dir = os.path.join(validation_dir, <span class="string">&#x27;cats&#x27;</span>)</span><br><span class="line">validation_dogs_dir = os.path.join(validation_dir, <span class="string">&#x27;dogs&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Now, let's see what the filenames look like in the <code>cats</code> and <code>dogs</code> <code>train</code> directories (file naming conventions are the same in the <code>validation</code> directory):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_cat_fnames = os.listdir( train_cats_dir )</span><br><span class="line">train_dog_fnames = os.listdir( train_dogs_dir )</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_cat_fnames[:<span class="number">10</span>])</span><br><span class="line"><span class="built_in">print</span>(train_dog_fnames[:<span class="number">10</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[&#39;cat.952.jpg&#39;, &#39;cat.946.jpg&#39;, &#39;cat.6.jpg&#39;, &#39;cat.749.jpg&#39;, &#39;cat.991.jpg&#39;, &#39;cat.985.jpg&#39;, &#39;cat.775.jpg&#39;, &#39;cat.761.jpg&#39;, &#39;cat.588.jpg&#39;, &#39;cat.239.jpg&#39;]
[&#39;dog.775.jpg&#39;, &#39;dog.761.jpg&#39;, &#39;dog.991.jpg&#39;, &#39;dog.749.jpg&#39;, &#39;dog.985.jpg&#39;, &#39;dog.952.jpg&#39;, &#39;dog.946.jpg&#39;, &#39;dog.211.jpg&#39;, &#39;dog.577.jpg&#39;, &#39;dog.563.jpg&#39;]</code></pre>
<p>Let's find out the total number of cat and dog images in the <code>train</code> and <code>validation</code> directories:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;total training cat images :&#x27;</span>, <span class="built_in">len</span>(os.listdir(      train_cats_dir ) ))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;total training dog images :&#x27;</span>, <span class="built_in">len</span>(os.listdir(      train_dogs_dir ) ))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;total validation cat images :&#x27;</span>, <span class="built_in">len</span>(os.listdir( validation_cats_dir ) ))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;total validation dog images :&#x27;</span>, <span class="built_in">len</span>(os.listdir( validation_dogs_dir ) ))</span><br></pre></td></tr></table></figure>
<pre><code>total training cat images : 1000
total training dog images : 1000
total validation cat images : 500
total validation dog images : 500</code></pre>
<p>For both cats and dogs, we have 1,000 training images and 500 validation images.</p>
<p>Now let's take a look at a few pictures to get a better sense of what the cat and dog datasets look like. First, we configure the <code>matplotlib</code> parameters:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> mpimg</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Parameters for our graph; we&#x27;ll output images in a 4x4 configuration</span></span><br><span class="line">nrows = <span class="number">4</span></span><br><span class="line">ncols = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">pic_index = <span class="number">0</span> <span class="comment"># Index for iterating over images</span></span><br></pre></td></tr></table></figure>
<p>Now, we display a batch of 8 cat and 8 dog pictures. You can re-run the cell to see a fresh batch each time:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set up matplotlib fig, and size it to fit 4x4 pics</span></span><br><span class="line">fig = plt.gcf()</span><br><span class="line">fig.set_size_inches(ncols*<span class="number">4</span>, nrows*<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">pic_index+=<span class="number">8</span></span><br><span class="line"></span><br><span class="line">next_cat_pix = [os.path.join(train_cats_dir, fname) </span><br><span class="line">                <span class="keyword">for</span> fname <span class="keyword">in</span> train_cat_fnames[ pic_index-<span class="number">8</span>:pic_index] </span><br><span class="line">               ]</span><br><span class="line"></span><br><span class="line">next_dog_pix = [os.path.join(train_dogs_dir, fname) </span><br><span class="line">                <span class="keyword">for</span> fname <span class="keyword">in</span> train_dog_fnames[ pic_index-<span class="number">8</span>:pic_index]</span><br><span class="line">               ]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, img_path <span class="keyword">in</span> <span class="built_in">enumerate</span>(next_cat_pix+next_dog_pix):</span><br><span class="line">    <span class="comment"># Set up subplot; subplot indices start at 1</span></span><br><span class="line">    sp = plt.subplot(nrows, ncols, i + <span class="number">1</span>)</span><br><span class="line">    sp.axis(<span class="string">&#x27;Off&#x27;</span>) <span class="comment"># Don&#x27;t show axes (or gridlines)</span></span><br><span class="line">    </span><br><span class="line">    img = mpimg.imread(img_path)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_17_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>It may not be obvious from looking at the images in this grid, but an important note here, and a significant difference from the previous lesson is that these images come in all shapes and sizes. When you did the handwriting recognition example, you had 28x28 greyscale images to work with. These are color and in a variety of shapes. Before training a Neural network with them you'll need to tweak the images. You'll see that in the next section.</p>
<p>Ok, now that you have an idea for what your data looks like, the next step is to define the model that will be trained to recognize cats or dogs from these images</p>
<h2 id="building-a-small-model-from-scratch-to-get-to-72-accuracy">Building a Small Model from Scratch to Get to ~72% Accuracy</h2>
<p>In the previous section you saw that the images were in a variety of shapes and sizes. In order to train a neural network to handle them you'll need them to be in a uniform size. We've chosen 150x150 for this, and you'll see the code that preprocesses the images to that shape shortly.</p>
<p>But before we continue, let's start defining the model. We will define a Sequential layer as before, adding some convolutional layers first. Note the input shape parameter this time. In the earlier example it was 28x28x1, because the image was 28x28 in greyscale (8 bits, 1 byte for color depth). This time it is 150x150 for the size and 3 (24 bits, 3 bytes) for the color depth.</p>
<p>We then add a couple of convolutional layers as in the previous example, and flatten the final result to feed into the densely connected layers.</p>
<p>Finally we add the densely connected layers.</p>
<p>Note that because we are facing a two-class classification problem, i.e. a <em>binary classification problem</em>, we will end our network with a <a target="_blank" rel="noopener" href="https://wikipedia.org/wiki/Sigmoid_function"><em>sigmoid</em> activation</a>, so that the output of our network will be a single scalar between 0 and 1, encoding the probability that the current image is class 1 (as opposed to class 0).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    <span class="comment"># Note the input shape is the desired size of the image 150x150 with 3 bytes color</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>), </span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>), </span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># Flatten the results to feed into a DNN</span></span><br><span class="line">    tf.keras.layers.Flatten(), </span><br><span class="line">    <span class="comment"># 512 neuron hidden layer</span></span><br><span class="line">    tf.keras.layers.Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>), </span><br><span class="line">    <span class="comment"># Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class (&#x27;cats&#x27;) and 1 for the other (&#x27;dogs&#x27;)</span></span><br><span class="line">    tf.keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)  </span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>The <code>model.summary()</code> method call prints a summary of the NN</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 148, 148, 16)      448       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         
_________________________________________________________________
flatten (Flatten)            (None, 18496)             0         
_________________________________________________________________
dense (Dense)                (None, 512)               9470464   
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 513       
=================================================================
Total params: 9,494,561
Trainable params: 9,494,561
Non-trainable params: 0
_________________________________________________________________</code></pre>
<p>The "output shape" column shows how the size of your feature map evolves in each successive layer. The convolution layers reduce the size of the feature maps by a bit due to padding, and each pooling layer halves the dimensions.</p>
<p>Next, we'll configure the specifications for model training. We will train our model with the <code>binary_crossentropy</code> loss, because it's a binary classification problem and our final activation is a sigmoid. (For a refresher on loss metrics, see the <a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/crash-course/descending-into-ml/video-lecture">Machine Learning Crash Course</a>.) We will use the <code>rmsprop</code> optimizer with a learning rate of <code>0.001</code>. During training, we will want to monitor classification accuracy.</p>
<p><strong>NOTE</strong>: In this case, using the <a target="_blank" rel="noopener" href="https://wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp">RMSprop optimization algorithm</a> is preferable to <a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/glossary/#SGD">stochastic gradient descent</a> (SGD), because RMSprop automates learning-rate tuning for us. (Other optimizers, such as <a target="_blank" rel="noopener" href="https://wikipedia.org/wiki/Stochastic_gradient_descent#Adam">Adam</a> and <a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/glossary/#AdaGrad">Adagrad</a>, also automatically adapt the learning rate during training, and would work equally well here.)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=RMSprop(lr=<span class="number">0.001</span>),</span><br><span class="line">              loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              metrics = [<span class="string">&#x27;acc&#x27;</span>])</span><br></pre></td></tr></table></figure>
<h3 id="data-preprocessing">Data Preprocessing</h3>
<p>Let's set up data generators that will read pictures in our source folders, convert them to <code>float32</code> tensors, and feed them (with their labels) to our network. We'll have one generator for the training images and one for the validation images. Our generators will yield batches of 20 images of size 150x150 and their labels (binary).</p>
<p>As you may already know, data that goes into neural networks should usually be normalized in some way to make it more amenable to processing by the network. (It is uncommon to feed raw pixels into a convnet.) In our case, we will preprocess our images by normalizing the pixel values to be in the <code>[0, 1]</code> range (originally all values are in the <code>[0, 255]</code> range).</p>
<p>In Keras this can be done via the <code>keras.preprocessing.image.ImageDataGenerator</code> class using the <code>rescale</code> parameter. This <code>ImageDataGenerator</code> class allows you to instantiate generators of augmented image batches (and their labels) via <code>.flow(data, labels)</code> or <code>.flow_from_directory(directory)</code>. These generators can then be used with the Keras model methods that accept data generators as inputs: <code>fit_generator</code>, <code>evaluate_generator</code>, and <code>predict_generator</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line"><span class="comment"># All images will be rescaled by 1./255.</span></span><br><span class="line">train_datagen = ImageDataGenerator( rescale = <span class="number">1.0</span>/<span class="number">255.</span> )</span><br><span class="line">test_datagen  = ImageDataGenerator( rescale = <span class="number">1.0</span>/<span class="number">255.</span> )</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------</span></span><br><span class="line"><span class="comment"># Flow training images in batches of 20 using train_datagen generator</span></span><br><span class="line"><span class="comment"># --------------------</span></span><br><span class="line">train_generator = train_datagen.flow_from_directory(train_dir,</span><br><span class="line">                                                    batch_size=<span class="number">20</span>,</span><br><span class="line">                                                    class_mode=<span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">                                                    target_size=(<span class="number">150</span>, <span class="number">150</span>))     </span><br><span class="line"><span class="comment"># --------------------</span></span><br><span class="line"><span class="comment"># Flow validation images in batches of 20 using test_datagen generator</span></span><br><span class="line"><span class="comment"># --------------------</span></span><br><span class="line">validation_generator =  test_datagen.flow_from_directory(validation_dir,</span><br><span class="line">                                                         batch_size=<span class="number">20</span>,</span><br><span class="line">                                                         class_mode  = <span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">                                                         target_size = (<span class="number">150</span>, <span class="number">150</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.</code></pre>
<h3 id="training">Training</h3>
<p>Let's train on all 2,000 images available, for 15 epochs, and validate on all 1,000 test images. (This may take a few minutes to run.)</p>
<p>Do note the values per epoch.</p>
<p>You'll see 4 values per epoch -- Loss, Accuracy, Validation Loss and Validation Accuracy.</p>
<p>The Loss and Accuracy are a great indication of progress of training. It's making a guess as to the classification of the training data, and then measuring it against the known label, calculating the result. Accuracy is the portion of correct guesses. The Validation accuracy is the measurement with the data that has not been used in training. As expected this would be a bit lower. You'll learn about why this occurs in the section on overfitting later in this course.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit_generator(train_generator,</span><br><span class="line">                              validation_data=validation_generator,</span><br><span class="line">                              steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">                              epochs=<span class="number">15</span>,</span><br><span class="line">                              validation_steps=<span class="number">50</span>,</span><br><span class="line">                              verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From &lt;ipython-input-17-c57227122236&gt;:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  [&#39;...&#39;]
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  [&#39;...&#39;]
Train for 100 steps, validate for 50 steps
Epoch 1/15
100/100 - 24s - loss: 0.9314 - acc: 0.5660 - val_loss: 0.6656 - val_acc: 0.6120
Epoch 2/15
100/100 - 25s - loss: 0.6632 - acc: 0.6310 - val_loss: 0.7892 - val_acc: 0.5310
Epoch 3/15
100/100 - 24s - loss: 0.5777 - acc: 0.7025 - val_loss: 0.5888 - val_acc: 0.6900
Epoch 4/15
100/100 - 23s - loss: 0.4736 - acc: 0.7785 - val_loss: 0.6290 - val_acc: 0.6970
Epoch 5/15
100/100 - 23s - loss: 0.3826 - acc: 0.8310 - val_loss: 0.6550 - val_acc: 0.6990
Epoch 6/15
100/100 - 23s - loss: 0.3170 - acc: 0.8695 - val_loss: 0.7551 - val_acc: 0.6940
Epoch 7/15
100/100 - 23s - loss: 0.2174 - acc: 0.9075 - val_loss: 1.0175 - val_acc: 0.6640
Epoch 8/15
100/100 - 23s - loss: 0.1598 - acc: 0.9420 - val_loss: 1.3129 - val_acc: 0.6650
Epoch 9/15
100/100 - 23s - loss: 0.1329 - acc: 0.9570 - val_loss: 1.1711 - val_acc: 0.6890
Epoch 10/15
100/100 - 23s - loss: 0.0960 - acc: 0.9735 - val_loss: 1.3053 - val_acc: 0.7130
Epoch 11/15
100/100 - 23s - loss: 0.0709 - acc: 0.9800 - val_loss: 1.5509 - val_acc: 0.6970
Epoch 12/15
100/100 - 23s - loss: 0.0496 - acc: 0.9865 - val_loss: 5.7583 - val_acc: 0.5370
Epoch 13/15
100/100 - 25s - loss: 0.0885 - acc: 0.9800 - val_loss: 3.9976 - val_acc: 0.5910
Epoch 14/15
100/100 - 23s - loss: 0.0423 - acc: 0.9830 - val_loss: 1.8770 - val_acc: 0.7040
Epoch 15/15
100/100 - 23s - loss: 0.0480 - acc: 0.9900 - val_loss: 2.3820 - val_acc: 0.6860</code></pre>
<h3 id="evaluating-accuracy-and-loss-for-the-model">Evaluating Accuracy and Loss for the Model</h3>
<p>Let's plot the training/validation accuracy and loss as collected during training:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-----------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Retrieve a list of list results on training and test data</span></span><br><span class="line"><span class="comment"># sets for each training epoch</span></span><br><span class="line"><span class="comment">#-----------------------------------------------------------</span></span><br><span class="line">acc      = history.history[     <span class="string">&#x27;acc&#x27;</span> ]</span><br><span class="line">val_acc  = history.history[ <span class="string">&#x27;val_acc&#x27;</span> ]</span><br><span class="line">loss     = history.history[    <span class="string">&#x27;loss&#x27;</span> ]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span> ]</span><br><span class="line"></span><br><span class="line">epochs   = <span class="built_in">range</span>(<span class="built_in">len</span>(acc)) <span class="comment"># Get number of epochs</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line"><span class="comment"># Plot training and validation accuracy per epoch</span></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line">plt.plot  ( epochs,     acc, label=<span class="string">&#x27;Training&#x27;</span>)</span><br><span class="line">plt.plot  ( epochs, val_acc, label=<span class="string">&#x27;Validation&#x27;</span>)</span><br><span class="line">plt.title (<span class="string">&#x27;Training and validation accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line"><span class="comment"># Plot training and validation loss per epoch</span></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line">plt.plot  ( epochs,     loss, label=<span class="string">&#x27;Training&#x27;</span>)</span><br><span class="line">plt.plot  ( epochs, val_loss, label=<span class="string">&#x27;Validation&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title (<span class="string">&#x27;Training and validation loss&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Text(0.5, 1.0, &#39;Training and validation loss&#39;)</code></pre>
<figure>
<img src="output_31_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_31_2.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>As you can see, we are <strong>overfitting</strong> like it's getting out of fashion. Our training accuracy (in blue) gets close to 100% (!) while our validation accuracy (in orange) stalls as 70%. Our validation loss reaches its minimum after only five epochs.</p>
<p>Since we have a relatively small number of training examples (2000), overfitting should be our number one concern. Overfitting happens when a model exposed to too few examples learns patterns that do not generalize to new data, i.e. when the model starts using irrelevant features for making predictions. For instance, if you, as a human, only see three images of people who are lumberjacks, and three images of people who are sailors, and among them the only person wearing a cap is a lumberjack, you might start thinking that wearing a cap is a sign of being a lumberjack as opposed to a sailor. You would then make a pretty lousy lumberjack/sailor classifier.</p>
<p>Overfitting is the central problem in machine learning: given that we are fitting the parameters of our model to a given dataset, how can we make sure that the representations learned by the model will be applicable to data never seen before? How do we avoid learning things that are specific to the training data?</p>
<p>In the next exercise, we'll look at ways to prevent overfitting in the cat vs. dog classification model.</p>
<h2 id="save-the-model">Save the Model</h2>
<p>In the cell below, save the trained model as a Keras model (<code>.h5</code> file).</p>
<p><strong>HINT</strong>: Use <code>model.save()</code>. Feel free to take a look at the <code>Linear-to-JavaScript.ipynb</code> example.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># EXERCISE: Save the trained model as a Keras HDF5 file. </span></span><br><span class="line"></span><br><span class="line">saved_model_path = <span class="string">&quot;./my_model.h5&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># YOUR CODE HERE</span></span><br><span class="line">model.save(saved_model_path)</span><br></pre></td></tr></table></figure>
<h2 id="run-the-tensorflow.js-converter-on-the-saved-keras-model">Run the TensorFlow.js Converter on The Saved Keras Model</h2>
<p>In the cell below, use the <code>tensorflowjs_converter</code> to convert the saved Keras model into JSON format.</p>
<p><strong>HINT</strong>: Make sure you specify the format of the input model as Keras by using the <code>--input_format</code> option. Feel free to take a look at the <code>Linear-to-JavaScript.ipynb</code> example and the <a target="_blank" rel="noopener" href="https://github.com/tensorflow/tfjs/tree/master/tfjs-converter#step-1-converting-a-tensorflow-savedmodel-tensorflow-hub-module-keras-hdf5-or-tfkeras-savedmodel-to-a-web-friendly-format">TensorFlow.js converter documentation</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># EXERCISE: Use the tensorflow.js converter to convert the saved Keras model into JSON format.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># YOUR CODE HERE</span></span><br><span class="line">! tensorflowjs_converter \</span><br><span class="line">    --input_format=keras \</span><br><span class="line">    &#123;saved_model_path&#125; \</span><br><span class="line">    <span class="string">&quot;./&quot;</span></span><br></pre></td></tr></table></figure>
<p>If you did things correctly, you should now have a <strong>JSON</strong> file named <code>model.json</code> and various <code>.bin</code> files, such as <code>group1-shard1of10.bin</code>. The number of <code>.bin</code> files will depend on the size of your model: the larger your model, the greater the number of <code>.bin</code> files. The <code>model.json</code> file contains the architecture of your model and the <code>.bin</code> files will contain the weights of your model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Evaluation-of-Diagnostic-Models/2020/04/17/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Evaluation-of-Diagnostic-Models/2020/04/17/" class="post-title-link" itemprop="url">Evaluation of Diagnostic Models</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-17 18:54:09" itemprop="dateCreated datePublished" datetime="2020-04-17T18:54:09+08:00">2020-04-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-12-31 15:55:19" itemprop="dateModified" datetime="2021-12-31T15:55:19+08:00">2021-12-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Evaluation-of-Diagnostic-Models/2020/04/17/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Evaluation-of-Diagnostic-Models/2020/04/17/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Evaluation of Diagnostic Models</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/Evaluation-of-Diagnostic-Models/2020/04/17/">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/" class="post-title-link" itemprop="url">Chest X-Ray Medical Diagnosis with Deep Learning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-15 21:11:55" itemprop="dateCreated datePublished" datetime="2020-04-15T21:11:55+08:00">2020-04-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-16 09:49:43" itemprop="dateModified" datetime="2020-04-16T09:49:43+08:00">2020-04-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Chest-X-Ray-Medical-Diagnosis-with-Deep-Learning/2020/04/15/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>This is the assignment of coursera course <a target="_blank" rel="noopener" href="https://www.coursera.org/learn/ai-for-medical-diagnosis/">Medical Diagnosis</a> from deeplearning.ai</li>
</ul>
<h1 id="chest-x-ray-medical-diagnosis-with-deep-learning">Chest X-Ray Medical Diagnosis with Deep Learning</h1>
<p><img src="output_1.png" style="padding-top: 50px;width: 87%;left: 0px;margin-left: 0px;margin-right: 0px;"></p>
<p>Welcome to the first assignment of course 1</p>
<p>In this assignment! You will explore medical image diagnosis by building a state-of-the-art chest X-ray classifier using Keras.</p>
<p>The assignment will walk through some of the steps of building and evaluating this deep learning classifier model. In particular, you will: - Pre-process and prepare a real-world X-ray dataset - Use transfer learning to retrain a DenseNet model for X-ray image classification - Learn a technique to handle class imbalance - Measure diagnostic performance by computing the AUC (Area Under the Curve) for the ROC (Receiver Operating Characteristic) curve - Visualize model activity using GradCAMs</p>
<p>In completing this assignment you will learn about the following topics:</p>
<ul>
<li>Data preparation
<ul>
<li>Visualizing data</li>
<li>Preventing data leakage</li>
</ul></li>
<li>Model Development
<ul>
<li>Addressing class imbalance</li>
<li>Leveraging pre-trained models using transfer learning</li>
</ul></li>
<li>Evaluation
<ul>
<li>AUC and ROC curves</li>
</ul></li>
</ul>
<h2 id="outline">Outline</h2>
<p>Use these links to jump to specific sections of this assignment!</p>
<ul>
<li><a href="#1">1. Import Packages and Function</a></li>
<li><a href="#2">2. Load the Datasets</a>
<ul>
<li><a href="#2-1">2.1 Preventing Data Leakage</a>
<ul>
<li><a href="#Ex-1">Exercise 1 - Checking Data Leakage</a></li>
</ul></li>
<li><a href="#2-2">2.2 Preparing Images</a></li>
</ul></li>
<li><a href="#3">3. Model Development</a>
<ul>
<li><a href="#3-1">3.1 Addressing Class Imbalance</a>
<ul>
<li><a href="#Ex-2">Exercise 2 - Computing Class Frequencies</a></li>
<li><a href="#Ex-3">Exercise 3 - Weighted Loss</a></li>
</ul></li>
<li><a href="#3-3">3.3 DenseNet121</a></li>
</ul></li>
<li><a href="#4">4. Training [optional]</a>
<ul>
<li><a href="#4-1">4.1 Training on the Larger Dataset</a></li>
</ul></li>
<li><a href="#5">5. Prediction and Evaluation</a>
<ul>
<li><a href="#5-1">5.1 ROC Curve and AUROC</a></li>
<li><a href="#5-2">5.2 Visualizing Learning with GradCAM</a></li>
</ul></li>
</ul>
<p><a name='1'></a> ## 1. Import Packages and Functions¶</p>
<p>We'll make use of the following packages: - <code>numpy</code> and <code>pandas</code> is what we'll use to manipulate our data - <code>matplotlib.pyplot</code> and <code>seaborn</code> will be used to produce plots for visualization - <code>util</code> will provide the locally defined utility functions that have been provided for this assignment</p>
<p>We will also use several modules from the <code>keras</code> framework for building deep learning models.</p>
<p>Run the next cell to import all the necessary packages.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.applications.densenet <span class="keyword">import</span> DenseNet121</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, GlobalAveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> util</span><br></pre></td></tr></table></figure>
<p><a name='2'></a> ## 2 Load the Datasets</p>
<p>For this assignment, we will be using the <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.02315">ChestX-ray8 dataset</a> which contains 108,948 frontal-view X-ray images of 32,717 unique patients. - Each image in the data set contains multiple text-mined labels identifying 14 different pathological conditions. - These in turn can be used by physicians to diagnose 8 different diseases. - We will use this data to develop a single model that will provide binary classification predictions for each of the 14 labeled pathologies. - In other words it will predict 'positive' or 'negative' for each of the pathologies.</p>
<p>You can download the entire dataset for free <a target="_blank" rel="noopener" href="https://nihcc.app.box.com/v/ChestXray-NIHCC">here</a>. - We have provided a ~1000 image subset of the images for you. - These can be accessed in the folder path stored in the <code>IMAGE_DIR</code> variable.</p>
<p>The dataset includes a CSV file that provides the labels for each X-ray.</p>
<p>To make your job a bit easier, we have processed the labels for our small sample and generated three new files to get you started. These three files are:</p>
<ol type="1">
<li><code>nih/train-small.csv</code>: 875 images from our dataset to be used for training.</li>
<li><code>nih/valid-small.csv</code>: 109 images from our dataset to be used for validation.</li>
<li><code>nih/test.csv</code>: 420 images from our dataset to be used for testing.</li>
</ol>
<p>This dataset has been annotated by consensus among four different radiologists for 5 of our 14 pathologies: - <code>Consolidation</code> - <code>Edema</code> - <code>Effusion</code> - <code>Cardiomegaly</code> - <code>Atelectasis</code></p>
<h4 id="sidebar-on-meaning-of-class">Sidebar on meaning of 'class'</h4>
<p>It is worth noting that the word <strong>'class'</strong> is used in multiple ways is these discussions. - We sometimes refer to each of the 14 pathological conditions that are labeled in our dataset as a class. - But for each of those pathologies we are attempting to predict whether a certain condition is present (i.e. positive result) or absent (i.e. negative result). - These two possible labels of 'positive' or 'negative' (or the numerical equivalent of 1 or 0) are also typically referred to as classes. - Moreover, we also use the term in reference to software code 'classes' such as <code>ImageDataGenerator</code>.</p>
<p>As long as you are aware of all this though, it should not cause you any confusion as the term 'class' is usually clear from the context in which it is used.</p>
<h4 id="read-in-the-data">Read in the data</h4>
<p>Let's open these files using the <a target="_blank" rel="noopener" href="https://pandas.pydata.org/">pandas</a> library</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">train_df = pd.read_csv(<span class="string">&quot;nih/train-small.csv&quot;</span>)</span><br><span class="line">valid_df = pd.read_csv(<span class="string">&quot;nih/valid-small.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">test_df = pd.read_csv(<span class="string">&quot;nih/test.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Image
</th>
<th>
Atelectasis
</th>
<th>
Cardiomegaly
</th>
<th>
Consolidation
</th>
<th>
Edema
</th>
<th>
Effusion
</th>
<th>
Emphysema
</th>
<th>
Fibrosis
</th>
<th>
Hernia
</th>
<th>
Infiltration
</th>
<th>
Mass
</th>
<th>
Nodule
</th>
<th>
PatientId
</th>
<th>
Pleural_Thickening
</th>
<th>
Pneumonia
</th>
<th>
Pneumothorax
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
00027079_001.png
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
27079
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
00004477_001.png
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
4477
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
00018530_002.png
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
18530
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
3
</th>
<td>
00026928_001.png
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
26928
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
4
</th>
<td>
00016687_000.png
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
16687
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df.shape</span><br></pre></td></tr></table></figure>
<pre><code>(875, 16)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">labels = [<span class="string">&#x27;Cardiomegaly&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Emphysema&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Effusion&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Hernia&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Infiltration&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Mass&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Nodule&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Atelectasis&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;Pneumothorax&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;Pleural_Thickening&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Pneumonia&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Fibrosis&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Edema&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;Consolidation&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p><a name='2-1'></a> ### 2.1 Preventing Data Leakage It is worth noting that our dataset contains multiple images for each patient. This could be the case, for example, when a patient has taken multiple X-ray images at different times during their hospital visits. In our data splitting, we have ensured that the split is done on the patient level so that there is no data "leakage" between the train, validation, and test datasets.</p>
<p><a name='Ex-1'></a> ### Exercise 1 - Checking Data Leakage In the cell below, write a function to check whether there is leakage between two datasets. We'll use this to make sure there are no patients in the test set that are also present in either the train or validation sets.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Make use of python's set.intersection() function.
</li>
<li>
In order to match the automatic grader's expectations, please start the line of code with <code>df1_patients_unique...[continue your code here]</code>
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_for_leakage</span>(<span class="params">df1, df2, patient_col</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Return True if there any patients are in both df1 and df2.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        df1 (dataframe): dataframe describing first dataset</span></span><br><span class="line"><span class="string">        df2 (dataframe): dataframe describing second dataset</span></span><br><span class="line"><span class="string">        patient_col (str): string name of column with patient IDs</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        leakage (bool): True if there is leakage, otherwise False</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    df1_patients_unique = <span class="built_in">set</span>(df1[patient_col].unique().tolist())</span><br><span class="line">    df2_patients_unique = <span class="built_in">set</span>(df2[patient_col].unique().tolist())</span><br><span class="line">    </span><br><span class="line">    patients_in_both_groups = df1_patients_unique.intersection(df2_patients_unique)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># leakage contains true if there is patient overlap, otherwise false.</span></span><br><span class="line">    leakage = <span class="built_in">len</span>(patients_in_both_groups) &gt;= <span class="number">1</span> <span class="comment"># boolean (true if there is at least 1 patient in both groups)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> leakage</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test case 1&quot;</span>)</span><br><span class="line">df1 = pd.DataFrame(&#123;<span class="string">&#x27;patient_id&#x27;</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]&#125;)</span><br><span class="line">df2 = pd.DataFrame(&#123;<span class="string">&#x27;patient_id&#x27;</span>: [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;df1&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;df2&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;leakage output: <span class="subst">&#123;check_for_leakage(df1, df2, <span class="string">&#x27;patient_id&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-------------------------------------&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test case 2&quot;</span>)</span><br><span class="line">df1 = pd.DataFrame(&#123;<span class="string">&#x27;patient_id&#x27;</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]&#125;)</span><br><span class="line">df2 = pd.DataFrame(&#123;<span class="string">&#x27;patient_id&#x27;</span>: [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;df1:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;df2:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;leakage output: <span class="subst">&#123;check_for_leakage(df1, df2, <span class="string">&#x27;patient_id&#x27;</span>)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>test case 1
df1
   patient_id
0           0
1           1
2           2
df2
   patient_id
0           2
1           3
2           4
leakage output: True
-------------------------------------
test case 2
df1:
   patient_id
0           0
1           1
2           2
df2:
   patient_id
0           3
1           4
2           5
leakage output: False</code></pre>
<h5 id="expected-output">Expected output</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">test case <span class="number">1</span></span><br><span class="line">df1</span><br><span class="line">   patient_id</span><br><span class="line"><span class="number">0</span>           <span class="number">0</span></span><br><span class="line"><span class="number">1</span>           <span class="number">1</span></span><br><span class="line"><span class="number">2</span>           <span class="number">2</span></span><br><span class="line">df2</span><br><span class="line">   patient_id</span><br><span class="line"><span class="number">0</span>           <span class="number">2</span></span><br><span class="line"><span class="number">1</span>           <span class="number">3</span></span><br><span class="line"><span class="number">2</span>           <span class="number">4</span></span><br><span class="line">leakage output: <span class="literal">True</span></span><br><span class="line">-------------------------------------</span><br><span class="line">test case <span class="number">2</span></span><br><span class="line">df1:</span><br><span class="line">   patient_id</span><br><span class="line"><span class="number">0</span>           <span class="number">0</span></span><br><span class="line"><span class="number">1</span>           <span class="number">1</span></span><br><span class="line"><span class="number">2</span>           <span class="number">2</span></span><br><span class="line">df2:</span><br><span class="line">   patient_id</span><br><span class="line"><span class="number">0</span>           <span class="number">3</span></span><br><span class="line"><span class="number">1</span>           <span class="number">4</span></span><br><span class="line"><span class="number">2</span>           <span class="number">5</span></span><br><span class="line">leakage output: <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>Run the next cell to check if there are patients in both train and test or in both valid and test.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;leakage between train and test: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(check_for_leakage(train_df, test_df, <span class="string">&#x27;PatientId&#x27;</span>)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;leakage between valid and test: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(check_for_leakage(valid_df, test_df, <span class="string">&#x27;PatientId&#x27;</span>)))</span><br></pre></td></tr></table></figure>
<pre><code>leakage between train and test: False
leakage between valid and test: False</code></pre>
<p>If we get <code>False</code> for both, then we're ready to start preparing the datasets for training. Remember to always check for data leakage!</p>
<p><a name='2-2'></a> ### 2.2 Preparing Images</p>
<p>With our dataset splits ready, we can now proceed with setting up our model to consume them. - For this we will use the off-the-shelf <a target="_blank" rel="noopener" href="https://keras.io/preprocessing/image/">ImageDataGenerator</a> class from the Keras framework, which allows us to build a "generator" for images specified in a dataframe. - This class also provides support for basic data augmentation such as random horizontal flipping of images. - We also use the generator to transform the values in each batch so that their mean is <span class="math inline">\(0\)</span> and their standard deviation is 1. - This will facilitate model training by standardizing the input distribution. - The generator also converts our single channel X-ray images (gray-scale) to a three-channel format by repeating the values in the image across all channels. - We will want this because the pre-trained model that we'll use requires three-channel inputs.</p>
<p>Since it is mainly a matter of reading and understanding Keras documentation, we have implemented the generator for you. There are a few things to note: 1. We normalize the mean and standard deviation of the data 3. We shuffle the input after each epoch. 4. We set the image size to be 320px by 320px</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_train_generator</span>(<span class="params">df, image_dir, x_col, y_cols, shuffle=<span class="literal">True</span>, batch_size=<span class="number">8</span>, seed=<span class="number">1</span>, target_w = <span class="number">320</span>, target_h = <span class="number">320</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Return generator for training set, normalizing using batch</span></span><br><span class="line"><span class="string">    statistics.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      train_df (dataframe): dataframe specifying training data.</span></span><br><span class="line"><span class="string">      image_dir (str): directory where image files are held.</span></span><br><span class="line"><span class="string">      x_col (str): name of column in df that holds filenames.</span></span><br><span class="line"><span class="string">      y_cols (list): list of strings that hold y labels for images.</span></span><br><span class="line"><span class="string">      sample_size (int): size of sample to use for normalization statistics.</span></span><br><span class="line"><span class="string">      batch_size (int): images per batch to be fed into model during training.</span></span><br><span class="line"><span class="string">      seed (int): random seed.</span></span><br><span class="line"><span class="string">      target_w (int): final width of input images.</span></span><br><span class="line"><span class="string">      target_h (int): final height of input images.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        train_generator (DataFrameIterator): iterator over training set</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>        </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;getting train generator...&quot;</span>) </span><br><span class="line">    <span class="comment"># normalize images</span></span><br><span class="line">    image_generator = ImageDataGenerator(</span><br><span class="line">        samplewise_center=<span class="literal">True</span>,</span><br><span class="line">        samplewise_std_normalization= <span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># flow from directory with specified batch size</span></span><br><span class="line">    <span class="comment"># and target image size</span></span><br><span class="line">    generator = image_generator.flow_from_dataframe(</span><br><span class="line">            dataframe=df,</span><br><span class="line">            directory=image_dir,</span><br><span class="line">            x_col=x_col,</span><br><span class="line">            y_col=y_cols,</span><br><span class="line">            class_mode=<span class="string">&quot;raw&quot;</span>,</span><br><span class="line">            batch_size=batch_size,</span><br><span class="line">            shuffle=shuffle,</span><br><span class="line">            seed=seed,</span><br><span class="line">            target_size=(target_w,target_h))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> generator</span><br></pre></td></tr></table></figure>
<h4 id="build-a-separate-generator-for-valid-and-test-sets">Build a separate generator for valid and test sets</h4>
<p>Now we need to build a new generator for validation and testing data.</p>
<p><strong>Why can't we use the same generator as for the training data?</strong></p>
<p>Look back at the generator we wrote for the training data. - It normalizes each image <strong>per batch</strong>, meaning that it uses batch statistics. - We should not do this with the test and validation data, since in a real life scenario we don't process incoming images a batch at a time (we process one image at a time). - Knowing the average per batch of test data would effectively give our model an advantage.<br />
- The model should not have any information about the test data.</p>
<p>What we need to do is normalize incoming test data using the statistics <strong>computed from the training set</strong>. * We implement this in the function below. * There is one technical note. Ideally, we would want to compute our sample mean and standard deviation using the entire training set. * However, since this is extremely large, that would be very time consuming. * In the interest of time, we'll take a random sample of the dataset and calcualte the sample mean and sample standard deviation.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_test_and_valid_generator</span>(<span class="params">valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=<span class="number">100</span>, batch_size=<span class="number">8</span>, seed=<span class="number">1</span>, target_w = <span class="number">320</span>, target_h = <span class="number">320</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Return generator for validation set and test test set using </span></span><br><span class="line"><span class="string">    normalization statistics from training set.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      valid_df (dataframe): dataframe specifying validation data.</span></span><br><span class="line"><span class="string">      test_df (dataframe): dataframe specifying test data.</span></span><br><span class="line"><span class="string">      train_df (dataframe): dataframe specifying training data.</span></span><br><span class="line"><span class="string">      image_dir (str): directory where image files are held.</span></span><br><span class="line"><span class="string">      x_col (str): name of column in df that holds filenames.</span></span><br><span class="line"><span class="string">      y_cols (list): list of strings that hold y labels for images.</span></span><br><span class="line"><span class="string">      sample_size (int): size of sample to use for normalization statistics.</span></span><br><span class="line"><span class="string">      batch_size (int): images per batch to be fed into model during training.</span></span><br><span class="line"><span class="string">      seed (int): random seed.</span></span><br><span class="line"><span class="string">      target_w (int): final width of input images.</span></span><br><span class="line"><span class="string">      target_h (int): final height of input images.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        test_generator (DataFrameIterator) and valid_generator: iterators over test set and validation set respectively</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;getting train and valid generators...&quot;</span>)</span><br><span class="line">    <span class="comment"># get generator to sample dataset</span></span><br><span class="line">    raw_train_generator = ImageDataGenerator().flow_from_dataframe(</span><br><span class="line">        dataframe=train_df, </span><br><span class="line">        directory=IMAGE_DIR, </span><br><span class="line">        x_col=<span class="string">&quot;Image&quot;</span>, </span><br><span class="line">        y_col=labels, </span><br><span class="line">        class_mode=<span class="string">&quot;raw&quot;</span>, </span><br><span class="line">        batch_size=sample_size, </span><br><span class="line">        shuffle=<span class="literal">True</span>, </span><br><span class="line">        target_size=(target_w, target_h))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># get data sample</span></span><br><span class="line">    batch = raw_train_generator.<span class="built_in">next</span>()</span><br><span class="line">    data_sample = batch[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># use sample to fit mean and std for test set generator</span></span><br><span class="line">    image_generator = ImageDataGenerator(</span><br><span class="line">        featurewise_center=<span class="literal">True</span>,</span><br><span class="line">        featurewise_std_normalization= <span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># fit generator to sample from training data</span></span><br><span class="line">    image_generator.fit(data_sample)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get test generator</span></span><br><span class="line">    valid_generator = image_generator.flow_from_dataframe(</span><br><span class="line">            dataframe=valid_df,</span><br><span class="line">            directory=image_dir,</span><br><span class="line">            x_col=x_col,</span><br><span class="line">            y_col=y_cols,</span><br><span class="line">            class_mode=<span class="string">&quot;raw&quot;</span>,</span><br><span class="line">            batch_size=batch_size,</span><br><span class="line">            shuffle=<span class="literal">False</span>,</span><br><span class="line">            seed=seed,</span><br><span class="line">            target_size=(target_w,target_h))</span><br><span class="line"></span><br><span class="line">    test_generator = image_generator.flow_from_dataframe(</span><br><span class="line">            dataframe=test_df,</span><br><span class="line">            directory=image_dir,</span><br><span class="line">            x_col=x_col,</span><br><span class="line">            y_col=y_cols,</span><br><span class="line">            class_mode=<span class="string">&quot;raw&quot;</span>,</span><br><span class="line">            batch_size=batch_size,</span><br><span class="line">            shuffle=<span class="literal">False</span>,</span><br><span class="line">            seed=seed,</span><br><span class="line">            target_size=(target_w,target_h))</span><br><span class="line">    <span class="keyword">return</span> valid_generator, test_generator</span><br></pre></td></tr></table></figure>
<p>With our generator function ready, let's make one generator for our training data and one each of our test and validation datasets.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">IMAGE_DIR = <span class="string">&quot;nih/images-small/&quot;</span></span><br><span class="line">train_generator = get_train_generator(train_df, IMAGE_DIR, <span class="string">&quot;Image&quot;</span>, labels)</span><br><span class="line">valid_generator, test_generator= get_test_and_valid_generator(valid_df, test_df, train_df, IMAGE_DIR, <span class="string">&quot;Image&quot;</span>, labels)</span><br></pre></td></tr></table></figure>
<pre><code>getting train generator...


/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 866 invalid image filename(s) in x_col=&quot;Image&quot;. These filename(s) will be ignored.
  .format(n_invalid, x_col)
/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 866 invalid image filename(s) in x_col=&quot;Image&quot;. These filename(s) will be ignored.
  .format(n_invalid, x_col)


Found 9 validated image filenames.
getting train and valid generators...
Found 9 validated image filenames.


/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 108 invalid image filename(s) in x_col=&quot;Image&quot;. These filename(s) will be ignored.
  .format(n_invalid, x_col)


Found 1 validated image filenames.
Found 420 validated image filenames.</code></pre>
<p>Let's peek into what the generator gives our model during training and validation. We can do this by calling the <code>__get_item__(index)</code> function:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x, y = train_generator.__getitem__(<span class="number">0</span>)</span><br><span class="line">plt.imshow(x[<span class="number">0</span>]);</span><br></pre></td></tr></table></figure>
<pre><code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).</code></pre>
<figure>
<img src="output_28_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p><a name='3'></a> ## 3 Model Development</p>
<p>Now we'll move on to model training and development. We have a few practical challenges to deal with before actually training a neural network, though. The first is class imbalance.</p>
<p><a name='3-1'></a> ### 3.1 Addressing Class Imbalance One of the challenges with working with medical diagnostic datasets is the large class imbalance present in such datasets. Let's plot the frequency of each of the labels in our dataset:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br><span class="line">plt.bar(x=labels, height=np.mean(train_generator.labels, axis=<span class="number">0</span>))</span><br><span class="line">plt.title(<span class="string">&quot;Frequency of Each Class&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_31_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>We can see from this plot that the prevalance of positive cases varies significantly across the different pathologies. (These trends mirror the ones in the full dataset as well.) * The <code>Hernia</code> pathology has the greatest imbalance with the proportion of positive training cases being about 0.2%. * But even the <code>Infiltration</code> pathology, which has the least amount of imbalance, has only 17.5% of the training cases labelled positive.</p>
<p>Ideally, we would train our model using an evenly balanced dataset so that the positive and negative training cases would contribute equally to the loss.</p>
<p>If we use a normal cross-entropy loss function with a highly unbalanced dataset, as we are seeing here, then the algorithm will be incentivized to prioritize the majority class (i.e negative in our case), since it contributes more to the loss.</p>
<h4 id="impact-of-class-imbalance-on-loss-function">Impact of class imbalance on loss function</h4>
<p>Let's take a closer look at this. Assume we would have used a normal cross-entropy loss for each pathology. We recall that the cross-entropy loss contribution from the <span class="math inline">\(i^{th}\)</span> training data case is:</p>
<p><span class="math display">\[\mathcal{L}_{cross-entropy}(x_i) = -(y_i \log(f(x_i)) + (1-y_i) \log(1-f(x_i))),\]</span></p>
<p>where <span class="math inline">\(x_i\)</span> and <span class="math inline">\(y_i\)</span> are the input features and the label, and <span class="math inline">\(f(x_i)\)</span> is the output of the model, i.e. the probability that it is positive.</p>
<p>Note that for any training case, either <span class="math inline">\(y_i=0\)</span> or else <span class="math inline">\((1-y_i)=0\)</span>, so only one of these terms contributes to the loss (the other term is multiplied by zero, and becomes zero).</p>
<p>We can rewrite the overall average cross-entropy loss over the entire training set <span class="math inline">\(\mathcal{D}\)</span> of size <span class="math inline">\(N\)</span> as follows:</p>
<p><span class="math display">\[\mathcal{L}_{cross-entropy}(\mathcal{D}) = - \frac{1}{N}\big( \sum_{\text{positive examples}} \log (f(x_i)) + \sum_{\text{negative examples}} \log(1-f(x_i)) \big).\]</span></p>
<p>Using this formulation, we can see that if there is a large imbalance with very few positive training cases, for example, then the loss will be dominated by the negative class. Summing the contribution over all the training cases for each class (i.e. pathological condition), we see that the contribution of each class (i.e. positive or negative) is:</p>
<p><span class="math display">\[freq_{p} = \frac{\text{number of positive examples}}{N} \]</span></p>
<p><span class="math display">\[\text{and}\]</span></p>
<p><span class="math display">\[freq_{n} = \frac{\text{number of negative examples}}{N}.\]</span></p>
<p><a name='Ex-2'></a> ### Exercise 2 - Computing Class Frequencies Complete the function below to calculate these frequences for each label in our dataset.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Use numpy.sum(a, axis=), and choose the axis (0 or 1)
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_class_freqs</span>(<span class="params">labels</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute positive and negative frequences for each class.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        labels (np.array): matrix of labels, size (num_examples, num_classes)</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        positive_frequencies (np.array): array of positive frequences for each</span></span><br><span class="line"><span class="string">                                         class, size (num_classes)</span></span><br><span class="line"><span class="string">        negative_frequencies (np.array): array of negative frequences for each</span></span><br><span class="line"><span class="string">                                         class, size (num_classes)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># total number of patients (rows)</span></span><br><span class="line">    N = labels.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    positive_frequencies = np.<span class="built_in">sum</span>(labels, axis=<span class="number">0</span>) / labels.shape[<span class="number">0</span>]</span><br><span class="line">    negative_frequencies = <span class="number">1</span> - positive_frequencies</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> positive_frequencies, negative_frequencies</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test</span></span><br><span class="line">labels_matrix = np.array(</span><br><span class="line">    [[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">     [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">     [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">     [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;labels:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(labels_matrix)</span><br><span class="line"></span><br><span class="line">test_pos_freqs, test_neg_freqs = compute_class_freqs(labels_matrix)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;pos freqs: <span class="subst">&#123;test_pos_freqs&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;neg freqs: <span class="subst">&#123;test_neg_freqs&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>labels:
[[1 0 0]
 [0 1 1]
 [1 0 1]
 [1 1 1]
 [1 0 1]]
pos freqs: [0.8 0.4 0.8]
neg freqs: [0.2 0.6 0.2]</code></pre>
<h5 id="expected-output-1">Expected output</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">labels:</span><br><span class="line">[[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]]</span><br><span class="line">pos freqs: [<span class="number">0.8</span> <span class="number">0.4</span> <span class="number">0.8</span>]</span><br><span class="line">neg freqs: [<span class="number">0.2</span> <span class="number">0.6</span> <span class="number">0.2</span>]</span><br></pre></td></tr></table></figure>
<p>Now we'll compute frequencies for our training data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">freq_pos, freq_neg = compute_class_freqs(train_generator.labels)</span><br><span class="line">freq_pos</span><br></pre></td></tr></table></figure>
<pre><code>array([0.        , 0.11111111, 0.22222222, 0.        , 0.22222222,
       0.11111111, 0.        , 0.11111111, 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        ])</code></pre>
<p>Let's visualize these two contribution ratios next to each other for each of the pathologies:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = pd.DataFrame(&#123;<span class="string">&quot;Class&quot;</span>: labels, <span class="string">&quot;Label&quot;</span>: <span class="string">&quot;Positive&quot;</span>, <span class="string">&quot;Value&quot;</span>: freq_pos&#125;)</span><br><span class="line">data = data.append([&#123;<span class="string">&quot;Class&quot;</span>: labels[l], <span class="string">&quot;Label&quot;</span>: <span class="string">&quot;Negative&quot;</span>, <span class="string">&quot;Value&quot;</span>: v&#125; <span class="keyword">for</span> l,v <span class="keyword">in</span> <span class="built_in">enumerate</span>(freq_neg)], ignore_index=<span class="literal">True</span>)</span><br><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br><span class="line">f = sns.barplot(x=<span class="string">&quot;Class&quot;</span>, y=<span class="string">&quot;Value&quot;</span>, hue=<span class="string">&quot;Label&quot;</span> ,data=data)</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_42_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>As we see in the above plot, the contributions of positive cases is significantly lower than that of the negative ones. However, we want the contributions to be equal. One way of doing this is by multiplying each example from each class by a class-specific weight factor, <span class="math inline">\(w_{pos}\)</span> and <span class="math inline">\(w_{neg}\)</span>, so that the overall contribution of each class is the same.</p>
<p>To have this, we want</p>
<p><span class="math display">\[w_{pos} \times freq_{p} = w_{neg} \times freq_{n},\]</span></p>
<p>which we can do simply by taking</p>
<p><span class="math display">\[w_{pos} = freq_{neg}\]</span> <span class="math display">\[w_{neg} = freq_{pos}\]</span></p>
<p>This way, we will be balancing the contribution of positive and negative labels.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pos_weights = freq_neg</span><br><span class="line">neg_weights = freq_pos</span><br><span class="line">pos_contribution = freq_pos * pos_weights </span><br><span class="line">neg_contribution = freq_neg * neg_weights</span><br></pre></td></tr></table></figure>
<p>Let's verify this by graphing the two contributions next to each other again:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = pd.DataFrame(&#123;<span class="string">&quot;Class&quot;</span>: labels, <span class="string">&quot;Label&quot;</span>: <span class="string">&quot;Positive&quot;</span>, <span class="string">&quot;Value&quot;</span>: pos_contribution&#125;)</span><br><span class="line">data = data.append([&#123;<span class="string">&quot;Class&quot;</span>: labels[l], <span class="string">&quot;Label&quot;</span>: <span class="string">&quot;Negative&quot;</span>, <span class="string">&quot;Value&quot;</span>: v&#125; </span><br><span class="line">                        <span class="keyword">for</span> l,v <span class="keyword">in</span> <span class="built_in">enumerate</span>(neg_contribution)], ignore_index=<span class="literal">True</span>)</span><br><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br><span class="line">sns.barplot(x=<span class="string">&quot;Class&quot;</span>, y=<span class="string">&quot;Value&quot;</span>, hue=<span class="string">&quot;Label&quot;</span> ,data=data);</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_46_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>As the above figure shows, by applying these weightings the positive and negative labels within each class would have the same aggregate contribution to the loss function. Now let's implement such a loss function.</p>
<p>After computing the weights, our final weighted loss for each training case will be</p>
<p><span class="math display">\[\mathcal{L}_{cross-entropy}^{w}(x) = - (w_{p} y \log(f(x)) + w_{n}(1-y) \log( 1 - f(x) ) ).\]</span></p>
<p><a name='Ex-3'></a> ### Exercise 3 - Weighted Loss Fill out the <code>weighted_loss</code> function below to return a loss function that calculates the weighted loss for each batch. Recall that for the multi-class loss, we add up the average loss for each individual class. Note that we also want to add a small value, <span class="math inline">\(\epsilon\)</span>, to the predicted values before taking their logs. This is simply to avoid a numerical error that would otherwise occur if the predicted value happens to be zero.</p>
<h5 id="note">Note</h5>
<p>Please use Keras functions to calculate the mean and the log.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/backend/mean">Keras.mean</a></li>
<li><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/backend/log">Keras.log</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_weighted_loss</span>(<span class="params">pos_weights, neg_weights, epsilon=<span class="number">1e-7</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Return weighted loss function given negative weights and positive weights.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      pos_weights (np.array): array of positive weights for each class, size (num_classes)</span></span><br><span class="line"><span class="string">      neg_weights (np.array): array of negative weights for each class, size (num_classes)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      weighted_loss (function): weighted loss function</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weighted_loss</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Return weighted loss value. </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            y_true (Tensor): Tensor of true labels, size is (num_examples, num_classes)</span></span><br><span class="line"><span class="string">            y_pred (Tensor): Tensor of predicted labels, size is (num_examples, num_classes)</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            loss (Tensor): overall scalar loss summed across all classes</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># initialize loss to zero</span></span><br><span class="line">        loss = <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(pos_weights)):</span><br><span class="line">            <span class="comment"># for each class, add average weighted loss for that class </span></span><br><span class="line">            loss += -(K.mean( pos_weights[i] * y_true[:,i] * K.log(y_pred[:,i] + epsilon) + \</span><br><span class="line">                                neg_weights[i] * (<span class="number">1</span> - y_true[:,i]) * K.log(<span class="number">1</span> - y_pred[:,i] + epsilon), axis = <span class="number">0</span>))</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line">    </span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> weighted_loss</span><br></pre></td></tr></table></figure>
<p>Now let's test our function with some simple cases.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test</span></span><br><span class="line">sess = K.get_session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test example:\n&quot;</span>)</span><br><span class="line">    y_true = K.constant(np.array(</span><br><span class="line">        [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line">    ))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;y_true:\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(y_true.<span class="built_in">eval</span>())</span><br><span class="line"></span><br><span class="line">    w_p = np.array([<span class="number">0.25</span>, <span class="number">0.25</span>, <span class="number">0.5</span>])</span><br><span class="line">    w_n = np.array([<span class="number">0.75</span>, <span class="number">0.75</span>, <span class="number">0.5</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nw_p:\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(w_p)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nw_n:\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(w_n)</span><br><span class="line"></span><br><span class="line">    y_pred_1 = K.constant(<span class="number">0.7</span>*np.ones(y_true.shape))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\ny_pred_1:\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(y_pred_1.<span class="built_in">eval</span>())</span><br><span class="line"></span><br><span class="line">    y_pred_2 = K.constant(<span class="number">0.3</span>*np.ones(y_true.shape))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\ny_pred_2:\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(y_pred_2.<span class="built_in">eval</span>())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># test with a large epsilon in order to catch errors</span></span><br><span class="line">    L = get_weighted_loss(w_p, w_n, epsilon=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nIf we weighted them correctly, we expect the two losses to be the same.&quot;</span>)</span><br><span class="line">    L1 = L(y_true, y_pred_1).<span class="built_in">eval</span>()</span><br><span class="line">    L2 = L(y_true, y_pred_2).<span class="built_in">eval</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\nL(y_pred_1)= <span class="subst">&#123;L1:<span class="number">.4</span>f&#125;</span>, L(y_pred_2)= <span class="subst">&#123;L2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Difference is L1 - L2 = <span class="subst">&#123;L1 - L2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test example:

y_true:

[[1. 1. 1.]
 [1. 1. 0.]
 [0. 1. 0.]
 [1. 0. 1.]]

w_p:

[0.25 0.25 0.5 ]

w_n:

[0.75 0.75 0.5 ]

y_pred_1:

[[0.7 0.7 0.7]
 [0.7 0.7 0.7]
 [0.7 0.7 0.7]
 [0.7 0.7 0.7]]

y_pred_2:

[[0.3 0.3 0.3]
 [0.3 0.3 0.3]
 [0.3 0.3 0.3]
 [0.3 0.3 0.3]]

If we weighted them correctly, we expect the two losses to be the same.

L(y_pred_1)= -0.4956, L(y_pred_2)= -0.4956
Difference is L1 - L2 = 0.0000</code></pre>
<h4 id="additional-check">Additional check</h4>
<p>If you implemented the function correctly, then if the epsilon for the <code>get_weighted_loss</code> is set to <code>1</code>, the weighted losses will be as follows: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L(y_pred_1)= -<span class="number">0.4956</span>, L(y_pred_2)= -<span class="number">0.4956</span></span><br></pre></td></tr></table></figure> If you are missing something in your implementation, you will see a different set of losses for L1 and L2 (even though L1 and L2 will be the same).</p>
<p><a name='3-3'></a> ### 3.3 DenseNet121</p>
<p>Next, we will use a pre-trained <a target="_blank" rel="noopener" href="https://www.kaggle.com/pytorch/densenet121">DenseNet121</a> model which we can load directly from Keras and then add two layers on top of it: 1. A <code>GlobalAveragePooling2D</code> layer to get the average of the last convolution layers from DenseNet121. 2. A <code>Dense</code> layer with <code>sigmoid</code> activation to get the prediction logits for each of our classes.</p>
<p>We can set our custom loss function for the model by specifying the <code>loss</code> parameter in the <code>compile()</code> function.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create the base pre-trained model</span></span><br><span class="line">base_model = DenseNet121(weights=<span class="string">&#x27;./nih/densenet.hdf5&#x27;</span>, include_top=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">x = base_model.output</span><br><span class="line"></span><br><span class="line"><span class="comment"># add a global spatial average pooling layer</span></span><br><span class="line">x = GlobalAveragePooling2D()(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># and a logistic layer</span></span><br><span class="line">predictions = Dense(<span class="built_in">len</span>(labels), activation=<span class="string">&quot;sigmoid&quot;</span>)(x)</span><br><span class="line"></span><br><span class="line">model = Model(inputs=base_model.<span class="built_in">input</span>, outputs=predictions)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=get_weighted_loss(pos_weights, neg_weights))</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.</code></pre>
<p><a name='4'></a> ## 4 Training [optional]</p>
<p>With our model ready for training, we will use the <code>model.fit()</code> function in Keras to train our model. - We are training on a small subset of the dataset (~1%).<br />
- So what we care about at this point is to make sure that the loss on the training set is decreasing.</p>
<p>Since training can take a considerable time, for pedagogical purposes we have chosen not to train the model here but rather to load a set of pre-trained weights in the next section. However, you can use the code shown below to practice training the model locally on your machine or in Colab.</p>
<p><strong>NOTE:</strong> Do not run the code below on the Coursera platform as it will exceed the platform's memory limitations.</p>
<p>Python Code for training the model:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit_generator(train_generator, </span><br><span class="line">                              validation_data=valid_generator,</span><br><span class="line">                              steps_per_epoch=<span class="number">100</span>, </span><br><span class="line">                              validation_steps=<span class="number">25</span>, </span><br><span class="line">                              epochs = <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.ylabel(<span class="string">&quot;loss&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Training Loss Curve&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><a name='4-1'></a> ### 4.1 Training on the Larger Dataset</p>
<p>Given that the original dataset is 40GB+ in size and the training process on the full dataset takes a few hours, we have trained the model on a GPU-equipped machine for you and provided the weights file from our model (with a batch size of 32 instead) to be used for the rest of this assignment.</p>
<p>The model architecture for our pre-trained model is exactly the same, but we used a few useful Keras "callbacks" for this training. Do spend time to read about these callbacks at your leisure as they will be very useful for managing long-running training sessions:</p>
<ol type="1">
<li>You can use <code>ModelCheckpoint</code> callback to monitor your model's <code>val_loss</code> metric and keep a snapshot of your model at the point.</li>
<li>You can use the <code>TensorBoard</code> to use the Tensorflow Tensorboard utility to monitor your runs in real-time.</li>
<li>You can use the <code>ReduceLROnPlateau</code> to slowly decay the learning rate for your model as it stops getting better on a metric such as <code>val_loss</code> to fine-tune the model in the final steps of training.</li>
<li>You can use the <code>EarlyStopping</code> callback to stop the training job when your model stops getting better in it's validation loss. You can set a <code>patience</code> value which is the number of epochs the model does not improve after which the training is terminated. This callback can also conveniently restore the weights for the best metric at the end of training to your model.</li>
</ol>
<p>You can read about these callbacks and other useful Keras callbacks <a target="_blank" rel="noopener" href="https://keras.io/callbacks/">here</a>.</p>
<p>Let's load our pre-trained weights into the model now:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_weights(<span class="string">&quot;./nih/pretrained_model.h5&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><a name='5'></a> ## 5 Prediction and Evaluation</p>
<p>Now that we have a model, let's evaluate it using our test set. We can conveniently use the <code>predict_generator</code> function to generate the predictions for the images in our test set.</p>
<p><strong>Note:</strong> The following cell can take about 4 minutes to run.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predicted_vals = model.predict_generator(test_generator, steps = <span class="built_in">len</span>(test_generator))</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.</code></pre>
<p><a name='5-1'></a> ### 5.1 ROC Curve and AUROC We'll cover topic of model evaluation in much more detail in later weeks, but for now we'll walk through computing a metric called the AUC (Area Under the Curve) from the ROC (<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">Receiver Operating Characteristic</a>) curve. This is also referred to as the AUROC value, but you will see all three terms in reference to the technique, and often used almost interchangeably.</p>
<p>For now, what you need to know in order to interpret the plot is that a curve that is more to the left and the top has more "area" under it, and indicates that the model is performing better.</p>
<p>We will use the <code>util.get_roc_curve()</code> function which has been provided for you in <code>util.py</code>. Look through this function and note the use of the <code>sklearn</code> library functions to generate the ROC curves and AUROC values for our model.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html">roc_curve</a></li>
<li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html">roc_auc_score</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">auc_rocs = util.get_roc_curve(labels, predicted_vals, test_generator)</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_62_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>You can compare the performance to the AUCs reported in the original ChexNeXt paper in the table below:</p>
<p>For reference, here's the AUC figure from the ChexNeXt paper which includes AUC values for their model as well as radiologists on this dataset:</p>
<p><img src="https://journals.plos.org/plosmedicine/article/figure/image?size=large&id=10.1371/journal.pmed.1002686.t001" width="80%"></p>
<p>This method does take advantage of a few other tricks such as self-training and ensembling as well, which can give a significant boost to the performance.</p>
<p>For details about the best performing methods and their performance on this dataset, we encourage you to read the following papers: - <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.05225">CheXNet</a> - <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1901.07031.pdf">CheXpert</a> - <a target="_blank" rel="noopener" href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002686">ChexNeXt</a></p>
<p><a name='5-2'></a> ### 5.2 Visualizing Learning with GradCAM</p>
<p>One of the challenges of using deep learning in medicine is that the complex architecture used for neural networks makes them much harder to interpret compared to traditional machine learning models (e.g. linear models).</p>
<p>One of the most common approaches aimed at increasing the interpretability of models for computer vision tasks is to use Class Activation Maps (CAM). - Class activation maps are useful for understanding where the model is "looking" when classifying an image.</p>
<p>In this section we will use a <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1610.02391">GradCAM's</a> technique to produce a heatmap highlighting the important regions in the image for predicting the pathological condition. - This is done by extracting the gradients of each predicted class, flowing into our model's final convolutional layer. Look at the <code>util.compute_gradcam</code> which has been provided for you in <code>util.py</code> to see how this is done with the Keras framework.</p>
<p>It is worth mentioning that GradCAM does not provide a full explanation of the reasoning for each classification probability. - However, it is still a useful tool for "debugging" our model and augmenting our prediction so that an expert could validate that a prediction is indeed due to the model focusing on the right regions of the image.</p>
<p>First we will load the small training set and setup to look at the 4 classes with the highest performing AUC measures.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&quot;nih/train-small.csv&quot;</span>)</span><br><span class="line">IMAGE_DIR = <span class="string">&quot;nih/images-small/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># only show the lables with top 4 AUC</span></span><br><span class="line">labels_to_show = np.take(labels, np.argsort(auc_rocs)[::-<span class="number">1</span>])[:<span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>Now let's look at a few specific images.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">util.compute_gradcam(model, <span class="string">&#x27;00008270_015.png&#x27;</span>, IMAGE_DIR, df, labels, labels_to_show)</span><br></pre></td></tr></table></figure>
<pre><code>Loading original image
Generating gradcam for class Cardiomegaly
Generating gradcam for class Mass
Generating gradcam for class Pneumothorax
Generating gradcam for class Edema</code></pre>
<figure>
<img src="output_71_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">util.compute_gradcam(model, <span class="string">&#x27;00011355_002.png&#x27;</span>, IMAGE_DIR, df, labels, labels_to_show)</span><br></pre></td></tr></table></figure>
<pre><code>Loading original image
Generating gradcam for class Cardiomegaly
Generating gradcam for class Mass
Generating gradcam for class Pneumothorax
Generating gradcam for class Edema</code></pre>
<figure>
<img src="output_72_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">util.compute_gradcam(model, <span class="string">&#x27;00029855_001.png&#x27;</span>, IMAGE_DIR, df, labels, labels_to_show)</span><br></pre></td></tr></table></figure>
<pre><code>Loading original image
Generating gradcam for class Cardiomegaly
Generating gradcam for class Mass
Generating gradcam for class Pneumothorax
Generating gradcam for class Edema</code></pre>
<figure>
<img src="output_73_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">util.compute_gradcam(model, <span class="string">&#x27;00005410_000.png&#x27;</span>, IMAGE_DIR, df, labels, labels_to_show)</span><br></pre></td></tr></table></figure>
<pre><code>Loading original image
Generating gradcam for class Cardiomegaly
Generating gradcam for class Mass
Generating gradcam for class Pneumothorax
Generating gradcam for class Edema</code></pre>
<figure>
<img src="output_74_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>Congratulations, you've completed the first assignment of course one! You've learned how to preprocess data, check for data leakage, train a pre-trained model, and evaluate using the AUC. Great work!</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Deploy-a-keras-model-on-IBM-cloud/2020/04/15/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Deploy-a-keras-model-on-IBM-cloud/2020/04/15/" class="post-title-link" itemprop="url">Deploy a keras model on IBM cloud</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-15 19:11:05" itemprop="dateCreated datePublished" datetime="2020-04-15T19:11:05+08:00">2020-04-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-18 10:58:47" itemprop="dateModified" datetime="2020-04-18T10:58:47+08:00">2020-04-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI-Workflow/" itemprop="url" rel="index"><span itemprop="name">AI Workflow</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI-Workflow/Deployment/" itemprop="url" rel="index"><span itemprop="name">Deployment</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Deploy-a-keras-model-on-IBM-cloud/2020/04/15/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Deploy-a-keras-model-on-IBM-cloud/2020/04/15/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="zero-to-singularity-create-tune-deploy-and-scale-a-deep-neural-network-in-90-minutes">Zero to Singularity: Create, Tune, Deploy and Scale a Deep Neural Network in 90 Minutes</h1>
<p>This notebook is part of a masterclass held at IBM Think on 13th of February 2019 in San Fransisco In this exercise you will train a Keras DeepLearning model running on top of TensorFlow.</p>
<p>Note: For sake of bringing the training runtime down we've done two things</p>
<ol type="1">
<li><p>Used a softmax regression model over a Convolutional Neural Network</p></li>
<li><p>Trained only for one epoch instead of 20</p></li>
</ol>
<p>This leads to approx. 5% less accuracy</p>
<p>Authors</p>
<p>Romeo Kienzler - Chief Data Scientist, IBM Watson IoT</p>
<p>Krishnamurthy Arthanarisamy - Architect, Watson Machine Learning Software Lab, Bangalore</p>
<h1 id="prerequisites">Prerequisites</h1>
<p>Please make sure the currently installed version of Keras and Tensorflow are matching the requirememts, if not, please run the two PIP commands below in order to re-install. Please restart the kernal before proceeding, please re-check if the versions are matching.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Current:\t&#x27;</span>, keras.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Expected:\t 2.2.5 &#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Using TensorFlow backend.


Current:     2.2.4
Expected:    2.2.5 </code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Current:\t&#x27;</span>, tf.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Expected:\t 1.15.0&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Current:     1.13.1
Expected:    1.15.0</code></pre>
<h1 id="important">IMPORTANT !!!</h1>
<p>If you ran the two lines below please restart your kernel (Kernel-&gt;Restart &amp; Clear Output)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!pip install keras==<span class="number">2.2</span><span class="number">.5</span> </span><br><span class="line">!pip install tensorflow==<span class="number">1.15</span><span class="number">.0</span></span><br></pre></td></tr></table></figure>
<h1 id="train-a-mnist-digits-recognition-model">1.0 Train a MNIST digits recognition model</h1>
<p>We start with some global parameters and imports</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#some learners constantly reported 502 errors in Watson Studio. </span></span><br><span class="line"><span class="comment">#This is due to the limited resources in the free tier and the heavy resource consumption of Keras.</span></span><br><span class="line"><span class="comment">#This is a workaround to limit resource consumption</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line">K.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=<span class="number">1</span>, inter_op_parallelism_threads=<span class="number">1</span>)))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout, Flatten</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential, load_model</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LeakyReLU</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">epochs = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># the data, split between train and test sets</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line">x_train = x_train.reshape(<span class="number">60000</span>, <span class="number">784</span>)</span><br><span class="line">x_test = x_test.reshape(<span class="number">10000</span>, <span class="number">784</span>)</span><br><span class="line">x_train = x_train.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x_test = x_test.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x_train /= <span class="number">255</span></span><br><span class="line">x_test /= <span class="number">255</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># convert class vectors to binary class matrices</span></span><br><span class="line">y_train = keras.utils.to_categorical(y_train, num_classes)</span><br><span class="line">y_test = keras.utils.to_categorical(y_test, num_classes)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step</code></pre>
<h1 id="training-a-simple-model">Training a simple model</h1>
<p>First we'll train a simple softmax regressor and check what accuracy we get</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">512</span>, input_shape=(<span class="number">784</span>,)))</span><br><span class="line">model.add(Dense(num_classes, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">        optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">        metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        epochs=epochs,</span><br><span class="line">        verbose=<span class="number">1</span>,</span><br><span class="line">        validation_data=(x_test, y_test))</span><br><span class="line">        </span><br><span class="line">score = model.evaluate(x_test, y_test, verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy:&#x27;</span>,score[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 60000 samples, validate on 10000 samples
Epoch 1/1
60000/60000 [==============================] - 14s 230us/step - loss: 0.3857 - acc: 0.8886 - val_loss: 0.3232 - val_acc: 0.9110


Accuracy: 0.911</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#some cleanup from the previous run</span></span><br><span class="line">!rm -f ker_*</span><br><span class="line">!rm -f my_best_model.tgz</span><br></pre></td></tr></table></figure>
<p>You should see an accuracy of approximately 90%. Now lets define a hyper-parameter grid including different activation functions and gradient descent optimizers. We’re optimizing over the grid using grid search (nested for loops) and store each model variant in a file. We then decide for the best one in order to deploy to IBM Watson Machine Learning.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#define parameter grid</span></span><br><span class="line"></span><br><span class="line">activation_functions_layer_1 = [<span class="string">&#x27;sigmoid&#x27;</span>,<span class="string">&#x27;tanh&#x27;</span>,<span class="string">&#x27;relu&#x27;</span>]</span><br><span class="line">opimizers = [<span class="string">&#x27;rmsprop&#x27;</span>,<span class="string">&#x27;adagrad&#x27;</span>,<span class="string">&#x27;adadelta&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#optimize over parameter grid (grid search)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> activation_function_layer_1 <span class="keyword">in</span> activation_functions_layer_1:</span><br><span class="line">    <span class="keyword">for</span> opimizer <span class="keyword">in</span> opimizers:</span><br><span class="line">        </span><br><span class="line">        model = Sequential()</span><br><span class="line">        model.add(Dense(<span class="number">512</span>, activation = activation_function_layer_1, input_shape=(<span class="number">784</span>,)))</span><br><span class="line">        model.add(Dense(num_classes, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=opimizer,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        model.fit(x_train, y_train,</span><br><span class="line">              batch_size=batch_size,</span><br><span class="line">              epochs=epochs,</span><br><span class="line">              verbose=<span class="number">1</span>,</span><br><span class="line">              validation_data=(x_test, y_test))</span><br><span class="line">        </span><br><span class="line">        score = model.evaluate(x_test, y_test, verbose=<span class="number">0</span>)</span><br><span class="line">        save_path = <span class="string">&quot;ker_func_mnist_model_2.%s.%s.%s.h5&quot;</span> % (activation_function_layer_1,opimizer,score[<span class="number">1</span>])</span><br><span class="line">        model.save(save_path)</span><br></pre></td></tr></table></figure>
<pre><code>Train on 60000 samples, validate on 10000 samples
Epoch 1/1
60000/60000 [==============================] - 16s 269us/step - loss: 0.4272 - acc: 0.8839 - val_loss: 0.2807 - val_acc: 0.9172
Train on 60000 samples, validate on 10000 samples
Epoch 1/1
60000/60000 [==============================] - 14s 233us/step - loss: 0.4151 - acc: 0.8871 - val_loss: 0.2874 - val_acc: 0.9162
Train on 60000 samples, validate on 10000 samples
Epoch 1/1
60000/60000 [==============================] - 16s 261us/step - loss: 0.5419 - acc: 0.8611 - val_loss: 0.3225 - val_acc: 0.9081
Train on 60000 samples, validate on 10000 samples
Epoch 1/1
60000/60000 [==============================] - 14s 238us/step - loss: 0.3358 - acc: 0.9009 - val_loss: 0.2107 - val_acc: 0.9391
Train on 60000 samples, validate on 10000 samples
Epoch 1/1
60000/60000 [==============================] - 14s 239us/step - loss: 0.3241 - acc: 0.9076 - val_loss: 0.2284 - val_acc: 0.9358
Train on 60000 samples, validate on 10000 samples
Epoch 1/1
60000/60000 [==============================] - 18s 308us/step - loss: 0.3640 - acc: 0.8943 - val_loss: 0.2737 - val_acc: 0.9186
Train on 60000 samples, validate on 10000 samples
Epoch 1/1
60000/60000 [==============================] - 22s 374us/step - loss: 0.2554 - acc: 0.9270 - val_loss: 0.1215 - val_acc: 0.9625
Train on 60000 samples, validate on 10000 samples
Epoch 1/1
60000/60000 [==============================] - 22s 367us/step - loss: 0.2377 - acc: 0.9315 - val_loss: 0.1378 - val_acc: 0.9588
Train on 60000 samples, validate on 10000 samples
Epoch 1/1
60000/60000 [==============================] - 24s 402us/step - loss: 0.2918 - acc: 0.9167 - val_loss: 0.1622 - val_acc: 0.9528</code></pre>
<h1 id="model-evaluation">Model evaluation</h1>
<p>Let's have a look at all the models and see which hyper parameter configuration was the best one. You should see that relu and rmsprop gives you &gt; 95% of accuracy on the validation set</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -ltr *</span><br></pre></td></tr></table></figure>
<pre><code>-rw-r----- 1 dsxuser dsxuser    2289 Apr 15 22:31 rklib.py
-rw-r----- 1 dsxuser dsxuser 3276560 Apr 15 22:33 ker_func_mnist_model_2.sigmoid.rmsprop.0.9172.h5
-rw-r----- 1 dsxuser dsxuser 3276560 Apr 15 22:33 ker_func_mnist_model_2.sigmoid.adagrad.0.9162.h5
-rw-r----- 1 dsxuser dsxuser 4905120 Apr 15 22:34 ker_func_mnist_model_2.sigmoid.adadelta.0.9081.h5
-rw-r----- 1 dsxuser dsxuser 3276560 Apr 15 22:34 ker_func_mnist_model_2.tanh.rmsprop.0.9391.h5
-rw-r----- 1 dsxuser dsxuser 3276568 Apr 15 22:34 ker_func_mnist_model_2.tanh.adagrad.0.9358.h5
-rw-r----- 1 dsxuser dsxuser 4905128 Apr 15 22:35 ker_func_mnist_model_2.tanh.adadelta.0.9186.h5
-rw-r----- 1 dsxuser dsxuser 3276568 Apr 15 22:35 ker_func_mnist_model_2.relu.rmsprop.0.9625.h5
-rw-r----- 1 dsxuser dsxuser 3276568 Apr 15 22:35 ker_func_mnist_model_2.relu.adagrad.0.9588.h5
-rw-r----- 1 dsxuser dsxuser 4905128 Apr 15 22:36 ker_func_mnist_model_2.relu.adadelta.0.9528.h5
-rw-r----- 1 dsxuser dsxuser 2887392 Apr 15 22:38 my_best_model.tgz

systemml:
total 0

__pycache__:
total 4
-rw-r----- 1 dsxuser dsxuser 1584 Apr 15 22:26 rklib.cpython-36.pyc

scratch_space:
total 0

mkdir :
total 4
drwxr-x--- 3 dsxuser dsxuser 4096 Apr 15 22:30</code></pre>
<p>Now it's time to create a tarball out of your favorite model, please replace the name of your favorite model H5 file with “please-put-me-here”</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!tar -zcvf my_best_model.tgz ker_func_mnist_model_2.relu.rmsprop<span class="number">.0</span><span class="number">.9625</span>.h5</span><br></pre></td></tr></table></figure>
<pre><code>ker_func_mnist_model_2.relu.rmsprop.0.9625.h5</code></pre>
<h2 id="save-the-trained-model-to-wml-repository">2.0 Save the trained model to WML Repository</h2>
<p>We will use <code>watson_machine_learning_client</code> python library to save the trained model to WML Repository, to deploy the saved model and to make predictions using the deployed model.</br></p>
<p><code>watson_machine_learning_client</code> can be installed using the following <code>pip</code> command in case you are running outside Watson Studio:</p>
<p><code>!pip install watson-machine-learning-client --upgrade</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> watson_machine_learning_client <span class="keyword">import</span> WatsonMachineLearningAPIClient</span><br></pre></td></tr></table></figure>
<pre><code>2020-04-15 22:57:03,361 - watson_machine_learning_client.metanames - WARNING - &#39;AUTHOR_EMAIL&#39; meta prop is deprecated. It will be ignored.</code></pre>
<p>Please go to https://cloud.ibm.com/, login, click on the “Create Resource” button. From the “AI” category, please choose “Machine Learning”. Wait for the “Create” button to activate and click on “Create”. Click on “Service Credentials”, then “New Credential”, then “Add”. From the new entry in the table, under “ACTIONS”, please click on “View Credentials”. Please copy the whole JSON object to your clipboard. Now just paste the JSON object below so that you are able to use your personal instance of Watson Machine Learning.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">wml_credentials=&#123;</span><br><span class="line">  <span class="string">&quot;apikey&quot;</span>: <span class="string">&quot;4EdHtgVIK5DfjhpOmUT8Tr9i5ad-9oWYMiyClbj0PUxJ&quot;</span>,</span><br><span class="line">  <span class="string">&quot;iam_apikey_description&quot;</span>: <span class="string">&quot;Auto-generated for key 9fa77406-bf31-478f-bfc9-78d8d16a0bd4&quot;</span>,</span><br><span class="line">  <span class="string">&quot;iam_apikey_name&quot;</span>: <span class="string">&quot;Service credentials-1&quot;</span>,</span><br><span class="line">  <span class="string">&quot;iam_role_crn&quot;</span>: <span class="string">&quot;crn:v1:bluemix:public:iam::::serviceRole:Writer&quot;</span>,</span><br><span class="line">  <span class="string">&quot;iam_serviceid_crn&quot;</span>: <span class="string">&quot;crn:v1:bluemix:public:iam-identity::a/dd8b066c8db947e8a36d2ac8acffee25::serviceid:ServiceId-b4b64d34-d93c-42dc-b024-af27a9ade4da&quot;</span>,</span><br><span class="line">  <span class="string">&quot;instance_id&quot;</span>: <span class="string">&quot;07660d0f-85d9-48fe-bc53-fe800754f9f8&quot;</span>,</span><br><span class="line">  <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://us-south.ml.cloud.ibm.com&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client = WatsonMachineLearningAPIClient(wml_credentials)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model_props = &#123;client.repository.ModelMetaNames.AUTHOR_NAME: <span class="string">&quot;RCZHANG&quot;</span>, </span><br><span class="line">               client.repository.ModelMetaNames.AUTHOR_EMAIL: <span class="string">&quot;lvduzhen@gmail.com&quot;</span>, </span><br><span class="line">               client.repository.ModelMetaNames.NAME: <span class="string">&quot;KK3_clt_keras_mnist&quot;</span>,</span><br><span class="line">               client.repository.ModelMetaNames.FRAMEWORK_NAME: <span class="string">&quot;tensorflow&quot;</span>,</span><br><span class="line">               client.repository.ModelMetaNames.FRAMEWORK_VERSION: <span class="string">&quot;1.15&quot;</span> ,</span><br><span class="line">               client.repository.ModelMetaNames.FRAMEWORK_LIBRARIES: [&#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;keras&quot;</span>, <span class="string">&quot;version&quot;</span>: <span class="string">&quot;2.2.5&quot;</span>&#125;]</span><br><span class="line">              &#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">published_model = client.repository.store_model(model=<span class="string">&quot;my_best_model.tgz&quot;</span>, meta_props=model_props)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">published_model_uid = client.repository.get_model_uid(published_model)</span><br><span class="line">model_details = client.repository.get_details(published_model_uid)</span><br></pre></td></tr></table></figure>
<h2 id="deploy-the-keras-model">3.0 Deploy the Keras model</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.deployments.<span class="built_in">list</span>()</span><br></pre></td></tr></table></figure>
<pre><code>------------------------------------  -------------------  ------  --------------  ------------------------  ---------------  -------------
GUID                                  NAME                 TYPE    STATE           CREATED                   FRAMEWORK        ARTIFACT TYPE
e69bb10d-67ea-4fa9-9788-4bbf80edac85  k1_keras_mnist_clt1  online  DEPLOY_SUCCESS  2020-04-15T22:59:44.929Z  tensorflow-1.15  model
------------------------------------  -------------------  ------  --------------  ------------------------  ---------------  -------------</code></pre>
<p>To keep your environment clean, just delete all deployments from previous runs</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># client.deployments.delete(&quot;PASTE_YOUR_GUID_HERE_IF_APPLICABLE&quot;)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">created_deployment = client.deployments.create(published_model_uid, name=<span class="string">&quot;k1_keras_mnist_clt1&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>#######################################################################################

Synchronous deployment creation for uid: &#39;cc79b7b9-ae8b-4cf1-b7a3-165b104867ab&#39; started

#######################################################################################


INITIALIZING
DEPLOY_IN_PROGRESS...
DEPLOY_SUCCESS


------------------------------------------------------------------------------------------------
Successfully finished deployment creation, deployment_uid=&#39;e69bb10d-67ea-4fa9-9788-4bbf80edac85&#39;
------------------------------------------------------------------------------------------------</code></pre>
<h2 id="test-the-model">Test the model</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#scoring_endpoint = client.deployments.get_scoring_url(created_deployment)</span></span><br><span class="line">scoring_endpoint = created_deployment[<span class="string">&#x27;entity&#x27;</span>][<span class="string">&#x27;scoring_url&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(scoring_endpoint)</span><br></pre></td></tr></table></figure>
<pre><code>https://us-south.ml.cloud.ibm.com/v3/wml_instances/07660d0f-85d9-48fe-bc53-fe800754f9f8/deployments/e69bb10d-67ea-4fa9-9788-4bbf80edac85/online</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_score_1 = x_test[<span class="number">23</span>].tolist()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The answer should be: &#x27;</span>,np.argmax(y_test[<span class="number">23</span>]))</span><br><span class="line">scoring_payload = &#123;<span class="string">&#x27;values&#x27;</span>: [x_score_1]&#125;</span><br></pre></td></tr></table></figure>
<pre><code>The answer should be:  5</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">predictions = client.deployments.score(scoring_endpoint, scoring_payload)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;And the answer is!... &#x27;</span>,predictions[<span class="string">&#x27;values&#x27;</span>][<span class="number">0</span>][<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<pre><code>And the answer is!...  5</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/27/">27</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ruochi Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">268</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zhangruochi" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zhangruochi" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zrc720@gmail.com" title="E-Mail → mailto:zrc720@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.healthinformaticslab.org/" title="http:&#x2F;&#x2F;www.healthinformaticslab.org" rel="noopener" target="_blank">HILab</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.shihaizhou.com/" title="http:&#x2F;&#x2F;www.shihaizhou.com" rel="noopener" target="_blank">Rose</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/cherish_CX/" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;cherish_CX&#x2F;" rel="noopener" target="_blank">Chunxia</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ruochi Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'qW3MLcAgcX96sB6qbegeL7rP-gzGzoHsz',
      appKey     : 'GL6JvT9DgGxqYrY5Vj6bXVuv',
      placeholder: "Thank you for your reply",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'en' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>

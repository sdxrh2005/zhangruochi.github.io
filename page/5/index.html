<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=PingFang SC:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhangruochi.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="RUOCHI.AI">
<meta property="og:url" content="https://zhangruochi.com/page/5/index.html">
<meta property="og:site_name" content="RUOCHI.AI">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Ruochi Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://zhangruochi.com/page/5/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>RUOCHI.AI</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RUOCHI.AI</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/ML-Interview-Decomposition/2020/05/26/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/ML-Interview-Decomposition/2020/05/26/" class="post-title-link" itemprop="url">ML-Interview-Decomposition</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-26 06:56:23" itemprop="dateCreated datePublished" datetime="2020-05-26T06:56:23+08:00">2020-05-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-29 06:52:58" itemprop="dateModified" datetime="2020-05-29T06:52:58+08:00">2020-05-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/" itemprop="url" rel="index"><span itemprop="name">Interview</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/ML-Interview-Decomposition/2020/05/26/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/ML-Interview-Decomposition/2020/05/26/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Decomposition, PCA,LDA</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/ML-Interview-Decomposition/2020/05/26/">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/ML-Interview-Classicial-Algorithms/2020/05/25/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/ML-Interview-Classicial-Algorithms/2020/05/25/" class="post-title-link" itemprop="url">ML-Interview-Classicial-Algorithms</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-25 08:28:33" itemprop="dateCreated datePublished" datetime="2020-05-25T08:28:33+08:00">2020-05-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-29 06:48:42" itemprop="dateModified" datetime="2020-05-29T06:48:42+08:00">2020-05-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/" itemprop="url" rel="index"><span itemprop="name">Interview</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/ML-Interview-Classicial-Algorithms/2020/05/25/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/ML-Interview-Classicial-Algorithms/2020/05/25/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>SVM, Logistic Regression, Decision Tree</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/ML-Interview-Classicial-Algorithms/2020/05/25/">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/ML-Interview-Feature-Engineering-and-Evaluation/2020/05/24/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/ML-Interview-Feature-Engineering-and-Evaluation/2020/05/24/" class="post-title-link" itemprop="url">ML-Interview-Feature-Engineering-and-Evaluation</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-24 16:02:06" itemprop="dateCreated datePublished" datetime="2020-05-24T16:02:06+08:00">2020-05-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-09-06 23:39:16" itemprop="dateModified" datetime="2020-09-06T23:39:16+08:00">2020-09-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/" itemprop="url" rel="index"><span itemprop="name">Interview</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/ML-Interview-Feature-Engineering-and-Evaluation/2020/05/24/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/ML-Interview-Feature-Engineering-and-Evaluation/2020/05/24/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>特征工程,模型评估相关问题</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/ML-Interview-Feature-Engineering-and-Evaluation/2020/05/24/">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Time-and-Ordering/2020/05/09/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Time-and-Ordering/2020/05/09/" class="post-title-link" itemprop="url">Time and Ordering</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-05-09 01:10:01 / Modified: 13:36:27" itemprop="dateCreated datePublished" datetime="2020-05-09T01:10:01+08:00">2020-05-09</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Big-Data-Architecture/" itemprop="url" rel="index"><span itemprop="name">Big Data Architecture</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Big-Data-Architecture/Distributed-Cloud-Computing/" itemprop="url" rel="index"><span itemprop="name">Distributed & Cloud Computing</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Time-and-Ordering/2020/05/09/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Time-and-Ordering/2020/05/09/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>分布式系统和传统的单机系统不同，彼此是通过网络而不是”主板”连接、消息通讯是不可靠的。因此如果没有任何同步机制，同一系统的成员之间无法确保时间戳的误差控制在某个范围内。这个基本条件的缺失，会给上层应用的设计带来很多的麻烦。比如，一个业务流程的两个阶段分别在两台机器上处理，而后在第三台机器上将处理记录join起来，就可能因为时间戳的问题引发混乱。如何做好时间同步的协议，成为了分布式系统中的一个基本的问题。</p>
<p>在系统对时的时候，有两类基本的协议，第一个是外部对时，简单的说，就是整个分布式系统中的所有成员，与外部某个指定的源头进行时间同步，确保与源头的时间的diff在某个误差范围<span class="math inline">\(D\)</span>内; 另一种是内部对时，即内部通过广播等各种手段，确保系统内的成员俩俩间的时间误差在一定范围内。从这里可以看出，如果一个集群使用了外部对时，控制误差在<span class="math inline">\(D\)</span>以内，那么这个集群内部的时间的误差，也一定能够控制在<span class="math inline">\(2D\)</span>的范围内。但反过来不一定，因为有可能整个集群与外部的时间存在很大的整体偏差，尽管在内部彼此的偏差很小。</p>
<p>那么如何进行时间的同步呢？这里介绍两个经典的协议：Cristian和NTP。</p>
<h2 id="cristian">Cristian</h2>
<p>Cristian的基本过程是这样的，假定现在P进程要从授时服务器S获取时间，那么最朴素的做法就是P向S发送请求，S将自己的时间t返回给P，而后P设置自己的时间为t。这个做法存在一个很关键的问题，就是由于网络的通讯时间是不确定的，P拿到t的时候，已经经过了不确定多久了，无法估计结束后P与S的时间误差范围。因此，我们需要将网络通讯的时间，即RTT(Rount Trip Time)也考虑进来。在这个场景下，RTT指的是P进程发出请求，到得到S的回应消息的时间差，这个时间差是P进程自己可以记录求得的。假定我们知道从 <span class="math inline">\(P \to S\)</span>的最小延时是 <span class="math inline">\(min_1\)</span>, <span class="math inline">\(S \to P\)</span>的最小延时是<span class="math inline">\(min_2\)</span>,那么，我们可以推断，真实的时间在<span class="math inline">\([t+min_2, t+RTT-min_1]\)</span>间内，Cristian的做法就将对时结果设置为：<span class="math inline">\(t&#39;=t+\frac{RTT+min_2-min_1}{2}\)</span> 这个中间位置上。那么，其误差就能控制在<span class="math inline">\(\pm \frac{RTT-min_1-min_2}{2}\)</span> 的范围内。</p>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="1.png" width = "70%" height="70%">
</center>
<h2 id="ntp">NTP</h2>
<p>另外一个知名的时间同步协议是NTP，全称Network Time Protocol。NTP协议一般在某个大的机构内部署，将机构内的设备组织成树形结构，每个节点都从父节点处获取时间。整个同步过程分为两轮，第一轮父节点记录自己发送返回的时间点<span class="math inline">\(ts_1\)</span>，子节点记录自己接收到返回消息的时间 <span class="math inline">\(tr_1\)</span>；而后第二轮，子节点记录自己的发送时间<span class="math inline">\(ts_2\)</span>；；父节点记录收到请求的时间<span class="math inline">\(tr_2\)</span>后将<span class="math inline">\(ts_1\)</span> 和 <span class="math inline">\(tr_2\)</span>返回。那么子节点可以计算出自己和父节点之间的时间偏差为: <span class="math inline">\(o=\frac{(tr_{1}-tr_{2}+ts_{2}-ts{1})}{2}\)</span>，并以此为依据进行修正(一般需要确保时间不能“倒流”)。那么为什么<span class="math inline">\(o\)</span>是这么计算呢？假定子节点与父节点的时间偏差(offset)为<span class="math inline">\(o\prime\)</span>、父节点往子节点的通讯时延为<span class="math inline">\(L_1\)</span>、子节点往父节点的通讯时延为<span class="math inline">\(L_2\)</span>，那么:</p>
<p><span class="math display">\[
\begin{align*} 
&amp; tr_{1}=ts_{1}+L_{1}+o&#39; \\
&amp; tr_{2}=ts_{2}+L_{2}-o&#39; \\
\end{align*}
\]</span></p>
<p>相减可以得到: <span class="math display">\[o&#39;= \frac{(tr_1-tr_2+ts_2-ts_1)}{2} + \frac{(L_2 - L1)}{2} = o + \frac{(L_2-L1)}{2}\]</span></p>
<p>因此:</p>
<p><span class="math display">\[
\lvert o&#39;-o \rvert \leqslant \lvert \frac{(L_2-L_1)}{2}\rvert &lt; \frac{(L_{1}+L_{2})}{2} = \frac{RTT}{2}
\]</span></p>
<p>由此可知o的这个值也在RTT相关的一个误差范围内，是可估计的。 从上面两个协议可以看出，对时的误差是与RTT强相关的。由于消息的传递受制于光速、距离越远时间准确度的保证就越差。对于那些假定了时间误差在某个范围内的分布式协议，在跨越距离很大的时候，我们就必须要将这个误差对系统的影响考虑在内，这将显著增加分布式系统设计的复杂度、或者影响设计出来的系统的吞吐(尤其是有高一致性要求的事务型系统)。</p>
<p>最后，不论是Cristian还是NTP，都只描述了一次对时如何将时间的偏移(clow skew)控制在一定范围内。由于不同机器的时钟的行进速度(clock drift)是不同的，因此我们需要每隔一段时间，进行一次修正，以消除时钟节奏不同的影响。多久需要做一次同步呢? 这个做一个简单的计算就可以得到。假定系统整体时钟的行进速率与标准时钟的速率小于MDR(Max Drift Rate, 一般由时钟的实现方式决定)，那么系统内俩俩时钟的行进速率差小于2MDR。如果我们要求系统内时间差不能超过M，那就必须以不低于<span class="math inline">\(\delta = \frac{M}{2 \times {MDR}}\)</span>的间隔进行时间同步。在现实的系统中，我们需要计算合理的M，以避免系统内出现过多的时间同步消息。</p>
<p>在上面部分，我们谈到了分布式系统里进程彼此的物理时间是如何进行同步的，并介绍了一些经典的时间同步算法。但静下心来仔细想想，我们希望进行时间同步，很多时候是希望不同的进程，对系统内事件的顺序达成一致。至于是否是使用真实世界的那个时间来排序，往往并不是那么重要。 那么，如何在一个分布式系统中，对发生在众多节点上的事件进行定序呢？目前已知的做法包括以下几种：</p>
<ul>
<li>使用物理时间同步的方法，确保众多节点的时间偏差在某个范围内。而后记录事件的发生时间及理论误差范围，比如将每个事件的发生时间登记为<span class="math inline">\((t \pm \Delta)\)</span>如果两个事件的时间范围没有overlap，那么就自然的可以排序判断；否则，则需要引入一个新的排序规则(比如以节点id)，对这两个事件约定一个排序。spanner中采用了这种方式。</li>
<li>采用Lamport Timestamp及其引申算法进行定序，确保事件满足causality consistency的性质，成为后续更高层次的分布式算法设计的基础。本文后面主要将展开这类算法，并引出分布式系统中一些基础概念。这些基础概念是理解分布式共识问题(consensus problem)的基础。</li>
</ul>
<h2 id="lamport">Lamport</h2>
<p>为明确这个问题，我们首先需要先对事件的序(happen-before)做出一个定义。在Lamport的体系中，事件的先后关系是按照如下原则设定的：</p>
<ul>
<li>规则一：如果A、B两个事件都发生在同一个进程内，那么，A、B之间的序自然可以由这个进程给出。假如进程先执行了A后执行了B，那么可以说A在B之前发生，记为<span class="math inline">\(A \prec B\)</span>;</li>
<li>规则二：如果进程x往进程y发送了一条消息M；设在进程x的消息发送事件为A，进程y收到消息的事件为B，则显然我们应当认为A在B之前发生，同样记为<span class="math inline">\(A \prec B\)</span>.</li>
</ul>
<p>由此引出了Lamport timestamp的算法，这个算法就是一种给事件打上逻辑时间戳、确保其满足causality的基本属性。这个算法的基本过程为：</p>
<ul>
<li>每个进程都记录自己的一个当前时间戳，初始的时候，大家都是0</li>
<li>如果进程内部发生了一个新的事件，那么将当前时间戳记为 <span class="math inline">\(t&#39;=t+1\)</span>，并认为事件发生于<span class="math inline">\(t&#39;\)</span>时刻</li>
<li>如果进程A向进程B通讯，则发送消息的时候，进程A的时间戳<span class="math inline">\(t&#39;\_A = t_A + 1\)</span>并随消息发送到B，B更新自己的时间戳为<span class="math inline">\(t&#39;\_B = max(t&#39;\_B, t&#39;\_A) + 1\)</span>.</li>
</ul>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="2.png" width = "70%" height="70%">
</center>
<h3 id="concurrent-events">Concurrent Events</h3>
<ul>
<li>A pair of concurrent events doesn’t have a causal path from one event to another (either way, in the pair)</li>
<li>Lamport timestamps not guaranteed to be ordered or unequal for concurrent events</li>
<li>Ok, since concurrent events are not causality related!</li>
<li>Remember</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">E1 -&gt; E2 =&gt; timestamp(E1) &lt; timestamp (E2), </span><br><span class="line">BUT timestamp(E1) &lt; timestamp (E2) =&gt; &#123;E1 -&gt; E2&#125; OR &#123;E1 and E2 concurrent&#125;</span><br></pre></td></tr></table></figure>
<h2 id="vector-timestamps">Vector timestamps</h2>
<ul>
<li>Used in key-value stores like Riak</li>
<li>Each process uses a vector of integer clocks</li>
<li>Suppose there are N processes in the group 1...N</li>
<li>Each vector has N elements</li>
<li>Process i maintains vector Vi[1...N]</li>
<li><span class="math inline">\(j_{th}\)</span> element of vector clock at process <span class="math inline">\(i\)</span>, <span class="math inline">\(V_i[j]\)</span>, is <span class="math inline">\(i’s\)</span> knowledge of latest events at process <span class="math inline">\(j\)</span></li>
</ul>
<p>Incrementing vector clocks</p>
<ol type="1">
<li>On an instruction or send event at process <span class="math inline">\(i\)</span>, it increments only its <span class="math inline">\(i_{th}\)</span> element of its vector clock.</li>
<li>Each message carries the send-event’s vector timestamp V_{message}[1...N]</li>
<li>On receiving a message at process <span class="math inline">\(i\)</span>:</li>
</ol>
<p><span class="math display">\[
\begin{align*} 
&amp;V_i[i] = V_i[i] + 1 \\
&amp; V_i[j] = max(V_{message}[j], V_i[j]) \quad for \ quad j \neq i \\
\end{align*}
\]</span></p>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="3.png" width = "70%" height="70%">
</center>
<h3 id="causality">Causality</h3>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="4.png" width = "70%" height="70%">
</center>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="5.png" width = "70%" height="70%">
</center>
<h2 id="reference">Reference</h2>
<ul>
<li>https://lvsizhe.github.io/course/2018/09/time-in-distributed-systems-part1.html</li>
<li>lecture slide from https://www.coursera.org/learn/cloud-computing/lecture/dy8wf/2-5-vector-clocks</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Programming-Language-New-Types-Pattern-Matching-Tail-Recursion/2020/05/03/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Programming-Language-New-Types-Pattern-Matching-Tail-Recursion/2020/05/03/" class="post-title-link" itemprop="url">Programming Language: New Types, Pattern Matching, Tail Recursion</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-03 03:29:05" itemprop="dateCreated datePublished" datetime="2020-05-03T03:29:05+08:00">2020-05-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-12-31 18:07:29" itemprop="dateModified" datetime="2021-12-31T18:07:29+08:00">2021-12-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Programming-Language/" itemprop="url" rel="index"><span itemprop="name">Programming Language</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Programming-Language-New-Types-Pattern-Matching-Tail-Recursion/2020/05/03/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Programming-Language-New-Types-Pattern-Matching-Tail-Recursion/2020/05/03/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>New Types, Pattern Matching, Tail Recursion</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/Programming-Language-New-Types-Pattern-Matching-Tail-Recursion/2020/05/03/">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/EDA-Summary/2020/04/30/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/EDA-Summary/2020/04/30/" class="post-title-link" itemprop="url">EDA Summary</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-30 19:55:33" itemprop="dateCreated datePublished" datetime="2020-04-30T19:55:33+08:00">2020-04-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-01 08:02:49" itemprop="dateModified" datetime="2020-05-01T08:02:49+08:00">2020-05-01</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI-Workflow/" itemprop="url" rel="index"><span itemprop="name">AI Workflow</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI-Workflow/EDA/" itemprop="url" rel="index"><span itemprop="name">EDA</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/EDA-Summary/2020/04/30/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/EDA-Summary/2020/04/30/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="the-main-goals-of-eda-are">The main goals of EDA are:</h2>
<ul>
<li>Provide summary level insight into a data set</li>
<li>Uncover underlying patterns and structure in the data</li>
<li>Identify outliers, missing data and class balance issues</li>
<li>Carry out quality control checks</li>
</ul>
<h2 id="the-principal-steps-in-the-process-of-eda-are">The principal steps in the process of EDA are:</h2>
<ol type="1">
<li>Summarize the data - Generally done using dataframes in R or Python</li>
<li>Tell the Story - Summarize the details of what connects the dataset to the business opportunity</li>
<li>Deal with missing data - Identify the strategy for dealing with missing data</li>
<li>Investigate - Using data visualization and hypothesis testing delve into the relationship between the dataset and the business opportunity</li>
<li>Communicate - Communicate the findings from the above steps</li>
</ol>
<h2 id="data-visualization">Data visualization</h2>
<ol type="1">
<li>Jupyter notebooks in combination with pandas and simple plots are the basis for modern EDA when using Python as a principal language</li>
</ol>
<h3 id="advantages-of-jupyter-notebooks">Advantages of Jupyter notebooks:</h3>
<ul>
<li>They are portable: then can be used locally on private servers, public cloud, and as part of IBM Watson Studio</li>
<li>They work with dozens of languages</li>
<li>They mix markdown with executable code in a way that works naturally with storytelling and investigation</li>
<li>matplotlib itself and its numerous derivative works like seaborn are the core of the Python data visualization landscape</li>
<li>pandas and specifically the dataframe class works naturally with Jupyter, matplotlib and downstream modeling frameworks like sklearn</li>
</ul>
<h3 id="eda-and-data-visualization-best-practices">EDA and Data Visualization best practices</h3>
<ol type="1">
<li>The majority of code for any data science project should be contained within text files. This is a software engineering best practice that ensures re-usability, allows for unit testing and works naturally with version control. &gt;In Python the text files can be executable scripts, modules, a full Python package or some combination of these.</li>
<li>Keep a record of plots and visualization code that you create. It is difficult to remember all of the details of how visualizations were created. Extracting the visualization code to a specific place will ensure that similar plots for future projects will be quick to create.</li>
<li>Use you plots as a quality assurance tool. Given what you know about the data it can be useful to make an educated guess before you execute the cell or run the script. This habit is surprisingly useful for quality assurance of both data and code.</li>
</ol>
<h2 id="missing-values">Missing values</h2>
<ul>
<li>Dealing with missing data sits at the intersection of EDA and data ingestion in the AI enterprise workflow</li>
<li>Ignoring missing data may have unintended consequences in terms of model performance that may not be easy to detect</li>
<li>Removing either complete rows or columns in a feature matrix that contain missing values is called complete case analysis</li>
<li>Complete case analysis, although commonly used, can lead to undesirable results—the extent to which depends on the category of missingness</li>
</ul>
<h3 id="the-categories-of-missingness-are">The categories of missingness are:</h3>
<ol type="1">
<li>Missing completely at random or MCAR:</li>
</ol>
<p>When data are MCAR, missing cases are, on average, identical to non-missing cases, with respect to the feature matrix. Complete case analysis will reduce the power of the analysis, but will not affect bias.</p>
<ol start="2" type="1">
<li>Missing at random or MAR:</li>
</ol>
<p>When data are MAR the missing data often have some dependence on measured values, and models can be used to help impute what the likely data would be. For example, in an MLB survey, there may be a gender bias when it comes to completing all of the questions.</p>
<ol start="3" type="1">
<li>Missing not at random or MNAR:</li>
</ol>
<p>In this case the missing data depend on unmeasured or unknown variables. There is no information available to account for the missingness.</p>
<ul>
<li>The best case scenario is that the data are MCAR. It should be noted that imputing values under the other two types of missingness can result in an increase in bias.</li>
<li>In statistics the process of replacing missing data with substituted values is known as imputation.</li>
<li>It is a common practice to perform multiple imputations.</li>
<li>The practice of imputing missing values introduces uncertainty into the results of a data science project.</li>
<li>One way to deal with that additional uncertainty is to try a range of different values for imputation and measure how the results vary between each set of imputations. This technique is known as multiple imputation.</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Model-Training-Tricks-2/2020/04/28/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Model-Training-Tricks-2/2020/04/28/" class="post-title-link" itemprop="url">Model Training Tricks (2)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-28 04:04:20" itemprop="dateCreated datePublished" datetime="2020-04-28T04:04:20+08:00">2020-04-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-29 05:09:54" itemprop="dateModified" datetime="2020-04-29T05:09:54+08:00">2020-04-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Competition/" itemprop="url" rel="index"><span itemprop="name">Competition</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Competition/Tricks/" itemprop="url" rel="index"><span itemprop="name">Tricks</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Model-Training-Tricks-2/2020/04/28/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Model-Training-Tricks-2/2020/04/28/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>If you have unlimited data, unlimited memory, and unlimited time, then the advice is easy: train a huge model on all of your data for a really long time. The reason that deep learning is not straightforward is because your data, memory, and time is limited. If you are running out of memory or time, then the solution is to train a smaller model. If you are not able to train for long enough to overfit, then you are not taking advantage of the capacity of your model.</p>
<p>So step one is to get to the point that you can overfit. Then, the question is how to reduce that overfitting.</p>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="1.png" width = "80%" height="80%">
</center>
<p>Many practitioners when faced with an overfitting model start at exactly the wrong end of this diagram. Their starting point is to use a smaller model, or more regularisation. Using a smaller model should be absolutely the last step you take, unless your model is taking up too much time or memory. Reducing the size of your model as reducing the ability of your model to learn subtle relationships in your data. Instead, your first step should be to seek to create more data. That could involve adding more labels to data that you already have in your organisation, finding additional tasks that your model could be asked to solve (or to think of it another way, identifying different kinds of labels that you could model), or creating additional synthetic data via using more or different data augmentation. Thanks to the development of mixup and similar approaches, effective data augmentation is now available for nearly all kinds of data. Once you've got as much data as you think you can reasonably get a hold of, and are using it as effectively as possible by taking advantage of all of the labels that you can find, and all of the augmentation that make sense, if you are still overfitting and you should think about using more generalisable architectures. For instance, adding batch normalisation may improve generalisation. If you are still overfitting after doing the best you can at using your data and tuning your architecture, then you can take a look at regularisation. Generally speaking, adding dropout to the last layer or two will do a good job of regularising your model. However, as we learnt from the story of the development of AWD-LSTM, it is often the case that adding dropout of different types throughout your model can help regularise even better. Generally speaking, a larger model with more regularisation is more flexible, and can therefore be more accurate than a smaller model with less regularisation. Only after considering all of these options would be recommend that you try using smaller versions of your architectures.</p>
<h2 id="reference">Reference</h2>
<ol type="1">
<li>https://github.com/fastai/fastbook/blob/master/15_arch_details.ipynb</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Model-Training-Tricks-1/2020/04/27/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Model-Training-Tricks-1/2020/04/27/" class="post-title-link" itemprop="url">Model Training Tricks (1)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-27 16:21:11" itemprop="dateCreated datePublished" datetime="2020-04-27T16:21:11+08:00">2020-04-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-12-31 15:41:56" itemprop="dateModified" datetime="2021-12-31T15:41:56+08:00">2021-12-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Competition/" itemprop="url" rel="index"><span itemprop="name">Competition</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Competition/Tricks/" itemprop="url" rel="index"><span itemprop="name">Tricks</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Model-Training-Tricks-1/2020/04/27/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Model-Training-Tricks-1/2020/04/27/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Model Training Tricks (1)</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/Model-Training-Tricks-1/2020/04/27/">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Empathize-Stage/2020/04/21/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Empathize-Stage/2020/04/21/" class="post-title-link" itemprop="url">Empathize Stage</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-21 23:47:10" itemprop="dateCreated datePublished" datetime="2020-04-21T23:47:10+08:00">2020-04-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-22 13:30:34" itemprop="dateModified" datetime="2020-04-22T13:30:34+08:00">2020-04-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI-Workflow/" itemprop="url" rel="index"><span itemprop="name">AI Workflow</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI-Workflow/Process-Model/" itemprop="url" rel="index"><span itemprop="name">Process Model</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Empathize-Stage/2020/04/21/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Empathize-Stage/2020/04/21/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="empathize-process">Empathize Process</h2>
<ol type="1">
<li>Get as close to the source of data as possible usually by interviewing the people involved</li>
<li>Identify the business problem</li>
<li>Obtain all of the relevant the data</li>
<li>Translate the business problem into a testable hypothesis or hypotheses</li>
</ol>
<h2 id="identifying-the-business-opportunity-through-the-eyes">Identifying the business opportunity: Through the eyes</h2>
<h3 id="our-story">Our story</h3>
<p><strong>The first stage of any project in a large enterprise is to identify the business opportunity. In the world of design thinking, this begins with the Empathize stage</strong>. During this time, you and your team are gathering as much information as possible to understand the challenges faced by your AAVAIL.</p>
<p>You are suprised by the fact that you, a data scientist, are being asked to help out with interviews, observations, process mapping, and various design thinking sessions. These techniques as well as many others are used during the empathize stage to gather <strong>as much information as possible</strong> so that a problem may be defined.</p>
<p>As a data scientist, this process should be used to guide your investigative process. Ultimately, your top priority is to analyze the data coming out of Singapore, understand the problem and fix the situation. <strong>The involved parties are subscribers, data engineers, data scientists, marketing and management</strong>. You are going to need to talk everyone involved in the data generation process. This is why you're spending time on interviews and observations.</p>
<p><strong>Asking questions is a critical part of getting the process started</strong>. You will want to be naturally curious gathering details about the product, the subscriber, and the interaction between the two. This information gathering stage provides both a perspective on the situation and it will help you formulate the business question.</p>
<p>In the short sections below, we provide guidelines for asking questions and beginning with an investigative mindset.</p>
<h3 id="articulate-the-business-question">Articulate the business question</h3>
<p>There are generally many business questions that can be derived from a given situation. It is an important thought exercise to enumerate the possible questions, that way it makes the discussion easier when you work with the involved stakeholders in order to focus and prioritize. In this situation here are some ways of articulating the business case.</p>
<ul>
<li>Can we use marketing to reduce the rate of churn?</li>
<li>Can we salvage the Singapore market with new products?</li>
<li>Are there factors outside of our influence that caused the situation in Singapore and is it temporary?</li>
<li>Can we identify the underlying variables in Singapore that are related to churn and can we use the knowledge to remedy the situations?</li>
<li>The business problem in all of these examples is written shown in terms of the data we have.</li>
</ul>
<p>NOTE: This case study can be approached in many different ways and there may not be a clear right or wrong. During the various modules of this course, we will provide guidance when there are multiple paths to choose from.</p>
<h3 id="prioritize">Prioritize</h3>
<p>It is logical, but there is a need to prioritize If there are several distinct business objectives. In this case maybe one is related to reducing chrun directly and another is about profitability.</p>
<p>There are three major contributing factors when it comes to priority.</p>
<h4 id="stakeholder-or-domain-expert-opinion">Stakeholder or domain expert opinion</h4>
<p>In situations where considerable domain expertise is required to effectively prioritize (e.g. Physics, Medicine and Finance) prioritization will likely be driven by the people closest to the domain.</p>
<h4 id="feasibility">Feasibility</h4>
<ul>
<li>Do we have the necessary data to address the business questions?</li>
<li>Do we have clean enough data to address the business questions?</li>
<li>Do we have the technology infrastructure to deploy a solution once the data are modeled?</li>
</ul>
<h4 id="impact">Impact</h4>
<p>When looking at Impact we’re purely looking at expected dollar contribution and added value from a monetary perspective. When possible, calculating the back-of-the-envelope ROI is a crucial step that you can do. This is an expectation and not real ROI calculation, but it is a guiding principle nonetheless.</p>
<p>The ROI calculation should be an expected dollar value that you can generate based on all available information you currently have in your organization combined with any domain insight you can collect.</p>
<p>Measuring the back-of-the-envelope ROI calculation could make use of any of the following:</p>
<ul>
<li>Estimates for fully-loaded salaries of employees involved</li>
<li>Cost per unit item and/or time required to produce</li>
<li>Number of customers, clients, or users</li>
<li>Revenue and more</li>
</ul>
<h2 id="scientific-thinking-for-business">Scientific Thinking for Business</h2>
<h3 id="our-story-1">Our Story</h3>
<p>Data science involves lots of investigation via trial and error. The investigations are based on evidence and this is one of the strongest reasons why data science is considered a "real" science.</p>
<p>You will be using a scientific process with your work at AAVAIL. This will help you to organize your work as well as be able to clearly explain everything you are doing to the AAVAIL leadership.</p>
<p>Let's take a look now at some guidance and best practices for engaging with a <strong>scientific mindset</strong>.</p>
<h3 id="science-is-a-process-and-the-route-to-solving-problems-is-not-always-direct">Science is a process and the route to solving problems is not always direct</h3>
<p>A common argument made by statisticians and mathematicians is that data science is not really a science. This is untrue, mainly because data science involves a lot of <strong>investigations</strong> through sometimes chaotic data sets, in search of meaningful patterns that might help in solving particular problems.</p>
<p>Since data science implies a scientific approach, it is important that all data scientists learn to adopt and use a scientific thought process. <strong>A scientific thought process of observation, developing hypotheses, testing hypotheses, and modifying hypotheses is critical to your success as a data scientist</strong>.</p>
<p>Pulling in data and jumping right into exploratory data analysis can make your work prone to exactly the types of negative issues that plague data science today. There are a number of well-discussed issues revolving around data science and data science teams not living up to promised potential.</p>
<p>At the heart of this problem is the process of communicating results to leadership. It should begin with a meaningful and well-articulated business opportunity. If that opportunity is stated too simply, as say, increasing overall revenue then the central talking point for communication is too vague to be meaningful from the data side.</p>
<blockquote>
<p>The business scenario needs to be communicated in a couple of ways: 1. Stated in a testable way in terms of data 2. Stated in a clear way that minimizes the influence of confounding factors</p>
</blockquote>
<h3 id="testable-hypotheses">Testable hypotheses</h3>
<p>There is no one single best way to articulate a business opportunity as a testable hypothesis. In some cases the statement will be intuitive, but in other cases there will be some back and forth with stakeholders and domain experts.</p>
<h3 id="guidelines-for-creating-testable-hypotheses">Guidelines for creating testable hypotheses</h3>
<ol type="1">
<li>Become a scientist of the business</li>
</ol>
<p>Spend a little bit less time learning new algorithms and Python packages and more time learning the levers that make your specific business go up or down and the variables that impact those levers.</p>
<ol start="2" type="1">
<li>Make an effort to understand how the data are produced</li>
</ol>
<p>If it comes down to it, sources of variation can be explicitly accounted for in many types of models. If the data come from a database you should ask about the process by which the data are stored. If the data are compiled by another person then dig into the details and find out about the compiling process as well as the details of what happened before the data arrived on their desk.</p>
<ol start="3" type="1">
<li>Make yourself part of the business</li>
</ol>
<p>Do not under any circumstances become siloed. Proactively get involved with the business unit as a partner, not a support function.</p>
<ol start="4" type="1">
<li>Think about how to measure success</li>
</ol>
<p>When thinking about what course of action might be most appropriate, keep at the forefront of your mind how you will measure business value when said action is complete.</p>
<p><strong>IMPORTANT</strong>: Data Science is NOT Business Intelligence. BI analysts serve to derive business insights out of data. There is without a doubt some overlap, but the job of a data scientist is to investigate the business opportunity and solve it.</p>
<p>There is a balancing act to maintain between directly addressing the business need and ensuring that you have thoughtfully studied the problem enough to ensure that you can account for most of the likely contingencies. The scientific method can be of some guidance here.</p>
<h3 id="thinking-scientifically-about-the-business-scenario">Thinking scientifically about the business scenario</h3>
<p>A major goal of this process is to make the business objectives clear to leadership. Some of these individuals are technical and some are not, so as a good rule-of-thumb get in the habit of articulating the business problem at a level that everyone can understand. Stakeholders and leadership need to know what you are trying to accomplish before you begin work. They also need to be aware from the start what success would look like. Science is an iterative process and many experiments produce results that some might consider a failure. However, experiments that are properly setup will not fail no matter the result–the result may not useful but you have gained valuable information along the way.</p>
<p>Experiments in this context could refer to an actual scientific experiment (e.g. A/B testing) or it could be more subtle. Let’s say you work for a company that collects tolls in an automated way, and you want to identify the make and model of each car in order to modify pricing models based on predicted vehicle weight. After talking with the stakeholders and the folks who implemented the image storage solution you are ready to begin. The experiment here has to do with how you begin. You may think that there is enough training data to implement a huge multi-class model and just solve most of the problem. If you approach it that way then you are hypothesizing that the solution will work.</p>
<p>For those of you who have done much image analysis work, you could guess that approach would likely result in a significant loss of time. If we take a step back and think scientifically, we could approach the solution from an evidence driven perspective. Before investing a significant amount of time you may try to see if you can distinguish one make and model from the rest before adding more classes. You may want to first pipe the images through an image segmentation algorithm to identify the make of the car. There are many possible ways to build towards a comprehensive solution, but it is important to determine if either of these piecemeal approaches would have any immediate business value.</p>
<p>This might be a good time for a reminder about the steps in the scientific method.</p>
<h3 id="the-scientific-method">The Scientific Method</h3>
<p>It is the process by which science is carried out. The general idea is to build on previous knowledge to in order to improve an understanding of a given topic.</p>
<ol type="1">
<li>Formulate the question</li>
<li>Generate a hypothesis to address the question</li>
<li>Make a prediction</li>
<li>Conduct an experiment</li>
<li>Analyze the data and draw a conclusion</li>
</ol>
<p>We will continue with an interactive example, but first it is important to note that <strong>Scientific experiments must be repeatable in order to become reliable evidence.</strong></p>
<h4 id="question">Question</h4>
<p>The question can be open-ended and generally it summarizes your business opportunity. Let’s say you work for a small business that manufactures sleds and other winter gear and you are not sure which cities to build your next retail locations. You have heard that Utah, Colorado and Vermont are all states that have high rates of snowfall, but it is unclear which one has the highest rate of snowfall.</p>
<h4 id="hypothesis">Hypothesis</h4>
<p>Because the Rocky mountains are higher in elevation and they are well-known for fresh powder on the ski slopes you hypothesize that both Utah and Colorado have more snow than Vermont.</p>
<h4 id="prediction">Prediction</h4>
<p>If you were to run a hypothesis test Vermont would have significantly less snow fall than Colorado or Utah</p>
<h4 id="experiment">Experiment</h4>
<p>You hit the NOAA weather API to get average annual snowfall by city. We have compiled these data for you in snowfall.csv. You could use a 1-way ANOVA to test the validity of your prediction, but let’s start by looking at the data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># First we read in the data</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;../data/snowfall.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Next, subset the data to focus only on the states of interest</span></span><br><span class="line"></span><br><span class="line">mask = [<span class="literal">True</span> <span class="keyword">if</span> s <span class="keyword">in</span> [<span class="string">&#x27;CO&#x27;</span>,<span class="string">&#x27;UT&#x27;</span>,<span class="string">&#x27;VT&#x27;</span>] <span class="keyword">else</span> <span class="literal">False</span> <span class="keyword">for</span> s <span class="keyword">in</span> df[<span class="string">&#x27;state&#x27;</span>].values]</span><br><span class="line">df1 = df[mask]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Finally, create a pivot of the data that focuses only on the relevant summary data</span></span><br><span class="line"></span><br><span class="line">pivot = df1.groupby([<span class="string">&#x27;state&#x27;</span>])[<span class="string">&#x27;snowfall&#x27;</span>].describe()</span><br><span class="line">df1_pivot = pd.DataFrame(&#123;<span class="string">&#x27;count&#x27;</span>: pivot[<span class="string">&#x27;count&#x27;</span>],</span><br><span class="line">                          <span class="string">&#x27;avg_snowfall&#x27;</span>: pivot[<span class="string">&#x27;mean&#x27;</span>],</span><br><span class="line">                          <span class="string">&#x27;max_snowfall&#x27;</span>: pivot[<span class="string">&#x27;max&#x27;</span>]&#125;)</span><br><span class="line"><span class="built_in">print</span>(df1_pivot)</span><br><span class="line"></span><br><span class="line"><span class="comment">#        count  avg_snowfall  max_snowfall</span></span><br><span class="line"><span class="comment"># state</span></span><br><span class="line"><span class="comment"># CO       5.0         37.76          59.6</span></span><br><span class="line"><span class="comment"># UT       2.0         51.65          58.2</span></span><br><span class="line"><span class="comment"># VT       1.0         80.90          80.9</span></span><br></pre></td></tr></table></figure>
<h4 id="analyze">Analyze</h4>
<p>There is not enough data to do a 1-way ANOVA. The experiment is not a failure; it has a few pieces of information.</p>
<p>There is not enough data There is a small possibility that VT gets more snow on average than either CO or UT Our degree of belief in the conclusion drawn from (2) is very small because of (1) The notion of degree of belief is central to scientific thinking. It is somehow a part of our human nature to believe statements that have little to no supporting evidence. <strong>In science the word belief, with respect to a hypothesis is proportional to the evidence</strong>. With more evidence available, ideally, from repeated experiments, one’s degree of belief should change. Evidence is derived from the process described above and if we have none then we are stuck at the question stage and a proper scientific hypothesiscannot be made.</p>
<p>The other important side to degree of belief is that it never caps out at 100 percent certainty. Some hypotheses have become laws like Newton’s Law of Gravitation, but most natural phenomena in the world outside of physics cannot be explained as a law.</p>
<p>A hypothesis is the simplest explanation of a phenomenon. A scientific theory is an in-depth explanation of the observed phenomenon. Do not be mistaken with the word theory, there can be sufficient evidence that your degree of belief all but touches 100%, and is plenty for decision making purposes. A built-in safeguard for scientific thought is that our degree of belief does not reach 100%, which leaves some room to find new evidence that could move the dial in the other direction.</p>
<p>There are additional factors like external peer review that help ensure the integrity of the scientific method and in the case of implementing a model for a specific business task this could mean assigning reviewers for a pull request or simply asking other qualified individuals to check over your work.</p>
<h2 id="gathering-data">Gathering Data</h2>
<h3 id="our-story-2">Our Story</h3>
<p>Your first step at AAVAIL, just like everywhere else, it to look at the data sources. You soon discover that AAVAIL has data everywhere! There is no shortage of data. It looks like they have managed to store every type of transaction with their subscribers.</p>
<p>You will need a smart way of managing all of this data. Let's take a look now at some best practices for managing data in a large enterprise.</p>
<h3 id="documenting-your-data">Documenting your data</h3>
<p>Too often data scientists will find themselves deep in the process of developing a solution, based on the data that was provided to them, before they realize that the data itself is flawed, inaccurate or in some other way non-ideal. Developing the habit of creating a simple document with at least a description of the ideal data needed to test the hypotheses around the business problem may seem like an unnecessary step, but it has potential to both:</p>
<ul>
<li>Streamline the modeling process</li>
<li>Help ensure that all future data come in an improved form</li>
</ul>
<h3 id="etl">ETL</h3>
<p>The process of gathering data is often referred to as Extract, Transform, Load (ETL). Data is generally gathered (or extracted) from heterogeneous sources, cleaned (transformed) and loaded into a single place that facilitates analysis. Before the advent of the modern data scientist’s toolkit data was often staged in a database,data lake or a data warehouse. Still today data is frequently staged to facilitate collaboration, but there are tools now that enable more possibilities today than ever before. Jupyter Lab has an extension called data grid that allows it to read delimited files with millions or even billions of rows. Then tools like Dask help you scale your analyses. To ensure that projects are completed in a reasonable amount of time the initial pass at ETL should use a simple format like CSV, then a more complex system can be built out once you have accomplished the Minimum Viable Product (MVP).</p>
<h3 id="common-methods-of-gathering-data">Common methods of gathering data</h3>
<h4 id="plain-text-files">Plain text files</h4>
<p>Plain text file can come in many forms and generally the open function is used to bring the data into a Python environment. This is a flexible format, but because no structure is imposed, custom scripts are generally needed to parse these files and these scripts do not always generalize to new files.</p>
<p>The large majority of data science projects involve a modeling step that requires input data in a tabular numeric format. In order to extract data from a plain text file you may need to identify patterns in the text and use regular expressions (regex) to pull out the relevant information. Python’s built-in regex library is known as re.</p>
<p>On the other hand if the data you are working with consists of natural language, then there are a number of libraries that can work directly with the text files. The two main libraries are:</p>
<ul>
<li>spaCy</li>
<li>NLTK</li>
</ul>
<p>Also, scikit-learn has become a standard tool in the overall workflow when processing these files.</p>
<ul>
<li>scikit-learn’s text tutorial</li>
</ul>
<p>These tools can be applied to unstructured text to generate things like word counts, and word frequencies. We saw an example of this in the Data science workflow combined with design thinking example.</p>
<h4 id="delimited-files">Delimited files</h4>
<p>One of the most commonly encountered ways of storing structured data is in delimited files, where rows of tabular data are stored in lines of a text file and the columns within each row are separated by a special “delimiter” character such as a comma or a tab character.</p>
<p>This simple structure helps account for the popularity of these formats, with probably the most widely used being Comma-Separated Values (CSV). CSV files are both human and machine readable, and have minimal overhead in terms of the proportion of the file devoted to defining the structure of the data when compared to most other file formats. As such Pandas comes with methods for both reading and writingCSV files. (Note that these functions can also handle other delimiters like tab or the pipe character “|”, but commas are the default.)</p>
<p>Spreadsheet programs like Microsoft Excel that are used for analyzing tabular data also read from and write to files in CSV format. The native Excel file format (often with file extensions .xls or .xlsx) can also be considered a delimited file type. Though these files also contain a significant amount of extra information related to things like styling that are separate from the actual data. Nonetheless, since these files are commonly used to save datasets, Pandas also has a method for reading them: pandas.read_excel.</p>
<p>HINT: A best practice when loading data from plain text or delimited files is to separate the code for parsing into its own script. Because the files are read line by line in a separate Python call, it is more memory efficient and this separation of tasks helps with automation and maintenance.</p>
<p>It is a common mistake to try to read large files into pandas then use the date frame environment to parse. If your parsing (cleaning) task is simple then use a parser. Here is a simple example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/evn/python</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">simple example of a parser</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"><span class="comment">## specify the files</span></span><br><span class="line">file_in = os.path.join(<span class="string">&quot;..&quot;</span>,<span class="string">&quot;data&quot;</span>,<span class="string">&quot;snowfall.csv&quot;</span>)</span><br><span class="line">file_out = os.path.join(<span class="string">&quot;..&quot;</span>,<span class="string">&quot;data&quot;</span>,<span class="string">&quot;snowfall_parsed.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## create an outfile handle (needs to be closed)</span></span><br><span class="line">fidout = <span class="built_in">open</span>(file_out,<span class="string">&quot;w&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## use the csv module to read/write</span></span><br><span class="line">writer = csv.writer(fidout)</span><br><span class="line"></span><br><span class="line"><span class="comment">## generic parsing function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_line</span>(<span class="params">line</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> line[<span class="number">3</span>] <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;HI&quot;</span>,<span class="string">&quot;NC&quot;</span>,<span class="string">&quot;OR&quot;</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> line + [<span class="string">&#x27;new_data&#x27;</span>]</span><br><span class="line">    </span><br><span class="line"><span class="comment">## for each line in the file read in the first file that you need to reference</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(file_in) <span class="keyword">as</span> csvfile:</span><br><span class="line">    reader = csv.reader(csvfile, delimiter=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">    header_in = reader.__next__()</span><br><span class="line">    writer.writerow(header_in + [<span class="string">&quot;new_column&quot;</span>])</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> reader:</span><br><span class="line">        line = parse_line(line)</span><br><span class="line">        <span class="keyword">if</span> line:</span><br><span class="line">            writer.writerow(line)</span><br><span class="line">   </span><br><span class="line">fidout.close()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;done parsing&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>The highlighted lines show where this parser changes the original data by filtering and adding an additional column.</p>
<h4 id="json-files">JSON files</h4>
<p>While delimited files are well suited for housing data in flat tables, datasets with more complex structures require different formats. The JavaScript Object Notation (JSON) file format can accommodate quite complex data hierarchies. Python’s built-in library handles reading/writing JSON files.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">data = json.load(<span class="built_in">open</span>(<span class="string">&#x27;some_file.json&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p>In addition, pandas.read_json is also available for loading JSON files.</p>
<p>At its base a JSON object can be thought of as analogous to a Python dictionary or list of dictionaries. For example a table of data from a JSON file could be read into Python as a list of dictionaries where each dictionary represented a row of the table, and the keys of each dictionary were the column names. This formatting is somewhat inefficient for simple tabular data, with column information explicitly repeated with each row, but is useful when representing more intricate relationships in the data. JSON objects often have a highly nested structure that you can think of as dictionaries within dictionaries within dictionaries.</p>
<p>For example, modern websites track a great deal of information about users’ interactions with the site and the varied nature of these interactions make a table structure too rigid for recording them. In practice, most sites send JSON objects back and forth between the user’s computer and the website’s server. Many data scientists’ primary source of data are ultimately these JSON objects.</p>
<h4 id="relational-databases">Relational databases</h4>
<p>Relational databases, i.e. those that impose a schema on datasets are a major source of data for data science projects. Database tables can naturally be converted into Python objects like Pandas DataFrames. Reading data into a Python environment requires opening a connection to a database and there are various libraries for managing this connection, depending on the type of database to be accessed. Some Relational DataBase Management System (RDBMS) and their corresponding interface utilities for Python:</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">RDBMS</th>
<th style="text-align: left;">Python Connector</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">MySQL</td>
<td style="text-align: left;">MySQL Connector</td>
</tr>
<tr class="even">
<td style="text-align: left;">PostgreSQL</td>
<td style="text-align: left;">Psycopg</td>
</tr>
<tr class="odd">
<td style="text-align: left;">SQLite</td>
<td style="text-align: left;">sqlite3</td>
</tr>
<tr class="even">
<td style="text-align: left;">Microsoft SQL</td>
<td style="text-align: left;">pyodbc</td>
</tr>
</tbody>
</table>
<p>Each of these tools are designed with maintaining the integrity of the database in mind, including methods for rolling back updates, and ways to safeguard against SQL Injection vulnerabilities. As such, the process of querying the database and ingesting the results can seem fairly involved. For example, here is a basic flow for getting the contents of a table from a PostgreSQL database using psycopg2.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> psycopg2 <span class="keyword">as</span> pg2</span><br><span class="line">conn = pg2.connect(database=<span class="string">&#x27;my_db&#x27;</span>, user=<span class="string">&#x27;my_username&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create a cursor to traverse the database</span></span><br><span class="line">cur = conn.cursor()</span><br><span class="line"></span><br><span class="line"><span class="comment"># cursor object executes a query, but does not automatically return results</span></span><br><span class="line">cur.execute(<span class="string">&quot;SELECT * FROM my_table&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Return all query results</span></span><br><span class="line">results = cur.fetchall()</span><br><span class="line"><span class="comment"># WARNING: If the result set is large, it may overwhelm the memory</span></span><br><span class="line"><span class="comment"># resources on your machine.</span></span><br><span class="line"></span><br><span class="line">cur.close()</span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure>
<p>While the steps required to connect, query, and disconnect from a relational database are more involved than when loading in data from a file on your local machine, the table structure from the database schema basically guarantees that the data will fit cleanly into a Pandas DataFrame or NumPy Array.</p>
<h4 id="nosql-databases">NoSQL databases</h4>
<p>“NoSQL” is a catch-all term referring to “non SQL” or “non relational”, or more recently “not only SQL”. Usually meaning that the method for housing data does not impose a schema on it (or at least not as tightly constrained as in relational databases). This tradeoff gives greater flexibility in what and how data are stored at the cost of increased traversal times when searching the database. This tradeoff is similar to the one we encountered when working with delimited files like CSVs and with JSON files. When loading or dumping data between a file and a database, CSVs are a good match for tables in a relational database, whereas JSONs are more aligned with NoSQL databases.</p>
<p>The are many examples of NoSQL databases, each with different use cases, and most of which can be accessed with Python.</p>
<p>One flexible and popular example is MongoDB. MongoDB is a document-oriented database, where a “document” encapsulates and encodes data in a standard format. In the case of MongoDB, that format is JSON-like. Like the relational databases mentioned above, MongoDB has a client for querying it directly, as well as a connector for querying from within Python. These queries are constructed usingMongoDB’s query syntax.</p>
<p>The Python connector to MongoDB is PyMongo.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</span><br><span class="line"><span class="comment"># By default a Mongo db running locally is accessible via port 27017</span></span><br><span class="line">client = MongoClient(<span class="string">&#x27;localhost&#x27;</span>, <span class="number">27017</span>)</span><br><span class="line">db = client[<span class="string">&#x27;database_name&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Within a db, documents are grouped into &quot;collections&quot; -- roughly equivalent</span></span><br><span class="line"><span class="comment"># to tables in a relational db.</span></span><br><span class="line">coll = db[<span class="string">&#x27;collection_name&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Return all the documents within the collection</span></span><br><span class="line">docs = coll.find()</span><br></pre></td></tr></table></figure>
<h4 id="web-scraping-and-apis">Web scraping and APIs</h4>
<p>Automating the process of downloading content from websites is known as web scraping.</p>
<p>** IMPORTANT ** &gt; Web scraping can be done in legitimate ways, but just as easily web scraping tools do not stop you from violating a websites terms of service. If a website encourages the sharing of their data then they will create a specific API endpoint that you will use. More often than not the API will require to have an identifying key.</p>
<p>Various tools in Python are available for accessing and parsing webpage data.Requests is a user-friendly library for downloading web pages. It can also be used to retrieve files that are exposed through a URL. For a webpage the data returned from a call using Requests is the HyperText Markup Language (HTML) code that instructs a client such as a web browser how to display a page. This HTML code will often (but not always) contain the data you want to collect from the particular webpage.</p>
<p>Modern webpages tend to have a great deal of information in their HTML beyond what is shown to the user, so parsing through it all to collect the relevant data can be a daunting task. Fortunately, if a page is readable in your browser, then its HTML must have a coherent structure. Beautiful Soup is a Python library that provides tools for walking through that structure in a systematic and repeatable way. Thus, in the context of web scraping Beautiful Soup can be used to extract the relevant data from the soup of all the other information contained in an HTML file.</p>
<p>Many websites’ contents are dynamically rendered in such a way that the information displayed on a page never makes it directly into the page’s HTML. In such cases it may not be possible to download the data of interest with a tool like Requests. One option in this scenario is to move to a tool for browser automation, such as Selenium. Selenium’s Python interface is described here.</p>
<p>Another tool, specifically designed for web scraping in Python, is Scrapy.</p>
<p>Depending on your website of interest you may have to try several of these tools to successfully collect the relevant data in a scalable way. But a general rule of thumb is that if you can see what you want to collect in your browser, the the website sent it to you, so it should be retrievable.</p>
<h4 id="streaming-data">Streaming data</h4>
<p>In the modern landscape of business data streams are becoming more common. A data stream is a sequence of digitally encoded signals. Data can be streamed for many purposes including storage and further processing (like modeling). Data streams become important when the data of a project or company becomes mature and the AI pipeline is connected to it. As we move into the portions of the AI enterprise workflow that focus on models in production we will be using Apache Spark’s streaming to connect deployed models with streaming data. Data collected from sensors or devices connected via the internet of things are oftent setup to produce streaming data. We will work specifically with these types of data in module 5.</p>
<h4 id="apache-hadoop-file-share-hdfs">Apache Hadoop File Share (HDFS)</h4>
<p>Apache Hadoop File Share (HDFS) is the core of Apache Hadoop , an open source system that is designed to use arrays of commodity hardware to store and manage very large datasets.</p>
<p>HDFS is the storage component of the system. Large datasets are divided into blocks, and those blocks are distributed and stored across the nodes in an HDFS cluster. Any code that is created to analyze the datasets stored in a Hadoop cluster is executed locally for each block of data, and in parallel. This parallel analysis of data blocks means that Hadoop can process very large data sets rapidly.</p>
<p>The Hadoop framework itself is written mostly in Java. However, any language, including Python, may be used to analyze the data stored in a Hadoop cluster. The Apache Foundation provides a number of other packages that may be installed alongside Hadoop to add additional relational database functionality and improve scalability.</p>
<p>IMPORTANT: Apache Hadoop is a de facto standard in many large enterprises today. It is often used with Apache Spark and a NoSQL database engine to provide data storage and management of data pipelines used by machine learning models.</p>
<h4 id="other-sources-of-data-formats">Other sources of data formats</h4>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Format</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">HDF5</td>
<td style="text-align: left;">There is a is a hierarchical format HDF5 used to store complex scientific data. The format is useful for storing and sharing large amounts of data.</td>
</tr>
<tr class="even">
<td style="text-align: left;">NumPy’s *.npy and *.nzp formats</td>
<td style="text-align: left;">NumPy has its own binary format (NPY) and the NPZ format is an extension of it that allows multiple arrays and compression.</td>
</tr>
</tbody>
</table>
<h2 id="summary">Summary</h2>
<p>In this module you should have learned:</p>
<ul>
<li>Stakeholder or domain expert opinion, feasibility and impact are three of the most important factors when prioritizing business opportunities</li>
<li>The practice of articulating a business opportunity, with the data in mind, as a testable hypothesis helps keep the overall project linked to the business needs</li>
<li>The notion of degree of belief is important when making statements both in science and in business. No statement has 100% degree of belief, it is some percentage of 100% that is a reflection of accumulated evidence</li>
<li>The scientific method helps formalize a process for rationalizing business decisions through experimentation and evidence</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Decision-Thinking-and-Data-Science-Process/2020/04/21/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Decision-Thinking-and-Data-Science-Process/2020/04/21/" class="post-title-link" itemprop="url">Decision Thinking and Data Science Process</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-21 17:18:18" itemprop="dateCreated datePublished" datetime="2020-04-21T17:18:18+08:00">2020-04-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-22 05:40:13" itemprop="dateModified" datetime="2020-04-22T05:40:13+08:00">2020-04-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI-Workflow/" itemprop="url" rel="index"><span itemprop="name">AI Workflow</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI-Workflow/Process-Model/" itemprop="url" rel="index"><span itemprop="name">Process Model</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Decision-Thinking-and-Data-Science-Process/2020/04/21/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Decision-Thinking-and-Data-Science-Process/2020/04/21/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Between design thinking and the above mentioned process models there are several 1:1 relationships between stages. The other relationships are generally straightforward to delineate. The design thinking process is consists of five stages and it has the distinct advantage of being applied outside of data science.</p>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="1.png" width = "70%" height="70%">
<div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">
Design Thinking
</div>
</center>
<center>
<img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="2.png" width = "70%" height="70%">
<div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">
Process Models
</div>
</center>
<p>It is the details that keep you flowing from one stage to the next, while iterating in ways that are business driven that makes the contents of this course new. Let’s use a simple example to illustrate the basic process.</p>
<blockquote>
<p>A friend of yours just opened a new Sherlock Holmes themed café. Her café is state-of-the-art complete with monitors built into the tables. The business is off to a good start, but she has gotten some feedback that the games could use improvement. She knows that good games keep the customers around a little longer. The games are a way to keep customers entertained while they drink coffee and buy food items. She has some games already, but wants your help to create a few more games to keep customers both informed and entertained.</p>
</blockquote>
<p>Being a data scientist you would not just sit down and create a game—you are, of course, going to create based on your initial investigation of the business scenario.</p>
<h3 id="empathize">Empathize</h3>
<p><strong>In this stage time is dedicated to understanding the business opportunities.</strong></p>
<p>In this setting the frequency and duration of customer visits are going to be related to overall sales. The initial business opportunity here is How do you ensure new games drive revenue?. There are many other business opportunities, like what is the optimal menu for the customer-base and do seasonal variations of offerings help the business?, but lets focus on the initial one for this example. As part of this stage you would talk with your friend, her employees and some customers to do your best to fully understand the experience of the customer. The important thing here is to spend time on-site simulating the experience of a customer to obtain as genuine an understanding of the problem as possible. You may realize that most customers are there to work or most of them are just passing through. This domain knowledge is useful when making decisions like which new types of new games to create. After you have gathered your information and studied it you will generally articulate the business scenario using a scientific thought process—this means a statement that can be tested. The business opportunity should be stated in a way that minimizes the presence of confounding factors.</p>
<p>There are logical follow-up questions to ask to fully understand the problem, but the next two stages are the more appropriate places to get into these details. Now that you understand the problem it is time to gather the data.</p>
<p><strong>HINT</strong>: This is the stage where we gather all of the data and we make note of what would be ideal data.</p>
<ol type="1">
<li><p>The data here are mostly sales and customer profiles. There are two important aspects of the data that would be ideal:</p></li>
<li><p>The data are at a transaction level (each purchase and its associated data are recorded) We can associate game usage with transactions.</p></li>
</ol>
<p>Fortunately for us this is a modern cafe so customers order and play games through the same interface. Additionally, they are incentivized to login to the system and generate a customer profile. In this stage we go through the process of gathering the raw data. This may involve querying a database, gathering files, web-scraping and other mechanisms. It is important to gather <strong>all of the relevant data</strong> in this stage, because access and quality of the data may force you to modify the business question. It is very difficult to assess the quality of data when it is not in hand. If possible effort should be made to collect even marginally related data.</p>
<p>Lets assume that your initial investigation led you to understand that games that used quotations from the books in an interactive way were the most effective. So you have come up with the idea to develop a game that is built on a chatbot that has been trained to talk like Sherlock. This would involve Natural Language Processing (NLP) and we would need a corpus. As a start you might download The Adventures of Sherlock Holmes, by Arthur Conan Doyle from Project Gutenberg.</p>
<p><strong>HINT</strong>: This is a live coding example and we suggest that you open a Jupyter notebook either locally or within Watson Studio so that you may annotate and expand on the example freely.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">text = requests.get(<span class="string">&#x27;https://www.gutenberg.org/files/1661/1661-0.txt&#x27;</span>).text</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;sherlock-holmes.txt&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> text_file:</span><br><span class="line">    text_file.write(text)</span><br></pre></td></tr></table></figure>
<h3 id="define">Define</h3>
<p><strong>This is the data wrangling stage</strong></p>
<p>Given the data, an understanding of the business scenario and your gathered domain knowledge you will next perform your data cleaning and preliminary exploratory data analysis. To get to the point of preliminary investigation into the findings from the empathize stage it is frequently the case that we need to clean our data.</p>
<p>This could involve parsing JSON, manipulating SQL queries, reading CSV, cleaning a corpus of text, sifting through images, and so much more. One common goal of this part of the process is the creation of one or more Pandas dataframes or NumPy arrays that will be used for initial exploratory data analysis (EDA).</p>
<blockquote>
<p>Exploratory data analysis (EDA) is the process of analyzing data sets to create summaries and visualizations of the data. These summaries and visualizations are then used to guide the use of the data for solving business challenges.</p>
</blockquote>
<p><strong>HINT</strong>: This is the stage where we perform the initial EDA</p>
<p>Sometimes we need to perform a little EDA in order to determine how to best clean the data so these two steps are not necessarily distinct from each other. Visualization, basic hypothesis testing and simple feature engineering are among the most important tasks for EDA at this stage. An minimal example of a EDA plot is one where we look at the average number of words per sentence for the name mentions.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## read in the book        </span></span><br><span class="line">text = <span class="built_in">open</span>(<span class="string">&#x27;sherlock-holmes.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>).read()</span><br><span class="line"></span><br><span class="line"><span class="comment">## do some basic parsing and cleaning of sentences</span></span><br><span class="line">stop_pattern = <span class="string">&#x27;\.|\?|\!&#x27;</span></span><br><span class="line">sentences = re.split(stop_pattern, text)</span><br><span class="line">sentences = [re.sub(<span class="string">&quot;\r|\n&quot;</span>,<span class="string">&quot; &quot;</span>,s.lower()) <span class="keyword">for</span> s <span class="keyword">in</span> sentences][<span class="number">3</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment">## extract a few features and create a pandas df</span></span><br><span class="line">has_sherlock =  [<span class="literal">True</span> <span class="keyword">if</span> re.search(<span class="string">&quot;sherlock|holmes&quot;</span>,s) <span class="keyword">else</span> <span class="literal">False</span> <span class="keyword">for</span> s <span class="keyword">in</span> sentences]</span><br><span class="line">has_watson = [<span class="literal">True</span> <span class="keyword">if</span> re.search(<span class="string">&quot;john|watson&quot;</span>,s) <span class="keyword">else</span> <span class="literal">False</span> <span class="keyword">for</span> s <span class="keyword">in</span> sentences]</span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;text&#x27;</span>:sentences,<span class="string">&#x27;has_sherlock&#x27;</span>:has_sherlock,<span class="string">&#x27;has_watson&#x27;</span>:has_watson&#125;)</span><br><span class="line">df[<span class="string">&#x27;num_words&#x27;</span>] = df[<span class="string">&#x27;text&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">len</span>(x.split(<span class="string">&quot; &quot;</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment">## make eda plot</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line">ax1 = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line"></span><br><span class="line">data1 = df[df[<span class="string">&#x27;has_sherlock&#x27;</span>]==<span class="literal">True</span>]</span><br><span class="line">data2 = df[df[<span class="string">&#x27;has_watson&#x27;</span>]==<span class="literal">True</span>]</span><br><span class="line"></span><br><span class="line">data = [df[df[col]==<span class="literal">True</span>][<span class="string">&#x27;num_words&#x27;</span>].values <span class="keyword">for</span> col <span class="keyword">in</span> [<span class="string">&#x27;has_sherlock&#x27;</span>,<span class="string">&#x27;has_watson&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">pos = [<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line">ax1.violinplot(data, pos, points=<span class="number">40</span>, widths=<span class="number">0.5</span>,showextrema=<span class="literal">True</span>, showmedians=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">labels = [<span class="string">&#x27;Sherlock&#x27;</span>, <span class="string">&#x27;Watson&#x27;</span>]</span><br><span class="line">ax1.set_xticks(np.arange(<span class="number">1</span>, <span class="built_in">len</span>(labels) + <span class="number">1</span>))</span><br><span class="line">ax1.set_xticklabels(labels)</span><br><span class="line">ax1.set_xlim(<span class="number">0.25</span>, <span class="built_in">len</span>(labels) + <span class="number">0.75</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;# Words&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&quot;Words per sentence&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="ideate">Ideate</h3>
<p><strong>This is the stage where we modify our data and our features</strong></p>
<p>Now that you have clean data the data processing must continue until you are ready to input your data into a model. This stage contains all of the possible data manipulations you might perform before modeling. Perhaps the data need to be log transformed, standardized, reduced in dimensionality, kernel transformed, engineered to contain more features or transformed in some other way.</p>
<p>For our text data we would likely want to dig into the sentences themselves to make sure they fit the desired use case. If we were building a chatbot to engage with in a very Holmes manner then we would likely want to remove any sentences that were not said by Mr. Holmes, but his name was mentioned. If we were building a predictive model to determine which story a phrase would most likely have been generated, we would need to create a new column in our data frame representing the books themselves.</p>
<p>When working with text data many models that we might consider prefer a numeric representation of the data. This may be occurrences, frequencies, or another transformation of the original data. It is in this stage that these types of transformations are readied or carried out. For example here we import the necessary transformers for usage in the next stage.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfTransformer</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># extract the data to be used in the model from the df</span></span><br><span class="line">labels = np.zeros(df.shape[<span class="number">0</span>])</span><br><span class="line">labels[(df[<span class="string">&#x27;has_sherlock&#x27;</span>] == <span class="literal">True</span>)] = <span class="number">1</span></span><br><span class="line">labels[(df[<span class="string">&#x27;has_watson&#x27;</span>] == <span class="literal">True</span>)] = <span class="number">2</span></span><br><span class="line">df[<span class="string">&#x27;labels&#x27;</span>] = labels</span><br><span class="line">df = df[df[<span class="string">&#x27;labels&#x27;</span>]!=<span class="number">0</span>]</span><br><span class="line">X = df[<span class="string">&#x27;text&#x27;</span>].values</span><br><span class="line">y = df[<span class="string">&#x27;labels&#x27;</span>].values</span><br></pre></td></tr></table></figure>
<p>There are a lot of ways to prepare data for different models. In some case you will not know the best transformation or series of transformations until you have run the different models and made a comparison. The concept of pipelines is extremely useful for iterating over different permutations of transformers and models. The following topics will be covered in detail during Module 3.</p>
<ul>
<li>Unsupervised learning</li>
<li>Feature engineering</li>
<li>Dimension Reduction</li>
<li>Simulation</li>
<li>Missing value imputation</li>
<li>Outlier detection</li>
</ul>
<p><strong>HINT</strong>: This is the stage where we enumerate the advantages and disadvantages of the possible modeling solutions</p>
<p>Once the transformations are carried or staged as part of some pipeline it is a valuable exercise to document what you know about the process so far. The form that this most commonly takes is a table of possible modeling strategies complete with the advantages and disadvantages of each.</p>
<h3 id="prototype">Prototype</h3>
<p><strong>This is the modeling stage</strong></p>
<p>The data have been cleaned, processed and staged (ideally in a pipeline) for modeling. The modeling (classic statistics and machine learning) is the bread and butter of data science. This is the stage where most data scientists want to spend the majority of their time. It is where you will interface with the most intriguing aspects of this discipline.</p>
<p>To illustrate the process to the end shown below is a Support Vector Machine with Stochastic gradient decent as a model. The process involves the use of a train-test split and a pipeline because we want you to be exposed from the very beginning of this course with best practices. Given this example we also see that there can be considerable overlap between the ideate and prototype stages. The overlap exists because transformations of data are generally specific to models–as you will explore which model fits the situation best you will be modifying the transformations of your data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment">## carry out the train test split</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.33</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line">text_clf = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;vect&#x27;</span>, CountVectorizer()),</span><br><span class="line">    (<span class="string">&#x27;tfidf&#x27;</span>, TfidfTransformer()),</span><br><span class="line">    (<span class="string">&#x27;clf&#x27;</span>, SGDClassifier(loss=<span class="string">&#x27;hinge&#x27;</span>, penalty=<span class="string">&#x27;l2&#x27;</span>,</span><br><span class="line">                        alpha=<span class="number">1e-3</span>, random_state=<span class="number">42</span>,</span><br><span class="line">                        max_iter=<span class="number">5</span>, tol=<span class="literal">None</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment">## train a model</span></span><br><span class="line">text_clf.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>
<h3 id="testing">Testing</h3>
<p><strong>This is the production, testing and feedback loop stage</strong></p>
<p>The model works and there are evaluation metrics to provide insight into how well it works. However, the process does not end here. Perhaps the model runs, but it is not yet in production or maybe you want to try different models and/or transformers. Once in production you might want to run some tests to determine if it will handle load or if it will scale well as the data grows. A working model with an impressive f-score does not mean it will be effective in practice. This stage is dedicated to all of the considerations that come after the initial modeling is carried out.</p>
<p>It is also the stage where you will determine how best to iterate. Design thinking like data science is an iterative process. Our model performed very well (see below), possibly because Dr. Holmes and Dr. Watson are described in very different ways in the stories, but it could be something else.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line"><span class="comment">## evaluate the model performance</span></span><br><span class="line">predicted = text_clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(metrics.classification_report(y_test, predicted,</span><br><span class="line">      target_names=[<span class="string">&#x27;sherlock&#x27;</span>,<span class="string">&#x27;watson&#x27;</span>]))</span><br></pre></td></tr></table></figure>
<p>As a scientist you always want to remain skeptical about your findings until you have multiple ways to corroborate them. You will also want to always be aware of the overall goal of why you are doing the work you are doing. This example is an interesting metaphor for what can happen as a data scientist. It is possible to go down a path that may only marginally be related to the central business question. Developing a game here is not unlike using a new model for deep-learning or incorporating a new technology into your workflow—it may be fun and it may to some degree help the business case, but you need to always ask yourself is this the best way for me or my team to address the business problem? The questions your ask here are going to guide how best to iterate on the entire workflow.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/27/">27</a><a class="extend next" rel="next" href="/page/6/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ruochi Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">268</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zhangruochi" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zhangruochi" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zrc720@gmail.com" title="E-Mail → mailto:zrc720@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.healthinformaticslab.org/" title="http:&#x2F;&#x2F;www.healthinformaticslab.org" rel="noopener" target="_blank">HILab</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.shihaizhou.com/" title="http:&#x2F;&#x2F;www.shihaizhou.com" rel="noopener" target="_blank">Rose</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/cherish_CX/" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;cherish_CX&#x2F;" rel="noopener" target="_blank">Chunxia</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ruochi Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'qW3MLcAgcX96sB6qbegeL7rP-gzGzoHsz',
      appKey     : 'GL6JvT9DgGxqYrY5Vj6bXVuv',
      placeholder: "Thank you for your reply",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'en' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>

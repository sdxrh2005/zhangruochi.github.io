<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=PingFang SC:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhangruochi.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="RUOCHI.AI">
<meta property="og:url" content="https://zhangruochi.com/page/4/index.html">
<meta property="og:site_name" content="RUOCHI.AI">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Ruochi Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://zhangruochi.com/page/4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>RUOCHI.AI</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RUOCHI.AI</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>About</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Auto-Correct/2020/07/19/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Auto-Correct/2020/07/19/" class="post-title-link" itemprop="url">Auto Correct</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-07-19 16:27:04" itemprop="dateCreated datePublished" datetime="2020-07-19T16:27:04+08:00">2020-07-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-09-06 23:32:06" itemprop="dateModified" datetime="2020-09-06T23:32:06+08:00">2020-09-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Auto-Correct/2020/07/19/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Auto-Correct/2020/07/19/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Assignment-1-Auto-Correct"><a href="#Assignment-1-Auto-Correct" class="headerlink" title="Assignment 1: Auto Correct"></a>Assignment 1: Auto Correct</h1><p>Welcome to the first assignment of Course 2. This assignment will give you a chance to brush up on your python and probability skills. In doing so, you will implement an auto-correct system that is very effective and useful.</p>
<h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li><a href="#0">0. Overview</a><ul>
<li><a href="#0-1">0.1 Edit Distance</a></li>
</ul>
</li>
<li><a href="#1">1. Data Preprocessing</a><ul>
<li><a href="#ex-1">1.1 Exercise 1</a></li>
<li><a href="#ex-2">1.2 Exercise 2</a></li>
<li><a href="#ex-3">1.3 Exercise 3</a></li>
</ul>
</li>
<li><a href="#2">2. String Manipulation</a><ul>
<li><a href="#ex-4">2.1 Exercise 4</a></li>
<li><a href="#ex-5">2.2 Exercise 5</a></li>
<li><a href="#ex-6">2.3 Exercise 6</a></li>
<li><a href="#ex-7">2.4 Exercise 7</a></li>
</ul>
</li>
<li><a href="#3">3. Combining the edits</a><ul>
<li><a href="#ex-8">3.1 Exercise 8</a></li>
<li><a href="#ex-9">3.2 Exercise 9</a></li>
<li><a href="#ex-10">3.3 Exercise 10</a></li>
</ul>
</li>
<li><a href="#4">4. Minimum Edit Distance</a><ul>
<li><a href="#ex-11">4.1 Exercise 11</a></li>
</ul>
</li>
<li><a href="#5">5. Backtrace (Optional)</a></li>
</ul>
<p><a name='0'></a></p>
<h2 id="0-Overview"><a href="#0-Overview" class="headerlink" title="0. Overview"></a>0. Overview</h2><p>You use autocorrect every day on your cell phone and computer. In this assignment, you will explore what really goes on behind the scenes. Of course, the model you are about to implement is not identical to the one used in your phone, but it is still quite good. </p>
<p>By completing this assignment you will learn how to: </p>
<ul>
<li>Get a word count given a corpus</li>
<li>Get a word probability in the corpus </li>
<li>Manipulate strings </li>
<li>Filter strings </li>
<li>Implement Minimum edit distance to compare strings and to help find the optimal path for the edits. </li>
<li>Understand how dynamic programming works</li>
</ul>
<p>Similar systems are used everywhere. </p>
<ul>
<li>For example, if you type in the word <strong>“I am lerningg”</strong>, chances are very high that you meant to write <strong>“learning”</strong>, as shown in <strong>Figure 1</strong>. </li>
</ul>
<div style="width:image width px; font-size:100%; text-align:center;"><img src='auto-correct.png' alt="alternate text" width="width" height="height" style="width:300px;height:250px;" /> Figure 1 </div>

<p><a name='0-1'></a></p>
<h4 id="0-1-Edit-Distance"><a href="#0-1-Edit-Distance" class="headerlink" title="0.1 Edit Distance"></a>0.1 Edit Distance</h4><p>In this assignment, you will implement models that correct words that are 1 and 2 edit distances away. </p>
<ul>
<li>We say two words are n edit distance away from each other when we need n edits to change one word into another. </li>
</ul>
<p>An edit could consist of one of the following options: </p>
<ul>
<li>Delete (remove a letter): ‘hat’ =&gt; ‘at, ha, ht’</li>
<li>Switch (swap 2 adjacent letters): ‘eta’ =&gt; ‘eat, tea,…’</li>
<li>Replace (change 1 letter to another): ‘jat’ =&gt; ‘hat, rat, cat, mat, …’</li>
<li>Insert (add a letter): ‘te’ =&gt; ‘the, ten, ate, …’</li>
</ul>
<p>You will be using the four methods above to implement an Auto-correct. </p>
<ul>
<li>To do so, you will need to compute probabilities that a certain word is correct given an input. </li>
</ul>
<p>This auto-correct you are about to implement was first created by <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Peter_Norvig">Peter Norvig</a> in 2007. </p>
<ul>
<li>His <a target="_blank" rel="noopener" href="https://norvig.com/spell-correct.html">original article</a> may be a useful reference for this assignment.</li>
</ul>
<p>The goal of our spell check model is to compute the following probability:</p>
<p>$$P(c|w) = \frac{P(w|c)\times P(c)}{P(w)} \tag{Eqn-1}$$</p>
<p>The equation above is <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes Rule</a>. </p>
<ul>
<li>Equation 1 says that the probability of a word being correct $P(c|w) $is equal to the probability of having a certain word $w$, given that it is correct $P(w|c)$, multiplied by the probability of being correct in general $P(C)$ divided by the probability of that word $w$ appearing $P(w)$ in general.</li>
<li>To compute equation 1, you will first import a data set and then create all the probabilities that you need using that data set. </li>
</ul>
<p><a name='1'></a></p>
<h1 id="Part-1-Data-Preprocessing"><a href="#Part-1-Data-Preprocessing" class="headerlink" title="Part 1: Data Preprocessing"></a>Part 1: Data Preprocessing</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>

<p>As in any other machine learning task, the first thing you have to do is process your data set. </p>
<ul>
<li>Many courses load in pre-processed data for you. </li>
<li>However, in the real world, when you build these NLP systems, you load the datasets and process them.</li>
<li>So let’s get some real world practice in pre-processing the data!</li>
</ul>
<p>Your first task is to read in a file called <strong>‘shakespeare.txt’</strong> which is found in your file directory. To look at this file you can go to <code>File ==&gt; Open </code>. </p>
<p><a name='ex-1'></a></p>
<h3 id="Exercise-1"><a href="#Exercise-1" class="headerlink" title="Exercise 1"></a>Exercise 1</h3><p>Implement the function <code>process_data</code> which </p>
<ol>
<li><p>Reads in a corpus (text file)</p>
</li>
<li><p>Changes everything to lowercase</p>
</li>
<li><p>Returns a list of words. </p>
</li>
</ol>
<h4 id="Options-and-Hints"><a href="#Options-and-Hints" class="headerlink" title="Options and Hints"></a>Options and Hints</h4><ul>
<li>If you would like more of a real-life practice, don’t open the ‘Hints’ below (yet) and try searching the web to derive your answer.</li>
<li>If you want a little help, click on the green “General Hints” section by clicking on it with your mouse.</li>
<li>If you get stuck or are not getting the expected results, click on the green ‘Detailed Hints’ section to get hints for each step that you’ll take to complete this function.</li>
</ul>
<details>    
<summary>
    <font size="3" color="darkgreen"><b>General Hints</b></font>
</summary>
<p>
    
<p>General Hints to get started</p>
<ul>
    <li>Python <a target="_blank" rel="noopener" href="https://docs.python.org/3/tutorial/inputoutput.html">input and output<a></li>
    <li>Python <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/re.html" >'re' documentation </a> </li>
</ul>
</p>


<details>    
<summary>
    <font size="3" color="darkgreen"><b>Detailed Hints</b></font>
</summary>
<p>     
Detailed hints if you're stuck
<ul>
    <li>Use 'with' syntax to read a file</li>
    <li>Decide whether to use 'read()' or 'readline().  What's the difference?</li>
    <li>Choose whether to use either str.lower() or str.lowercase().  What is the difference?</li>
    <li>Use re.findall(pattern, string)</li>
    <li>Look for the "Raw String Notation" section in the Python 're' documentation to understand the difference between r'\W', r'\W' and '\\W'. </li>
    <li>For the pattern, decide between using '\s', '\w', '\s+' or '\w+'.  What do you think are the differences?</li>
</ul>
</p>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: process_data</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_data</span>(<span class="params">file_name</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Input: </span></span><br><span class="line"><span class="string">        A file_name which is found in your current directory. You just have to read it in. </span></span><br><span class="line"><span class="string">    Output: </span></span><br><span class="line"><span class="string">        words: a list containing all the words in the corpus (text file you read) in lower case. </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    words = [] <span class="comment"># return this variable correctly</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ### </span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_name, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        content = f.read().lower()</span><br><span class="line">    </span><br><span class="line">    words = re.findall(<span class="string">&#x27;\w+&#x27;</span>,content)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> words</span><br></pre></td></tr></table></figure>

<p>Note, in the following cell, ‘words’ is converted to a python <code>set</code>. This eliminates any duplicate entries.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#DO NOT MODIFY THIS CELL</span></span><br><span class="line">word_l = process_data(<span class="string">&#x27;shakespeare.txt&#x27;</span>)</span><br><span class="line">vocab = <span class="built_in">set</span>(word_l)  <span class="comment"># this will be your new vocabulary</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;The first ten words in the text are: \n<span class="subst">&#123;word_l[<span class="number">0</span>:<span class="number">10</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;There are <span class="subst">&#123;<span class="built_in">len</span>(vocab)&#125;</span> unique words in the vocabulary.&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>The first ten words in the text are: 
[&#39;o&#39;, &#39;for&#39;, &#39;a&#39;, &#39;muse&#39;, &#39;of&#39;, &#39;fire&#39;, &#39;that&#39;, &#39;would&#39;, &#39;ascend&#39;, &#39;the&#39;]
There are 6116 unique words in the vocabulary.
</code></pre>
<h4 id="Expected-Output"><a href="#Expected-Output" class="headerlink" title="Expected Output"></a>Expected Output</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">The first ten words <span class="keyword">in</span> the text are: </span><br><span class="line">[<span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;for&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;muse&#x27;</span>, <span class="string">&#x27;of&#x27;</span>, <span class="string">&#x27;fire&#x27;</span>, <span class="string">&#x27;that&#x27;</span>, <span class="string">&#x27;would&#x27;</span>, <span class="string">&#x27;ascend&#x27;</span>, <span class="string">&#x27;the&#x27;</span>]</span><br><span class="line">There are <span class="number">6116</span> unique words <span class="keyword">in</span> the vocabulary.</span><br></pre></td></tr></table></figure>

<p><a name='ex-2'></a></p>
<h3 id="Exercise-2"><a href="#Exercise-2" class="headerlink" title="Exercise 2"></a>Exercise 2</h3><p>Implement a <code>get_count</code> function that returns a dictionary</p>
<ul>
<li>The dictionary’s keys are words</li>
<li>The value for each word is the number of times that word appears in the corpus. </li>
</ul>
<p>For example, given the following sentence: <strong>“I am happy because I am learning”</strong>, your dictionary should return the following: </p>
<table style="width:20%">

  <tr>
    <td> <b>Key </b>  </td>
    <td> <b>Value </b> </td> 


  </tr>
  <tr>
    <td> I  </td>
    <td> 2</td> 
 
  </tr>
   
  <tr>
    <td>am</td>
    <td>2</td> 
  </tr>

  <tr>
    <td>happy</td>
    <td>1</td> 
  </tr>
  
   <tr>
    <td>because</td>
    <td>1</td> 
  </tr>
  
   <tr>
    <td>learning</td>
    <td>1</td> 
  </tr>
</table>


<p><strong>Instructions</strong>:<br>Implement a <code>get_count</code> which returns a dictionary where the key is a word and the value is the number of times the word appears in the list.  </p>
<details>    
<summary>
    <font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
    <li>Try implementing this using a for loop and a regular dictionary. This may be good practice for similar coding interview questions</li>
    <li>You can also use defaultdict instead of a regualr dictionary, along with the for loop</li>
    <li>Otherwise, to skip using a for loop, you can use Python's <a target="_blank" rel="noopener" href="https://docs.python.org/3.7/library/collections.html#collections.Counter" > Counter class</a> </li>
</ul>
</p>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># UNIT TEST COMMENT: Candidate for Table Driven Tests</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: get_count</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_count</span>(<span class="params">word_l</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">        word_l: a set of words representing the corpus. </span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    word_count_dict = &#123;&#125;  <span class="comment"># fill this with word counts</span></span><br><span class="line">    <span class="comment">### START CODE HERE </span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> word_l:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> word_count_dict:</span><br><span class="line">            word_count_dict[word] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            word_count_dict[word] += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ### </span></span><br><span class="line">    <span class="keyword">return</span> word_count_dict</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#DO NOT MODIFY THIS CELL</span></span><br><span class="line">word_count_dict = get_count(word_l)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;There are <span class="subst">&#123;<span class="built_in">len</span>(word_count_dict)&#125;</span> key values pairs&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;The count for the word &#x27;thee&#x27; is <span class="subst">&#123;word_count_dict.get(<span class="string">&#x27;thee&#x27;</span>,<span class="number">0</span>)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>There are 6116 key values pairs
The count for the word &#39;thee&#39; is 240
</code></pre>
<h4 id="Expected-Output-1"><a href="#Expected-Output-1" class="headerlink" title="Expected Output"></a>Expected Output</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">There are <span class="number">6116</span> key values pairs</span><br><span class="line">The count <span class="keyword">for</span> the word <span class="string">&#x27;thee&#x27;</span> <span class="keyword">is</span> <span class="number">240</span></span><br></pre></td></tr></table></figure>

<p><a name='ex-3'></a></p>
<h3 id="Exercise-3"><a href="#Exercise-3" class="headerlink" title="Exercise 3"></a>Exercise 3</h3><p>Given the dictionary of word counts, compute the probability that each word will appear if randomly selected from the corpus of words.</p>
<p>$$P(w_i) = \frac{C(w_i)}{M} \tag{Eqn-2}$$<br>where </p>
<p>$C(w_i)$ is the total number of times $w_i$ appears in the corpus.</p>
<p>$M$ is the total number of words in the corpus.</p>
<p>For example, the probability of the word ‘am’ in the sentence <strong>‘I am happy because I am learning’</strong> is:</p>
<p>$$P(am) = \frac{C(w_i)}{M} = \frac {2}{7} \tag{Eqn-3}.$$</p>
<p><strong>Instructions:</strong> Implement <code>get_probs</code> function which gives you the probability<br>that a word occurs in a sample. This returns a dictionary where the keys are words, and the value for each word is its probability in the corpus of words.</p>
<details>    
<summary>
    <font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
General advice
<ul>
    <li> Use dictionary.values() </li>
    <li> Use sum() </li>
    <li> The cardinality (number of words in the corpus should be equal to len(word_l).  You will calculate this same number, but using the word count dictionary.</li>
</ul>
    
<p>If you’re using a for loop:</p>
<ul>
    <li> Use dictionary.keys() </li>
</ul>
    
<p>If you’re using a dictionary comprehension:</p>
<ul>
    <li>Use dictionary.items() </li>
</ul>
</p>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: get_probs</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_probs</span>(<span class="params">word_count_dict</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.</span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">        probs: A dictionary where keys are the words and the values are the probability that a word will occur. </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    probs = &#123;&#125;  <span class="comment"># return this variable correctly</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    M = np.<span class="built_in">sum</span>(<span class="built_in">list</span>(word_count_dict.values()))</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> word, C <span class="keyword">in</span> word_count_dict.items():</span><br><span class="line">        probs[word] =  <span class="built_in">float</span>(C) / M</span><br><span class="line">        </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> probs</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#DO NOT MODIFY THIS CELL</span></span><br><span class="line">probs = get_probs(word_count_dict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Length of probs is <span class="subst">&#123;<span class="built_in">len</span>(probs)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;P(&#x27;thee&#x27;) is <span class="subst">&#123;probs[<span class="string">&#x27;thee&#x27;</span>]:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Length of probs is 6116
P(&#39;thee&#39;) is 0.0045
</code></pre>
<h4 id="Expected-Output-2"><a href="#Expected-Output-2" class="headerlink" title="Expected Output"></a>Expected Output</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Length of probs <span class="keyword">is</span> <span class="number">6116</span></span><br><span class="line">P(<span class="string">&#x27;thee&#x27;</span>) <span class="keyword">is</span> <span class="number">0.0045</span></span><br></pre></td></tr></table></figure>

<p><a name='2'></a></p>
<h1 id="Part-2-String-Manipulations"><a href="#Part-2-String-Manipulations" class="headerlink" title="Part 2: String Manipulations"></a>Part 2: String Manipulations</h1><p>Now, that you have computed $P(w_i)$ for all the words in the corpus, you will write a few functions to manipulate strings so that you can edit the erroneous strings and return the right spellings of the words. In this section, you will implement four functions: </p>
<ul>
<li><code>delete_letter</code>: given a word, it returns all the possible strings that have <strong>one character removed</strong>. </li>
<li><code>switch_letter</code>: given a word, it returns all the possible strings that have <strong>two adjacent letters switched</strong>.</li>
<li><code>replace_letter</code>: given a word, it returns all the possible strings that have <strong>one character replaced by another different letter</strong>.</li>
<li><code>insert_letter</code>: given a word, it returns all the possible strings that have an <strong>additional character inserted</strong>. </li>
</ul>
<h4 id="List-comprehensions"><a href="#List-comprehensions" class="headerlink" title="List comprehensions"></a>List comprehensions</h4><p>String and list manipulation in python will often make use of a python feature called  <a target="_blank" rel="noopener" href="https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions">list comprehensions</a>. The routines below will be described as using list comprehensions, but if you would rather implement them in another way, you are free to do so as long as the result is the same. Further, the following section will provide detailed instructions on how to use list comprehensions and how to implement the desired functions. If you are a python expert, feel free to skip the python hints and move to implementing the routines directly.</p>
<p>Python List Comprehensions embed a looping structure inside of a list declaration, collapsing many lines of code into a single line. If you are not familiar with them, they seem slightly out of order relative to for loops. </p>
<div style="width:image width px; font-size:100%; text-align:center;"><img src='GenericListComp3.png' alt="alternate text" width="width" height="height"  style="width:800px;height:400px;"/> Figure 2 </div>

<p>The diagram above shows that the components of a list comprehension are the same components you would find in a typical for loop that appends to a list, but in a different order. With that in mind, we’ll continue the specifics of this assignment. We will be very descriptive for the first function, <code>deletes()</code>, and less so in later functions as you become familiar with list comprehensions.</p>
<p><a name='ex-4'></a></p>
<h3 id="Exercise-4"><a href="#Exercise-4" class="headerlink" title="Exercise 4"></a>Exercise 4</h3><p><strong>Instructions for delete_letter():</strong> Implement a <code>delete_letter()</code> function that, given a word, returns a list of strings with one character deleted. </p>
<p>For example, given the word <strong>nice</strong>, it would return the set: {‘ice’, ‘nce’, ‘nic’, ‘nie’}. </p>
<p><strong>Step 1:</strong> Create a list of ‘splits’. This is all the ways you can split a word into Left and Right: For example,<br>‘nice is split into : <code>[(&#39;&#39;, &#39;nice&#39;), (&#39;n&#39;, &#39;ice&#39;), (&#39;ni&#39;, &#39;ce&#39;), (&#39;nic&#39;, &#39;e&#39;), (&#39;nice&#39;, &#39;&#39;)]</code><br>This is common to all four functions (delete, replace, switch, insert).</p>
<div style="width:image width px; font-size:100%; text-align:center;"><img src='Splits1.png' alt="alternate text" width="width" height="height" style="width:650px;height:200px;" /> Figure 3 </div>

<p><strong>Step 2:</strong> This is specific to <code>delete_letter</code>. Here, we are generating all words that result from deleting one character.<br>This can be done in a single line with a list comprehension. You can makes use of this type of syntax:<br><code>[f(a,b) for a, b in splits if condition]</code>  </p>
<p>For our ‘nice’ example you get:<br>[‘ice’, ‘nce’, ‘nie’, ‘nic’]</p>
<div style="width:image width px; font-size:100%; text-align:center;"><img src='ListComp2.png' alt="alternate text" width="width" height="height" style="width:550px;height:300px;" /> Figure 4 </div>

<h4 id="Levels-of-assistance"><a href="#Levels-of-assistance" class="headerlink" title="Levels of assistance"></a>Levels of assistance</h4><p>Try this exercise with these levels of assistance.  </p>
<ul>
<li><p>We hope that this will make it both a meaningful experience but also not a frustrating experience. </p>
</li>
<li><p>Start with level 1, then move onto level 2, and 3 as needed.</p>
<ul>
<li>Level 1. Try to think this through and implement this yourself.</li>
<li>Level 2. Click on the “Level 2 Hints” section for some hints to get started.</li>
<li>Level 3. If you would prefer more guidance, please click on the “Level 3 Hints” cell for step by step instructions.</li>
</ul>
</li>
<li><p>If you are still stuck, look at the images in the “list comprehensions” section above.</p>
</li>
</ul>
<details>    
<summary>
    <font size="3" color="darkgreen"><b>Level 2 Hints</b></font>
</summary>
<p>
<ul>
    <li><a href="" > Use array slicing like my_string[0:2] </a> </li>
    <li><a href="" > Use list comprehensions or for loops </a> </li>
</ul>
</p>


<details>    
<summary>
    <font size="3" color="darkgreen"><b>Level 3 Hints</b></font>
</summary>
<p>
<ul>
    <li>splits: Use array slicing, like my_str[0:2], to separate a string into two pieces.</li>
    <li>Do this in a loop or list comprehension, so that you have a list of tuples.
    <li> For example, "cake" can get split into "ca" and "ke". They're stored in a tuple ("ca","ke"), and the tuple is appended to a list.  We'll refer to these as L and R, so the tuple is (L,R)</li>
    <li>When choosing the range for your loop, if you input the word "cans" and generate the tuple  ('cans',''), make sure to include an if statement to check the length of that right-side string (R) in the tuple (L,R) </li>
    <li>deletes: Go through the list of tuples and combine the two strings together. You can use the + operator to combine two strings</li>
    <li>When combining the tuples, make sure that you leave out a middle character.</li>
    <li>Use array slicing to leave out the first character of the right substring.</li>
</ul>
</p>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># UNIT TEST COMMENT: Candidate for Table Driven Tests</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: deletes</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">delete_letter</span>(<span class="params">word, verbose=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">        word: the string/word for which you will generate all possible words </span></span><br><span class="line"><span class="string">                in the vocabulary which have 1 missing character</span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">        delete_l: a list of all possible strings obtained by deleting 1 character from word</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    delete_l = []</span><br><span class="line">    split_l = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    split_l = [(word[:i],word[i:]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(word) + <span class="number">1</span>)]</span><br><span class="line">    delete_l = [L + R[<span class="number">1</span>:] <span class="keyword">for</span> L,R <span class="keyword">in</span> split_l <span class="keyword">if</span> R]</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> verbose: <span class="built_in">print</span>(<span class="string">f&quot;input word <span class="subst">&#123;word&#125;</span>, \nsplit_l = <span class="subst">&#123;split_l&#125;</span>, \ndelete_l = <span class="subst">&#123;delete_l&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> delete_l</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">delete_word_l = delete_letter(word=<span class="string">&quot;cans&quot;</span>,</span><br><span class="line">                        verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<pre><code>input word cans, 
split_l = [(&#39;&#39;, &#39;cans&#39;), (&#39;c&#39;, &#39;ans&#39;), (&#39;ca&#39;, &#39;ns&#39;), (&#39;can&#39;, &#39;s&#39;), (&#39;cans&#39;, &#39;&#39;)], 
delete_l = [&#39;ans&#39;, &#39;cns&#39;, &#39;cas&#39;, &#39;can&#39;]
</code></pre>
<h4 id="Expected-Output-3"><a href="#Expected-Output-3" class="headerlink" title="Expected Output"></a>Expected Output</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> word cans, </span><br><span class="line">split_l = [(<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;cans&#x27;</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;ans&#x27;</span>), (<span class="string">&#x27;ca&#x27;</span>, <span class="string">&#x27;ns&#x27;</span>), (<span class="string">&#x27;can&#x27;</span>, <span class="string">&#x27;s&#x27;</span>)], </span><br><span class="line">delete_l = [<span class="string">&#x27;ans&#x27;</span>, <span class="string">&#x27;cns&#x27;</span>, <span class="string">&#x27;cas&#x27;</span>, <span class="string">&#x27;can&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h4 id="Note-1"><a href="#Note-1" class="headerlink" title="Note 1"></a>Note 1</h4><p>You might get a slightly different result with split_l.  </p>
<ul>
<li>Notice how it has the extra tuple <code>(&#39;cans&#39;, &#39;&#39;)</code>.</li>
<li>This will be fine as long as you have checked the size of the right-side substring in tuple (L,R).</li>
<li>Can you explain why this will give you the same result for the list of deletion strings (delete_l)?</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> word cans, </span><br><span class="line">split_l = [(<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;cans&#x27;</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;ans&#x27;</span>), (<span class="string">&#x27;ca&#x27;</span>, <span class="string">&#x27;ns&#x27;</span>), (<span class="string">&#x27;can&#x27;</span>, <span class="string">&#x27;s&#x27;</span>), (<span class="string">&#x27;cans&#x27;</span>, <span class="string">&#x27;&#x27;</span>)], </span><br><span class="line">delete_l = [<span class="string">&#x27;ans&#x27;</span>, <span class="string">&#x27;cns&#x27;</span>, <span class="string">&#x27;cas&#x27;</span>, <span class="string">&#x27;can&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h4 id="Note-2"><a href="#Note-2" class="headerlink" title="Note 2"></a>Note 2</h4><p>If you end up getting the same word as your input word, like this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> word cans, </span><br><span class="line">split_l = [(<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;cans&#x27;</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;ans&#x27;</span>), (<span class="string">&#x27;ca&#x27;</span>, <span class="string">&#x27;ns&#x27;</span>), (<span class="string">&#x27;can&#x27;</span>, <span class="string">&#x27;s&#x27;</span>), (<span class="string">&#x27;cans&#x27;</span>, <span class="string">&#x27;&#x27;</span>)], </span><br><span class="line">delete_l = [<span class="string">&#x27;ans&#x27;</span>, <span class="string">&#x27;cns&#x27;</span>, <span class="string">&#x27;cas&#x27;</span>, <span class="string">&#x27;can&#x27;</span>, <span class="string">&#x27;cans&#x27;</span>]</span><br></pre></td></tr></table></figure>

<ul>
<li>Check how you set the <code>range</code>.</li>
<li>See if you check the length of the string on the right-side of the split.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test # 2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of outputs of delete_letter(&#x27;at&#x27;) is <span class="subst">&#123;<span class="built_in">len</span>(delete_letter(<span class="string">&#x27;at&#x27;</span>))&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Number of outputs of delete_letter(&#39;at&#39;) is 2
</code></pre>
<h4 id="Expected-output"><a href="#Expected-output" class="headerlink" title="Expected output"></a>Expected output</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Number of outputs of <span class="title">delete_letter</span><span class="params">(<span class="string">&#x27;at&#x27;</span>)</span> is 2</span></span><br></pre></td></tr></table></figure>

<p><a name='ex-5'></a></p>
<h3 id="Exercise-5"><a href="#Exercise-5" class="headerlink" title="Exercise 5"></a>Exercise 5</h3><p><strong>Instructions for switch_letter()</strong>: Now implement a function that switches two letters in a word. It takes in a word and returns a list of all the possible switches of two letters <strong>that are adjacent to each other</strong>. </p>
<ul>
<li>For example, given the word ‘eta’, it returns {‘eat’, ‘tea’}, but does not return ‘ate’.</li>
</ul>
<p><strong>Step 1:</strong> is the same as in delete_letter()<br><strong>Step 2:</strong> A list comprehension or for loop which forms strings by swapping adjacent letters. This is of the form:<br><code>[f(L,R) for L, R in splits if condition]</code>  where ‘condition’ will test the length of R in a given iteration. See below.</p>
<div style="width:image width px; font-size:100%; text-align:center;"><img src='Switches1.png' alt="alternate text" width="width" height="height" style="width:600px;height:200px;"/> Figure 5 </div>      

<h4 id="Levels-of-difficulty"><a href="#Levels-of-difficulty" class="headerlink" title="Levels of difficulty"></a>Levels of difficulty</h4><p>Try this exercise with these levels of difficulty.  </p>
<ul>
<li>Level 1. Try to think this through and implement this yourself.</li>
<li>Level 2. Click on the “Level 2 Hints” section for some hints to get started.</li>
<li>Level 3. If you would prefer more guidance, please click on the “Level 3 Hints” cell for step by step instructions.</li>
</ul>
<details>    
<summary>
    <font size="3" color="darkgreen"><b>Level 2 Hints</b></font>
</summary>
<p>
<ul>
    <li><a href="" > Use array slicing like my_string[0:2] </a> </li>
    <li><a href="" > Use list comprehensions or for loops </a> </li>
    <li>To do a switch, think of the whole word as divided into 4 distinct parts.  Write out 'cupcakes' on a piece of paper and see how you can split it into ('cupc', 'k', 'a', 'es')</li>
</ul>
</p>


<details>    
<summary>
    <font size="3" color="darkgreen"><b>Level 3 Hints</b></font>
</summary>
<p>
<ul>
    <li>splits: Use array slicing, like my_str[0:2], to separate a string into two pieces.</li>
    <li>Splitting is the same as for delete_letter</li>
    <li>To perform the switch, go through the list of tuples and combine four strings together. You can use the + operator to combine strings</li>
    <li>The four strings will be the left substring from the split tuple, followed by the first (index 1) character of the right substring, then the zero-th character (index 0) of the right substring, and then the remaining part of the right substring.</li>
    <li>Unlike delete_letter, you will want to check that your right substring is at least a minimum length.  To see why, review the previous hint bullet point (directly before this one).</li>
</ul>
</p>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># UNIT TEST COMMENT: Candidate for Table Driven Tests</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: switches</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">switch_letter</span>(<span class="params">word, verbose=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">        word: input string</span></span><br><span class="line"><span class="string">     Output:</span></span><br><span class="line"><span class="string">        switches: a list of all possible strings with one adjacent charater switched</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span> </span><br><span class="line">    </span><br><span class="line">    switch_l = []</span><br><span class="line">    split_l = []</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">L,R</span>):</span></span><br><span class="line">        <span class="keyword">return</span> L[:-<span class="number">1</span>] + R[<span class="number">0</span>] + L[-<span class="number">1</span>] + R[<span class="number">1</span>:]</span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    split_l = [(word[:i],word[i:]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(word) + <span class="number">1</span>)]</span><br><span class="line">    switch_l = [f(L,R) <span class="keyword">for</span> L,R <span class="keyword">in</span> split_l <span class="keyword">if</span> L <span class="keyword">and</span> R]</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> verbose: <span class="built_in">print</span>(<span class="string">f&quot;Input word = <span class="subst">&#123;word&#125;</span> \nsplit_l = <span class="subst">&#123;split_l&#125;</span> \nswitch_l = <span class="subst">&#123;switch_l&#125;</span>&quot;</span>) </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> switch_l</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">switch_word_l = switch_letter(word=<span class="string">&quot;eta&quot;</span>,</span><br><span class="line">                         verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Input word = eta 
split_l = [(&#39;&#39;, &#39;eta&#39;), (&#39;e&#39;, &#39;ta&#39;), (&#39;et&#39;, &#39;a&#39;), (&#39;eta&#39;, &#39;&#39;)] 
switch_l = [&#39;tea&#39;, &#39;eat&#39;]
</code></pre>
<h4 id="Expected-output-1"><a href="#Expected-output-1" class="headerlink" title="Expected output"></a>Expected output</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input word = eta </span><br><span class="line">split_l = [(<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;eta&#x27;</span>), (<span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;ta&#x27;</span>), (<span class="string">&#x27;et&#x27;</span>, <span class="string">&#x27;a&#x27;</span>)] </span><br><span class="line">switch_l = [<span class="string">&#x27;tea&#x27;</span>, <span class="string">&#x27;eat&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h4 id="Note-1-1"><a href="#Note-1-1" class="headerlink" title="Note 1"></a>Note 1</h4><p>You may get this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input word = eta </span><br><span class="line">split_l = [(<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;eta&#x27;</span>), (<span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;ta&#x27;</span>), (<span class="string">&#x27;et&#x27;</span>, <span class="string">&#x27;a&#x27;</span>), (<span class="string">&#x27;eta&#x27;</span>, <span class="string">&#x27;&#x27;</span>)] </span><br><span class="line">switch_l = [<span class="string">&#x27;tea&#x27;</span>, <span class="string">&#x27;eat&#x27;</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>Notice how it has the extra tuple <code>(&#39;eta&#39;, &#39;&#39;)</code>.</li>
<li>This is also correct.</li>
<li>Can you think of why this is the case?</li>
</ul>
<h4 id="Note-2-1"><a href="#Note-2-1" class="headerlink" title="Note 2"></a>Note 2</h4><p>If you get an error</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IndexError: string index out of <span class="built_in">range</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Please see if you have checked the length of the strings when switching characters.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test # 2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of outputs of switch_letter(&#x27;at&#x27;) is <span class="subst">&#123;<span class="built_in">len</span>(switch_letter(<span class="string">&#x27;at&#x27;</span>))&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Number of outputs of switch_letter(&#39;at&#39;) is 1
</code></pre>
<h4 id="Expected-output-2"><a href="#Expected-output-2" class="headerlink" title="Expected output"></a>Expected output</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Number of outputs of <span class="title">switch_letter</span><span class="params">(<span class="string">&#x27;at&#x27;</span>)</span> is 1</span></span><br></pre></td></tr></table></figure>

<p><a name='ex-6'></a></p>
<h3 id="Exercise-6"><a href="#Exercise-6" class="headerlink" title="Exercise 6"></a>Exercise 6</h3><p><strong>Instructions for replace_letter()</strong>: Now implement a function that takes in a word and returns a list of strings with one <strong>replaced letter</strong> from the original word. </p>
<p><strong>Step 1:</strong> is the same as in <code>delete_letter()</code></p>
<p><strong>Step 2:</strong> A list comprehension or for loop which form strings by replacing letters.  This can be of the form:<br><code>[f(a,b,c) for a, b in splits if condition for c in string]</code>   Note the use of the second for loop.<br>It is expected in this routine that one or more of the replacements will include the original word. For example, replacing the first letter of ‘ear’ with ‘e’ will return ‘ear’.</p>
<p><strong>Step 3:</strong> Remove the original input letter from the output.</p>
<details>    
<summary>
    <font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
    <li>To remove a word from a list, first store its contents inside a set()</li>
    <li>Use set.discard('the_word') to remove a word in a set (if the word does not exist in the set, then it will not throw a KeyError.  Using set.remove('the_word') throws a KeyError if the word does not exist in the set. </li>
</ul>
</p>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># UNIT TEST COMMENT: Candidate for Table Driven Tests</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: replaces</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">replace_letter</span>(<span class="params">word, verbose=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">        word: the input string/word </span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">        replaces: a list of all possible strings where we replaced one letter from the original word. </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span> </span><br><span class="line">    </span><br><span class="line">    letters = <span class="string">&#x27;abcdefghijklmnopqrstuvwxyz&#x27;</span></span><br><span class="line">    replace_l = []</span><br><span class="line">    split_l = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    split_l = [(word[:i],word[i:]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(word) + <span class="number">1</span>)]</span><br><span class="line">    replace_set = [L + C + R[<span class="number">1</span>:] <span class="keyword">for</span> L,R <span class="keyword">in</span> split_l <span class="keyword">if</span> R <span class="keyword">for</span> C <span class="keyword">in</span> letters <span class="keyword">if</span> C <span class="keyword">is</span> <span class="keyword">not</span> R[<span class="number">0</span>]]</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># turn the set back into a list and sort it, for easier viewing</span></span><br><span class="line">    replace_l = <span class="built_in">sorted</span>(<span class="built_in">list</span>(replace_set))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> verbose: <span class="built_in">print</span>(<span class="string">f&quot;Input word = <span class="subst">&#123;word&#125;</span> \nsplit_l = <span class="subst">&#123;split_l&#125;</span> \nreplace_l <span class="subst">&#123;replace_l&#125;</span>&quot;</span>)   </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> replace_l</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">replace_l = replace_letter(word=<span class="string">&#x27;can&#x27;</span>,</span><br><span class="line">                              verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Input word = can 
split_l = [(&#39;&#39;, &#39;can&#39;), (&#39;c&#39;, &#39;an&#39;), (&#39;ca&#39;, &#39;n&#39;), (&#39;can&#39;, &#39;&#39;)] 
replace_l [&#39;aan&#39;, &#39;ban&#39;, &#39;caa&#39;, &#39;cab&#39;, &#39;cac&#39;, &#39;cad&#39;, &#39;cae&#39;, &#39;caf&#39;, &#39;cag&#39;, &#39;cah&#39;, &#39;cai&#39;, &#39;caj&#39;, &#39;cak&#39;, &#39;cal&#39;, &#39;cam&#39;, &#39;cao&#39;, &#39;cap&#39;, &#39;caq&#39;, &#39;car&#39;, &#39;cas&#39;, &#39;cat&#39;, &#39;cau&#39;, &#39;cav&#39;, &#39;caw&#39;, &#39;cax&#39;, &#39;cay&#39;, &#39;caz&#39;, &#39;cbn&#39;, &#39;ccn&#39;, &#39;cdn&#39;, &#39;cen&#39;, &#39;cfn&#39;, &#39;cgn&#39;, &#39;chn&#39;, &#39;cin&#39;, &#39;cjn&#39;, &#39;ckn&#39;, &#39;cln&#39;, &#39;cmn&#39;, &#39;cnn&#39;, &#39;con&#39;, &#39;cpn&#39;, &#39;cqn&#39;, &#39;crn&#39;, &#39;csn&#39;, &#39;ctn&#39;, &#39;cun&#39;, &#39;cvn&#39;, &#39;cwn&#39;, &#39;cxn&#39;, &#39;cyn&#39;, &#39;czn&#39;, &#39;dan&#39;, &#39;ean&#39;, &#39;fan&#39;, &#39;gan&#39;, &#39;han&#39;, &#39;ian&#39;, &#39;jan&#39;, &#39;kan&#39;, &#39;lan&#39;, &#39;man&#39;, &#39;nan&#39;, &#39;oan&#39;, &#39;pan&#39;, &#39;qan&#39;, &#39;ran&#39;, &#39;san&#39;, &#39;tan&#39;, &#39;uan&#39;, &#39;van&#39;, &#39;wan&#39;, &#39;xan&#39;, &#39;yan&#39;, &#39;zan&#39;]
</code></pre>
<h4 id="Expected-Output-4"><a href="#Expected-Output-4" class="headerlink" title="Expected Output**:"></a>Expected Output**:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input word = can </span><br><span class="line">split_l = [(<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;can&#x27;</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;an&#x27;</span>), (<span class="string">&#x27;ca&#x27;</span>, <span class="string">&#x27;n&#x27;</span>)] </span><br><span class="line">replace_l [<span class="string">&#x27;aan&#x27;</span>, <span class="string">&#x27;ban&#x27;</span>, <span class="string">&#x27;caa&#x27;</span>, <span class="string">&#x27;cab&#x27;</span>, <span class="string">&#x27;cac&#x27;</span>, <span class="string">&#x27;cad&#x27;</span>, <span class="string">&#x27;cae&#x27;</span>, <span class="string">&#x27;caf&#x27;</span>, <span class="string">&#x27;cag&#x27;</span>, <span class="string">&#x27;cah&#x27;</span>, <span class="string">&#x27;cai&#x27;</span>, <span class="string">&#x27;caj&#x27;</span>, <span class="string">&#x27;cak&#x27;</span>, <span class="string">&#x27;cal&#x27;</span>, <span class="string">&#x27;cam&#x27;</span>, <span class="string">&#x27;cao&#x27;</span>, <span class="string">&#x27;cap&#x27;</span>, <span class="string">&#x27;caq&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;cas&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;cau&#x27;</span>, <span class="string">&#x27;cav&#x27;</span>, <span class="string">&#x27;caw&#x27;</span>, <span class="string">&#x27;cax&#x27;</span>, <span class="string">&#x27;cay&#x27;</span>, <span class="string">&#x27;caz&#x27;</span>, <span class="string">&#x27;cbn&#x27;</span>, <span class="string">&#x27;ccn&#x27;</span>, <span class="string">&#x27;cdn&#x27;</span>, <span class="string">&#x27;cen&#x27;</span>, <span class="string">&#x27;cfn&#x27;</span>, <span class="string">&#x27;cgn&#x27;</span>, <span class="string">&#x27;chn&#x27;</span>, <span class="string">&#x27;cin&#x27;</span>, <span class="string">&#x27;cjn&#x27;</span>, <span class="string">&#x27;ckn&#x27;</span>, <span class="string">&#x27;cln&#x27;</span>, <span class="string">&#x27;cmn&#x27;</span>, <span class="string">&#x27;cnn&#x27;</span>, <span class="string">&#x27;con&#x27;</span>, <span class="string">&#x27;cpn&#x27;</span>, <span class="string">&#x27;cqn&#x27;</span>, <span class="string">&#x27;crn&#x27;</span>, <span class="string">&#x27;csn&#x27;</span>, <span class="string">&#x27;ctn&#x27;</span>, <span class="string">&#x27;cun&#x27;</span>, <span class="string">&#x27;cvn&#x27;</span>, <span class="string">&#x27;cwn&#x27;</span>, <span class="string">&#x27;cxn&#x27;</span>, <span class="string">&#x27;cyn&#x27;</span>, <span class="string">&#x27;czn&#x27;</span>, <span class="string">&#x27;dan&#x27;</span>, <span class="string">&#x27;ean&#x27;</span>, <span class="string">&#x27;fan&#x27;</span>, <span class="string">&#x27;gan&#x27;</span>, <span class="string">&#x27;han&#x27;</span>, <span class="string">&#x27;ian&#x27;</span>, <span class="string">&#x27;jan&#x27;</span>, <span class="string">&#x27;kan&#x27;</span>, <span class="string">&#x27;lan&#x27;</span>, <span class="string">&#x27;man&#x27;</span>, <span class="string">&#x27;nan&#x27;</span>, <span class="string">&#x27;oan&#x27;</span>, <span class="string">&#x27;pan&#x27;</span>, <span class="string">&#x27;qan&#x27;</span>, <span class="string">&#x27;ran&#x27;</span>, <span class="string">&#x27;san&#x27;</span>, <span class="string">&#x27;tan&#x27;</span>, <span class="string">&#x27;uan&#x27;</span>, <span class="string">&#x27;van&#x27;</span>, <span class="string">&#x27;wan&#x27;</span>, <span class="string">&#x27;xan&#x27;</span>, <span class="string">&#x27;yan&#x27;</span>, <span class="string">&#x27;zan&#x27;</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>Note how the input word ‘can’ should not be one of the output words.</li>
</ul>
<h4 id="Note-1-2"><a href="#Note-1-2" class="headerlink" title="Note 1"></a>Note 1</h4><p>If you get something like this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input word = can </span><br><span class="line">split_l = [(<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;can&#x27;</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;an&#x27;</span>), (<span class="string">&#x27;ca&#x27;</span>, <span class="string">&#x27;n&#x27;</span>), (<span class="string">&#x27;can&#x27;</span>, <span class="string">&#x27;&#x27;</span>)] </span><br><span class="line">replace_l [<span class="string">&#x27;aan&#x27;</span>, <span class="string">&#x27;ban&#x27;</span>, <span class="string">&#x27;caa&#x27;</span>, <span class="string">&#x27;cab&#x27;</span>, <span class="string">&#x27;cac&#x27;</span>, <span class="string">&#x27;cad&#x27;</span>, <span class="string">&#x27;cae&#x27;</span>, <span class="string">&#x27;caf&#x27;</span>, <span class="string">&#x27;cag&#x27;</span>, <span class="string">&#x27;cah&#x27;</span>, <span class="string">&#x27;cai&#x27;</span>, <span class="string">&#x27;caj&#x27;</span>, <span class="string">&#x27;cak&#x27;</span>, <span class="string">&#x27;cal&#x27;</span>, <span class="string">&#x27;cam&#x27;</span>, <span class="string">&#x27;cao&#x27;</span>, <span class="string">&#x27;cap&#x27;</span>, <span class="string">&#x27;caq&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;cas&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;cau&#x27;</span>, <span class="string">&#x27;cav&#x27;</span>, <span class="string">&#x27;caw&#x27;</span>, <span class="string">&#x27;cax&#x27;</span>, <span class="string">&#x27;cay&#x27;</span>, <span class="string">&#x27;caz&#x27;</span>, <span class="string">&#x27;cbn&#x27;</span>, <span class="string">&#x27;ccn&#x27;</span>, <span class="string">&#x27;cdn&#x27;</span>, <span class="string">&#x27;cen&#x27;</span>, <span class="string">&#x27;cfn&#x27;</span>, <span class="string">&#x27;cgn&#x27;</span>, <span class="string">&#x27;chn&#x27;</span>, <span class="string">&#x27;cin&#x27;</span>, <span class="string">&#x27;cjn&#x27;</span>, <span class="string">&#x27;ckn&#x27;</span>, <span class="string">&#x27;cln&#x27;</span>, <span class="string">&#x27;cmn&#x27;</span>, <span class="string">&#x27;cnn&#x27;</span>, <span class="string">&#x27;con&#x27;</span>, <span class="string">&#x27;cpn&#x27;</span>, <span class="string">&#x27;cqn&#x27;</span>, <span class="string">&#x27;crn&#x27;</span>, <span class="string">&#x27;csn&#x27;</span>, <span class="string">&#x27;ctn&#x27;</span>, <span class="string">&#x27;cun&#x27;</span>, <span class="string">&#x27;cvn&#x27;</span>, <span class="string">&#x27;cwn&#x27;</span>, <span class="string">&#x27;cxn&#x27;</span>, <span class="string">&#x27;cyn&#x27;</span>, <span class="string">&#x27;czn&#x27;</span>, <span class="string">&#x27;dan&#x27;</span>, <span class="string">&#x27;ean&#x27;</span>, <span class="string">&#x27;fan&#x27;</span>, <span class="string">&#x27;gan&#x27;</span>, <span class="string">&#x27;han&#x27;</span>, <span class="string">&#x27;ian&#x27;</span>, <span class="string">&#x27;jan&#x27;</span>, <span class="string">&#x27;kan&#x27;</span>, <span class="string">&#x27;lan&#x27;</span>, <span class="string">&#x27;man&#x27;</span>, <span class="string">&#x27;nan&#x27;</span>, <span class="string">&#x27;oan&#x27;</span>, <span class="string">&#x27;pan&#x27;</span>, <span class="string">&#x27;qan&#x27;</span>, <span class="string">&#x27;ran&#x27;</span>, <span class="string">&#x27;san&#x27;</span>, <span class="string">&#x27;tan&#x27;</span>, <span class="string">&#x27;uan&#x27;</span>, <span class="string">&#x27;van&#x27;</span>, <span class="string">&#x27;wan&#x27;</span>, <span class="string">&#x27;xan&#x27;</span>, <span class="string">&#x27;yan&#x27;</span>, <span class="string">&#x27;zan&#x27;</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>Notice how split_l has an extra tuple <code>(&#39;can&#39;, &#39;&#39;)</code>, but the output is still the same, so this is okay.</li>
</ul>
<h4 id="Note-2-2"><a href="#Note-2-2" class="headerlink" title="Note 2"></a>Note 2</h4><p>If you get something like this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input word = can </span><br><span class="line">split_l = [(<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;can&#x27;</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;an&#x27;</span>), (<span class="string">&#x27;ca&#x27;</span>, <span class="string">&#x27;n&#x27;</span>), (<span class="string">&#x27;can&#x27;</span>, <span class="string">&#x27;&#x27;</span>)] </span><br><span class="line">replace_l [<span class="string">&#x27;aan&#x27;</span>, <span class="string">&#x27;ban&#x27;</span>, <span class="string">&#x27;caa&#x27;</span>, <span class="string">&#x27;cab&#x27;</span>, <span class="string">&#x27;cac&#x27;</span>, <span class="string">&#x27;cad&#x27;</span>, <span class="string">&#x27;cae&#x27;</span>, <span class="string">&#x27;caf&#x27;</span>, <span class="string">&#x27;cag&#x27;</span>, <span class="string">&#x27;cah&#x27;</span>, <span class="string">&#x27;cai&#x27;</span>, <span class="string">&#x27;caj&#x27;</span>, <span class="string">&#x27;cak&#x27;</span>, <span class="string">&#x27;cal&#x27;</span>, <span class="string">&#x27;cam&#x27;</span>, <span class="string">&#x27;cana&#x27;</span>, <span class="string">&#x27;canb&#x27;</span>, <span class="string">&#x27;canc&#x27;</span>, <span class="string">&#x27;cand&#x27;</span>, <span class="string">&#x27;cane&#x27;</span>, <span class="string">&#x27;canf&#x27;</span>, <span class="string">&#x27;cang&#x27;</span>, <span class="string">&#x27;canh&#x27;</span>, <span class="string">&#x27;cani&#x27;</span>, <span class="string">&#x27;canj&#x27;</span>, <span class="string">&#x27;cank&#x27;</span>, <span class="string">&#x27;canl&#x27;</span>, <span class="string">&#x27;canm&#x27;</span>, <span class="string">&#x27;cann&#x27;</span>, <span class="string">&#x27;cano&#x27;</span>, <span class="string">&#x27;canp&#x27;</span>, <span class="string">&#x27;canq&#x27;</span>, <span class="string">&#x27;canr&#x27;</span>, <span class="string">&#x27;cans&#x27;</span>, <span class="string">&#x27;cant&#x27;</span>, <span class="string">&#x27;canu&#x27;</span>, <span class="string">&#x27;canv&#x27;</span>, <span class="string">&#x27;canw&#x27;</span>, <span class="string">&#x27;canx&#x27;</span>, <span class="string">&#x27;cany&#x27;</span>, <span class="string">&#x27;canz&#x27;</span>, <span class="string">&#x27;cao&#x27;</span>, <span class="string">&#x27;cap&#x27;</span>, <span class="string">&#x27;caq&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;cas&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;cau&#x27;</span>, <span class="string">&#x27;cav&#x27;</span>, <span class="string">&#x27;caw&#x27;</span>, <span class="string">&#x27;cax&#x27;</span>, <span class="string">&#x27;cay&#x27;</span>, <span class="string">&#x27;caz&#x27;</span>, <span class="string">&#x27;cbn&#x27;</span>, <span class="string">&#x27;ccn&#x27;</span>, <span class="string">&#x27;cdn&#x27;</span>, <span class="string">&#x27;cen&#x27;</span>, <span class="string">&#x27;cfn&#x27;</span>, <span class="string">&#x27;cgn&#x27;</span>, <span class="string">&#x27;chn&#x27;</span>, <span class="string">&#x27;cin&#x27;</span>, <span class="string">&#x27;cjn&#x27;</span>, <span class="string">&#x27;ckn&#x27;</span>, <span class="string">&#x27;cln&#x27;</span>, <span class="string">&#x27;cmn&#x27;</span>, <span class="string">&#x27;cnn&#x27;</span>, <span class="string">&#x27;con&#x27;</span>, <span class="string">&#x27;cpn&#x27;</span>, <span class="string">&#x27;cqn&#x27;</span>, <span class="string">&#x27;crn&#x27;</span>, <span class="string">&#x27;csn&#x27;</span>, <span class="string">&#x27;ctn&#x27;</span>, <span class="string">&#x27;cun&#x27;</span>, <span class="string">&#x27;cvn&#x27;</span>, <span class="string">&#x27;cwn&#x27;</span>, <span class="string">&#x27;cxn&#x27;</span>, <span class="string">&#x27;cyn&#x27;</span>, <span class="string">&#x27;czn&#x27;</span>, <span class="string">&#x27;dan&#x27;</span>, <span class="string">&#x27;ean&#x27;</span>, <span class="string">&#x27;fan&#x27;</span>, <span class="string">&#x27;gan&#x27;</span>, <span class="string">&#x27;han&#x27;</span>, <span class="string">&#x27;ian&#x27;</span>, <span class="string">&#x27;jan&#x27;</span>, <span class="string">&#x27;kan&#x27;</span>, <span class="string">&#x27;lan&#x27;</span>, <span class="string">&#x27;man&#x27;</span>, <span class="string">&#x27;nan&#x27;</span>, <span class="string">&#x27;oan&#x27;</span>, <span class="string">&#x27;pan&#x27;</span>, <span class="string">&#x27;qan&#x27;</span>, <span class="string">&#x27;ran&#x27;</span>, <span class="string">&#x27;san&#x27;</span>, <span class="string">&#x27;tan&#x27;</span>, <span class="string">&#x27;uan&#x27;</span>, <span class="string">&#x27;van&#x27;</span>, <span class="string">&#x27;wan&#x27;</span>, <span class="string">&#x27;xan&#x27;</span>, <span class="string">&#x27;yan&#x27;</span>, <span class="string">&#x27;zan&#x27;</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>Notice how there are strings that are 1 letter longer than the original word, such as <code>cana</code>.</li>
<li>Please check for the case when there is an empty string <code>&#39;&#39;</code>, and if so, do not use that empty string when setting replace_l.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test # 2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of outputs of switch_letter(&#x27;at&#x27;) is <span class="subst">&#123;<span class="built_in">len</span>(switch_letter(<span class="string">&#x27;at&#x27;</span>))&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Number of outputs of switch_letter(&#39;at&#39;) is 1
</code></pre>
<h4 id="Expected-output-3"><a href="#Expected-output-3" class="headerlink" title="Expected output"></a>Expected output</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Number of outputs of <span class="title">switch_letter</span><span class="params">(<span class="string">&#x27;at&#x27;</span>)</span> is 1</span></span><br></pre></td></tr></table></figure>

<p><a name='ex-7'></a></p>
<h3 id="Exercise-7"><a href="#Exercise-7" class="headerlink" title="Exercise 7"></a>Exercise 7</h3><p><strong>Instructions for insert_letter()</strong>: Now implement a function that takes in a word and returns a list with a letter inserted at every offset.</p>
<p><strong>Step 1:</strong> is the same as in <code>delete_letter()</code></p>
<p><strong>Step 2:</strong> This can be a list comprehension of the form:<br><code>[f(a,b,c) for a, b in splits if condition for c in string]</code>   </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C7 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># UNIT TEST COMMENT: Candidate for Table Driven Tests</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: inserts</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_letter</span>(<span class="params">word, verbose=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">        word: the input string/word </span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">        inserts: a set of all possible strings with one new letter inserted at every offset</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span> </span><br><span class="line">    letters = <span class="string">&#x27;abcdefghijklmnopqrstuvwxyz&#x27;</span></span><br><span class="line">    insert_l = []</span><br><span class="line">    split_l = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    split_l = [(word[:i],word[i:]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(word) + <span class="number">1</span>)]</span><br><span class="line">    insert_l = [L + C + R <span class="keyword">for</span> L, R <span class="keyword">in</span> split_l <span class="keyword">for</span> C <span class="keyword">in</span> letters]</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> verbose: <span class="built_in">print</span>(<span class="string">f&quot;Input word <span class="subst">&#123;word&#125;</span> \nsplit_l = <span class="subst">&#123;split_l&#125;</span> \ninsert_l = <span class="subst">&#123;insert_l&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> insert_l</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">insert_l = insert_letter(<span class="string">&#x27;at&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of strings output by insert_letter(&#x27;at&#x27;) is <span class="subst">&#123;<span class="built_in">len</span>(insert_l)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Input word at 
split_l = [(&#39;&#39;, &#39;at&#39;), (&#39;a&#39;, &#39;t&#39;), (&#39;at&#39;, &#39;&#39;)] 
insert_l = [&#39;aat&#39;, &#39;bat&#39;, &#39;cat&#39;, &#39;dat&#39;, &#39;eat&#39;, &#39;fat&#39;, &#39;gat&#39;, &#39;hat&#39;, &#39;iat&#39;, &#39;jat&#39;, &#39;kat&#39;, &#39;lat&#39;, &#39;mat&#39;, &#39;nat&#39;, &#39;oat&#39;, &#39;pat&#39;, &#39;qat&#39;, &#39;rat&#39;, &#39;sat&#39;, &#39;tat&#39;, &#39;uat&#39;, &#39;vat&#39;, &#39;wat&#39;, &#39;xat&#39;, &#39;yat&#39;, &#39;zat&#39;, &#39;aat&#39;, &#39;abt&#39;, &#39;act&#39;, &#39;adt&#39;, &#39;aet&#39;, &#39;aft&#39;, &#39;agt&#39;, &#39;aht&#39;, &#39;ait&#39;, &#39;ajt&#39;, &#39;akt&#39;, &#39;alt&#39;, &#39;amt&#39;, &#39;ant&#39;, &#39;aot&#39;, &#39;apt&#39;, &#39;aqt&#39;, &#39;art&#39;, &#39;ast&#39;, &#39;att&#39;, &#39;aut&#39;, &#39;avt&#39;, &#39;awt&#39;, &#39;axt&#39;, &#39;ayt&#39;, &#39;azt&#39;, &#39;ata&#39;, &#39;atb&#39;, &#39;atc&#39;, &#39;atd&#39;, &#39;ate&#39;, &#39;atf&#39;, &#39;atg&#39;, &#39;ath&#39;, &#39;ati&#39;, &#39;atj&#39;, &#39;atk&#39;, &#39;atl&#39;, &#39;atm&#39;, &#39;atn&#39;, &#39;ato&#39;, &#39;atp&#39;, &#39;atq&#39;, &#39;atr&#39;, &#39;ats&#39;, &#39;att&#39;, &#39;atu&#39;, &#39;atv&#39;, &#39;atw&#39;, &#39;atx&#39;, &#39;aty&#39;, &#39;atz&#39;]
Number of strings output by insert_letter(&#39;at&#39;) is 78
</code></pre>
<h4 id="Expected-output-4"><a href="#Expected-output-4" class="headerlink" title="Expected output"></a>Expected output</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Input word at </span><br><span class="line">split_l = [(<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;at&#x27;</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;t&#x27;</span>), (<span class="string">&#x27;at&#x27;</span>, <span class="string">&#x27;&#x27;</span>)] </span><br><span class="line">insert_l = [<span class="string">&#x27;aat&#x27;</span>, <span class="string">&#x27;bat&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dat&#x27;</span>, <span class="string">&#x27;eat&#x27;</span>, <span class="string">&#x27;fat&#x27;</span>, <span class="string">&#x27;gat&#x27;</span>, <span class="string">&#x27;hat&#x27;</span>, <span class="string">&#x27;iat&#x27;</span>, <span class="string">&#x27;jat&#x27;</span>, <span class="string">&#x27;kat&#x27;</span>, <span class="string">&#x27;lat&#x27;</span>, <span class="string">&#x27;mat&#x27;</span>, <span class="string">&#x27;nat&#x27;</span>, <span class="string">&#x27;oat&#x27;</span>, <span class="string">&#x27;pat&#x27;</span>, <span class="string">&#x27;qat&#x27;</span>, <span class="string">&#x27;rat&#x27;</span>, <span class="string">&#x27;sat&#x27;</span>, <span class="string">&#x27;tat&#x27;</span>, <span class="string">&#x27;uat&#x27;</span>, <span class="string">&#x27;vat&#x27;</span>, <span class="string">&#x27;wat&#x27;</span>, <span class="string">&#x27;xat&#x27;</span>, <span class="string">&#x27;yat&#x27;</span>, <span class="string">&#x27;zat&#x27;</span>, <span class="string">&#x27;aat&#x27;</span>, <span class="string">&#x27;abt&#x27;</span>, <span class="string">&#x27;act&#x27;</span>, <span class="string">&#x27;adt&#x27;</span>, <span class="string">&#x27;aet&#x27;</span>, <span class="string">&#x27;aft&#x27;</span>, <span class="string">&#x27;agt&#x27;</span>, <span class="string">&#x27;aht&#x27;</span>, <span class="string">&#x27;ait&#x27;</span>, <span class="string">&#x27;ajt&#x27;</span>, <span class="string">&#x27;akt&#x27;</span>, <span class="string">&#x27;alt&#x27;</span>, <span class="string">&#x27;amt&#x27;</span>, <span class="string">&#x27;ant&#x27;</span>, <span class="string">&#x27;aot&#x27;</span>, <span class="string">&#x27;apt&#x27;</span>, <span class="string">&#x27;aqt&#x27;</span>, <span class="string">&#x27;art&#x27;</span>, <span class="string">&#x27;ast&#x27;</span>, <span class="string">&#x27;att&#x27;</span>, <span class="string">&#x27;aut&#x27;</span>, <span class="string">&#x27;avt&#x27;</span>, <span class="string">&#x27;awt&#x27;</span>, <span class="string">&#x27;axt&#x27;</span>, <span class="string">&#x27;ayt&#x27;</span>, <span class="string">&#x27;azt&#x27;</span>, <span class="string">&#x27;ata&#x27;</span>, <span class="string">&#x27;atb&#x27;</span>, <span class="string">&#x27;atc&#x27;</span>, <span class="string">&#x27;atd&#x27;</span>, <span class="string">&#x27;ate&#x27;</span>, <span class="string">&#x27;atf&#x27;</span>, <span class="string">&#x27;atg&#x27;</span>, <span class="string">&#x27;ath&#x27;</span>, <span class="string">&#x27;ati&#x27;</span>, <span class="string">&#x27;atj&#x27;</span>, <span class="string">&#x27;atk&#x27;</span>, <span class="string">&#x27;atl&#x27;</span>, <span class="string">&#x27;atm&#x27;</span>, <span class="string">&#x27;atn&#x27;</span>, <span class="string">&#x27;ato&#x27;</span>, <span class="string">&#x27;atp&#x27;</span>, <span class="string">&#x27;atq&#x27;</span>, <span class="string">&#x27;atr&#x27;</span>, <span class="string">&#x27;ats&#x27;</span>, <span class="string">&#x27;att&#x27;</span>, <span class="string">&#x27;atu&#x27;</span>, <span class="string">&#x27;atv&#x27;</span>, <span class="string">&#x27;atw&#x27;</span>, <span class="string">&#x27;atx&#x27;</span>, <span class="string">&#x27;aty&#x27;</span>, <span class="string">&#x27;atz&#x27;</span>]</span><br><span class="line">Number of strings output by insert_letter(<span class="string">&#x27;at&#x27;</span>) <span class="keyword">is</span> <span class="number">78</span></span><br></pre></td></tr></table></figure>

<h4 id="Note-1-3"><a href="#Note-1-3" class="headerlink" title="Note 1"></a>Note 1</h4><p>If you get a split_l like this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Input word at </span><br><span class="line">split_l = [(<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;at&#x27;</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;t&#x27;</span>)] </span><br><span class="line">insert_l = [<span class="string">&#x27;aat&#x27;</span>, <span class="string">&#x27;bat&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dat&#x27;</span>, <span class="string">&#x27;eat&#x27;</span>, <span class="string">&#x27;fat&#x27;</span>, <span class="string">&#x27;gat&#x27;</span>, <span class="string">&#x27;hat&#x27;</span>, <span class="string">&#x27;iat&#x27;</span>, <span class="string">&#x27;jat&#x27;</span>, <span class="string">&#x27;kat&#x27;</span>, <span class="string">&#x27;lat&#x27;</span>, <span class="string">&#x27;mat&#x27;</span>, <span class="string">&#x27;nat&#x27;</span>, <span class="string">&#x27;oat&#x27;</span>, <span class="string">&#x27;pat&#x27;</span>, <span class="string">&#x27;qat&#x27;</span>, <span class="string">&#x27;rat&#x27;</span>, <span class="string">&#x27;sat&#x27;</span>, <span class="string">&#x27;tat&#x27;</span>, <span class="string">&#x27;uat&#x27;</span>, <span class="string">&#x27;vat&#x27;</span>, <span class="string">&#x27;wat&#x27;</span>, <span class="string">&#x27;xat&#x27;</span>, <span class="string">&#x27;yat&#x27;</span>, <span class="string">&#x27;zat&#x27;</span>, <span class="string">&#x27;aat&#x27;</span>, <span class="string">&#x27;abt&#x27;</span>, <span class="string">&#x27;act&#x27;</span>, <span class="string">&#x27;adt&#x27;</span>, <span class="string">&#x27;aet&#x27;</span>, <span class="string">&#x27;aft&#x27;</span>, <span class="string">&#x27;agt&#x27;</span>, <span class="string">&#x27;aht&#x27;</span>, <span class="string">&#x27;ait&#x27;</span>, <span class="string">&#x27;ajt&#x27;</span>, <span class="string">&#x27;akt&#x27;</span>, <span class="string">&#x27;alt&#x27;</span>, <span class="string">&#x27;amt&#x27;</span>, <span class="string">&#x27;ant&#x27;</span>, <span class="string">&#x27;aot&#x27;</span>, <span class="string">&#x27;apt&#x27;</span>, <span class="string">&#x27;aqt&#x27;</span>, <span class="string">&#x27;art&#x27;</span>, <span class="string">&#x27;ast&#x27;</span>, <span class="string">&#x27;att&#x27;</span>, <span class="string">&#x27;aut&#x27;</span>, <span class="string">&#x27;avt&#x27;</span>, <span class="string">&#x27;awt&#x27;</span>, <span class="string">&#x27;axt&#x27;</span>, <span class="string">&#x27;ayt&#x27;</span>, <span class="string">&#x27;azt&#x27;</span>]</span><br><span class="line">Number of strings output by insert_letter(<span class="string">&#x27;at&#x27;</span>) <span class="keyword">is</span> <span class="number">52</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Notice that split_l is missing the extra tuple (‘at’, ‘’).  For insertion, we actually <strong>WANT</strong> this tuple.</li>
<li>The function is not creating all the desired output strings.</li>
<li>Check the range that you use for the for loop.</li>
</ul>
<h4 id="Note-2-3"><a href="#Note-2-3" class="headerlink" title="Note 2"></a>Note 2</h4><p>If you see this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Input word at </span><br><span class="line">split_l = [(<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;at&#x27;</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;t&#x27;</span>), (<span class="string">&#x27;at&#x27;</span>, <span class="string">&#x27;&#x27;</span>)] </span><br><span class="line">insert_l = [<span class="string">&#x27;aat&#x27;</span>, <span class="string">&#x27;bat&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dat&#x27;</span>, <span class="string">&#x27;eat&#x27;</span>, <span class="string">&#x27;fat&#x27;</span>, <span class="string">&#x27;gat&#x27;</span>, <span class="string">&#x27;hat&#x27;</span>, <span class="string">&#x27;iat&#x27;</span>, <span class="string">&#x27;jat&#x27;</span>, <span class="string">&#x27;kat&#x27;</span>, <span class="string">&#x27;lat&#x27;</span>, <span class="string">&#x27;mat&#x27;</span>, <span class="string">&#x27;nat&#x27;</span>, <span class="string">&#x27;oat&#x27;</span>, <span class="string">&#x27;pat&#x27;</span>, <span class="string">&#x27;qat&#x27;</span>, <span class="string">&#x27;rat&#x27;</span>, <span class="string">&#x27;sat&#x27;</span>, <span class="string">&#x27;tat&#x27;</span>, <span class="string">&#x27;uat&#x27;</span>, <span class="string">&#x27;vat&#x27;</span>, <span class="string">&#x27;wat&#x27;</span>, <span class="string">&#x27;xat&#x27;</span>, <span class="string">&#x27;yat&#x27;</span>, <span class="string">&#x27;zat&#x27;</span>, <span class="string">&#x27;aat&#x27;</span>, <span class="string">&#x27;abt&#x27;</span>, <span class="string">&#x27;act&#x27;</span>, <span class="string">&#x27;adt&#x27;</span>, <span class="string">&#x27;aet&#x27;</span>, <span class="string">&#x27;aft&#x27;</span>, <span class="string">&#x27;agt&#x27;</span>, <span class="string">&#x27;aht&#x27;</span>, <span class="string">&#x27;ait&#x27;</span>, <span class="string">&#x27;ajt&#x27;</span>, <span class="string">&#x27;akt&#x27;</span>, <span class="string">&#x27;alt&#x27;</span>, <span class="string">&#x27;amt&#x27;</span>, <span class="string">&#x27;ant&#x27;</span>, <span class="string">&#x27;aot&#x27;</span>, <span class="string">&#x27;apt&#x27;</span>, <span class="string">&#x27;aqt&#x27;</span>, <span class="string">&#x27;art&#x27;</span>, <span class="string">&#x27;ast&#x27;</span>, <span class="string">&#x27;att&#x27;</span>, <span class="string">&#x27;aut&#x27;</span>, <span class="string">&#x27;avt&#x27;</span>, <span class="string">&#x27;awt&#x27;</span>, <span class="string">&#x27;axt&#x27;</span>, <span class="string">&#x27;ayt&#x27;</span>, <span class="string">&#x27;azt&#x27;</span>]</span><br><span class="line">Number of strings output by insert_letter(<span class="string">&#x27;at&#x27;</span>) <span class="keyword">is</span> <span class="number">52</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Even though you may have fixed the split_l so that it contains the tuple <code>(&#39;at&#39;, &#39;&#39;)</code>, notice that you’re still missing some output strings.<ul>
<li>Notice that it’s missing strings such as ‘ata’, ‘atb’, ‘atc’ all the way to ‘atz’.</li>
</ul>
</li>
<li>To fix this, make sure that when you set insert_l, you allow the use of the empty string <code>&#39;&#39;</code>.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test # 2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of outputs of insert_letter(&#x27;at&#x27;) is <span class="subst">&#123;<span class="built_in">len</span>(insert_letter(<span class="string">&#x27;at&#x27;</span>))&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Number of outputs of insert_letter(&#39;at&#39;) is 78
</code></pre>
<h4 id="Expected-output-5"><a href="#Expected-output-5" class="headerlink" title="Expected output"></a>Expected output</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Number of outputs of <span class="title">insert_letter</span><span class="params">(<span class="string">&#x27;at&#x27;</span>)</span> is 78</span></span><br></pre></td></tr></table></figure>

<p><a name='3'></a></p>
<h1 id="Part-3-Combining-the-edits"><a href="#Part-3-Combining-the-edits" class="headerlink" title="Part 3: Combining the edits"></a>Part 3: Combining the edits</h1><p>Now that you have implemented the string manipulations, you will create two functions that, given a string, will return all the possible single and double edits on that string. These will be <code>edit_one_letter()</code> and <code>edit_two_letters()</code>.</p>
<p><a name='3-1'></a></p>
<h2 id="3-1-Edit-one-letter"><a href="#3-1-Edit-one-letter" class="headerlink" title="3.1 Edit one letter"></a>3.1 Edit one letter</h2><p><a name='ex-8'></a></p>
<h3 id="Exercise-8"><a href="#Exercise-8" class="headerlink" title="Exercise 8"></a>Exercise 8</h3><p><strong>Instructions</strong>: Implement the <code>edit_one_letter</code> function to get all the possible edits that are one edit away from a word. The edits  consist of the replace, insert, delete, and optionally the switch operation. You should use the previous functions you have already implemented to complete this function. The ‘switch’ function  is a less common edit function, so its use will be selected by an “allow_switches” input argument.</p>
<p>Note that those functions return <em>lists</em> while this function should return a <em>python set</em>. Utilizing a set eliminates any duplicate entries.</p>
<details>    
<summary>
    <font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
    <li> Each of the functions returns a list.  You can combine lists using the `+` operator. </li>
    <li> To get unique strings (avoid duplicates), you can use the set() function. </li>
</ul>
</p>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C8 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># UNIT TEST COMMENT: Candidate for Table Driven Tests</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: edit_one_letter</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">edit_one_letter</span>(<span class="params">word, allow_switches = <span class="literal">True</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">        word: the string/word for which we will generate all possible wordsthat are one edit away.</span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    edit_one_set = <span class="built_in">set</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    edit_one_set = edit_one_set | <span class="built_in">set</span>(delete_letter(word)) | <span class="built_in">set</span>(insert_letter(word)) | <span class="built_in">set</span>(replace_letter(word))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> allow_switches:</span><br><span class="line">        edit_one_set |= <span class="built_in">set</span>(switch_letter(word))</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> edit_one_set</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tmp_word = <span class="string">&quot;at&quot;</span></span><br><span class="line">tmp_edit_one_set = edit_one_letter(tmp_word)</span><br><span class="line"><span class="comment"># turn this into a list to sort it, in order to view it</span></span><br><span class="line">tmp_edit_one_l = <span class="built_in">sorted</span>(<span class="built_in">list</span>(tmp_edit_one_set))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;input word <span class="subst">&#123;tmp_word&#125;</span> \nedit_one_l \n<span class="subst">&#123;tmp_edit_one_l&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;The type of the returned object should be a set <span class="subst">&#123;<span class="built_in">type</span>(tmp_edit_one_set)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of outputs from edit_one_letter(&#x27;at&#x27;) is <span class="subst">&#123;<span class="built_in">len</span>(edit_one_letter(<span class="string">&#x27;at&#x27;</span>))&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>input word at 
edit_one_l 
[&#39;a&#39;, &#39;aa&#39;, &#39;aat&#39;, &#39;ab&#39;, &#39;abt&#39;, &#39;ac&#39;, &#39;act&#39;, &#39;ad&#39;, &#39;adt&#39;, &#39;ae&#39;, &#39;aet&#39;, &#39;af&#39;, &#39;aft&#39;, &#39;ag&#39;, &#39;agt&#39;, &#39;ah&#39;, &#39;aht&#39;, &#39;ai&#39;, &#39;ait&#39;, &#39;aj&#39;, &#39;ajt&#39;, &#39;ak&#39;, &#39;akt&#39;, &#39;al&#39;, &#39;alt&#39;, &#39;am&#39;, &#39;amt&#39;, &#39;an&#39;, &#39;ant&#39;, &#39;ao&#39;, &#39;aot&#39;, &#39;ap&#39;, &#39;apt&#39;, &#39;aq&#39;, &#39;aqt&#39;, &#39;ar&#39;, &#39;art&#39;, &#39;as&#39;, &#39;ast&#39;, &#39;ata&#39;, &#39;atb&#39;, &#39;atc&#39;, &#39;atd&#39;, &#39;ate&#39;, &#39;atf&#39;, &#39;atg&#39;, &#39;ath&#39;, &#39;ati&#39;, &#39;atj&#39;, &#39;atk&#39;, &#39;atl&#39;, &#39;atm&#39;, &#39;atn&#39;, &#39;ato&#39;, &#39;atp&#39;, &#39;atq&#39;, &#39;atr&#39;, &#39;ats&#39;, &#39;att&#39;, &#39;atu&#39;, &#39;atv&#39;, &#39;atw&#39;, &#39;atx&#39;, &#39;aty&#39;, &#39;atz&#39;, &#39;au&#39;, &#39;aut&#39;, &#39;av&#39;, &#39;avt&#39;, &#39;aw&#39;, &#39;awt&#39;, &#39;ax&#39;, &#39;axt&#39;, &#39;ay&#39;, &#39;ayt&#39;, &#39;az&#39;, &#39;azt&#39;, &#39;bat&#39;, &#39;bt&#39;, &#39;cat&#39;, &#39;ct&#39;, &#39;dat&#39;, &#39;dt&#39;, &#39;eat&#39;, &#39;et&#39;, &#39;fat&#39;, &#39;ft&#39;, &#39;gat&#39;, &#39;gt&#39;, &#39;hat&#39;, &#39;ht&#39;, &#39;iat&#39;, &#39;it&#39;, &#39;jat&#39;, &#39;jt&#39;, &#39;kat&#39;, &#39;kt&#39;, &#39;lat&#39;, &#39;lt&#39;, &#39;mat&#39;, &#39;mt&#39;, &#39;nat&#39;, &#39;nt&#39;, &#39;oat&#39;, &#39;ot&#39;, &#39;pat&#39;, &#39;pt&#39;, &#39;qat&#39;, &#39;qt&#39;, &#39;rat&#39;, &#39;rt&#39;, &#39;sat&#39;, &#39;st&#39;, &#39;t&#39;, &#39;ta&#39;, &#39;tat&#39;, &#39;tt&#39;, &#39;uat&#39;, &#39;ut&#39;, &#39;vat&#39;, &#39;vt&#39;, &#39;wat&#39;, &#39;wt&#39;, &#39;xat&#39;, &#39;xt&#39;, &#39;yat&#39;, &#39;yt&#39;, &#39;zat&#39;, &#39;zt&#39;]

The type of the returned object should be a set &lt;class &#39;set&#39;&gt;
Number of outputs from edit_one_letter(&#39;at&#39;) is 129
</code></pre>
<h4 id="Expected-Output-5"><a href="#Expected-Output-5" class="headerlink" title="Expected Output"></a>Expected Output</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">input word at </span><br><span class="line">edit_one_l </span><br><span class="line">[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;aa&#x27;</span>, <span class="string">&#x27;aat&#x27;</span>, <span class="string">&#x27;ab&#x27;</span>, <span class="string">&#x27;abt&#x27;</span>, <span class="string">&#x27;ac&#x27;</span>, <span class="string">&#x27;act&#x27;</span>, <span class="string">&#x27;ad&#x27;</span>, <span class="string">&#x27;adt&#x27;</span>, <span class="string">&#x27;ae&#x27;</span>, <span class="string">&#x27;aet&#x27;</span>, <span class="string">&#x27;af&#x27;</span>, <span class="string">&#x27;aft&#x27;</span>, <span class="string">&#x27;ag&#x27;</span>, <span class="string">&#x27;agt&#x27;</span>, <span class="string">&#x27;ah&#x27;</span>, <span class="string">&#x27;aht&#x27;</span>, <span class="string">&#x27;ai&#x27;</span>, <span class="string">&#x27;ait&#x27;</span>, <span class="string">&#x27;aj&#x27;</span>, <span class="string">&#x27;ajt&#x27;</span>, <span class="string">&#x27;ak&#x27;</span>, <span class="string">&#x27;akt&#x27;</span>, <span class="string">&#x27;al&#x27;</span>, <span class="string">&#x27;alt&#x27;</span>, <span class="string">&#x27;am&#x27;</span>, <span class="string">&#x27;amt&#x27;</span>, <span class="string">&#x27;an&#x27;</span>, <span class="string">&#x27;ant&#x27;</span>, <span class="string">&#x27;ao&#x27;</span>, <span class="string">&#x27;aot&#x27;</span>, <span class="string">&#x27;ap&#x27;</span>, <span class="string">&#x27;apt&#x27;</span>, <span class="string">&#x27;aq&#x27;</span>, <span class="string">&#x27;aqt&#x27;</span>, <span class="string">&#x27;ar&#x27;</span>, <span class="string">&#x27;art&#x27;</span>, <span class="string">&#x27;as&#x27;</span>, <span class="string">&#x27;ast&#x27;</span>, <span class="string">&#x27;ata&#x27;</span>, <span class="string">&#x27;atb&#x27;</span>, <span class="string">&#x27;atc&#x27;</span>, <span class="string">&#x27;atd&#x27;</span>, <span class="string">&#x27;ate&#x27;</span>, <span class="string">&#x27;atf&#x27;</span>, <span class="string">&#x27;atg&#x27;</span>, <span class="string">&#x27;ath&#x27;</span>, <span class="string">&#x27;ati&#x27;</span>, <span class="string">&#x27;atj&#x27;</span>, <span class="string">&#x27;atk&#x27;</span>, <span class="string">&#x27;atl&#x27;</span>, <span class="string">&#x27;atm&#x27;</span>, <span class="string">&#x27;atn&#x27;</span>, <span class="string">&#x27;ato&#x27;</span>, <span class="string">&#x27;atp&#x27;</span>, <span class="string">&#x27;atq&#x27;</span>, <span class="string">&#x27;atr&#x27;</span>, <span class="string">&#x27;ats&#x27;</span>, <span class="string">&#x27;att&#x27;</span>, <span class="string">&#x27;atu&#x27;</span>, <span class="string">&#x27;atv&#x27;</span>, <span class="string">&#x27;atw&#x27;</span>, <span class="string">&#x27;atx&#x27;</span>, <span class="string">&#x27;aty&#x27;</span>, <span class="string">&#x27;atz&#x27;</span>, <span class="string">&#x27;au&#x27;</span>, <span class="string">&#x27;aut&#x27;</span>, <span class="string">&#x27;av&#x27;</span>, <span class="string">&#x27;avt&#x27;</span>, <span class="string">&#x27;aw&#x27;</span>, <span class="string">&#x27;awt&#x27;</span>, <span class="string">&#x27;ax&#x27;</span>, <span class="string">&#x27;axt&#x27;</span>, <span class="string">&#x27;ay&#x27;</span>, <span class="string">&#x27;ayt&#x27;</span>, <span class="string">&#x27;az&#x27;</span>, <span class="string">&#x27;azt&#x27;</span>, <span class="string">&#x27;bat&#x27;</span>, <span class="string">&#x27;bt&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;ct&#x27;</span>, <span class="string">&#x27;dat&#x27;</span>, <span class="string">&#x27;dt&#x27;</span>, <span class="string">&#x27;eat&#x27;</span>, <span class="string">&#x27;et&#x27;</span>, <span class="string">&#x27;fat&#x27;</span>, <span class="string">&#x27;ft&#x27;</span>, <span class="string">&#x27;gat&#x27;</span>, <span class="string">&#x27;gt&#x27;</span>, <span class="string">&#x27;hat&#x27;</span>, <span class="string">&#x27;ht&#x27;</span>, <span class="string">&#x27;iat&#x27;</span>, <span class="string">&#x27;it&#x27;</span>, <span class="string">&#x27;jat&#x27;</span>, <span class="string">&#x27;jt&#x27;</span>, <span class="string">&#x27;kat&#x27;</span>, <span class="string">&#x27;kt&#x27;</span>, <span class="string">&#x27;lat&#x27;</span>, <span class="string">&#x27;lt&#x27;</span>, <span class="string">&#x27;mat&#x27;</span>, <span class="string">&#x27;mt&#x27;</span>, <span class="string">&#x27;nat&#x27;</span>, <span class="string">&#x27;nt&#x27;</span>, <span class="string">&#x27;oat&#x27;</span>, <span class="string">&#x27;ot&#x27;</span>, <span class="string">&#x27;pat&#x27;</span>, <span class="string">&#x27;pt&#x27;</span>, <span class="string">&#x27;qat&#x27;</span>, <span class="string">&#x27;qt&#x27;</span>, <span class="string">&#x27;rat&#x27;</span>, <span class="string">&#x27;rt&#x27;</span>, <span class="string">&#x27;sat&#x27;</span>, <span class="string">&#x27;st&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;ta&#x27;</span>, <span class="string">&#x27;tat&#x27;</span>, <span class="string">&#x27;tt&#x27;</span>, <span class="string">&#x27;uat&#x27;</span>, <span class="string">&#x27;ut&#x27;</span>, <span class="string">&#x27;vat&#x27;</span>, <span class="string">&#x27;vt&#x27;</span>, <span class="string">&#x27;wat&#x27;</span>, <span class="string">&#x27;wt&#x27;</span>, <span class="string">&#x27;xat&#x27;</span>, <span class="string">&#x27;xt&#x27;</span>, <span class="string">&#x27;yat&#x27;</span>, <span class="string">&#x27;yt&#x27;</span>, <span class="string">&#x27;zat&#x27;</span>, <span class="string">&#x27;zt&#x27;</span>]</span><br><span class="line"></span><br><span class="line">The type of the returned object should be a set &lt;class &#x27;set&#x27;&gt;</span><br><span class="line"><span class="function">Number of outputs from <span class="title">edit_one_letter</span><span class="params">(<span class="string">&#x27;at&#x27;</span>)</span> is 129</span></span><br></pre></td></tr></table></figure>

<p><a name='3-2'></a></p>
<h2 id="Part-3-2-Edit-two-letters"><a href="#Part-3-2-Edit-two-letters" class="headerlink" title="Part 3.2 Edit two letters"></a>Part 3.2 Edit two letters</h2><p><a name='ex-9'></a></p>
<h3 id="Exercise-9"><a href="#Exercise-9" class="headerlink" title="Exercise 9"></a>Exercise 9</h3><p>Now you can generalize this to implement to get two edits on a word. To do so, you would have to get all the possible edits on a single word and then for each modified word, you would have to modify it again. </p>
<p><strong>Instructions</strong>: Implement the <code>edit_two_letters</code> function that returns a set of words that are two edits away. Note that creating additional edits based on the <code>edit_one_letter</code> function may ‘restore’ some one_edits to zero or one edits. That is allowed here. This accounted for in get_corrections.</p>
<details>    
<summary>
    <font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
    <li>You will likely want to take the union of two sets.</li>
    <li>You can either use set.union() or use the '|' (or operator) to union two sets</li>
    <li>See the documentation <a target="_blank" rel="noopener" href="https://docs.python.org/2/library/sets.html" > Python sets </a> for examples of using operators or functions of the Python set.</li>
</ul>
</p>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C9 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># UNIT TEST COMMENT: Candidate for Table Driven Tests</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: edit_two_letters</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">edit_two_letters</span>(<span class="params">word, allow_switches = <span class="literal">True</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">        word: the input string/word </span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">        edit_two_set: a set of strings with all possible two edits</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    edit_two_set = <span class="built_in">set</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    one_letter =  edit_one_letter(word,allow_switches)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> one_letter:</span><br><span class="line">        edit_two_set |= edit_one_letter(word,allow_switches)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> edit_two_set</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tmp_edit_two_set = edit_two_letters(<span class="string">&quot;a&quot;</span>)</span><br><span class="line">tmp_edit_two_l = <span class="built_in">sorted</span>(<span class="built_in">list</span>(tmp_edit_two_set))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of strings with edit distance of two: <span class="subst">&#123;<span class="built_in">len</span>(tmp_edit_two_l)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;First 10 strings <span class="subst">&#123;tmp_edit_two_l[:<span class="number">10</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Last 10 strings <span class="subst">&#123;tmp_edit_two_l[-<span class="number">10</span>:]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;The data type of the returned object should be a set <span class="subst">&#123;<span class="built_in">type</span>(tmp_edit_two_set)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of strings that are 2 edit distances from &#x27;at&#x27; is <span class="subst">&#123;<span class="built_in">len</span>(edit_two_letters(<span class="string">&#x27;at&#x27;</span>))&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Number of strings with edit distance of two: 2654
First 10 strings [&#39;&#39;, &#39;a&#39;, &#39;aa&#39;, &#39;aaa&#39;, &#39;aab&#39;, &#39;aac&#39;, &#39;aad&#39;, &#39;aae&#39;, &#39;aaf&#39;, &#39;aag&#39;]
Last 10 strings [&#39;zv&#39;, &#39;zva&#39;, &#39;zw&#39;, &#39;zwa&#39;, &#39;zx&#39;, &#39;zxa&#39;, &#39;zy&#39;, &#39;zya&#39;, &#39;zz&#39;, &#39;zza&#39;]
The data type of the returned object should be a set &lt;class &#39;set&#39;&gt;
Number of strings that are 2 edit distances from &#39;at&#39; is 7154
</code></pre>
<h4 id="Expected-Output-6"><a href="#Expected-Output-6" class="headerlink" title="Expected Output"></a>Expected Output</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Number of strings with edit distance of two: <span class="number">2654</span></span><br><span class="line">First <span class="number">10</span> strings [<span class="string">&#x27;&#x27;, &#x27;</span>a<span class="number">&#x27;</span>, <span class="string">&#x27;aa&#x27;</span>, <span class="string">&#x27;aaa&#x27;</span>, <span class="string">&#x27;aab&#x27;</span>, <span class="string">&#x27;aac&#x27;</span>, <span class="string">&#x27;aad&#x27;</span>, <span class="string">&#x27;aae&#x27;</span>, <span class="string">&#x27;aaf&#x27;</span>, <span class="string">&#x27;aag&#x27;</span>]</span><br><span class="line">Last <span class="number">10</span> strings [<span class="string">&#x27;zv&#x27;</span>, <span class="string">&#x27;zva&#x27;</span>, <span class="string">&#x27;zw&#x27;</span>, <span class="string">&#x27;zwa&#x27;</span>, <span class="string">&#x27;zx&#x27;</span>, <span class="string">&#x27;zxa&#x27;</span>, <span class="string">&#x27;zy&#x27;</span>, <span class="string">&#x27;zya&#x27;</span>, <span class="string">&#x27;zz&#x27;</span>, <span class="string">&#x27;zza&#x27;</span>]</span><br><span class="line">The data type of the returned object should be a set &lt;class &#x27;set&#x27;&gt;</span><br><span class="line">Number of strings that are <span class="number">2</span> edit distances from <span class="string">&#x27;at&#x27;</span> is <span class="number">7154</span></span><br></pre></td></tr></table></figure>

<p><a name='3-3'></a></p>
<h2 id="Part-3-3-suggest-spelling-suggestions"><a href="#Part-3-3-suggest-spelling-suggestions" class="headerlink" title="Part 3-3: suggest spelling suggestions"></a>Part 3-3: suggest spelling suggestions</h2><p>Now you will use your <code>edit_two_letters</code> function to get a set of all the possible 2 edits on your word. You will then use those strings to get the most probable word you meant to type aka your typing suggestion.</p>
<p><a name='ex-10'></a></p>
<h3 id="Exercise-10"><a href="#Exercise-10" class="headerlink" title="Exercise 10"></a>Exercise 10</h3><p><strong>Instructions</strong>: Implement <code>get_corrections</code>, which returns a list of zero to n possible suggestion tuples of the form (word, probability_of_word). </p>
<p><strong>Step 1:</strong> Generate suggestions for a supplied word: You’ll use the edit functions you have developed. The ‘suggestion algorithm’ should follow this logic: </p>
<ul>
<li>If the word is in the vocabulary, suggest the word. </li>
<li>Otherwise, if there are suggestions from <code>edit_one_letter</code> that are in the vocabulary, use those. </li>
<li>Otherwise, if there are suggestions from <code>edit_two_letters</code> that are in the vocabulary, use those. </li>
<li>Otherwise, suggest the input word.*  </li>
<li>The idea is that words generated from fewer edits are more likely than words with more edits.</li>
</ul>
<p>Note: </p>
<ul>
<li>Edits of one or two letters may ‘restore’ strings to either zero or one edit. This algorithm accounts for this by preferentially selecting lower distance edits first.</li>
</ul>
<h4 id="Short-circuit"><a href="#Short-circuit" class="headerlink" title="Short circuit"></a>Short circuit</h4><p>In Python, logical operations such as <code>and</code> and <code>or</code> have two useful properties. They can operate on lists and they have <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html">‘short-circuit’ behavior</a>. Try these:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example of logical operation on lists or sets</span></span><br><span class="line"><span class="built_in">print</span>( [] <span class="keyword">and</span> [<span class="string">&quot;a&quot;</span>,<span class="string">&quot;b&quot;</span>] )</span><br><span class="line"><span class="built_in">print</span>( [] <span class="keyword">or</span> [<span class="string">&quot;a&quot;</span>,<span class="string">&quot;b&quot;</span>] )</span><br><span class="line"><span class="comment">#example of Short circuit behavior</span></span><br><span class="line">val1 =  [<span class="string">&quot;Most&quot;</span>,<span class="string">&quot;Likely&quot;</span>] <span class="keyword">or</span> [<span class="string">&quot;Less&quot;</span>,<span class="string">&quot;so&quot;</span>] <span class="keyword">or</span> [<span class="string">&quot;least&quot;</span>,<span class="string">&quot;of&quot;</span>,<span class="string">&quot;all&quot;</span>]  <span class="comment"># selects first, does not evalute remainder</span></span><br><span class="line"><span class="built_in">print</span>(val1)</span><br><span class="line">val2 =  [] <span class="keyword">or</span> [] <span class="keyword">or</span> [<span class="string">&quot;least&quot;</span>,<span class="string">&quot;of&quot;</span>,<span class="string">&quot;all&quot;</span>] <span class="comment"># continues evaluation until there is a non-empty list</span></span><br><span class="line"><span class="built_in">print</span>(val2)</span><br></pre></td></tr></table></figure>

<pre><code>[]
[&#39;a&#39;, &#39;b&#39;]
[&#39;Most&#39;, &#39;Likely&#39;]
[&#39;least&#39;, &#39;of&#39;, &#39;all&#39;]
</code></pre>
<p>The logical <code>or</code> could be used to implement the suggestion algorithm very compactly. Alternately, if/then constructs could be used.</p>
<p><strong>Step 2</strong>: Create a ‘best_words’ dictionary where the ‘key’ is a suggestion and the ‘value’ is the probability of that word in your vocabulary. If the word is not in the vocabulary, assign it a probability of 0.</p>
<p><strong>Step 3</strong>: Select the n best suggestions. There may be fewer than n.</p>
<details>    
<summary>
    <font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
    <li>edit_one_letter and edit_two_letters return *python sets*. </li>
    <li> Sets have a handy <a target="_blank" rel="noopener" href="https://docs.python.org/2/library/sets.html" > set.intersection </a> feature</li>
    <li>To find the keys that have the highest values in a dictionary, you can use the Counter dictionary to create a Counter object from a regular dictionary.  Then you can use Counter.most_common(n) to get the n most common keys.
    </li>
    <li>To find the intersection of two sets, you can use set.intersection or the & operator.</li>
    <li>If you are not as familiar with short circuit syntax (as shown above), feel free to use if else statements instead.</li>
    <li>To use an if statement to check of a set is empty, use 'if not x:' syntax </li>
</ul>
</p>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C10 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># UNIT TEST COMMENT: Candidate for Table Driven Tests</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: get_corrections</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_corrections</span>(<span class="params">word, probs, vocab, n=<span class="number">2</span>, verbose = <span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Input: </span></span><br><span class="line"><span class="string">        word: a user entered string to check for suggestions</span></span><br><span class="line"><span class="string">        probs: a dictionary that maps each word to its probability in the corpus</span></span><br><span class="line"><span class="string">        vocab: a set containing all the vocabulary</span></span><br><span class="line"><span class="string">        n: number of possible word corrections you want returned in the dictionary</span></span><br><span class="line"><span class="string">    Output: </span></span><br><span class="line"><span class="string">        n_best: a list of tuples with the most probable n corrected words and their probabilities.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    suggestions = []</span><br><span class="line">    n_best = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="keyword">if</span> word <span class="keyword">in</span> vocab:</span><br><span class="line">        suggestions = [(word, probs[word])]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        suggestions = [(_, probs[_]) <span class="keyword">for</span> _ <span class="keyword">in</span> edit_one_letter(word) <span class="keyword">if</span> _ <span class="keyword">in</span> vocab] <span class="keyword">or</span>  \</span><br><span class="line">                    [(_, probs[_]) <span class="keyword">for</span> _ <span class="keyword">in</span> edit_two_letter(word) <span class="keyword">if</span> _ <span class="keyword">in</span> vocab] <span class="keyword">or</span> \</span><br><span class="line">                    [(word,<span class="number">0</span>)]</span><br><span class="line">    </span><br><span class="line">    n_best = <span class="built_in">sorted</span>(suggestions, key = <span class="keyword">lambda</span> x : x[-<span class="number">1</span>], reverse = <span class="literal">True</span>)[:n]</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> verbose: <span class="built_in">print</span>(<span class="string">&quot;suggestions = &quot;</span>, suggestions)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> n_best</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test your implementation - feel free to try other words in my word</span></span><br><span class="line">my_word = <span class="string">&#x27;dys&#x27;</span> </span><br><span class="line">tmp_corrections = get_corrections(my_word, probs, vocab, <span class="number">2</span>, verbose=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> i, word_prob <span class="keyword">in</span> <span class="built_in">enumerate</span>(tmp_corrections):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;word <span class="subst">&#123;i&#125;</span>: <span class="subst">&#123;word_prob[<span class="number">0</span>]&#125;</span>, probability <span class="subst">&#123;word_prob[<span class="number">1</span>]:<span class="number">.6</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># CODE REVIEW COMMENT: using &quot;tmp_corrections&quot; insteads of &quot;cors&quot;. &quot;cors&quot; is not defined</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;data type of corrections <span class="subst">&#123;<span class="built_in">type</span>(tmp_corrections)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>suggestions =  [(&#39;dye&#39;, 1.865184466743761e-05), (&#39;days&#39;, 0.0004103405826836274)]
word 0: days, probability 0.000410
word 1: dye, probability 0.000019
data type of corrections &lt;class &#39;list&#39;&gt;
</code></pre>
<h4 id="Expected-Output-7"><a href="#Expected-Output-7" class="headerlink" title="Expected Output"></a>Expected Output</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">word <span class="number">0</span>: days, probability <span class="number">0.000410</span></span><br><span class="line">word <span class="number">1</span>: dye, probability <span class="number">0.000019</span></span><br><span class="line">data type of corrections &lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">list</span>&#x27;&gt;</span></span><br></pre></td></tr></table></figure>

<p><a name='4'></a></p>
<h1 id="Part-4-Minimum-Edit-distance"><a href="#Part-4-Minimum-Edit-distance" class="headerlink" title="Part 4: Minimum Edit distance"></a>Part 4: Minimum Edit distance</h1><p>Now that you have implemented your auto-correct, how do you evaluate the similarity between two strings? For example: ‘waht’ and ‘what’</p>
<p>Also how do you efficiently find the shortest path to go from the word, ‘waht’ to the word ‘what’?</p>
<p>You will implement a dynamic programming system that will tell you the minimum number of edits required to convert a string into another string.</p>
<p><a name='4-1'></a></p>
<h3 id="Part-4-1-Dynamic-Programming"><a href="#Part-4-1-Dynamic-Programming" class="headerlink" title="Part 4.1 Dynamic Programming"></a>Part 4.1 Dynamic Programming</h3><p>Dynamic Programming breaks a problem down into subproblems which can be combined to form the final solution. Here, given a string source[0..i] and a string target[0..j], we will compute all the combinations of substrings[i, j] and calculate their edit distance. To do this efficiently, we will use a table to maintain the previously computed substrings and use those to calculate larger substrings.</p>
<p>You have to create a matrix and update each element in the matrix as follows:  </p>
<p>$$\text{Initialization}$$</p>
<p>\begin{align}<br>D[0,0] &amp;= 0 \<br>D[i,0] &amp;= D[i-1,0] + del_cost(source[i]) \tag{4}\<br>D[0,j] &amp;= D[0,j-1] + ins_cost(target[j]) \<br>\end{align}</p>
<p>$$\text{Per Cell Operations}$$<br>\begin{align}<br> \<br>D[i,j] =min<br>\begin{cases}<br>D[i-1,j] + del_cost\<br>D[i,j-1] + ins_cost\<br>D[i-1,j-1] + \left{\begin{matrix}<br>rep_cost; &amp; if src[i]\neq tar[j]\<br>0 ; &amp; if src[i]=tar[j]<br>\end{matrix}\right.<br>\end{cases}<br>\tag{5}<br>\end{align}</p>
<p>So converting the source word <strong>play</strong> to the target word <strong>stay</strong>, using an input cost of one, a delete cost of 1, and replace cost of 2 would give you the following table:</p>
<table style="width:20%">

  <tr>
    <td> <b> </b>  </td>
    <td> <b># </b>  </td>
    <td> <b>s </b>  </td>
    <td> <b>t </b> </td> 
    <td> <b>a </b> </td> 
    <td> <b>y </b> </td> 
  </tr>
   <tr>
    <td> <b>  #  </b></td>
    <td> 0</td> 
    <td> 1</td> 
    <td> 2</td> 
    <td> 3</td> 
    <td> 4</td> 
 
  </tr>
  <tr>
    <td> <b>  p  </b></td>
    <td> 1</td> 
 <td> 2</td> 
    <td> 3</td> 
    <td> 4</td> 
   <td> 5</td>
  </tr>
   
  <tr>
    <td> <b> l </b></td>
    <td>2</td> 
    <td>3</td> 
    <td>4</td> 
    <td>5</td> 
    <td>6</td>
  </tr>

  <tr>
    <td> <b> a </b></td>
    <td>3</td> 
     <td>4</td> 
     <td>5</td> 
     <td>4</td>
     <td>5</td> 
  </tr>
  
   <tr>
    <td> <b> y </b></td>
    <td>4</td> 
      <td>5</td> 
     <td>6</td> 
     <td>5</td>
     <td>4</td> 
  </tr>
  

</table>



<p>The operations used in this algorithm are ‘insert’, ‘delete’, and ‘replace’. These correspond to the functions that you defined earlier: insert_letter(), delete_letter() and replace_letter(). switch_letter() is not used here.</p>
<p>The diagram below describes how to initialize the table. Each entry in D[i,j] represents the minimum cost of converting string source[0:i] to string target[0:j]. The first column is initialized to represent the cumulative cost of deleting the source characters to convert string “EER” to “”. The first row is initialized to represent the cumulative cost of inserting the target characters to convert from “” to “NEAR”.</p>
<div style="width:image width px; font-size:100%; text-align:center;"><img src='EditDistInit4.png' alt="alternate text" width="width" height="height" style="width:1000px;height:400px;"/> Figure 6 Initializing Distance Matrix</div>     

<p>Filling in the remainder of the table utilizes the ‘Per Cell Operations’ in the equation (5) above. Note, the diagram below includes in the table some of the 3 sub-calculations shown in light grey. Only ‘min’ of those operations is stored in the table in the <code>min_edit_distance()</code> function.</p>
<div style="width:image width px; font-size:100%; text-align:center;"><img src='EditDistFill2.png' alt="alternate text" width="width" height="height" style="width:800px;height:400px;"/> Figure 7 Filling Distance Matrix</div>     

<p>Note that the formula for $D[i,j]$ shown in the image is equivalent to:</p>
<p>\begin{align}<br> \<br>D[i,j] =min<br>\begin{cases}<br>D[i-1,j] + del_cost\<br>D[i,j-1] + ins_cost\<br>D[i-1,j-1] + \left{\begin{matrix}<br>rep_cost; &amp; if src[i]\neq tar[j]\<br>0 ; &amp; if src[i]=tar[j]<br>\end{matrix}\right.<br>\end{cases}<br>\tag{5}<br>\end{align}</p>
<p>The variable <code>sub_cost</code> (for substitution cost) is the same as <code>rep_cost</code>; replacement cost.  We will stick with the term “replace” whenever possible.</p>
<p>Below are some examples of cells where replacement is used. This also shows the minimum path from the lower right final position where “EER” has been replaced by “NEAR” back to the start. This provides a starting point for the optional ‘backtrace’ algorithm below.</p>
<div style="width:image width px; font-size:100%; text-align:center;"><img src='EditDistExample1.png' alt="alternate text" width="width" height="height" style="width:1200px;height:400px;"/> Figure 8 Examples Distance Matrix</div>    

<p><a name='ex-11'></a></p>
<h3 id="Exercise-11"><a href="#Exercise-11" class="headerlink" title="Exercise 11"></a>Exercise 11</h3><p>Again, the word “substitution” appears in the figure, but think of this as “replacement”.</p>
<p><strong>Instructions</strong>: Implement the function below to get the minimum amount of edits required given a source string and a target string. </p>
<details>    
<summary>
    <font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
    <li>The range(start, stop, step) function excludes 'stop' from its output</li>
    <li><a href="" > words </a> </li>
</ul>
</p>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C11 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: min_edit_distance</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">min_edit_distance</span>(<span class="params">source, target, ins_cost = <span class="number">1</span>, del_cost = <span class="number">1</span>, rep_cost = <span class="number">2</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Input: </span></span><br><span class="line"><span class="string">        source: a string corresponding to the string you are starting with</span></span><br><span class="line"><span class="string">        target: a string corresponding to the string you want to end with</span></span><br><span class="line"><span class="string">        ins_cost: an integer setting the insert cost</span></span><br><span class="line"><span class="string">        del_cost: an integer setting the delete cost</span></span><br><span class="line"><span class="string">        rep_cost: an integer setting the replace cost</span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">        D: a matrix of len(source)+1 by len(target)+1 containing minimum edit distances</span></span><br><span class="line"><span class="string">        med: the minimum edit distance (med) required to convert the source string to the target</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># use deletion and insert cost as  1</span></span><br><span class="line">    m = <span class="built_in">len</span>(source) </span><br><span class="line">    n = <span class="built_in">len</span>(target) </span><br><span class="line">    <span class="comment">#initialize cost matrix with zeros and dimensions (m+1,n+1) </span></span><br><span class="line">    D = np.zeros((m+<span class="number">1</span>, n+<span class="number">1</span>), dtype=<span class="built_in">int</span>) </span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (Replace instances of &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Fill in column 0, from row 1 to row m, both inclusive</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,m+<span class="number">1</span>): <span class="comment"># Replace None with the proper range</span></span><br><span class="line">        D[row,<span class="number">0</span>] = row</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Fill in row 0, for all columns from 1 to n, both inclusive</span></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,n+<span class="number">1</span>): <span class="comment"># Replace None with the proper range</span></span><br><span class="line">        D[<span class="number">0</span>,col] = col</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Loop through row 1 to row m, both inclusive</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,m+<span class="number">1</span>): </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Loop through column 1 to column n, both inclusive</span></span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Intialize r_cost to the &#x27;replace&#x27; cost that is passed into this function</span></span><br><span class="line">            r_cost = rep_cost</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Check to see if source character at the previous row</span></span><br><span class="line">            <span class="comment"># matches the target character at the previous column, </span></span><br><span class="line">            <span class="keyword">if</span> source[row-<span class="number">1</span>] == target[col-<span class="number">1</span>]:</span><br><span class="line">                <span class="comment"># Update the replacement cost to 0 if source and target are the same</span></span><br><span class="line">                r_cost = <span class="number">0</span></span><br><span class="line">                </span><br><span class="line">            <span class="comment"># Update the cost at row, col based on previous entries in the cost matrix</span></span><br><span class="line">            <span class="comment"># Refer to the equation calculate for D[i,j] (the minimum of three calculated costs)</span></span><br><span class="line">            D[row,col] = <span class="built_in">min</span>([ D[row-<span class="number">1</span>,col] + del_cost, D[row, col-<span class="number">1</span>] + ins_cost , D[row-<span class="number">1</span>, col-<span class="number">1</span>] + r_cost])</span><br><span class="line">          </span><br><span class="line">    <span class="comment"># Set the minimum edit distance with the cost found at row m, column n</span></span><br><span class="line">    med = D[m,n]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> D, med</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#DO NOT MODIFY THIS CELL</span></span><br><span class="line"><span class="comment"># testing your implementation </span></span><br><span class="line">source =  <span class="string">&#x27;play&#x27;</span></span><br><span class="line">target = <span class="string">&#x27;stay&#x27;</span></span><br><span class="line">matrix, min_edits = min_edit_distance(source, target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;minimum edits: &quot;</span>,min_edits, <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">idx = <span class="built_in">list</span>(<span class="string">&#x27;#&#x27;</span> + source)</span><br><span class="line">cols = <span class="built_in">list</span>(<span class="string">&#x27;#&#x27;</span> + target)</span><br><span class="line">df = pd.DataFrame(matrix, index=idx, columns= cols)</span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure>

<pre><code>minimum edits:  4 

   #  s  t  a  y
#  0  1  2  3  4
p  1  2  3  4  5
l  2  3  4  5  6
a  3  4  5  4  5
y  4  5  6  5  4
</code></pre>
<p><strong>Expected Results:</strong>  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">   <span class="meta">#  s  t  a  y</span></span><br><span class="line">#  <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>  <span class="number">4</span></span><br><span class="line">p  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>  <span class="number">4</span>  <span class="number">5</span></span><br><span class="line">l  <span class="number">2</span>  <span class="number">3</span>  <span class="number">4</span>  <span class="number">5</span>  <span class="number">6</span></span><br><span class="line">a  <span class="number">3</span>  <span class="number">4</span>  <span class="number">5</span>  <span class="number">4</span>  <span class="number">5</span></span><br><span class="line">y  <span class="number">4</span>  <span class="number">5</span>  <span class="number">6</span>  <span class="number">5</span>  <span class="number">4</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#DO NOT MODIFY THIS CELL</span></span><br><span class="line"><span class="comment"># testing your implementation </span></span><br><span class="line">source =  <span class="string">&#x27;eer&#x27;</span></span><br><span class="line">target = <span class="string">&#x27;near&#x27;</span></span><br><span class="line">matrix, min_edits = min_edit_distance(source, target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;minimum edits: &quot;</span>,min_edits, <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">idx = <span class="built_in">list</span>(source)</span><br><span class="line">idx.insert(<span class="number">0</span>, <span class="string">&#x27;#&#x27;</span>)</span><br><span class="line">cols = <span class="built_in">list</span>(target)</span><br><span class="line">cols.insert(<span class="number">0</span>, <span class="string">&#x27;#&#x27;</span>)</span><br><span class="line">df = pd.DataFrame(matrix, index=idx, columns= cols)</span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure>

<pre><code>minimum edits:  3 

   #  n  e  a  r
#  0  1  2  3  4
e  1  2  1  2  3
e  2  3  2  3  4
r  3  4  3  4  3
</code></pre>
<p><strong>Expected Results</strong>  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">minimum edits:  <span class="number">3</span> </span><br><span class="line"></span><br><span class="line">   <span class="meta">#  n  e  a  r</span></span><br><span class="line">#  <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>  <span class="number">4</span></span><br><span class="line">e  <span class="number">1</span>  <span class="number">2</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span></span><br><span class="line">e  <span class="number">2</span>  <span class="number">3</span>  <span class="number">2</span>  <span class="number">3</span>  <span class="number">4</span></span><br><span class="line">r  <span class="number">3</span>  <span class="number">4</span>  <span class="number">3</span>  <span class="number">4</span>  <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>We can now test several of our routines at once:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">source = <span class="string">&quot;eer&quot;</span></span><br><span class="line">targets = edit_one_letter(source,allow_switches = <span class="literal">False</span>)  <span class="comment">#disable switches since min_edit_distance does not include them</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> targets:</span><br><span class="line">    _, min_edits = min_edit_distance(source, t,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)  <span class="comment"># set ins, del, sub costs all to one</span></span><br><span class="line">    <span class="keyword">if</span> min_edits != <span class="number">1</span>: <span class="built_in">print</span>(source, t, min_edits)</span><br></pre></td></tr></table></figure>

<p><strong>Expected Results:</strong>  (empty)</p>
<p>The ‘replace()’ routine utilizes all letters a-z one of which returns the original word.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">source = <span class="string">&quot;eer&quot;</span></span><br><span class="line">targets = edit_two_letters(source,allow_switches = <span class="literal">False</span>) <span class="comment">#disable switches since min_edit_distance does not include them</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> targets:</span><br><span class="line">    _, min_edits = min_edit_distance(source, t,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)  <span class="comment"># set ins, del, sub costs all to one</span></span><br><span class="line">    <span class="keyword">if</span> min_edits != <span class="number">2</span> <span class="keyword">and</span> min_edits != <span class="number">1</span>: <span class="built_in">print</span>(source, t, min_edits)</span><br></pre></td></tr></table></figure>

<pre><code>eer eer 0
</code></pre>
<p><strong>Expected Results:</strong>  eer eer 0<br>We have to allow single edits here because some two_edits will restore a single edit.</p>
<h1 id="Submission"><a href="#Submission" class="headerlink" title="Submission"></a>Submission</h1><p>Make sure you submit your assignment before you modify anything below</p>
<p><a name='5'></a></p>
<h1 id="Part-5-Optional-Backtrace"><a href="#Part-5-Optional-Backtrace" class="headerlink" title="Part 5: Optional - Backtrace"></a>Part 5: Optional - Backtrace</h1><p>Once you have computed your matrix using minimum edit distance, how would find the shortest path from the top left corner to the bottom right corner? </p>
<p>Note that you could use backtrace algorithm.  Try to find the shortest path given the matrix that your <code>min_edit_distance</code> function returned.</p>
<p>You can use these <a target="_blank" rel="noopener" href="https://web.stanford.edu/class/cs124/lec/med.pdf">lecture slides on minimum edit distance</a> by Dan Jurafsky to learn about the algorithm for backtrace.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Experiment with back trace - insert your code here</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="References"><a href="#References" class="headerlink" title="References"></a>References</h4><ul>
<li>Dan Jurafsky - Speech and Language Processing - Textbook</li>
<li>This auto-correct explanation was first done by Peter Norvig in 2007 </li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Parts-of-Speech-Tagging/2020/07/19/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Parts-of-Speech-Tagging/2020/07/19/" class="post-title-link" itemprop="url">Parts-of-Speech Tagging</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-07-19 01:39:21 / Modified: 01:50:42" itemprop="dateCreated datePublished" datetime="2020-07-19T01:39:21+08:00">2020-07-19</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Parts-of-Speech-Tagging/2020/07/19/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Parts-of-Speech-Tagging/2020/07/19/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Assignment-2-Parts-of-Speech-Tagging-POS"><a href="#Assignment-2-Parts-of-Speech-Tagging-POS" class="headerlink" title="Assignment 2: Parts-of-Speech Tagging (POS)"></a>Assignment 2: Parts-of-Speech Tagging (POS)</h1><p>Welcome to the second assignment of Course 2 in the Natural Language Processing specialization. This assignment will develop skills in part-of-speech (POS) tagging, the process of assigning a part-of-speech tag (Noun, Verb, Adjective…) to each word in an input text.  Tagging is difficult because some words can represent more than one part of speech at different times. They are  <strong>Ambiguous</strong>. Let’s look at the following example: </p>
<ul>
<li>The whole team played <strong>well</strong>. [adverb]</li>
<li>You are doing <strong>well</strong> for yourself. [adjective]</li>
<li><strong>Well</strong>, this assignment took me forever to complete. [interjection]</li>
<li>The <strong>well</strong> is dry. [noun]</li>
<li>Tears were beginning to <strong>well</strong> in her eyes. [verb]</li>
</ul>
<p>Distinguishing the parts-of-speech of a word in a sentence will help you better understand the meaning of a sentence. This would be critically important in search queries. Identifying the proper noun, the organization, the stock symbol, or anything similar would greatly improve everything ranging from speech recognition to search. By completing this assignment, you will: </p>
<ul>
<li>Learn how parts-of-speech tagging works</li>
<li>Compute the transition matrix A in a Hidden Markov Model</li>
<li>Compute the transition matrix B in a Hidden Markov Model</li>
<li>Compute the Viterbi algorithm </li>
<li>Compute the accuracy of your own model </li>
</ul>
<h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li><a href="#0">0 Data Sources</a></li>
<li><a href="#1">1 POS Tagging</a><ul>
<li><a href="#1.1">1.1 Training</a><ul>
<li><a href="#ex-01">Exercise 01</a></li>
</ul>
</li>
<li><a href="#1.2">1.2 Testing</a><ul>
<li><a href="#ex-02">Exercise 02</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#2">2 Hidden Markov Models</a><ul>
<li><a href="#2.1">2.1 Generating Matrices</a><ul>
<li><a href="#ex-03">Exercise 03</a></li>
<li><a href="#ex-04">Exercise 04</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#3">3 Viterbi Algorithm</a><ul>
<li><a href="#3.1">3.1 Initialization</a><ul>
<li><a href="#ex-05">Exercise 05</a></li>
</ul>
</li>
<li><a href="#3.2">3.2 Viterbi Forward</a><ul>
<li><a href="#ex-06">Exercise 06</a></li>
</ul>
</li>
<li><a href="#3.3">3.3 Viterbi Backward</a><ul>
<li><a href="#ex-07">Exercise 07</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#4">4 Predicting on a data set</a><ul>
<li><a href="#ex-08">Exercise 08</a></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing packages and loading in the data set </span></span><br><span class="line"><span class="keyword">from</span> utils_pos <span class="keyword">import</span> get_word_tag, preprocess  </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>

<p><a name='0'></a></p>
<h2 id="Part-0-Data-Sources"><a href="#Part-0-Data-Sources" class="headerlink" title="Part 0: Data Sources"></a>Part 0: Data Sources</h2><p>This assignment will use two tagged data sets collected from the <strong>Wall Street Journal (WSJ)</strong>. </p>
<p><a target="_blank" rel="noopener" href="http://relearn.be/2015/training-common-sense/sources/software/pattern-2.6-critical-fork/docs/html/mbsp-tags.html">Here</a> is an example ‘tag-set’ or Part of Speech designation describing the two or three letter tag and their meaning. </p>
<ul>
<li>One data set (<strong>WSJ-2_21.pos</strong>) will be used for <strong>training</strong>.</li>
<li>The other (<strong>WSJ-24.pos</strong>) for <strong>testing</strong>. </li>
<li>The tagged training data has been preprocessed to form a vocabulary (<strong>hmm_vocab.txt</strong>). </li>
<li>The words in the vocabulary are words from the training set that were used two or more times. </li>
<li>The vocabulary is augmented with a set of ‘unknown word tokens’, described below. </li>
</ul>
<p>The training set will be used to create the emission, transmission and tag counts. </p>
<p>The test set (WSJ-24.pos) is read in to create <code>y</code>. </p>
<ul>
<li>This contains both the test text and the true tag. </li>
<li>The test set has also been preprocessed to remove the tags to form <strong>test_words.txt</strong>. </li>
<li>This is read in and further processed to identify the end of sentences and handle words not in the vocabulary using functions provided in <strong>utils_pos.py</strong>. </li>
<li>This forms the list <code>prep</code>, the preprocessed text used to test our  POS taggers.</li>
</ul>
<p>A POS tagger will necessarily encounter words that are not in its datasets. </p>
<ul>
<li>To improve accuracy, these words are further analyzed during preprocessing to extract available hints as to their appropriate tag. </li>
<li>For example, the suffix ‘ize’ is a hint that the word is a verb, as in ‘final-ize’ or ‘character-ize’. </li>
<li>A set of unknown-tokens, such as ‘–unk-verb–’ or ‘–unk-noun–’ will replace the unknown words in both the training and test corpus and will appear in the emission, transmission and tag data structures.</li>
</ul>
<img src = "DataSources1.png" />

<p>Implementation note: </p>
<ul>
<li>For python 3.6 and beyond, dictionaries retain the insertion order. </li>
<li>Furthermore, their hash-based lookup makes them suitable for rapid membership tests. <ul>
<li>If <em>di</em> is a dictionary, <code>key in di</code> will return <code>True</code> if <em>di</em> has a key <em>key</em>, else <code>False</code>. </li>
</ul>
</li>
</ul>
<p>The dictionary <code>vocab</code> will utilize these features.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load in the training corpus</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;WSJ_02-21.pos&quot;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    training_corpus = f.readlines()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;A few items of the training corpus list&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(training_corpus[<span class="number">0</span>:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<pre><code>A few items of the training corpus list
[&#39;In\tIN\n&#39;, &#39;an\tDT\n&#39;, &#39;Oct.\tNNP\n&#39;, &#39;19\tCD\n&#39;, &#39;review\tNN\n&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># read the vocabulary data, split by each line of text, and save the list</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;hmm_vocab.txt&quot;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    voc_l = f.read().split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;A few items of the vocabulary list&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(voc_l[<span class="number">0</span>:<span class="number">50</span>])</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;A few items at the end of the vocabulary list&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(voc_l[-<span class="number">50</span>:])</span><br></pre></td></tr></table></figure>

<pre><code>A few items of the vocabulary list
[&#39;!&#39;, &#39;#&#39;, &#39;$&#39;, &#39;%&#39;, &#39;&amp;&#39;, &quot;&#39;&quot;, &quot;&#39;&#39;&quot;, &quot;&#39;40s&quot;, &quot;&#39;60s&quot;, &quot;&#39;70s&quot;, &quot;&#39;80s&quot;, &quot;&#39;86&quot;, &quot;&#39;90s&quot;, &quot;&#39;N&quot;, &quot;&#39;S&quot;, &quot;&#39;d&quot;, &quot;&#39;em&quot;, &quot;&#39;ll&quot;, &quot;&#39;m&quot;, &quot;&#39;n&#39;&quot;, &quot;&#39;re&quot;, &quot;&#39;s&quot;, &quot;&#39;til&quot;, &quot;&#39;ve&quot;, &#39;(&#39;, &#39;)&#39;, &#39;,&#39;, &#39;-&#39;, &#39;--&#39;, &#39;--n--&#39;, &#39;--unk--&#39;, &#39;--unk_adj--&#39;, &#39;--unk_adv--&#39;, &#39;--unk_digit--&#39;, &#39;--unk_noun--&#39;, &#39;--unk_punct--&#39;, &#39;--unk_upper--&#39;, &#39;--unk_verb--&#39;, &#39;.&#39;, &#39;...&#39;, &#39;0.01&#39;, &#39;0.0108&#39;, &#39;0.02&#39;, &#39;0.03&#39;, &#39;0.05&#39;, &#39;0.1&#39;, &#39;0.10&#39;, &#39;0.12&#39;, &#39;0.13&#39;, &#39;0.15&#39;]

A few items at the end of the vocabulary list
[&#39;yards&#39;, &#39;yardstick&#39;, &#39;year&#39;, &#39;year-ago&#39;, &#39;year-before&#39;, &#39;year-earlier&#39;, &#39;year-end&#39;, &#39;year-on-year&#39;, &#39;year-round&#39;, &#39;year-to-date&#39;, &#39;year-to-year&#39;, &#39;yearlong&#39;, &#39;yearly&#39;, &#39;years&#39;, &#39;yeast&#39;, &#39;yelled&#39;, &#39;yelling&#39;, &#39;yellow&#39;, &#39;yen&#39;, &#39;yes&#39;, &#39;yesterday&#39;, &#39;yet&#39;, &#39;yield&#39;, &#39;yielded&#39;, &#39;yielding&#39;, &#39;yields&#39;, &#39;you&#39;, &#39;young&#39;, &#39;younger&#39;, &#39;youngest&#39;, &#39;youngsters&#39;, &#39;your&#39;, &#39;yourself&#39;, &#39;youth&#39;, &#39;youthful&#39;, &#39;yuppie&#39;, &#39;yuppies&#39;, &#39;zero&#39;, &#39;zero-coupon&#39;, &#39;zeroing&#39;, &#39;zeros&#39;, &#39;zinc&#39;, &#39;zip&#39;, &#39;zombie&#39;, &#39;zone&#39;, &#39;zones&#39;, &#39;zoning&#39;, &#39;&#123;&#39;, &#39;&#125;&#39;, &#39;&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vocab: dictionary that has the index of the corresponding words</span></span><br><span class="line">vocab = &#123;&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the index of the corresponding words. </span></span><br><span class="line"><span class="keyword">for</span> i, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">sorted</span>(voc_l)): </span><br><span class="line">    vocab[word] = i       </span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Vocabulary dictionary, key is the word, value is a unique integer&quot;</span>)</span><br><span class="line">cnt = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> vocab.items():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;k&#125;</span>:<span class="subst">&#123;v&#125;</span>&quot;</span>)</span><br><span class="line">    cnt += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> cnt &gt; <span class="number">20</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<pre><code>Vocabulary dictionary, key is the word, value is a unique integer
:0
!:1
#:2
$:3
%:4
&amp;:5
&#39;:6
&#39;&#39;:7
&#39;40s:8
&#39;60s:9
&#39;70s:10
&#39;80s:11
&#39;86:12
&#39;90s:13
&#39;N:14
&#39;S:15
&#39;d:16
&#39;em:17
&#39;ll:18
&#39;m:19
&#39;n&#39;:20
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load in the test corpus</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;WSJ_24.pos&quot;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    y = f.readlines()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;A sample of the test corpus&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(y[<span class="number">0</span>:<span class="number">10</span>])</span><br></pre></td></tr></table></figure>

<pre><code>A sample of the test corpus
[&#39;The\tDT\n&#39;, &#39;economy\tNN\n&#39;, &quot;&#39;s\tPOS\n&quot;, &#39;temperature\tNN\n&#39;, &#39;will\tMD\n&#39;, &#39;be\tVB\n&#39;, &#39;taken\tVBN\n&#39;, &#39;from\tIN\n&#39;, &#39;several\tJJ\n&#39;, &#39;vantage\tNN\n&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#corpus without tags, preprocessed</span></span><br><span class="line">_, prep = preprocess(vocab, <span class="string">&quot;test.words&quot;</span>)     </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The length of the preprocessed test corpus: &#x27;</span>, <span class="built_in">len</span>(prep))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;This is a sample of the test_corpus: &#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(prep[<span class="number">0</span>:<span class="number">10</span>])</span><br></pre></td></tr></table></figure>

<pre><code>The length of the preprocessed test corpus:  34199
This is a sample of the test_corpus: 
[&#39;The&#39;, &#39;economy&#39;, &quot;&#39;s&quot;, &#39;temperature&#39;, &#39;will&#39;, &#39;be&#39;, &#39;taken&#39;, &#39;from&#39;, &#39;several&#39;, &#39;--unk--&#39;]
</code></pre>
<p><a name='1'></a></p>
<h1 id="Part-1-Parts-of-speech-tagging"><a href="#Part-1-Parts-of-speech-tagging" class="headerlink" title="Part 1: Parts-of-speech tagging"></a>Part 1: Parts-of-speech tagging</h1><p><a name='1.1'></a></p>
<h2 id="Part-1-1-Training"><a href="#Part-1-1-Training" class="headerlink" title="Part 1.1 - Training"></a>Part 1.1 - Training</h2><p>You will start with the simplest possible parts-of-speech tagger and we will build up to the state of the art. </p>
<p>In this section, you will find the words that are not ambiguous. </p>
<ul>
<li>For example, the word <code>is</code> is a verb and it is not ambiguous. </li>
<li>In the <code>WSJ</code> corpus, $86$% of the token are unambiguous (meaning they have only one tag) </li>
<li>About $14%$ are ambiguous (meaning that they have more than one tag)</li>
</ul>
<img src = "pos.png" style="width:400px;height:250px;"/>

<p>Before you start predicting the tags of each word, you will need to compute a few dictionaries that will help you to generate the tables. </p>
<h4 id="Transition-counts"><a href="#Transition-counts" class="headerlink" title="Transition counts"></a>Transition counts</h4><ul>
<li>The first dictionary is the <code>transition_counts</code> dictionary which computes the number of times each tag happened next to another tag. </li>
</ul>
<p>This dictionary will be used to compute:<br>$$P(t_i |t_{i-1}) \tag{1}$$</p>
<p>This is the probability of a tag at position $i$ given the tag at position $i-1$.</p>
<p>In order for you to compute equation 1, you will create a <code>transition_counts</code> dictionary where </p>
<ul>
<li>The keys are <code>(prev_tag, tag)</code></li>
<li>The values are the number of times those two tags appeared in that order. </li>
</ul>
<h4 id="Emission-counts"><a href="#Emission-counts" class="headerlink" title="Emission counts"></a>Emission counts</h4><p>The second dictionary you will compute is the <code>emission_counts</code> dictionary. This dictionary will be used to compute:</p>
<p>$$P(w_i|t_i)\tag{2}$$</p>
<p>In other words, you will use it to compute the probability of a word given its tag. </p>
<p>In order for you to compute equation 2, you will create an <code>emission_counts</code> dictionary where </p>
<ul>
<li>The keys are <code>(tag, word)</code> </li>
<li>The values are the number of times that pair showed up in your training set. </li>
</ul>
<h4 id="Tag-counts"><a href="#Tag-counts" class="headerlink" title="Tag counts"></a>Tag counts</h4><p>The last dictionary you will compute is the <code>tag_counts</code> dictionary. </p>
<ul>
<li>The key is the tag </li>
<li>The value is the number of times each tag appeared.</li>
</ul>
<p><a name='ex-01'></a></p>
<h3 id="Exercise-01"><a href="#Exercise-01" class="headerlink" title="Exercise 01"></a>Exercise 01</h3><p><strong>Instructions:</strong> Write a program that takes in the <code>training_corpus</code> and returns the three dictionaries mentioned above <code>transition_counts</code>, <code>emission_counts</code>, and <code>tag_counts</code>. </p>
<ul>
<li><code>emission_counts</code>: maps (tag, word) to the number of times it happened. </li>
<li><code>transition_counts</code>: maps (prev_tag, tag) to the number of times it has appeared. </li>
<li><code>tag_counts</code>: maps (tag) to the number of times it has occured. </li>
</ul>
<p>Implementation note: This routine utilises <em>defaultdict</em>, which is a subclass of <em>dict</em>. </p>
<ul>
<li>A standard Python dictionary throws a <em>KeyError</em> if you try to access an item with a key that is not currently in the dictionary. </li>
<li>In contrast, the <em>defaultdict</em> will create an item of the type of the argument, in this case an integer with the default value of 0. </li>
<li>See <a target="_blank" rel="noopener" href="https://docs.python.org/3.3/library/collections.html#defaultdict-objects">defaultdict</a>.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: create_dictionaries</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dictionaries</span>(<span class="params">training_corpus, vocab</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Input: </span></span><br><span class="line"><span class="string">        training_corpus: a corpus where each line has a word followed by its tag.</span></span><br><span class="line"><span class="string">        vocab: a dictionary where keys are words in vocabulary and value is an index</span></span><br><span class="line"><span class="string">    Output: </span></span><br><span class="line"><span class="string">        emission_counts: a dictionary where the keys are (tag, word) and the values are the counts</span></span><br><span class="line"><span class="string">        transition_counts: a dictionary where the keys are (prev_tag, tag) and the values are the counts</span></span><br><span class="line"><span class="string">        tag_counts: a dictionary where the keys are the tags and the values are the counts</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize the dictionaries using defaultdict</span></span><br><span class="line">    emission_counts = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    transition_counts = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    tag_counts = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize &quot;prev_tag&quot; (previous tag) with the start state, denoted by &#x27;--s--&#x27;</span></span><br><span class="line">    prev_tag = <span class="string">&#x27;--s--&#x27;</span> </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># use &#x27;i&#x27; to track the line number in the corpus</span></span><br><span class="line">    i = <span class="number">0</span> </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Each item in the training corpus contains a word and its POS tag</span></span><br><span class="line">    <span class="comment"># Go through each word and its tag in the training corpus</span></span><br><span class="line">    <span class="keyword">for</span> word_tag <span class="keyword">in</span> training_corpus:</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Increment the word_tag count</span></span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Every 50,000 words, print the word count</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">50000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;word count = <span class="subst">&#123;i&#125;</span>&quot;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="comment">### START CODE HERE (Replace instances of &#x27;None&#x27; with your code) ###</span></span><br><span class="line">        <span class="comment"># get the word and tag using the get_word_tag helper function (imported from utils_pos.py)</span></span><br><span class="line">        word, tag = get_word_tag(word_tag,vocab)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Increment the transition count for the previous word and tag</span></span><br><span class="line">        transition_counts[(prev_tag, tag)] += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Increment the emission count for the tag and word</span></span><br><span class="line">        emission_counts[(tag, word)] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Increment the tag count</span></span><br><span class="line">        tag_counts[tag] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Set the previous tag to this tag (for the next iteration of the loop)</span></span><br><span class="line">        prev_tag = tag</span><br><span class="line">        </span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> emission_counts, transition_counts, tag_counts</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">emission_counts, transition_counts, tag_counts = create_dictionaries(training_corpus, vocab)</span><br></pre></td></tr></table></figure>

<pre><code>word count = 50000
word count = 100000
word count = 150000
word count = 200000
word count = 250000
word count = 300000
word count = 350000
word count = 400000
word count = 450000
word count = 500000
word count = 550000
word count = 600000
word count = 650000
word count = 700000
word count = 750000
word count = 800000
word count = 850000
word count = 900000
word count = 950000
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get all the POS states</span></span><br><span class="line">states = <span class="built_in">sorted</span>(tag_counts.keys())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of POS tags (number of &#x27;states&#x27;): <span class="subst">&#123;<span class="built_in">len</span>(states)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;View these POS tags (states)&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(states)</span><br></pre></td></tr></table></figure>

<pre><code>Number of POS tags (number of &#39;states&#39;): 46
View these POS tags (states)
[&#39;#&#39;, &#39;$&#39;, &quot;&#39;&#39;&quot;, &#39;(&#39;, &#39;)&#39;, &#39;,&#39;, &#39;--s--&#39;, &#39;.&#39;, &#39;:&#39;, &#39;CC&#39;, &#39;CD&#39;, &#39;DT&#39;, &#39;EX&#39;, &#39;FW&#39;, &#39;IN&#39;, &#39;JJ&#39;, &#39;JJR&#39;, &#39;JJS&#39;, &#39;LS&#39;, &#39;MD&#39;, &#39;NN&#39;, &#39;NNP&#39;, &#39;NNPS&#39;, &#39;NNS&#39;, &#39;PDT&#39;, &#39;POS&#39;, &#39;PRP&#39;, &#39;PRP$&#39;, &#39;RB&#39;, &#39;RBR&#39;, &#39;RBS&#39;, &#39;RP&#39;, &#39;SYM&#39;, &#39;TO&#39;, &#39;UH&#39;, &#39;VB&#39;, &#39;VBD&#39;, &#39;VBG&#39;, &#39;VBN&#39;, &#39;VBP&#39;, &#39;VBZ&#39;, &#39;WDT&#39;, &#39;WP&#39;, &#39;WP$&#39;, &#39;WRB&#39;, &#39;``&#39;]
</code></pre>
<h5 id="Expected-Output"><a href="#Expected-Output" class="headerlink" title="Expected Output"></a>Expected Output</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Number of POS <span class="title">tags</span> <span class="params">(number of <span class="string">&#x27;states&#x27;</span><span class="number">46</span></span></span></span><br><span class="line"><span class="params"><span class="function">View these states</span></span></span><br><span class="line"><span class="params"><span class="function">[<span class="string">&#x27;#&#x27;</span>, <span class="string">&#x27;$&#x27;</span>, <span class="string">&quot;&#x27;&#x27;&quot;</span>, <span class="string">&#x27;(&#x27;</span>, <span class="string">&#x27;)&#x27;</span>, <span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;--s--&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;:&#x27;</span>, <span class="string">&#x27;CC&#x27;</span>, <span class="string">&#x27;CD&#x27;</span>, <span class="string">&#x27;DT&#x27;</span>, <span class="string">&#x27;EX&#x27;</span>, <span class="string">&#x27;FW&#x27;</span>, <span class="string">&#x27;IN&#x27;</span>, <span class="string">&#x27;JJ&#x27;</span>, <span class="string">&#x27;JJR&#x27;</span>, <span class="string">&#x27;JJS&#x27;</span>, <span class="string">&#x27;LS&#x27;</span>, <span class="string">&#x27;MD&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>, <span class="string">&#x27;NNP&#x27;</span>, <span class="string">&#x27;NNPS&#x27;</span>, <span class="string">&#x27;NNS&#x27;</span>, <span class="string">&#x27;PDT&#x27;</span>, <span class="string">&#x27;POS&#x27;</span>, <span class="string">&#x27;PRP&#x27;</span>, <span class="string">&#x27;PRP$&#x27;</span>, <span class="string">&#x27;RB&#x27;</span>, <span class="string">&#x27;RBR&#x27;</span>, <span class="string">&#x27;RBS&#x27;</span>, <span class="string">&#x27;RP&#x27;</span>, <span class="string">&#x27;SYM&#x27;</span>, <span class="string">&#x27;TO&#x27;</span>, <span class="string">&#x27;UH&#x27;</span>, <span class="string">&#x27;VB&#x27;</span>, <span class="string">&#x27;VBD&#x27;</span>, <span class="string">&#x27;VBG&#x27;</span>, <span class="string">&#x27;VBN&#x27;</span>, <span class="string">&#x27;VBP&#x27;</span>, <span class="string">&#x27;VBZ&#x27;</span>, <span class="string">&#x27;WDT&#x27;</span>, <span class="string">&#x27;WP&#x27;</span>, <span class="string">&#x27;WP$&#x27;</span>, <span class="string">&#x27;WRB&#x27;</span>, <span class="string">&#x27;``&#x27;</span>]</span></span></span><br></pre></td></tr></table></figure>

<p>The ‘states’ are the Parts-of-speech designations found in the training data. They will also be referred to as ‘tags’ or POS in this assignment. </p>
<ul>
<li>“NN” is noun, singular, </li>
<li>‘NNS’ is noun, plural. </li>
<li>In addition, there are helpful tags like ‘–s–’ which indicate a start of a sentence.</li>
<li>You can get a more complete description at <a target="_blank" rel="noopener" href="https://www.clips.uantwerpen.be/pages/mbsp-tags">Penn Treebank II tag set</a>. </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;transition examples: &quot;</span>)</span><br><span class="line"><span class="keyword">for</span> ex <span class="keyword">in</span> <span class="built_in">list</span>(transition_counts.items())[:<span class="number">3</span>]:</span><br><span class="line">    <span class="built_in">print</span>(ex)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;emission examples: &quot;</span>)</span><br><span class="line"><span class="keyword">for</span> ex <span class="keyword">in</span> <span class="built_in">list</span>(emission_counts.items())[<span class="number">200</span>:<span class="number">203</span>]:</span><br><span class="line">    <span class="built_in">print</span> (ex)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;ambiguous word example: &quot;</span>)</span><br><span class="line"><span class="keyword">for</span> tup,cnt <span class="keyword">in</span> emission_counts.items():</span><br><span class="line">    <span class="keyword">if</span> tup[<span class="number">1</span>] == <span class="string">&#x27;back&#x27;</span>: <span class="built_in">print</span> (tup, cnt) </span><br></pre></td></tr></table></figure>

<pre><code>transition examples: 
((&#39;--s--&#39;, &#39;IN&#39;), 5050)
((&#39;IN&#39;, &#39;DT&#39;), 32364)
((&#39;DT&#39;, &#39;NNP&#39;), 9044)

emission examples: 
((&#39;DT&#39;, &#39;any&#39;), 721)
((&#39;NN&#39;, &#39;decrease&#39;), 7)
((&#39;NN&#39;, &#39;insider-trading&#39;), 5)

ambiguous word example: 
(&#39;RB&#39;, &#39;back&#39;) 304
(&#39;VB&#39;, &#39;back&#39;) 20
(&#39;RP&#39;, &#39;back&#39;) 84
(&#39;JJ&#39;, &#39;back&#39;) 25
(&#39;NN&#39;, &#39;back&#39;) 29
(&#39;VBP&#39;, &#39;back&#39;) 4
</code></pre>
<h5 id="Expected-Output-1"><a href="#Expected-Output-1" class="headerlink" title="Expected Output"></a>Expected Output</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">transition examples: </span><br><span class="line">((<span class="string">&#x27;--s--&#x27;</span>, <span class="string">&#x27;IN&#x27;</span>), <span class="number">5050</span>)</span><br><span class="line">((<span class="string">&#x27;IN&#x27;</span>, <span class="string">&#x27;DT&#x27;</span>), <span class="number">32364</span>)</span><br><span class="line">((<span class="string">&#x27;DT&#x27;</span>, <span class="string">&#x27;NNP&#x27;</span>), <span class="number">9044</span>)</span><br><span class="line"></span><br><span class="line">emission examples: </span><br><span class="line">((<span class="string">&#x27;DT&#x27;</span>, <span class="string">&#x27;any&#x27;</span>), <span class="number">721</span>)</span><br><span class="line">((<span class="string">&#x27;NN&#x27;</span>, <span class="string">&#x27;decrease&#x27;</span>), <span class="number">7</span>)</span><br><span class="line">((<span class="string">&#x27;NN&#x27;</span>, <span class="string">&#x27;insider-trading&#x27;</span>), <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">ambiguous word example: </span><br><span class="line">(<span class="string">&#x27;RB&#x27;</span>, <span class="string">&#x27;back&#x27;</span>) <span class="number">304</span></span><br><span class="line">(<span class="string">&#x27;VB&#x27;</span>, <span class="string">&#x27;back&#x27;</span>) <span class="number">20</span></span><br><span class="line">(<span class="string">&#x27;RP&#x27;</span>, <span class="string">&#x27;back&#x27;</span>) <span class="number">84</span></span><br><span class="line">(<span class="string">&#x27;JJ&#x27;</span>, <span class="string">&#x27;back&#x27;</span>) <span class="number">25</span></span><br><span class="line">(<span class="string">&#x27;NN&#x27;</span>, <span class="string">&#x27;back&#x27;</span>) <span class="number">29</span></span><br><span class="line">(<span class="string">&#x27;VBP&#x27;</span>, <span class="string">&#x27;back&#x27;</span>) <span class="number">4</span></span><br></pre></td></tr></table></figure>

<p><a name='1.2'></a></p>
<h3 id="Part-1-2-Testing"><a href="#Part-1-2-Testing" class="headerlink" title="Part 1.2 - Testing"></a>Part 1.2 - Testing</h3><p>Now you will test the accuracy of your parts-of-speech tagger using your <code>emission_counts</code> dictionary. </p>
<ul>
<li>Given your preprocessed test corpus <code>prep</code>, you will assign a parts-of-speech tag to every word in that corpus. </li>
<li>Using the original tagged test corpus <code>y</code>, you will then compute what percent of the tags you got correct. </li>
</ul>
<p><a name='ex-02'></a></p>
<h3 id="Exercise-02"><a href="#Exercise-02" class="headerlink" title="Exercise 02"></a>Exercise 02</h3><p><strong>Instructions:</strong> Implement <code>predict_pos</code> that computes the accuracy of your model. </p>
<ul>
<li>This is a warm up exercise. </li>
<li>To assign a part of speech to a word, assign the most frequent POS for that word in the training set. </li>
<li>Then evaluate how well this approach works.  Each time you predict based on the most frequent POS for the given word, check whether the actual POS of that word is the same.  If so, the prediction was correct!</li>
<li>Calculate the accuracy as the number of correct predictions divided by the total number of words for which you predicted the POS tag.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: predict_pos</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_pos</span>(<span class="params">prep, y, emission_counts, vocab, states</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Input: </span></span><br><span class="line"><span class="string">        prep: a preprocessed version of &#x27;y&#x27;. A list with the &#x27;word&#x27; component of the tuples.</span></span><br><span class="line"><span class="string">        y: a corpus composed of a list of tuples where each tuple consists of (word, POS)</span></span><br><span class="line"><span class="string">        emission_counts: a dictionary where the keys are (tag,word) tuples and the value is the count</span></span><br><span class="line"><span class="string">        vocab: a dictionary where keys are words in vocabulary and value is an index</span></span><br><span class="line"><span class="string">        states: a sorted list of all possible tags for this assignment</span></span><br><span class="line"><span class="string">    Output: </span></span><br><span class="line"><span class="string">        accuracy: Number of times you classified a word correctly</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize the number of correct predictions to zero</span></span><br><span class="line">    num_correct = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Get the (tag, word) tuples, stored as a set</span></span><br><span class="line">    all_words = <span class="built_in">set</span>(emission_counts.keys())  <span class="comment"># (tag, word)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Get the number of (word, POS) tuples in the corpus &#x27;y&#x27;</span></span><br><span class="line">    total = <span class="built_in">len</span>(y)</span><br><span class="line">    <span class="keyword">for</span> word, y_tup <span class="keyword">in</span> <span class="built_in">zip</span>(prep, y): </span><br><span class="line"></span><br><span class="line">        <span class="comment"># Split the (word, POS) string into a list of two items</span></span><br><span class="line">        y_tup_l = y_tup.split()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Verify that y_tup contain both word and POS</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(y_tup_l) == <span class="number">2</span>:</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Set the true POS label for this word</span></span><br><span class="line">            true_label = y_tup_l[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># If the y_tup didn&#x27;t contain word and POS, go to next word</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line">        count_final = <span class="number">0</span></span><br><span class="line">        pos_final = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># If the word is in the vocabulary...</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocab:</span><br><span class="line">            <span class="keyword">for</span> pos <span class="keyword">in</span> states:</span><br><span class="line"></span><br><span class="line">            <span class="comment">### START CODE HERE (Replace instances of &#x27;None&#x27; with your code) ###</span></span><br><span class="line">                        </span><br><span class="line">                <span class="comment"># define the key as the tuple containing the POS and word</span></span><br><span class="line">                key = (pos, word)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># check if the (pos, word) key exists in the emission_counts dictionary</span></span><br><span class="line">                <span class="keyword">if</span> key <span class="keyword">in</span> emission_counts: <span class="comment"># complete this line</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># get the emission count of the (pos,word) tuple </span></span><br><span class="line">                    count = emission_counts[key]</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># keep track of the POS with the largest count</span></span><br><span class="line">                    <span class="keyword">if</span> count &gt; count_final: <span class="comment"># complete this line</span></span><br><span class="line"></span><br><span class="line">                        <span class="comment"># update the final count (largest count)</span></span><br><span class="line">                        count_final = count</span><br><span class="line"></span><br><span class="line">                        <span class="comment"># update the final POS</span></span><br><span class="line">                        pos_final = pos</span><br><span class="line"></span><br><span class="line">            <span class="comment"># If the final POS (with the largest count) matches the true POS:</span></span><br><span class="line">            <span class="keyword">if</span> pos_final == true_label: <span class="comment"># complete this line</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Update the number of correct predictions</span></span><br><span class="line">                num_correct += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    accuracy = num_correct / total</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> accuracy</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">accuracy_predict_pos = predict_pos(prep, y, emission_counts, vocab, states)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy of prediction using predict_pos is <span class="subst">&#123;accuracy_predict_pos:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Accuracy of prediction using predict_pos is 0.8889
</code></pre>
<h5 id="Expected-Output-2"><a href="#Expected-Output-2" class="headerlink" title="Expected Output"></a>Expected Output</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy of prediction <span class="keyword">using</span> predict_pos is <span class="number">0.8889</span></span><br></pre></td></tr></table></figure>

<p>88.9% is really good for this warm up exercise. With hidden markov models, you should be able to get <strong>95% accuracy.</strong></p>
<p><a name='2'></a></p>
<h1 id="Part-2-Hidden-Markov-Models-for-POS"><a href="#Part-2-Hidden-Markov-Models-for-POS" class="headerlink" title="Part 2: Hidden Markov Models for POS"></a>Part 2: Hidden Markov Models for POS</h1><p>Now you will build something more context specific. Concretely, you will be implementing a Hidden Markov Model (HMM) with a Viterbi decoder</p>
<ul>
<li>The HMM is one of the most commonly used algorithms in Natural Language Processing, and is a foundation to many deep learning techniques you will see in this specialization. </li>
<li>In addition to parts-of-speech tagging, HMM is used in speech recognition, speech synthesis, etc. </li>
<li>By completing this part of the assignment you will get a 95% accuracy on the same dataset you used in Part 1.</li>
</ul>
<p>The Markov Model contains a number of states and the probability of transition between those states. </p>
<ul>
<li>In this case, the states are the parts-of-speech. </li>
<li>A Markov Model utilizes a transition matrix, <code>A</code>. </li>
<li>A Hidden Markov Model adds an observation or emission matrix <code>B</code> which describes the probability of a visible observation when we are in a particular state. </li>
<li>In this case, the emissions are the words in the corpus</li>
<li>The state, which is hidden, is the POS tag of that word.</li>
</ul>
<p><a name='2.1'></a></p>
<h2 id="Part-2-1-Generating-Matrices"><a href="#Part-2-1-Generating-Matrices" class="headerlink" title="Part 2.1 Generating Matrices"></a>Part 2.1 Generating Matrices</h2><h3 id="Creating-the-‘A’-transition-probabilities-matrix"><a href="#Creating-the-‘A’-transition-probabilities-matrix" class="headerlink" title="Creating the ‘A’ transition probabilities matrix"></a>Creating the ‘A’ transition probabilities matrix</h3><p>Now that you have your <code>emission_counts</code>, <code>transition_counts</code>, and <code>tag_counts</code>, you will start implementing the Hidden Markov Model. </p>
<p>This will allow you to quickly construct the </p>
<ul>
<li><code>A</code> transition probabilities matrix.</li>
<li>and the <code>B</code> emission probabilities matrix. </li>
</ul>
<p>You will also use some smoothing when computing these matrices. </p>
<p>Here is an example of what the <code>A</code> transition matrix would look like (it is simplified to 5 tags for viewing. It is 46x46 in this assignment.):</p>
<table>
<thead>
<tr>
<th><strong>A</strong></th>
<th>…</th>
<th>RBS</th>
<th>RP</th>
<th>SYM</th>
<th>TO</th>
<th>UH</th>
<th>…</th>
</tr>
</thead>
<tbody><tr>
<td><strong>RBS</strong></td>
<td>…</td>
<td>2.217069e-06</td>
<td>2.217069e-06</td>
<td>2.217069e-06</td>
<td>0.008870</td>
<td>2.217069e-06</td>
<td>…</td>
</tr>
<tr>
<td><strong>RP</strong></td>
<td>…</td>
<td>3.756509e-07</td>
<td>7.516775e-04</td>
<td>3.756509e-07</td>
<td>0.051089</td>
<td>3.756509e-07</td>
<td>…</td>
</tr>
<tr>
<td><strong>SYM</strong></td>
<td>…</td>
<td>1.722772e-05</td>
<td>1.722772e-05</td>
<td>1.722772e-05</td>
<td>0.000017</td>
<td>1.722772e-05</td>
<td>…</td>
</tr>
<tr>
<td><strong>TO</strong></td>
<td>…</td>
<td>4.477336e-05</td>
<td>4.472863e-08</td>
<td>4.472863e-08</td>
<td>0.000090</td>
<td>4.477336e-05</td>
<td>…</td>
</tr>
<tr>
<td><strong>UH</strong></td>
<td>…</td>
<td>1.030439e-05</td>
<td>1.030439e-05</td>
<td>1.030439e-05</td>
<td>0.061837</td>
<td>3.092348e-02</td>
<td>…</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody></table>
<p>Note that the matrix above was computed with smoothing. </p>
<p>Each cell gives you the probability to go from one part of speech to another. </p>
<ul>
<li>In other words, there is a 4.47e-8 chance of going from parts-of-speech <code>TO</code> to <code>RP</code>. </li>
<li>The sum of each row has to equal 1, because we assume that the next POS tag must be one of the available columns in the table.</li>
</ul>
<p>The smoothing was done as follows: </p>
<p>$$ P(t_i | t_{i-1}) = \frac{C(t_{i-1}, t_{i}) + \alpha }{C(t_{i-1}) +\alpha * N}\tag{3}$$</p>
<ul>
<li>$N$ is the total number of tags</li>
<li>$C(t_{i-1}, t_{i})$ is the count of the tuple (previous POS, current POS) in <code>transition_counts</code> dictionary.</li>
<li>$C(t_{i-1})$ is the count of the previous POS in the <code>tag_counts</code> dictionary.</li>
<li>$\alpha$ is a smoothing parameter.</li>
</ul>
<p><a name='ex-03'></a></p>
<h3 id="Exercise-03"><a href="#Exercise-03" class="headerlink" title="Exercise 03"></a>Exercise 03</h3><p><strong>Instructions:</strong> Implement the <code>create_transition_matrix</code> below for all tags. Your task is to output a matrix that computes equation 3 for each cell in matrix <code>A</code>. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: create_transition_matrix</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_transition_matrix</span>(<span class="params">alpha, tag_counts, transition_counts</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; </span></span><br><span class="line"><span class="string">    Input: </span></span><br><span class="line"><span class="string">        alpha: number used for smoothing</span></span><br><span class="line"><span class="string">        tag_counts: a dictionary mapping each tag to its respective count</span></span><br><span class="line"><span class="string">        transition_counts: transition count for the previous word and tag</span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">        A: matrix of dimension (num_tags,num_tags)</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># Get a sorted list of unique POS tags</span></span><br><span class="line">    all_tags = <span class="built_in">sorted</span>(tag_counts.keys())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Count the number of unique POS tags</span></span><br><span class="line">    num_tags = <span class="built_in">len</span>(all_tags)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize the transition matrix &#x27;A&#x27;</span></span><br><span class="line">    A = np.zeros((num_tags,num_tags))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Get the unique transition tuples (previous POS, current POS)</span></span><br><span class="line">    trans_keys = <span class="built_in">set</span>(transition_counts.keys())</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (Return instances of &#x27;None&#x27; with your code) ### </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Go through each row of the transition matrix A</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_tags):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Go through each column of the transition matrix A</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_tags):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Initialize the count of the (prev POS, current POS) to zero</span></span><br><span class="line">            count = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">            <span class="comment"># Define the tuple (prev POS, current POS)</span></span><br><span class="line">            <span class="comment"># Get the tag at position i and tag at position j (from the all_tags list)</span></span><br><span class="line">            key = (all_tags[i],all_tags[j])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Check if the (prev POS, current POS) tuple </span></span><br><span class="line">            <span class="comment"># exists in the transition counts dictionaory</span></span><br><span class="line">            <span class="keyword">if</span> key <span class="keyword">in</span> trans_keys: <span class="comment">#complete this line</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Get count from the transition_counts dictionary </span></span><br><span class="line">                <span class="comment"># for the (prev POS, current POS) tuple</span></span><br><span class="line">                count = transition_counts[key]</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># Get the count of the previous tag (index position i) from tag_counts</span></span><br><span class="line">            count_prev_tag = tag_counts[all_tags[i]]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Apply smoothing using count of the tuple, alpha, </span></span><br><span class="line">            <span class="comment"># count of previous tag, alpha, and number of total tags</span></span><br><span class="line">            A[i,j] = (count + alpha ) / ( count_prev_tag + alpha * num_tags)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> A</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.001</span></span><br><span class="line">A = create_transition_matrix(alpha, tag_counts, transition_counts)</span><br><span class="line"><span class="comment"># Testing your function</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;A at row 0, col 0: <span class="subst">&#123;A[<span class="number">0</span>,<span class="number">0</span>]:<span class="number">.9</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;A at row 3, col 1: <span class="subst">&#123;A[<span class="number">3</span>,<span class="number">1</span>]:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;View a subset of transition matrix A&quot;</span>)</span><br><span class="line">A_sub = pd.DataFrame(A[<span class="number">30</span>:<span class="number">35</span>,<span class="number">30</span>:<span class="number">35</span>], index=states[<span class="number">30</span>:<span class="number">35</span>], columns = states[<span class="number">30</span>:<span class="number">35</span>] )</span><br><span class="line"><span class="built_in">print</span>(A_sub)</span><br></pre></td></tr></table></figure>

<pre><code>A at row 0, col 0: 0.000007040
A at row 3, col 1: 0.1691
View a subset of transition matrix A
              RBS            RP           SYM        TO            UH
RBS  2.217069e-06  2.217069e-06  2.217069e-06  0.008870  2.217069e-06
RP   3.756509e-07  7.516775e-04  3.756509e-07  0.051089  3.756509e-07
SYM  1.722772e-05  1.722772e-05  1.722772e-05  0.000017  1.722772e-05
TO   4.477336e-05  4.472863e-08  4.472863e-08  0.000090  4.477336e-05
UH   1.030439e-05  1.030439e-05  1.030439e-05  0.061837  3.092348e-02
</code></pre>
<h5 id="Expected-Output-3"><a href="#Expected-Output-3" class="headerlink" title="Expected Output"></a>Expected Output</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">A at row <span class="number">0</span>, col <span class="number">0</span>: <span class="number">0.000007040</span></span><br><span class="line">A at row <span class="number">3</span>, col <span class="number">1</span>: <span class="number">0.1691</span></span><br><span class="line">View a subset of transition matrix A</span><br><span class="line">              RBS            RP           SYM        TO            UH</span><br><span class="line">RBS  <span class="number">2.217069e-06</span>  <span class="number">2.217069e-06</span>  <span class="number">2.217069e-06</span>  <span class="number">0.008870</span>  <span class="number">2.217069e-06</span></span><br><span class="line">RP   <span class="number">3.756509e-07</span>  <span class="number">7.516775e-04</span>  <span class="number">3.756509e-07</span>  <span class="number">0.051089</span>  <span class="number">3.756509e-07</span></span><br><span class="line">SYM  <span class="number">1.722772e-05</span>  <span class="number">1.722772e-05</span>  <span class="number">1.722772e-05</span>  <span class="number">0.000017</span>  <span class="number">1.722772e-05</span></span><br><span class="line">TO   <span class="number">4.477336e-05</span>  <span class="number">4.472863e-08</span>  <span class="number">4.472863e-08</span>  <span class="number">0.000090</span>  <span class="number">4.477336e-05</span></span><br><span class="line">UH   <span class="number">1.030439e-05</span>  <span class="number">1.030439e-05</span>  <span class="number">1.030439e-05</span>  <span class="number">0.061837</span>  <span class="number">3.092348e-02</span></span><br></pre></td></tr></table></figure>

<h3 id="Create-the-‘B’-emission-probabilities-matrix"><a href="#Create-the-‘B’-emission-probabilities-matrix" class="headerlink" title="Create the ‘B’ emission probabilities matrix"></a>Create the ‘B’ emission probabilities matrix</h3><p>Now you will create the <code>B</code> transition matrix which computes the emission probability. </p>
<p>You will use smoothing as defined below: </p>
<p>$$P(w_i | t_i) = \frac{C(t_i, word_i)+ \alpha}{C(t_{i}) +\alpha * N}\tag{4}$$</p>
<ul>
<li>$C(t_i, word_i)$ is the number of times $word_i$ was associated with $tag_i$ in the training data (stored in <code>emission_counts</code> dictionary).</li>
<li>$C(t_i)$ is the number of times $tag_i$ was in the training data (stored in <code>tag_counts</code> dictionary).</li>
<li>$N$ is the number of words in the vocabulary</li>
<li>$\alpha$ is a smoothing parameter. </li>
</ul>
<p>The matrix <code>B</code> is of dimension (num_tags, N), where num_tags is the number of possible parts-of-speech tags. </p>
<p>Here is an example of the matrix, only a subset of tags and words are shown: </p>
<p style='text-align: center;'> <b>B Emissions Probability Matrix (subset)</b>  </p>

<table>
<thead>
<tr>
<th><strong>B</strong></th>
<th>…</th>
<th>725</th>
<th>adroitly</th>
<th>engineers</th>
<th>promoted</th>
<th>synergy</th>
<th>…</th>
</tr>
</thead>
<tbody><tr>
<td><strong>CD</strong></td>
<td>…</td>
<td><strong>8.201296e-05</strong></td>
<td>2.732854e-08</td>
<td>2.732854e-08</td>
<td>2.732854e-08</td>
<td>2.732854e-08</td>
<td>…</td>
</tr>
<tr>
<td><strong>NN</strong></td>
<td>…</td>
<td>7.521128e-09</td>
<td>7.521128e-09</td>
<td>7.521128e-09</td>
<td>7.521128e-09</td>
<td><strong>2.257091e-05</strong></td>
<td>…</td>
</tr>
<tr>
<td><strong>NNS</strong></td>
<td>…</td>
<td>1.670013e-08</td>
<td>1.670013e-08</td>
<td><strong>4.676203e-04</strong></td>
<td>1.670013e-08</td>
<td>1.670013e-08</td>
<td>…</td>
</tr>
<tr>
<td><strong>VB</strong></td>
<td>…</td>
<td>3.779036e-08</td>
<td>3.779036e-08</td>
<td>3.779036e-08</td>
<td>3.779036e-08</td>
<td>3.779036e-08</td>
<td>…</td>
</tr>
<tr>
<td><strong>RB</strong></td>
<td>…</td>
<td>3.226454e-08</td>
<td><strong>6.456135e-05</strong></td>
<td>3.226454e-08</td>
<td>3.226454e-08</td>
<td>3.226454e-08</td>
<td>…</td>
</tr>
<tr>
<td><strong>RP</strong></td>
<td>…</td>
<td>3.723317e-07</td>
<td>3.723317e-07</td>
<td>3.723317e-07</td>
<td><strong>3.723317e-07</strong></td>
<td>3.723317e-07</td>
<td>…</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody></table>
<p><a name='ex-04'></a></p>
<h3 id="Exercise-04"><a href="#Exercise-04" class="headerlink" title="Exercise 04"></a>Exercise 04</h3><p><strong>Instructions:</strong> Implement the <code>create_emission_matrix</code> below that computes the <code>B</code> emission probabilities matrix. Your function takes in $\alpha$, the smoothing parameter, <code>tag_counts</code>, which is a dictionary mapping each tag to its respective count, the <code>emission_counts</code> dictionary where the keys are (tag, word) and the values are the counts. Your task is to output a matrix that computes equation 4 for each cell in matrix <code>B</code>. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: create_emission_matrix</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_emission_matrix</span>(<span class="params">alpha, tag_counts, emission_counts, vocab</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Input: </span></span><br><span class="line"><span class="string">        alpha: tuning parameter used in smoothing </span></span><br><span class="line"><span class="string">        tag_counts: a dictionary mapping each tag to its respective count</span></span><br><span class="line"><span class="string">        emission_counts: a dictionary where the keys are (tag, word) and the values are the counts</span></span><br><span class="line"><span class="string">        vocab: a dictionary where keys are words in vocabulary and value is an index</span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">        B: a matrix of dimension (num_tags, len(vocab))</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># get the number of POS tag</span></span><br><span class="line">    num_tags = <span class="built_in">len</span>(tag_counts)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Get a list of all POS tags</span></span><br><span class="line">    all_tags = <span class="built_in">sorted</span>(tag_counts.keys())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Get the total number of unique words in the vocabulary</span></span><br><span class="line">    num_words = <span class="built_in">len</span>(vocab)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize the emission matrix B with places for</span></span><br><span class="line">    <span class="comment"># tags in the rows and words in the columns</span></span><br><span class="line">    B = np.zeros((num_tags, num_words))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Get a set of all (POS, word) tuples </span></span><br><span class="line">    <span class="comment"># from the keys of the emission_counts dictionary</span></span><br><span class="line">    emis_keys = <span class="built_in">set</span>(<span class="built_in">list</span>(emission_counts.keys()))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (Replace instances of &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Go through each row (POS tags)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_tags): <span class="comment"># complete this line</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Go through each column (words)</span></span><br><span class="line">        <span class="keyword">for</span> j,word <span class="keyword">in</span> <span class="built_in">enumerate</span>(vocab): <span class="comment"># complete this line</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Initialize the emission count for the (POS tag, word) to zero</span></span><br><span class="line">            count = <span class="number">0</span></span><br><span class="line">                    </span><br><span class="line">            <span class="comment"># Define the (POS tag, word) tuple for this row and column</span></span><br><span class="line">            key =  (all_tags[i], word)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># check if the (POS tag, word) tuple exists as a key in emission counts</span></span><br><span class="line">            <span class="keyword">if</span> key <span class="keyword">in</span> emis_keys: <span class="comment"># complete this line</span></span><br><span class="line">        </span><br><span class="line">                <span class="comment"># Get the count of (POS tag, word) from the emission_counts d</span></span><br><span class="line">                count = emission_counts[key]</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># Get the count of the POS tag</span></span><br><span class="line">            count_tag = tag_counts[all_tags[i]]</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># Apply smoothing and store the smoothed value </span></span><br><span class="line">            <span class="comment"># into the emission matrix B for this row and column</span></span><br><span class="line">            B[i,j] = (count + alpha) / (count_tag + alpha * num_words)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> B</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># creating your emission probability matrix. this takes a few minutes to run. </span></span><br><span class="line">B = create_emission_matrix(alpha, tag_counts, emission_counts, <span class="built_in">list</span>(vocab))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;View Matrix position at row 0, column 0: <span class="subst">&#123;B[<span class="number">0</span>,<span class="number">0</span>]:<span class="number">.9</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;View Matrix position at row 3, column 1: <span class="subst">&#123;B[<span class="number">3</span>,<span class="number">1</span>]:<span class="number">.9</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Try viewing emissions for a few words in a sample dataframe</span></span><br><span class="line">cidx  = [<span class="string">&#x27;725&#x27;</span>,<span class="string">&#x27;adroitly&#x27;</span>,<span class="string">&#x27;engineers&#x27;</span>, <span class="string">&#x27;promoted&#x27;</span>, <span class="string">&#x27;synergy&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the integer ID for each word</span></span><br><span class="line">cols = [vocab[a] <span class="keyword">for</span> a <span class="keyword">in</span> cidx]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Choose POS tags to show in a sample dataframe</span></span><br><span class="line">rvals =[<span class="string">&#x27;CD&#x27;</span>,<span class="string">&#x27;NN&#x27;</span>,<span class="string">&#x27;NNS&#x27;</span>, <span class="string">&#x27;VB&#x27;</span>,<span class="string">&#x27;RB&#x27;</span>,<span class="string">&#x27;RP&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># For each POS tag, get the row number from the &#x27;states&#x27; list</span></span><br><span class="line">rows = [states.index(a) <span class="keyword">for</span> a <span class="keyword">in</span> rvals]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the emissions for the sample of words, and the sample of POS tags</span></span><br><span class="line">B_sub = pd.DataFrame(B[np.ix_(rows,cols)], index=rvals, columns = cidx )</span><br><span class="line"><span class="built_in">print</span>(B_sub)</span><br></pre></td></tr></table></figure>

<pre><code>View Matrix position at row 0, column 0: 0.000006032
View Matrix position at row 3, column 1: 0.000000720
              725      adroitly     engineers      promoted       synergy
CD   8.201296e-05  2.732854e-08  2.732854e-08  2.732854e-08  2.732854e-08
NN   7.521128e-09  7.521128e-09  7.521128e-09  7.521128e-09  2.257091e-05
NNS  1.670013e-08  1.670013e-08  4.676203e-04  1.670013e-08  1.670013e-08
VB   3.779036e-08  3.779036e-08  3.779036e-08  3.779036e-08  3.779036e-08
RB   3.226454e-08  6.456135e-05  3.226454e-08  3.226454e-08  3.226454e-08
RP   3.723317e-07  3.723317e-07  3.723317e-07  3.723317e-07  3.723317e-07
</code></pre>
<h5 id="Expected-Output-4"><a href="#Expected-Output-4" class="headerlink" title="Expected Output"></a>Expected Output</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">View Matrix position at row <span class="number">0</span>, column <span class="number">0</span>: <span class="number">0.000006032</span></span><br><span class="line">View Matrix position at row <span class="number">3</span>, column <span class="number">1</span>: <span class="number">0.000000720</span></span><br><span class="line">              <span class="number">725</span>      adroitly     engineers      promoted       synergy</span><br><span class="line">CD   <span class="number">8.201296e-05</span>  <span class="number">2.732854e-08</span>  <span class="number">2.732854e-08</span>  <span class="number">2.732854e-08</span>  <span class="number">2.732854e-08</span></span><br><span class="line">NN   <span class="number">7.521128e-09</span>  <span class="number">7.521128e-09</span>  <span class="number">7.521128e-09</span>  <span class="number">7.521128e-09</span>  <span class="number">2.257091e-05</span></span><br><span class="line">NNS  <span class="number">1.670013e-08</span>  <span class="number">1.670013e-08</span>  <span class="number">4.676203e-04</span>  <span class="number">1.670013e-08</span>  <span class="number">1.670013e-08</span></span><br><span class="line">VB   <span class="number">3.779036e-08</span>  <span class="number">3.779036e-08</span>  <span class="number">3.779036e-08</span>  <span class="number">3.779036e-08</span>  <span class="number">3.779036e-08</span></span><br><span class="line">RB   <span class="number">3.226454e-08</span>  <span class="number">6.456135e-05</span>  <span class="number">3.226454e-08</span>  <span class="number">3.226454e-08</span>  <span class="number">3.226454e-08</span></span><br><span class="line">RP   <span class="number">3.723317e-07</span>  <span class="number">3.723317e-07</span>  <span class="number">3.723317e-07</span>  <span class="number">3.723317e-07</span>  <span class="number">3.723317e-07</span></span><br></pre></td></tr></table></figure>

<p><a name='3'></a></p>
<h1 id="Part-3-Viterbi-Algorithm-and-Dynamic-Programming"><a href="#Part-3-Viterbi-Algorithm-and-Dynamic-Programming" class="headerlink" title="Part 3: Viterbi Algorithm and Dynamic Programming"></a>Part 3: Viterbi Algorithm and Dynamic Programming</h1><p>In this part of the assignment you will implement the Viterbi algorithm which makes use of dynamic programming. Specifically, you will use your two matrices, <code>A</code> and <code>B</code> to compute the Viterbi algorithm. We have decomposed this process into three main steps for you. </p>
<ul>
<li><strong>Initialization</strong> - In this part you initialize the <code>best_paths</code> and <code>best_probabilities</code> matrices that you will be populating in <code>feed_forward</code>.</li>
<li><strong>Feed forward</strong> - At each step, you calculate the probability of each path happening and the best paths up to that point. </li>
<li><strong>Feed backward</strong>: This allows you to find the best path with the highest probabilities. </li>
</ul>
<p><a name='3.1'></a></p>
<h2 id="Part-3-1-Initialization"><a href="#Part-3-1-Initialization" class="headerlink" title="Part 3.1:  Initialization"></a>Part 3.1:  Initialization</h2><p>You will start by initializing two matrices of the same dimension. </p>
<ul>
<li><p>best_probs: Each cell contains the probability of going from one POS tag to a word in the corpus.</p>
</li>
<li><p>best_paths: A matrix that helps you trace through the best possible path in the corpus. </p>
</li>
</ul>
<p><a name='ex-05'></a></p>
<h3 id="Exercise-05"><a href="#Exercise-05" class="headerlink" title="Exercise 05"></a>Exercise 05</h3><p><strong>Instructions</strong>:<br>Write a program below that initializes the <code>best_probs</code> and the <code>best_paths</code> matrix. </p>
<p>Both matrices will be initialized to zero except for column zero of <code>best_probs</code>.  </p>
<ul>
<li>Column zero of <code>best_probs</code> is initialized with the assumption that the first word of the corpus was preceded by a start token (“–s–”). </li>
<li>This allows you to reference the <strong>A</strong> matrix for the transition probability</li>
</ul>
<p>Here is how to initialize column 0 of <code>best_probs</code>:</p>
<ul>
<li>The probability of the best path going from the start index to a given POS tag indexed by integer $i$ is denoted by $\textrm{best_probs}[s_{idx}, i]$.</li>
<li>This is estimated as the probability that the start tag transitions to the POS denoted by index $i$: $\mathbf{A}[s_{idx}, i]$ AND that the POS tag denoted by $i$ emits the first word of the given corpus, which is $\mathbf{B}[i, vocab[corpus[0]]]$.</li>
<li>Note that vocab[corpus[0]] refers to the first word of the corpus (the word at position 0 of the corpus). </li>
<li><strong>vocab</strong> is a dictionary that returns the unique integer that refers to that particular word.</li>
</ul>
<p>Conceptually, it looks like this:<br>$\textrm{best_probs}[s_{idx}, i] = \mathbf{A}[s_{idx}, i] \times \mathbf{B}[i, corpus[0] ]$</p>
<p>In order to avoid multiplying and storing small values on the computer, we’ll take the log of the product, which becomes the sum of two logs:</p>
<p>$best_probs[i,0] = log(A[s_{idx}, i]) + log(B[i, vocab[corpus[0]]$</p>
<p>Also, to avoid taking the log of 0 (which is defined as negative infinity), the code itself will just set $best_probs[i,0] = float(‘-inf’)$ when $A[s_{idx}, i] == 0$</p>
<p>So the implementation to initialize $best_probs$ looks like this:</p>
<p>$ if A[s_{idx}, i] &lt;&gt; 0 : best_probs[i,0] = log(A[s_{idx}, i]) + log(B[i, vocab[corpus[0]]])$</p>
<p>$ if A[s_{idx}, i] == 0 : best_probs[i,0] = float(‘-inf’)$</p>
<p>Please use <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/math.html">math.log</a> to compute the natural logarithm.</p>
<p>The example below shows the initialization assuming the corpus starts with the phrase “Loss tracks upward”.</p>
<img src = "Initialize4.png"/>

<p>Represent infinity and negative infinity like this:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in"><span class="keyword">float</span></span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line"><span class="built_in"><span class="keyword">float</span></span>(<span class="string">&#x27;-inf&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: initialize</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize</span>(<span class="params">states, tag_counts, A, B, corpus, vocab</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Input: </span></span><br><span class="line"><span class="string">        states: a list of all possible parts-of-speech</span></span><br><span class="line"><span class="string">        tag_counts: a dictionary mapping each tag to its respective count</span></span><br><span class="line"><span class="string">        A: Transition Matrix of dimension (num_tags, num_tags)</span></span><br><span class="line"><span class="string">        B: Emission Matrix of dimension (num_tags, len(vocab))</span></span><br><span class="line"><span class="string">        corpus: a sequence of words whose POS is to be identified in a list </span></span><br><span class="line"><span class="string">        vocab: a dictionary where keys are words in vocabulary and value is an index</span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">        best_probs: matrix of dimension (num_tags, len(corpus)) of floats</span></span><br><span class="line"><span class="string">        best_paths: matrix of dimension (num_tags, len(corpus)) of integers</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># Get the total number of unique POS tags</span></span><br><span class="line">    num_tags = <span class="built_in">len</span>(tag_counts)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize best_probs matrix </span></span><br><span class="line">    <span class="comment"># POS tags in the rows, number of words in the corpus as the columns</span></span><br><span class="line">    best_probs = np.zeros((num_tags, <span class="built_in">len</span>(corpus)))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize best_paths matrix</span></span><br><span class="line">    <span class="comment"># POS tags in the rows, number of words in the corpus as columns</span></span><br><span class="line">    best_paths = np.zeros((num_tags, <span class="built_in">len</span>(corpus)), dtype=<span class="built_in">int</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define the start token</span></span><br><span class="line">    s_idx = states.index(<span class="string">&quot;--s--&quot;</span>)</span><br><span class="line">    <span class="comment">### START CODE HERE (Replace instances of &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Go through each of the POS tags</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_tags) : <span class="comment"># complete this line</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Handle the special case when the transition from start token to POS tag i is zero</span></span><br><span class="line">        <span class="keyword">if</span> A[<span class="number">0</span>,i] == <span class="number">0</span>: <span class="comment"># complete this line</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Initialize best_probs at POS tag &#x27;i&#x27;, column 0, to negative infinity</span></span><br><span class="line">            best_probs[i,<span class="number">0</span>] = <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># For all other cases when transition from start token to POS tag i is non-zero:</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Initialize best_probs at POS tag &#x27;i&#x27;, column 0</span></span><br><span class="line">            <span class="comment"># Check the formula in the instructions above</span></span><br><span class="line">            best_probs[i,<span class="number">0</span>] = math.log(A[s_idx,i])  +  math.log(B[i,vocab[corpus[<span class="number">0</span>]]])</span><br><span class="line">            </span><br><span class="line">                         </span><br><span class="line">    <span class="comment">### END CODE HERE ### </span></span><br><span class="line">    <span class="keyword">return</span> best_probs, best_paths</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_probs, best_paths = initialize(states, tag_counts, A, B, prep, vocab)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test the function</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;best_probs[0,0]: <span class="subst">&#123;best_probs[<span class="number">0</span>,<span class="number">0</span>]:<span class="number">.4</span>f&#125;</span>&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;best_paths[2,3]: <span class="subst">&#123;best_paths[<span class="number">2</span>,<span class="number">3</span>]:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>best_probs[0,0]: -22.6098
best_paths[2,3]: 0.0000
</code></pre>
<h5 id="Expected-Output-5"><a href="#Expected-Output-5" class="headerlink" title="Expected Output"></a>Expected Output</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">best_probs[<span class="number">0</span>,<span class="number">0</span>]: <span class="number">-22.6098</span></span><br><span class="line">best_paths[<span class="number">2</span>,<span class="number">3</span>]: <span class="number">0.0000</span></span><br></pre></td></tr></table></figure>


<p><a name='3.2'></a></p>
<h2 id="Part-3-2-Viterbi-Forward"><a href="#Part-3-2-Viterbi-Forward" class="headerlink" title="Part 3.2 Viterbi Forward"></a>Part 3.2 Viterbi Forward</h2><p>In this part of the assignment, you will implement the <code>viterbi_forward</code> segment. In other words, you will populate your <code>best_probs</code> and <code>best_paths</code> matrices.</p>
<ul>
<li>Walk forward through the corpus.</li>
<li>For each word, compute a probability for each possible tag. </li>
<li>Unlike the previous algorithm <code>predict_pos</code> (the ‘warm-up’ exercise), this will include the path up to that (word,tag) combination. </li>
</ul>
<p>Here is an example with a three-word corpus “Loss tracks upward”:</p>
<ul>
<li>Note, in this example, only a subset of states (POS tags) are shown in the diagram below, for easier reading. </li>
<li>In the diagram below, the first word “Loss” is already initialized. </li>
<li>The algorithm will compute a probability for each of the potential tags in the second and future words. </li>
</ul>
<p>Compute the probability that the tag of the second work (‘tracks’) is a verb, 3rd person singular present (VBZ).  </p>
<ul>
<li>In the <code>best_probs</code> matrix, go to the column of the second word (‘tracks’), and row 40 (VBZ), this cell is highlighted in light orange in the diagram below.</li>
<li>Examine each of the paths from the tags of the first word (‘Loss’) and choose the most likely path.  </li>
<li>An example of the calculation for <strong>one</strong> of those paths is the path from (‘Loss’, NN) to (‘tracks’, VBZ).</li>
<li>The log of the probability of the path up to and including the first word ‘Loss’ having POS tag NN is $-14.32$.  The <code>best_probs</code> matrix contains this value -14.32 in the column for ‘Loss’ and row for ‘NN’.</li>
<li>Find the probability that NN transitions to VBZ.  To find this probability, go to the <code>A</code> transition matrix, and go to the row for ‘NN’ and the column for ‘VBZ’.  The value is $4.37e-02$, which is circled in the diagram, so add $-14.32 + log(4.37e-02)$. </li>
<li>Find the log of the probability that the tag VBS would ‘emit’ the word ‘tracks’.  To find this, look at the ‘B’ emission matrix in row ‘VBZ’ and the column for the word ‘tracks’.  The value $4.61e-04$ is circled in the diagram below.  So add $-14.32 + log(4.37e-02) + log(4.61e-04)$.</li>
<li>The sum of $-14.32 + log(4.37e-02) + log(4.61e-04)$ is $-25.13$. Store $-25.13$ in the <code>best_probs</code> matrix at row ‘VBZ’ and column ‘tracks’ (as seen in the cell that is highlighted in light orange in the diagram).</li>
<li>All other paths in best_probs are calculated.  Notice that $-25.13$ is greater than all of the other values in column ‘tracks’ of matrix <code>best_probs</code>, and so the most likely path to ‘VBZ’ is from ‘NN’.  ‘NN’ is in row 20 of the <code>best_probs</code> matrix, so $20$ is the most likely path.</li>
<li>Store the most likely path $20$ in the <code>best_paths</code> table.  This is highlighted in light orange in the diagram below.</li>
</ul>
<p>The formula to compute the probability and path for the $i^{th}$ word in the $corpus$, the prior word $i-1$ in the corpus, current POS tag $j$, and previous POS tag $k$ is:</p>
<p>$\mathrm{prob} = \mathbf{best_prob}<em>{k, i-1} + \mathrm{log}(\mathbf{A}</em>{k, j}) + \mathrm{log}(\mathbf{B}<em>{j, vocab(corpus</em>{i})})$</p>
<p>where $corpus_{i}$ is the word in the corpus at index $i$, and $vocab$ is the dictionary that gets the unique integer that represents a given word.</p>
<p>$\mathrm{path} = k$</p>
<p>where $k$ is the integer representing the previous POS tag.</p>
<p><a name='ex-06'></a></p>
<h3 id="Exercise-06"><a href="#Exercise-06" class="headerlink" title="Exercise 06"></a>Exercise 06</h3><p>Instructions: Implement the <code>viterbi_forward</code> algorithm and store the best_path and best_prob for every possible tag for each word in the matrices <code>best_probs</code> and <code>best_tags</code> using the pseudo code below.</p>
<p>`for each word in the corpus</p>
<pre><code>for each POS tag type that this word may be

    for POS tag type that the previous word could be
    
        compute the probability that the previous word had a given POS tag, that the current word has a given POS tag, and that the POS tag would emit this current word.
        
        retain the highest probability computed for the current word
        
        set best_probs to this highest probability
        
        set best_paths to the index &#39;k&#39;, representing the POS tag of the previous word which produced the highest probability `
</code></pre>
<p>Please use <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/math.html">math.log</a> to compute the natural logarithm.</p>
<img src = "Forward4.png"/>

<h2 id=""><a href="#" class="headerlink" title=""></a><details></h2><summary>
    <font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
    <li>Remember that when accessing emission matrix B, the column index is the unique integer ID associated with the word.  It can be accessed by using the 'vocab' dictionary, where the key is the word, and the value is the unique integer ID for that word.</li>
</ul>
</p>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: viterbi_forward</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">viterbi_forward</span>(<span class="params">A, B, test_corpus, best_probs, best_paths, vocab</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Input: </span></span><br><span class="line"><span class="string">        A, B: The transiton and emission matrices respectively</span></span><br><span class="line"><span class="string">        test_corpus: a list containing a preprocessed corpus</span></span><br><span class="line"><span class="string">        best_probs: an initilized matrix of dimension (num_tags, len(corpus))</span></span><br><span class="line"><span class="string">        best_paths: an initilized matrix of dimension (num_tags, len(corpus))</span></span><br><span class="line"><span class="string">        vocab: a dictionary where keys are words in vocabulary and value is an index </span></span><br><span class="line"><span class="string">    Output: </span></span><br><span class="line"><span class="string">        best_probs: a completed matrix of dimension (num_tags, len(corpus))</span></span><br><span class="line"><span class="string">        best_paths: a completed matrix of dimension (num_tags, len(corpus))</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># Get the number of unique POS tags (which is the num of rows in best_probs)</span></span><br><span class="line">    num_tags = best_probs.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Go through every word in the corpus starting from word 1</span></span><br><span class="line">    <span class="comment"># Recall that word 0 was initialized in `initialize()`</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(test_corpus)): </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Print number of words processed, every 5000 words</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">5000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Words processed: &#123;:&gt;8&#125;&quot;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">            </span><br><span class="line">        <span class="comment">### START CODE HERE (Replace instances of &#x27;None&#x27; with your code EXCEPT the first &#x27;best_path_i = None&#x27;) ###</span></span><br><span class="line">        <span class="comment"># For each unique POS tag that the current word can be</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_tags): <span class="comment"># complete this line</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Initialize best_prob for word i to negative infinity</span></span><br><span class="line">            best_prob_i = <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Initialize best_path for current word i to None</span></span><br><span class="line">            best_path_i = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># For each POS tag that the previous word can be:</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(num_tags): <span class="comment"># complete this line</span></span><br><span class="line">            </span><br><span class="line">                <span class="comment"># Calculate the probability = </span></span><br><span class="line">                <span class="comment"># best probs of POS tag k, previous word i-1 + </span></span><br><span class="line">                <span class="comment"># log(prob of transition from POS k to POS j) + </span></span><br><span class="line">                <span class="comment"># log(prob that emission of POS j is word i)</span></span><br><span class="line">                prob = best_probs[k, i-<span class="number">1</span>] + math.log(A[k,j]) + math.log(B[j, vocab[test_corpus[i]]])</span><br><span class="line"></span><br><span class="line">                <span class="comment"># check if this path&#x27;s probability is greater than</span></span><br><span class="line">                <span class="comment"># the best probability up to and before this point</span></span><br><span class="line">                <span class="keyword">if</span> prob &gt; best_prob_i: <span class="comment"># complete this line</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Keep track of the best probability</span></span><br><span class="line">                    best_prob_i = prob</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># keep track of the POS tag of the previous word</span></span><br><span class="line">                    <span class="comment"># that is part of the best path.  </span></span><br><span class="line">                    <span class="comment"># Save the index (integer) associated with </span></span><br><span class="line">                    <span class="comment"># that previous word&#x27;s POS tag</span></span><br><span class="line">                    best_path_i = k</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Save the best probability for the </span></span><br><span class="line">            <span class="comment"># given current word&#x27;s POS tag</span></span><br><span class="line">            <span class="comment"># and the position of the current word inside the corpus</span></span><br><span class="line">            best_probs[j,i] = best_prob_i</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Save the unique integer ID of the previous POS tag</span></span><br><span class="line">            <span class="comment"># into best_paths matrix, for the POS tag of the current word</span></span><br><span class="line">            <span class="comment"># and the position of the current word inside the corpus.</span></span><br><span class="line">            best_paths[j,i] = best_path_i</span><br><span class="line"></span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> best_probs, best_paths</span><br></pre></td></tr></table></figure>

<p>Run the <code>viterbi_forward</code> function to fill in the <code>best_probs</code> and <code>best_paths</code> matrices.</p>
<p><strong>Note</strong> that this will take a few minutes to run.  There are about 30,000 words to process.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># this will take a few minutes to run =&gt; processes ~ 30,000 words</span></span><br><span class="line">best_probs, best_paths = viterbi_forward(A, B, prep, best_probs, best_paths, vocab)</span><br></pre></td></tr></table></figure>

<pre><code>Words processed:     5000
Words processed:    10000
Words processed:    15000
Words processed:    20000
Words processed:    25000
Words processed:    30000
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test this function </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;best_probs[0,1]: <span class="subst">&#123;best_probs[<span class="number">0</span>,<span class="number">1</span>]:<span class="number">.4</span>f&#125;</span>&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;best_probs[0,4]: <span class="subst">&#123;best_probs[<span class="number">0</span>,<span class="number">4</span>]:<span class="number">.4</span>f&#125;</span>&quot;</span>) </span><br></pre></td></tr></table></figure>

<pre><code>best_probs[0,1]: -24.7822
best_probs[0,4]: -49.5601
</code></pre>
<h5 id="Expected-Output-6"><a href="#Expected-Output-6" class="headerlink" title="Expected Output"></a>Expected Output</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">best_probs[<span class="number">0</span>,<span class="number">1</span>]: <span class="number">-24.7822</span></span><br><span class="line">best_probs[<span class="number">0</span>,<span class="number">4</span>]: <span class="number">-49.5601</span></span><br></pre></td></tr></table></figure>

<p><a name='3.3'></a></p>
<h2 id="Part-3-3-Viterbi-backward"><a href="#Part-3-3-Viterbi-backward" class="headerlink" title="Part 3.3 Viterbi backward"></a>Part 3.3 Viterbi backward</h2><p>Now you will implement the Viterbi backward algorithm.</p>
<ul>
<li>The Viterbi backward algorithm gets the predictions of the POS tags for each word in the corpus using the <code>best_paths</code> and the <code>best_probs</code> matrices.</li>
</ul>
<p>The example below shows how to walk backwards through the best_paths matrix to get the POS tags of each word in the corpus. Recall that this example corpus has three words: “Loss tracks upward”.</p>
<p>POS tag for ‘upward’ is <code>RB</code></p>
<ul>
<li>Select the the most likely POS tag for the last word in the corpus, ‘upward’ in the <code>best_prob</code> table.</li>
<li>Look for the row in the column for ‘upward’ that has the largest probability.</li>
<li>Notice that in row 28 of <code>best_probs</code>, the estimated probability is -34.99, which is larger than the other values in the column.  So the most likely POS tag for ‘upward’ is <code>RB</code> an adverb, at row 28 of <code>best_prob</code>. </li>
<li>The variable <code>z</code> is an array that stores the unique integer ID of the predicted POS tags for each word in the corpus.  In array z, at position 2, store the value 28 to indicate that the word ‘upward’ (at index 2 in the corpus), most likely has the POS tag associated with unique ID 28 (which is <code>RB</code>).</li>
<li>The variable <code>pred</code> contains the POS tags in string form.  So <code>pred</code> at index 2 stores the string <code>RB</code>.</li>
</ul>
<p>POS tag for ‘tracks’ is <code>VBZ</code></p>
<ul>
<li>The next step is to go backward one word in the corpus (‘tracks’).  Since the most likely POS tag for ‘upward’ is <code>RB</code>, which is uniquely identified by integer ID 28, go to the <code>best_paths</code> matrix in column 2, row 28.  The value stored in <code>best_paths</code>, column 2, row 28 indicates the unique ID of the POS tag of the previous word.  In this case, the value stored here is 40, which is the unique ID for POS tag <code>VBZ</code> (verb, 3rd person singular present).</li>
<li>So the previous word at index 1 of the corpus (‘tracks’), most likely has the POS tag with unique ID 40, which is <code>VBZ</code>.</li>
<li>In array <code>z</code>, store the value 40 at position 1, and for array <code>pred</code>, store the string <code>VBZ</code> to indicate that the word ‘tracks’ most likely has POS tag <code>VBZ</code>.</li>
</ul>
<p>POS tag for ‘Loss’ is <code>NN</code></p>
<ul>
<li>In <code>best_paths</code> at column 1, the unique ID stored at row 40 is 20.  20 is the unique ID for POS tag <code>NN</code>.</li>
<li>In array <code>z</code> at position 0, store 20.  In array <code>pred</code> at position 0, store <code>NN</code>.</li>
</ul>
<img src = "Backwards5.png"/>

<p><a name='ex-07'></a></p>
<h3 id="Exercise-07"><a href="#Exercise-07" class="headerlink" title="Exercise 07"></a>Exercise 07</h3><p>Implement the <code>viterbi_backward</code> algorithm, which returns a list of predicted POS tags for each word in the corpus.</p>
<ul>
<li>Note that the numbering of the index positions starts at 0 and not 1. </li>
<li><code>m</code> is the number of words in the corpus.  <ul>
<li>So the indexing into the corpus goes from <code>0</code> to <code>m - 1</code>.</li>
<li>Also, the columns in <code>best_probs</code> and <code>best_paths</code> are indexed from <code>0</code> to <code>m - 1</code></li>
</ul>
</li>
</ul>
<p><strong>In Step 1:</strong><br>Loop through all the rows (POS tags) in the last entry of <code>best_probs</code> and find the row (POS tag) with the maximum value.<br>Convert the unique integer ID to a tag (a string representation) using the dictionary <code>states</code>.  </p>
<p>Referring to the three-word corpus described above:</p>
<ul>
<li><code>z[2] = 28</code>: For the word ‘upward’ at position 2 in the corpus, the POS tag ID is 28.  Store 28 in <code>z</code> at position 2.</li>
<li>states(28) is ‘RB’: The POS tag ID 28 refers to the POS tag ‘RB’.</li>
<li><code>pred[2] = &#39;RB&#39;</code>: In array <code>pred</code>, store the POS tag for the word ‘upward’.</li>
</ul>
<p><strong>In Step 2:</strong>  </p>
<ul>
<li>Starting at the last column of best_paths, use <code>best_probs</code> to find the most likely POS tag for the last word in the corpus.</li>
<li>Then use <code>best_paths</code> to find the most likely POS tag for the previous word. </li>
<li>Update the POS tag for each word in <code>z</code> and in <code>preds</code>.</li>
</ul>
<p>Referring to the three-word example from above, read best_paths at column 2 and fill in z at position 1.<br><code>z[1] = best_paths[z[2],2]</code>  </p>
<p>The small test following the routine prints the last few words of the corpus and their states to aid in debug.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C7 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: viterbi_backward</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">viterbi_backward</span>(<span class="params">best_probs, best_paths, corpus, states</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    This function returns the best path.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># Get the number of words in the corpus</span></span><br><span class="line">    <span class="comment"># which is also the number of columns in best_probs, best_paths</span></span><br><span class="line">    m = best_paths.shape[<span class="number">1</span>] </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize array z, same length as the corpus</span></span><br><span class="line">    z = [<span class="literal">None</span>] * m</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Get the number of unique POS tags</span></span><br><span class="line">    num_tags = best_probs.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize the best probability for the last word</span></span><br><span class="line">    best_prob_for_last_word = <span class="built_in">float</span>(<span class="string">&#x27;-inf&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize pred array, same length as corpus</span></span><br><span class="line">    pred = [<span class="literal">None</span>] * m</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (Replace instances of &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    <span class="comment">## Step 1 ##</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Go through each POS tag for the last word (last column of best_probs)</span></span><br><span class="line">    <span class="comment"># in order to find the row (POS tag integer ID) </span></span><br><span class="line">    <span class="comment"># with highest probability for the last word</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(num_tags): <span class="comment"># complete this line</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># If the probability of POS tag at row k </span></span><br><span class="line">        <span class="comment"># is better than the previosly best probability for the last word:</span></span><br><span class="line">        <span class="keyword">if</span> best_probs[k,-<span class="number">1</span>] &gt; best_prob_for_last_word: <span class="comment"># complete this line</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Store the new best probability for the lsat word</span></span><br><span class="line">            best_prob_for_last_word = best_probs[k,-<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">            <span class="comment"># Store the unique integer ID of the POS tag</span></span><br><span class="line">            <span class="comment"># which is also the row number in best_probs</span></span><br><span class="line">            z[m - <span class="number">1</span>] = k</span><br><span class="line">            </span><br><span class="line">    <span class="comment"># Convert the last word&#x27;s predicted POS tag</span></span><br><span class="line">    <span class="comment"># from its unique integer ID into the string representation</span></span><br><span class="line">    <span class="comment"># using the &#x27;states&#x27; dictionary</span></span><br><span class="line">    <span class="comment"># store this in the &#x27;pred&#x27; array for the last word</span></span><br><span class="line">    pred[m - <span class="number">1</span>] = states[k]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## Step 2 ##</span></span><br><span class="line">    <span class="comment"># Find the best POS tags by walking backward through the best_paths</span></span><br><span class="line">    <span class="comment"># From the last word in the corpus to the 0th word in the corpus</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m-<span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>): <span class="comment"># complete this line</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Retrieve the unique integer ID of</span></span><br><span class="line">        <span class="comment"># the POS tag for the word at position &#x27;i&#x27; in the corpus</span></span><br><span class="line">        pos_tag_for_word_i = best_paths[z[i], i]</span><br><span class="line"><span class="comment">#         print(z[i])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># In best_paths, go to the row representing the POS tag of word i</span></span><br><span class="line">        <span class="comment"># and the column representing the word&#x27;s position in the corpus</span></span><br><span class="line">        <span class="comment"># to retrieve the predicted POS for the word at position i-1 in the corpus</span></span><br><span class="line">        z[i - <span class="number">1</span>] = pos_tag_for_word_i</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Get the previous word&#x27;s POS tag in string form</span></span><br><span class="line">        <span class="comment"># Use the &#x27;states&#x27; dictionary, </span></span><br><span class="line">        <span class="comment"># where the key is the unique integer ID of the POS tag,</span></span><br><span class="line">        <span class="comment"># and the value is the string representation of that POS tag</span></span><br><span class="line">        pred[i - <span class="number">1</span>] = states[pos_tag_for_word_i]        </span><br><span class="line">     <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> pred</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run and test your function</span></span><br><span class="line">pred = viterbi_backward(best_probs, best_paths, prep, states)</span><br><span class="line">m=<span class="built_in">len</span>(pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The prediction for pred[-7:m-1] is: \n&#x27;</span>, prep[-<span class="number">7</span>:m-<span class="number">1</span>], <span class="string">&quot;\n&quot;</span>, pred[-<span class="number">7</span>:m-<span class="number">1</span>], <span class="string">&quot;\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The prediction for pred[0:8] is: \n&#x27;</span>, pred[<span class="number">0</span>:<span class="number">7</span>], <span class="string">&quot;\n&quot;</span>, prep[<span class="number">0</span>:<span class="number">7</span>])</span><br></pre></td></tr></table></figure>

<pre><code>The prediction for pred[-7:m-1] is: 
 [&#39;see&#39;, &#39;them&#39;, &#39;here&#39;, &#39;with&#39;, &#39;us&#39;, &#39;.&#39;] 
 [&#39;VB&#39;, &#39;PRP&#39;, &#39;RB&#39;, &#39;IN&#39;, &#39;PRP&#39;, &#39;.&#39;] 

The prediction for pred[0:8] is: 
 [&#39;DT&#39;, &#39;NN&#39;, &#39;POS&#39;, &#39;NN&#39;, &#39;MD&#39;, &#39;VB&#39;, &#39;VBN&#39;] 
 [&#39;The&#39;, &#39;economy&#39;, &quot;&#39;s&quot;, &#39;temperature&#39;, &#39;will&#39;, &#39;be&#39;, &#39;taken&#39;]
</code></pre>
<p><strong>Expected Output:</strong>   </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">The prediction <span class="keyword">for</span> prep[<span class="number">-7</span>:m<span class="number">-1</span>] is:  </span><br><span class="line"> [<span class="string">&#x27;see&#x27;</span>, <span class="string">&#x27;them&#x27;</span>, <span class="string">&#x27;here&#x27;</span>, <span class="string">&#x27;with&#x27;</span>, <span class="string">&#x27;us&#x27;</span>, <span class="string">&#x27;.&#x27;</span>]  </span><br><span class="line"> [<span class="string">&#x27;VB&#x27;</span>, <span class="string">&#x27;PRP&#x27;</span>, <span class="string">&#x27;RB&#x27;</span>, <span class="string">&#x27;IN&#x27;</span>, <span class="string">&#x27;PRP&#x27;</span>, <span class="string">&#x27;.&#x27;</span>]   </span><br><span class="line">The prediction <span class="keyword">for</span> pred[<span class="number">0</span>:<span class="number">8</span>] is:    </span><br><span class="line"> [<span class="string">&#x27;DT&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>, <span class="string">&#x27;POS&#x27;</span>, <span class="string">&#x27;NN&#x27;</span>, <span class="string">&#x27;MD&#x27;</span>, <span class="string">&#x27;VB&#x27;</span>, <span class="string">&#x27;VBN&#x27;</span>]   </span><br><span class="line"> [<span class="string">&#x27;The&#x27;</span>, <span class="string">&#x27;economy&#x27;</span>, <span class="string">&quot;&#x27;s&quot;</span>, <span class="string">&#x27;temperature&#x27;</span>, <span class="string">&#x27;will&#x27;</span>, <span class="string">&#x27;be&#x27;</span>, <span class="string">&#x27;taken&#x27;</span>] </span><br></pre></td></tr></table></figure>

<p>Now you just have to compare the predicted labels to the true labels to evaluate your model on the accuracy metric!</p>
<p><a name='4'></a></p>
<h1 id="Part-4-Predicting-on-a-data-set"><a href="#Part-4-Predicting-on-a-data-set" class="headerlink" title="Part 4: Predicting on a data set"></a>Part 4: Predicting on a data set</h1><p>Compute the accuracy of your prediction by comparing it with the true <code>y</code> labels. </p>
<ul>
<li><code>pred</code> is a list of predicted POS tags corresponding to the words of the <code>test_corpus</code>. </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The third word is:&#x27;</span>, prep[<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Your prediction is:&#x27;</span>, pred[<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Your corresponding label y is: &#x27;</span>, y[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<pre><code>The third word is: temperature
Your prediction is: NN
Your corresponding label y is:  temperature NN
</code></pre>
<p><a name='ex-08'></a></p>
<h3 id="Exercise-08"><a href="#Exercise-08" class="headerlink" title="Exercise 08"></a>Exercise 08</h3><p>Implement a function to compute the accuracy of the viterbi algorithm’s POS tag predictions.</p>
<ul>
<li>To split y into the word and its tag you can use <code>y.split()</code>. </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C8 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># GRADED FUNCTION: compute_accuracy</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_accuracy</span>(<span class="params">pred, y</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Input: </span></span><br><span class="line"><span class="string">        pred: a list of the predicted parts-of-speech </span></span><br><span class="line"><span class="string">        y: a list of lines where each word is separated by a &#x27;\t&#x27; (i.e. word \t tag)</span></span><br><span class="line"><span class="string">    Output: </span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    num_correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Zip together the prediction and the labels</span></span><br><span class="line">    <span class="keyword">for</span> prediction, y <span class="keyword">in</span> <span class="built_in">zip</span>(pred, y):</span><br><span class="line">        <span class="comment">### START CODE HERE (Replace instances of &#x27;None&#x27; with your code) ###</span></span><br><span class="line">        <span class="comment"># Split the label into the word and the POS tag</span></span><br><span class="line">        word_tag_tuple = y.strip().split(<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Check that there is actually a word and a tag</span></span><br><span class="line">        <span class="comment"># no more and no less than 2 items</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(word_tag_tuple) &lt; <span class="number">2</span>: <span class="comment"># complete this line</span></span><br><span class="line">            <span class="keyword">continue</span> </span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line">        <span class="comment"># store the word and tag separately</span></span><br><span class="line">        word, tag = [item.strip() <span class="keyword">for</span> item <span class="keyword">in</span> word_tag_tuple]</span><br><span class="line">        </span><br><span class="line"><span class="comment">#         print(tag, prediction)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Check if the POS tag label matches the prediction</span></span><br><span class="line">        <span class="keyword">if</span> tag == prediction: <span class="comment"># complete this line</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># count the number of times that the prediction</span></span><br><span class="line">            <span class="comment"># and label match</span></span><br><span class="line">            num_correct += <span class="number">1.0</span></span><br><span class="line">            </span><br><span class="line">        <span class="comment"># keep track of the total number of examples (that have valid labels)</span></span><br><span class="line">        total += <span class="number">1.0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> num_correct/total</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy of the Viterbi algorithm is <span class="subst">&#123;compute_accuracy(pred, y):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Accuracy of the Viterbi algorithm is 0.9531
</code></pre>
<h5 id="Expected-Output-7"><a href="#Expected-Output-7" class="headerlink" title="Expected Output"></a>Expected Output</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy of the Viterbi algorithm is <span class="number">0.9531</span></span><br></pre></td></tr></table></figure>

<p>Congratulations you were able to classify the parts-of-speech with 95% accuracy. </p>
<h3 id="Key-Points-and-overview"><a href="#Key-Points-and-overview" class="headerlink" title="Key Points and overview"></a>Key Points and overview</h3><p>In this assignment you learned about parts-of-speech tagging. </p>
<ul>
<li>In this assignment, you predicted POS tags by walking forward through a corpus and knowing the previous word.</li>
<li>There are other implementations that use bidirectional POS tagging.</li>
<li>Bidirectional POS tagging requires knowing the previous word and the next word in the corpus when predicting the current word’s POS tag.</li>
<li>Bidirectional POS tagging would tell you more about the POS instead of just knowing the previous word. </li>
<li>Since you have learned to implement the unidirectional approach, you have the foundation to implement other POS taggers used in industry.</li>
</ul>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ul>
<li><a target="_blank" rel="noopener" href="https://web.stanford.edu/~jurafsky/slp3/">“Speech and Language Processing”, Dan Jurafsky and James H. Martin</a></li>
<li>We would like to thank Melanie Tosik for her help and inspiration</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/ML-Interview-Computer-Vision/2020/05/29/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/ML-Interview-Computer-Vision/2020/05/29/" class="post-title-link" itemprop="url">ML-Interview-Computer-Vision</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-05-29 07:41:05 / Modified: 12:43:09" itemprop="dateCreated datePublished" datetime="2020-05-29T07:41:05+08:00">2020-05-29</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/" itemprop="url" rel="index"><span itemprop="name">Interview</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/ML-Interview-Computer-Vision/2020/05/29/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/ML-Interview-Computer-Vision/2020/05/29/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>FCN, Unet, Mask R-CNN, YOLO</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/ML-Interview-Computer-Vision/2020/05/29/">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/ML-Interview-Natural-Language-Processing/2020/05/28/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/ML-Interview-Natural-Language-Processing/2020/05/28/" class="post-title-link" itemprop="url">ML-Interview-Natural-Language-Processing</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-28 15:14:07" itemprop="dateCreated datePublished" datetime="2020-05-28T15:14:07+08:00">2020-05-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-29 06:50:59" itemprop="dateModified" datetime="2020-05-29T06:50:59+08:00">2020-05-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/" itemprop="url" rel="index"><span itemprop="name">Interview</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/ML-Interview-Natural-Language-Processing/2020/05/28/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/ML-Interview-Natural-Language-Processing/2020/05/28/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Natural language processing</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/ML-Interview-Natural-Language-Processing/2020/05/28/">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/ML-Interview-Ensemble/2020/05/28/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/ML-Interview-Ensemble/2020/05/28/" class="post-title-link" itemprop="url">ML-Interview-Ensemble</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-28 10:07:46" itemprop="dateCreated datePublished" datetime="2020-05-28T10:07:46+08:00">2020-05-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-29 06:45:39" itemprop="dateModified" datetime="2020-05-29T06:45:39+08:00">2020-05-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/" itemprop="url" rel="index"><span itemprop="name">Interview</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/ML-Interview-Ensemble/2020/05/28/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/ML-Interview-Ensemble/2020/05/28/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>集成学习,Bagging,Boosting, Bias,Variance</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/ML-Interview-Ensemble/2020/05/28/">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/ML-Interview-Deep-Learning/2020/05/27/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/ML-Interview-Deep-Learning/2020/05/27/" class="post-title-link" itemprop="url">ML-Interview-Deep-Learning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-27 17:46:36" itemprop="dateCreated datePublished" datetime="2020-05-27T17:46:36+08:00">2020-05-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-29 07:09:19" itemprop="dateModified" datetime="2020-05-29T07:09:19+08:00">2020-05-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/" itemprop="url" rel="index"><span itemprop="name">Interview</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/ML-Interview-Deep-Learning/2020/05/27/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/ML-Interview-Deep-Learning/2020/05/27/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>MLP, 神经网络训练技巧, CNN, RNN, Seq2Seq</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/ML-Interview-Deep-Learning/2020/05/27/">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/ML-Interview-Optimization/2020/05/27/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/ML-Interview-Optimization/2020/05/27/" class="post-title-link" itemprop="url">ML-Interview-Optimization</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-27 07:19:28" itemprop="dateCreated datePublished" datetime="2020-05-27T07:19:28+08:00">2020-05-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-29 07:04:38" itemprop="dateModified" datetime="2020-05-29T07:04:38+08:00">2020-05-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/" itemprop="url" rel="index"><span itemprop="name">Interview</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/ML-Interview-Optimization/2020/05/27/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/ML-Interview-Optimization/2020/05/27/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>损失函数，优化算法</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/ML-Interview-Optimization/2020/05/27/">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/ML-Interview-Unsupervised-Learning/2020/05/26/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/ML-Interview-Unsupervised-Learning/2020/05/26/" class="post-title-link" itemprop="url">ML-Interview-Unsupervised-Learning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-26 09:14:23" itemprop="dateCreated datePublished" datetime="2020-05-26T09:14:23+08:00">2020-05-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-29 06:49:19" itemprop="dateModified" datetime="2020-05-29T06:49:19+08:00">2020-05-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/" itemprop="url" rel="index"><span itemprop="name">Interview</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/ML-Interview-Unsupervised-Learning/2020/05/26/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/ML-Interview-Unsupervised-Learning/2020/05/26/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>无监督学习，K-Means，DBSCANS，Birch，GMM</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/ML-Interview-Unsupervised-Learning/2020/05/26/">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/ML-Interview-Decomposition/2020/05/26/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/ML-Interview-Decomposition/2020/05/26/" class="post-title-link" itemprop="url">ML-Interview-Decomposition</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-26 06:56:23" itemprop="dateCreated datePublished" datetime="2020-05-26T06:56:23+08:00">2020-05-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-29 06:52:58" itemprop="dateModified" datetime="2020-05-29T06:52:58+08:00">2020-05-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/" itemprop="url" rel="index"><span itemprop="name">Interview</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/ML-Interview-Decomposition/2020/05/26/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/ML-Interview-Decomposition/2020/05/26/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Decomposition, PCA,LDA</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/ML-Interview-Decomposition/2020/05/26/">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/ML-Interview-Classicial-Algorithms/2020/05/25/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/ML-Interview-Classicial-Algorithms/2020/05/25/" class="post-title-link" itemprop="url">ML-Interview-Classicial-Algorithms</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-25 08:28:33" itemprop="dateCreated datePublished" datetime="2020-05-25T08:28:33+08:00">2020-05-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-29 06:48:42" itemprop="dateModified" datetime="2020-05-29T06:48:42+08:00">2020-05-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/" itemprop="url" rel="index"><span itemprop="name">Interview</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Interview/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/ML-Interview-Classicial-Algorithms/2020/05/25/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/ML-Interview-Classicial-Algorithms/2020/05/25/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>SVM, Logistic Regression, Decision Tree</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/ML-Interview-Classicial-Algorithms/2020/05/25/">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/27/">27</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ruochi Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">266</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zhangruochi" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zhangruochi" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zrc720@gmail.com" title="E-Mail → mailto:zrc720@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.healthinformaticslab.org/" title="http:&#x2F;&#x2F;www.healthinformaticslab.org" rel="noopener" target="_blank">HILab</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.shihaizhou.com/" title="http:&#x2F;&#x2F;www.shihaizhou.com" rel="noopener" target="_blank">Rose</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/cherish_CX/" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;cherish_CX&#x2F;" rel="noopener" target="_blank">Chunxia</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ruochi Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '[object Object]';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'qW3MLcAgcX96sB6qbegeL7rP-gzGzoHsz',
      appKey     : 'GL6JvT9DgGxqYrY5Vj6bXVuv',
      placeholder: "Thank you for your reply",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
